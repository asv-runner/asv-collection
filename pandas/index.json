{"project": "pandas", "project_url": "https://pandas.pydata.org/", "show_commit_url": "https://github.com/pandas-dev/pandas/commit/", "hash_length": 8, "revision_to_hash": {"288": "4906ee79d730f77be02ec586ec7f66c95a0433da", "862": "9e406c50b77949433ed8f7fd094fd30b5421a35e", "874": "645d61131ad5acf768fff906a25e9e34b53efb92", "926": "cdc607c8ebd05419c0c446298a89814eac817459", "933": "ba1ff88c95b081741eb28c8630aaa6b0423900e0", "981": "35c6b68facf00788e9092d1fcedd53acbf99be89", "1029": "a8b14798fe18050e486845b26370d4899f46a8b3", "1084": "a0aa6a96d8a2456523d9f407d3f9f936f24dd7c8", "1185": "8f79f7c6e01874bbf7f3b9bc38af01551c90121e", "1194": "da3e95da95e1e07acc535b8e734b9b80a0972609", "1342": "010a620da89e5babc137b924dd1f632b4f6e6fee", "1440": "d5fbdcc26520d1c92b5dd73bb6e9a9902756ad16", "1632": "2ca93a17ed4609960f0ee3b8704b8b2edca1db5b", "1812": "06f608182ecd516abcd140531c65e07b30293eb0", "2072": "13f5db0ac0ba5a30d64866cdbd02b9985efa6303", "2077": "abc59ab02622560f226dd32bd068857053bc96d0", "2196": "776d80c2145ce4a4df1cf5c9ad21140b09df671d", "2247": "483ca398bd20ae42dd1a9d12f972634b384d560b", "2358": "4117b4fde3ffbc74a48b01f3a28f1f76b2db05fd", "2539": "9d0949396a8533d9fb9b0a6d0fb90a9f0ac16b23", "2555": "dfd7447e47562a941bb355af51c475823520f9e3", "3074": "5b98fdfeae2ef42d78242c4cca1e0959b9c710db", "3262": "fde270b20861fbf36d3063d504fb299d0b58695b", "3266": "a1d768829015796d16486cbc1e99020348901e25", "3344": "1c08383fc3cf24d503ae221c5d31b93899da6473", "3360": "5f5df2aa34f027d3fc83abb19cf7840ababd4557", "3361": "5d90f7d0e7e9bb53e55fdb7b70f972aa502004ed", "3393": "c91f6d1f62d02a65af78651f61f8db9a62c58b1b", "3412": "a901af2cdfe411d6aa9f9b1f6fa3223738f3e514", "3418": "f5a1bc9cda068f724d2de2ddc0da8ac2c518095b", "3494": "1c24700c3ba74419988e74319fd46e1f937c1f4d", "3551": "4e95b311bbf320d7b88edd6f8ce17194e48b8145", "3557": "23fa6f8b3d1f823dbafb64dc52e5a96fefe9236c", "3912": "e1b6e44bed02f47f59bf2d71c836f42f6e130dea", "3955": "6d9bd5a6374f1d6b4c18d3d53fc0413c82a16b49", "4026": "b5956fdc123b0208cf36fafc1b80a9671c66efbb", "4249": "2d576ee9b9337210a8c85f11e48177db42ecd57f", "4289": "9867f8af6e20cd2248626548f9b3f9a66b57789c", "4723": "78ce0ce8baef9c66bbee77083c0d12a47d5e294f", "4816": "1751bae723d336904bca81945097b3b700b11801", "5022": "31ecaa9d06f71b5d652d15441cf6b2dcc6f7e640", "5767": "258c7e3c5ec5dca7bec32308925b94267fbcff61", "5863": "f9eea308611152f1f7bb89981380fa5d85685f48", "6664": "b96ab6bddd5f2e84bd88a0659c4d98154819cffc", "6794": "8c0a34f15f8a87def3f7ad6ebdac052de44669f2", "7983": "16052e501adc3dedec3bf8cf65a7ea24300de1b1", "8139": "a5410ed841759badae2c3fe4cc71335c9dd6ad92", "8234": "db18d443dc0eac6454b864e179579619493899dc", "8327": "48c005ea761adcaf6b76a84aa94da0d35db8c6d6", "8680": "d10a658673b7d2c2e7a346461c9a4bfc5233d7e1", "9617": "76f6cf0050025ec5a6187e17957ea9a158cc2d56", "9713": "da0f7ae362bb0ee747c3c5c141327d1d8ba161bc", "10140": "d839555f5e080a981ce5faf89b4df7dfe0924541", "10501": "12248ffc942acf3a224922495102462c6999c804", "10793": "8dfbe09c1443334fc3036465712195a36c773f4b", "10853": "017adeaa4b70d63fe6c788db457dc9d31562f4d6", "10956": "d8ab3415373ea42713c096a97c3d9ed5c9cb82ee", "11042": "f1b270fcf5d505eebe4bf964f0541d6a43c3560e", "11188": "18ea1d856d45c87fe18a41d1a267ede46e10880e", "11528": "9e859f40c1651b38f9528aaccd211b1706cf317e", "11564": "c91bdbadfdbf9f60879ead8dd86bd1e72ca18ccf", "11906": "ca9eefc3c4733f368c054e33537ff18384114b43", "12077": "06832891870119984c6a5404bc7f7a471f43b99c", "12091": "6b1055c765c488e6fb411eed452abf75ff8df4bb", "12722": "9687145e06aed545c14630460d24a9693c9a0b39", "12860": "071cffd63e4b99362c68a5e2d472b629618c50a1", "12889": "fe48704835323c140846d1bde5e1387aa0cac3d4", "13158": "6c30cbecf8e5ae610f2a37ba821116bd9f77044d", "13524": "9259a56c600f6ea247a9c58c00af017790fe5e21", "13615": "e5ed87b33ab6cd9dade10df945bc5d7452310b7d", "13626": "e462ece64b7cb12fe7cad6e085f62f3bfe9785c6", "13836": "87b0f4dc1e91571cc4dd933b7cb181b99606ad20", "14282": "497a3bcbf6a1f97a9596278f78b9883b50a4c66f", "14330": "b97dbd01e49f54ae6fa8df382d6f6e4c771d2bc0", "14435": "27b783986230a3d044d045604b72a51acd13b7be", "14706": "825876ca7ee8ac7bea463925399c083d5f190b3e", "15300": "19fc8dac68e088126ffd132dc322dbf8a163ec69", "15357": "2002da33b0a755fcf7ef64b2c87ca4252f0e7df0", "15365": "a31c96d34d00dc757908b564dc93991e867d83e2", "15371": "e346c663cf76186c22f4d3b703461b1b60db280f", "15372": "e5134306bd47db9f6d0f125d2cafd0b8a789e065", "15574": "2814061730893bc8122caa4e01197c699da352e6", "15686": "3a7f956c30528736beaae5784f509a76d892e229", "16095": "c277cd76416d4e930b1f05da873b9eaf101139da", "16141": "81372093f1fdc0c07e4b45ba0f47b0360fabd405", "16142": "fc1e50733ea4c372f4c9eb3a53bf35e102d5d215", "16592": "7bb204a05fee20c3c825e7da39ccaf39fbeb8ca5", "16694": "fae79204e2b60ac1ff2b2309352ffb5d9382a017", "16721": "a00154dcfe5057cb3fd86653172e74b6893e337d", "17530": "44ccca1f3c27795322b979cf6e5dbd49422b5173", "17532": "b02c69ac7309ccf63a17471b25475bf0c0ebe3c3", "17589": "3147a86e1b20571766b488a8444c74cef29729ad", "17590": "2eb5a67999552d60f7a2a9e1922549d5417d714f", "17746": "1a23779f09abc6ebf908d66ee88b973b767e2e3c", "17916": "9b0f560a73d11b2fa72c48d7fd16126b5137f349", "17943": "edb71fda022c6a155717e7a25679040ee0476639", "18118": "0409521665bd436a10aea7e06336066bf07ff057", "19274": "fdc4db25a9988a7b595a3756760d05a6c177123d", "19354": "83eb2428ceb6257042173582f3f436c2c887aa69", "19355": "0c4113fa0906273007cc12a4bcadff85d943dc84", "19436": "1700680381bdbfbc1abe9774f96881801b24d6ca", "19671": "cb00deb94500205fcb27a33cc1d0df79a9727f8b", "20330": "2efb60717bda9fc64344c5f6647d58564930808e", "20423": "d1accd032b648c9affd6dce1f81feb9c99422483", "20424": "d48306e77c0a708e0ee33a2aa1da7e267df52ef6", "20697": "171c71611886aab8549a8620c5b0071a129ad685", "21096": "0efc71b53f019c6c5a8da7a38e08646ca75c17d9", "21232": "62a87bf4a2af02a8d3bc271ad26e5994292b8e6a", "22237": "d3f08566a80239a18a813ebda9a2ebb0368b1dc5", "22238": "b7fcb545a1a298817cd7d9f8940f19992d1202d2", "22538": "fd9ceb9dce3d62d8a9caa6ba7c127b512939452e", "22700": "29d6b0232aab9576afa896ff5bab0b994760495a", "23185": "7485dbe6fcdab3fe2e5a23534ba00767d50374d8", "23272": "3adf3340453d6704d4a2cb47058214cc697a7d29", "24131": "1ce1c3c1ef9894bf1ba79805f37514291f52a9da", "24338": "b687cd4d9e520666a956a60849568a98dd00c672", "24593": "bfac13628394ac7317bb94833319bd6bf87603af", "24603": "d9fff2792bf16178d4e450fe7384244e50635733", "24604": "d1b1faa3f68dad6163000784c34a66b8f6c227e1", "24770": "f2ca0a2665b2d169c97de87b8e778dbed86aea07", "24989": "2a7d3326dee660824a8433ffd01065f8ac37f7d6", "25339": "db08276bc116c438d3fdee492026f8223584c477", "25725": "67a3d4241ab84419856b84fc3ebc9abcbe66c6b3", "26258": "b5958ee1999e9aead1938c0bba2b674378807b3d", "26276": "7688d3cfebb7227c978cb386145c0d4924209efc", "26277": "0f587028e42d5444e2f0edbc0b4c889af16eae26", "26509": "3e89b4c4b1580aa890023fc550774e63d499da25", "26847": "9d598a5e1eee26df95b3910e3f2934890d062caa", "27078": "7d32926db8f7541c356066dcadabf854487738de", "27326": "f2c8480af2f25efdbd803218b9d87980f416563e", "27737": "2cb96529396d93b46abab7bbc73a208e708c642e", "28350": "3765b2099e6e2cb4d180edbb354045ae09a40269", "28351": "cff206be208c61146c0aead51ffacb5a15b4e31d", "28359": "2dd9e9ba9009a40191c0c0b96262fa3939d609f0", "28492": "7c48ff4409c622c582c56a5702373f726de08e96", "28584": "f00ed8f47020034e752baf0250483053340971b0", "28769": "c7f7443c1bad8262358114d5e88cd9c8a308e8aa", "28954": "5f648bf1706dd75a9ca0d29f26eadfbb595fe52b", "29206": "73c68257545b5f8530b7044f56647bd2db92e2ba", "29489": "945c9ed766a61c7d2c0a7cbb251b6edebf9cb7d5", "29970": "66e3805b8cabe977f40c05259cc3fcf7ead5687d", "30182": "d023ba755322e09b95fd954bbdc43f5be224688e", "30183": "7a4a85a0f76c81f8d03d5603baf626a9a068a655", "30391": "bb1f651536508cdfef8550f93ace7849b00046ee", "30639": "06d230151e6f18fdb8139d09abf539867a8cd481", "30963": "4bfe3d07b4858144c219b9346329027024102ab6", "31386": "e8093ba372f9adfe79439d90fe74b0b5b6dea9d6", "31689": "e754faebe0818f87ecad04894299aec7372f338a", "31690": "315bcd05f2319c0311e6495d2cc9afa39d53d0a3", "31691": "e0cadc567013beefea0db87f038bb665b8f68cd4", "31692": "d9e2fb5e4be0b0dea5725bfdf86675e803b46ae1", "31693": "06dd5dab93ff4a55377309c0315aa767fdf9937e", "31694": "c70f9b9b57094674df9b5682ff2d0073363bdd22", "31695": "152c4dac7420bff9708b02d7c7f9d3428ec464f6", "31696": "50c2af1a6322375359a8bacfd79056ca4ab02df2", "31697": "8b72297c8799725e98cb2c6aee664325b752194f", "31703": "9dfbd9f45d9afb6975884f6a55e246f423519b9f", "31704": "c7b470c3e13f99ce990e23b2a311d3a2c633499c", "31705": "9f81aa65a416510b0ad7cb1d473600f261169813", "31706": "e5bfbdc239ee4c55dd3d731a7119d0cf191ebb5f", "31707": "aa9a1b3c5f0d56dacfa9e2ebfb99683827bf7f2e", "31712": "89d024e788f3687fe2b2f4d3a50675503f792971", "31713": "57edc45ef1cb91cf000164b7e12acf8f745c7a69", "31714": "d906b3316380d376ed765eed980a77ed514d1cc9", "31715": "3512e2408429ed0f058480e5df4d54e0f9bdc25c", "31716": "a6aaeb6baf679fe133e968e0f65199fc56d177b2", "31717": "5ad44e71a12ea2c77449a229b86cc1a31b33f2f6", "31718": "9de1f0b32de55ec6d892cea31449cfaf1996ccbe", "31719": "e94faa23e24c0abf9db74d79cfebe06676577867", "31720": "b3f8ab4f645ba8e1f609f4d48577d76c4b522974", "31721": "655d9f4fe7d9fed1aea7baaa0886be6017e08878", "31727": "157a65ed58f333f9d0a5b03cb7ded740359c7c4f", "31728": "c19a4ad6e15ea37af0eec40aeed2d961e7f8bfec", "31729": "065b51c1a17c6ee472af0273c0a16dfc55e26fb5", "31748": "7b7beb903b1d1d80ea5c2dd434bfbeacb3c2fbd7", "31749": "5cbbc2c0afc74b57d5d6d0774ac71eb55d5bc19f", "31750": "cf88cc14787bd4d1c769e269ec5f0469b2eea820", "31751": "30efa5fbda46b1d71779cb7f7ce0e5b81fa5474f", "31752": "ae47909f030f1ff900888a64b8d12d81a763e14d", "31754": "221f6362bc25833da87f00015d4d5418ee316eff", "31759": "901b02f67c426872d75b5ba3e2eb5e42732a6c67", "31760": "af146315a5df2d821c54df137495013064edd061", "31761": "e65a30e3ebdb7572a943d097882c241789569669", "31764": "2856ce13aa19ec07d2f6c9165b6f18f0146a3dd5", "31765": "606dd3c40ce48dbf5616901b0d179e4aea7e6e55", "31775": "3b901a4143d2263bbc7fc5076f040eb70166ff92", "31776": "224458ee25d92ccdf289d1ae2741d178df4f323e", "31777": "573e7eaffd801ee5bd1f7685697b51eef5b8ed85", "31778": "0402367c8342564538999a559e057e6af074e5e4", "31779": "378fcefcb203907ba651b9ebd570982ffe020bc8", "31782": "1f41ff07d1f86113c1e7c128ee612dca8bd65ac8", "31783": "2e9619368c7aec7bee20471c6eec368c27d055bb", "31785": "6df6691438dde3aa9c6fdfa359d39b730e29e331", "31789": "a294a15f95b96c4bb43a2b79f43661d6e841d869", "31790": "b01bd9004951330a86d917547c96c8d3d3228730", "31791": "ed03e396ea33dedc1b61868a07d34dd367a79518", "31794": "e0cf2645095a5164ea7a7b143097bf0051f11481", "31795": "a203a307da58819c9e0e994867a5a0dc4ddad7b3", "31802": "64e7859deb5656cf5c6aab2742ad8cbaf831e0c8", "31803": "1b2cc268e485158ca57d1630f558107b2bca725f", "31804": "c08c925b7b35ff1deb9013305236cbf5c735f73a", "31805": "e97b0824097182a735995f67dfd42b4484eb62a1", "31806": "9757d1f93faaa517161fd719e884be7344c18b62", "31807": "03d8cd27d5aa18a06a67e8aefe2fa8a49f557292", "31808": "b8dcd27b74ed09130e283a557bb85ee0eafefead", "31809": "7650e4e66dfc3d441df790cb4662348d30bbb7ad", "31810": "8955276b7079e85251b1b89962cc531fae0c5b80", "31811": "87e59820865e1da2f39109c41925ed9cc9583e79", "31812": "6559eda304d9a8b23e52043c6b540b0302d9ca20", "31814": "707039adf0aefcb32f4f2b4db14c528773d6b605", "31817": "642bd3de5461f4083649281c9deda432e229fd86", "31818": "1843cf23c7aa74248d956ae28a30abfc2c0af8e8", "31823": "b1e6c1fd108a2be6a64973eb66e9da7cab006f94", "31824": "654c4c05447897cb0678d5cc189a89fa4071e382", "31827": "3a3ed661c0a62b97f6fffc05bbf1fe6769b908cc", "31828": "f0814bcca41a116794ff926b571ec6c2d15685d7", "31829": "ca60aab7340d9989d9428e11a51467658190bb6b", "31833": "3f9c04275e87e806dc8f5082aa3f3fc987c41a51", "31834": "baf1d2c80f41c51454a07917a28e6d0535880a0a", "31835": "e7414aa17f67d05b6ae5a7a66881178936c8b2ac", "31836": "b3e8bbe4e5af934b3103b533de9349291e4caf4b", "31837": "bfdb524f5807892adde0e5d3d754351459cd1614", "31838": "d0268e719f899789f9606beb4592a17d27086b4c", "31839": "6165b6495f364155b221e5f8099acbd729b49a17", "31840": "96ad686a0f5eba9524b6b2e672af9c4600ec4e7e", "31841": "126f48784042e84f26ce41c827354d2a258b69eb", "31843": "10855f6b55dfb05b1e9a0186b8203bcf4bea7df6", "31845": "ddc52f203c3f1e6a8e1738da34225dfd56375591", "31846": "b1c3da6ca3b2e32b4c463a418eb62298252d31e4", "31847": "ee1c4c15de86dcb075af3bae07d5d647ace1e6c7", "31848": "003f1253dddff5b4bf1fcbcd74c66904a0ba0b04", "31849": "a1e49873ca61286deaf7b81548ec95ed7fc53561", "31850": "298dac384f92726b6da9a6319695cb0269e6eeb8", "31853": "82c39f008f2724f30439583454d8a070b4cec72c", "31854": "d8ddfcac96c1acd8792d81bc522dc57b8da5d1bb", "31855": "fee9b5d3a459eaf24398ec7cf2717e935af5549a", "31856": "854987f2deaa39effababc6e8f2cfc5c5534f6cc", "31857": "9c509e2812dbb27735288095f3305a08722594bc", "31859": "f0fff8cfbf76fca9e228dafa882e3a51339161b0", "31860": "a72340acee1f9a613a304f639e75b255181bf42d", "31861": "64c8a05a3c1a9aac3ffb78884fe3a00fe9f8ea08", "31862": "4b645ae5a0c77aff7828515de02ea567e52ed1cb", "31863": "ddf2541df866e89150210d41c22e45eb2cf83e91", "31864": "fa211d47604f5de7667440a842f7fbbb463de31d", "31866": "480d6be456ee3813b9ac1a14daa8c07672b99730", "31867": "6787b8b73f4c54a0cf742a90433e6fb6c7edb231", "31868": "2d8d31355f10da9d90d7db1c59dc4b9793910cf6", "31869": "82ce975b16195b66ce2bdb00b9040d843412cc33", "31870": "a9138a974fe7464c84a7110488555faa563b8385", "31875": "d1d9b7f8d61e22fb62ba40611d8d02c1fba49568", "31876": "6f8ab49ce31245f2c935d7c0364bc81753ed7105", "31877": "1196bb0ccdd48612d31067c6932b3ce8afb45169", "31878": "edf0fce742bf9443e38c035deffa10f6a18591bd", "31879": "50c119dce9005cb3e49c0cfb89f396aeecab94f1", "31882": "58c124feb4dffe46a73a43fbe995421ea361dfee", "31885": "ce143a2fb0a41e78c85d5311d0e159552d651b00", "31886": "b8ae9bbab3c3384ad90e6145fda13a338767ea21", "31887": "6dc589b957e494750351e8572b45b8fa12c27d01", "31888": "7ee5d600d84ab42c3e8ae0ce1c747ca1bc3b863d", "31889": "266dbd5c5efc5770f0fd1785415237ee1cb2437b", "31890": "78a5f7193cfc05640f83818cff0ee586a61ff3be", "31892": "0b1d400080508d205bcbb9050ea7e83be493fd98", "31896": "28331e0cc7aa0729968565bbd1278b3b6239c823", "31898": "c30456f9e465edb4bfc66a44eaee7a781ae0037f", "31899": "ae6dc976d334e791b3e215cf6e63a267675cccbe", "31900": "54347fe684e0f7844bf407b1fb958a5269646825", "31902": "f3b4490c3aa0f0ea55603dd139078fcbe5e7b42f", "31903": "5bcf4d532bbd40337e5fc4ad0f126266caf1e01a", "31904": "047c11d7801ffd0cf679d606293af510e34d7b92", "31908": "1b2646a7b6e728b51bce04a2263f3f3dec00938a", "31911": "8fef0185fea9d5a4da71fd92a7074f92b02df87e", "31912": "769c2422fcaf9f5888e77be9d580a755d6decb07", "31913": "cc920b4ff17d7903aa565bf57a1b2a20658fce3c", "31914": "4aaef2d507addb7ccdec3dd0e439e3e102bc6496", "31915": "191557db8e6de0772d8df987a630dc397928bcd6", "31917": "4e72340d9161c0f89c2e9d96253f75d7b7991cae", "31918": "7b89f3e41fac8d5f6dd2d898d6ed8728cae85a3a", "31919": "fe9e5d023e20304ad1bdfa1da53f3af452c72a00", "31921": "28bf7f28300adf592f24634a50f39d18342bd587", "31922": "122cd0745657687efe04cefe9471938cf0609f3a", "31923": "bed6b613bb81be208ae66fb00b992852659f345a", "31930": "9f9d80ff115d0d6fc2afd9ada83ddbb24eeeaa16", "31931": "ef32d4cf7ba8daaffdaf9a972230321963460907", "31933": "12dce19a74b7cd5badad0f61ca079b873c1b6089", "31934": "8f21b977a4b346aa92f61e40402776a2704e6f78", "31935": "94044c85326250717819bb33fb52848b1191af82", "31936": "5514aa3713b66f531f3abfc9cfe726a1dac638ff", "31937": "3e1d1752bf36b7988693d5817153a07e3a01933e", "31938": "86967da0ad0af2cc6bf4d6ea150bc98ee43950df", "31939": "6b396cf85d5cf390935e82789b09b5d197492274", "31940": "68d6b475283264f198fbe6449ea054f1350bd770", "31942": "aea824f9aa9d86bb9f25c9b3db6f7a585025fc22", "31944": "65af4ef2043a5f879dc42e009de1323fdcea225b", "31946": "f79ee8a7d7611e755b3f9fc11f4d7ae497e1a8ac", "31947": "2b2720aae01c416f8ebdbcca5a46cc938581f751", "31948": "23603171fab52bff4521888f05b68cbf520e687a", "31949": "6e853d6dd0c0cf74528fb89faf1da5bac294b629", "31950": "5e2e92ef3cf1caa56d8a1a5961f58f2dfe180d82", "31952": "4fb83b00137256e4ab0c4f2a7bd33cc2bdc5cd91", "31953": "a551f1b7b0aeace5d3c6a1c629dce5442fcee85b", "31954": "5f5a38261cd1a74898258eddd8553174f76eb748", "31957": "752fda842f90b98c6c9be8c0267a412c6a63b99e", "31958": "faa81145cd80e73a2db4965511d9ecbeb427bc70", "31960": "c01532ed75ca5cab3a8017d1a555866bbdab477d", "31961": "b99f0735bdb16d34a9acb01b1e0da70ebefdfd1d", "31964": "d5c0f57d39c27b139c765350b96e3f8e00b1aa1d", "31965": "e024cba59f8785b27596900d013086aea161ef08", "31966": "5d7b54b4d8179cd19361e187e283b873845217a8", "31967": "bbf17ea692e437cec908eae6759ffff8092fb42e", "31971": "ac648eeaf5c27ab957e8cd284eb7e49a45232f00", "31972": "b934b0e529fc245460fd81481eee97237fba9c04", "31973": "23056954673754a85fb50959b1701f0ed8111bba", "31974": "b5632fb310c26292ac37c64b6a514f50eff1d77d", "31978": "a712c5019dc0cfb58652ddcdf06361244f38ad9f", "31980": "85246fe460e93d2b891a1c116bcef3cb1a698664", "31982": "f088f6125da0ac296d64fe742cd1947b99846319", "31984": "64e042e6f988908c25a45ddf2760584618106b8d", "31985": "bf856a85a3b769821809ff456e288542af16310c", "31988": "87cfe4e38bafe7300a6003a1d18bd80f3f77c763", "31989": "2e151072345791eba2ce9982c7d67b6d5f1d8a32", "32001": "3038c6e8a1c7f8f016bafa037848fab2722d09e0", "32002": "81b5f1d390e1c57de833a56dc90afa7fd47f0b3f", "32003": "1273bc98f6af779af4779985c2faec66a3308026", "32004": "f19aeaf4976228ed936e9cc85b6f430ab72c1793", "32005": "5de24481d817339829911e61bd62170a8d0b2734", "32006": "c68a96f6994a1c4a3e684669b293b5ae37634f2c", "32008": "9ca7729118ab8c5227c8a2246a3606652bca754e", "32009": "9a607e2afa549a9295db09ad05df6572c1a85542", "32014": "7007ad8f39f1d1e8952d0b961b6c7d9f18840f27", "32015": "658b2b86f351ca5f03514ce82ea268b98f1cebc1", "32016": "3937fbe1106c5b30b9072243920a8521d36dc301", "32017": "744b846557540a86286f3bdc534a6a70639dd902", "32018": "73d15a7632e1b555defcc7942e5f629161626a4c", "32019": "e493323d93e6a3447f0adfded493b80a42f4fec4", "32020": "06e197830a625f132f54be8ef56c5358fb4d8d79", "32021": "c52ab6d8aafd49275dd325c9513f8288dbff5f5c", "32023": "e8a4ce2dd2de124fae5d51eb66d84e4c5816dc91", "32025": "fc8be37ceb05848e0fa11271606ba8ab7d58e96c", "32026": "9b5c5d169592a3921363a94ccb5de979c234d40e", "32027": "709f274245dc2f3fe2d91ad53a4cfa57f9d41d59", "32028": "71fc89cd515c3c19230fbab64e979118858b808a", "32030": "a375061d9518de447ef05b6490eeb264490a3952", "32031": "1c51e6004c09e6ccbbb8841dcb327ac0b5c9c80d", "32032": "aec51a1842c2281164e262bf0b158abab54bbf99", "32034": "6b9d0f7850f03a51a96d164e4a3e06aec2a2da39", "32035": "26d1cecbc9add6956220a4642b90b9ad8ad909bf", "32036": "36a67f6c99becaf8fd48678cd5733c54fd81c2f5", "32037": "cda0f6bee2a6520729247f92eef9f722ad2487ec", "32040": "7d852a9b15f92e57327f6e210157b67decda4fd3", "32041": "c2fade19bbf275f1fe5022f1c9ded387e52a3921", "32042": "9ad36f23a58b712c09a8a29c60b539ec50e65fcf", "32045": "2fbdd1eb4ef73a470f3db60cbf38a7d9f6c3ffe1", "32046": "04b338328d09000f428c902b71b3851bacd91038", "32047": "fc9b62aa75cf5a08174549419d2e83437cf0ed98", "32048": "12091609eb7c6a77d3921bc935f465d0c265aa34", "32049": "44a4f1619ff5031e59a970a61fac94c3745e4433", "32053": "6745e4463180e5808d87a48717728509efaff3bf", "32055": "576302378541230f63a0ad782ed8df399f488a00", "32057": "6b93a0c6687ad1362ec58715b1751912783be411", "32058": "e0608cb42e98f165fd99b595b2c9d0bfeb208b8f", "32059": "0eb6d33d7c27ea20f24744ecdae8238f650a37ad", "32060": "6c7507fb7d4b624b9710d7c6be6d4b74395c8094", "32061": "4baeede019754603c64f700821f43f35469e9a45", "32065": "3622f15b5056b8f038d3b7adeb82eecfe980beca", "32066": "e853e039f0191b1a0db6d30c7e7db826a150722a", "32067": "2dd2ee16af58ee52cabba7407073b5c7ecc8f51e", "32069": "2a6c6a2d131e49aa1b0272d5d5bef94c9810f67f", "32070": "b3552c54be2d49d52e6c0ae90db23ccb13bbfe0d", "32072": "49d4c075e015b5cec0c334554d9d980ae6bf0224", "32074": "43a54b5b9460ee4c768c1a9c792794925e6e0e37", "32077": "235d9009b571c21b353ab215e1e675b1924ae55c", "32078": "dd846e93a06740ce1ab536b92d70fdb7e0e213f0", "32079": "0e93cafb394131c64c4c4cc95c8c43967f09a0c2", "32080": "8b0ad717d1ec54dd40136817a326b41817ffcb86", "32082": "070e1fe860495e408c049155d1928f8f7b970408", "32084": "73c7dc9acb3af777aa25a9a463dec13af2b9e921", "32086": "07023aa0c3bdae40e38567789ae96a2a1727106e", "32087": "0dadc71dd4653e5b858d7b4153df1d7aded4ba46", "32088": "979c1c6d62efb01b7423a23e2a2fae5622f43b2d", "32089": "c68d053364e79df52a11425ec6dae454d37579e5", "32090": "d719840e5a2639babab3b4646b11a111547c518f", "32091": "336896907748389e2cd0d57504508475d425348e", "32092": "953921f2782062a67aa3886837fac563892d7ec6", "32093": "5c0ef1b5d84ce2619cc1a66965470c2448ae8a17", "32094": "80271b0b34dc280452367758bf7fe99ef1bda4eb", "32104": "5a9de8baca5f97811ad6579e3e569b8f385c7b08", "32105": "f1ed6def2ad4f0d347a8a877dfd5628e8bef871a", "32106": "0dfe909aa44c174aae13b1caf8fdb5b7a8997869", "32107": "5516d8fb996708d46050a8fdd8df3ac4a5b54826", "32108": "5e503b4bdb6c21a4813a210a1078bca9a251ff7b", "32112": "050b3b815604652bc445d2487f6e1fc83eaa8d1f", "32113": "9ec687ee0a00bb4022c2d7efba7d6913bd314c84", "32116": "58f3afc5dd8a071f5222fdb4a7149db64ae1caef", "32118": "1dee9344a4e9a3a00935d3b91587254b5fb0b4f0", "32119": "d76b9f2cd045ea0c6e32bedfeaea0410c569f56e", "32122": "dc796005742fcec18793415c6c81f171e7713d30", "32123": "b0237ed682fd226e6c76327e6524b54ea7ace9a3", "32124": "cfeed03306ec1e939c9dcde2cf953af666bb465b", "32125": "e43d75e7adc1bb7d5b72e5268b462be4499d0d49", "32126": "6e95d7ab11ca4d6c23d7dd0b7ca293e05d161259", "32127": "5344107b8c53d1f176717a257e4df9644364a7d5", "32128": "b116c10301cbf73f092f6784af5456d360862d48", "32129": "e6024c12f0061602b67f64adcaf8ab5cb77d5418", "32130": "fba672389b74ca4afece56040ae079a1f2b71544", "32131": "053305fbf19e57724d1b344c723190371a4fb74b", "32132": "00b5cc54e215b2cf828ae25033da79186451b9e8", "32133": "2ef8d147c51afa9dfb5d184c2407227cf9e661db", "32135": "9f9448073f49e6ae3ee3b8fbfcbe0b76d7f0b574", "32136": "39fc318920ce65cfd181b1f67595ce65abfdf199", "32137": "ca191f187d906d3c4474bcb41fa6443baa46e10d", "32138": "21ad93bd5f93ed45d06af437751406e021b66da2", "32139": "8c3c9e3bdc6e6870036428bd192c8fa92b93c295", "32140": "8bcc1ebb8babdfc95afe89219dabcaa98614caea", "32141": "ff9a1dcda9580f5b7a1480b67044e11374bf3187", "32142": "e25aa9d313dc372c70d826e3c57c65b6724190e5", "32144": "c855be85bdb08dfb8d503f9f1ce5daf6e037a59d", "32145": "d8e76517ee98f957d461309de26022acde5714d8", "32146": "98cb9a5b9341ba2b837f18e5fcac19dceb2e8e37", "32147": "bf9926519acdcc9e52845af1d10b9087d1673ba5", "32150": "0c3dd0643061a14e5576eb22174c810550e96333", "32151": "ca2d5ad6ad34ca2d3d9b82e89268b6a4f87fc68d", "32152": "855ed4ed1383fd5a571c39699404feb28d134f0b", "32153": "29f67d38c6292b7cd2994abaabd42d10ecb7d2f4", "32154": "f47d82baf2f69da84b808fa537b72c3aee5657e7", "32156": "c34da509497717308c97c4a211ad3ff9bab92d87", "32157": "814fd82beadf7155f8429c58c27425edd241922c", "32158": "32474d919eb4b048464e0250c1384d244f9909e7", "32159": "159a91754159545df743ff89fc51e83d5421993b", "32160": "b5d6ae32e5d0736cad4eb9be21330e74e3eca65f", "32161": "e4dd35fb10349f804bc51bafeec14ec3e33a10e6", "32162": "ee352b14cc5704245b7f05688edb1fc5991a8b70", "32163": "c0e6baf3e5cea44d105c0e9ebb3bafbc9fb5fd27", "32164": "c0c65371be1af0d5d5e480fdba6ae15071afe371", "32165": "3d6b36557582279a8a3bc45a49aa15c5cf44bdd9", "32167": "7f24bff9b599a822384e8640dba7481b00c61664", "32168": "295bc764b3850146f0cf041ae5867b68aee6639c", "32169": "9fb69e6359ee9b1fae0ca9d3a795574dcedfe3aa", "32170": "4ceb5d96ab8bf4721fffba5b8c02517ca02437d5", "32171": "5620f0e3dfcb4e9d612bc72ee7998188e34102c2", "32173": "77d4c3eee7c68700c3027e7e3b126b329f15d990", "32174": "ac05d29cf8cae186e96c83a03e2e80542ce2ad38", "32175": "55dc32437ea43a238975439ddb6c9dda81b33020", "32177": "5f0ac04bad108e037018ecd6577ad03091adf067", "32178": "464c10993c6ec76636a1335903f21baf8622c1e0", "32179": "712c2b197c3b3a7a68e9da3eac965525a9eb53d6", "32180": "f3f675c2f24346b547d6d01edcd9351dc1aaedad", "32181": "582377f7d8a68437e5b0af4e17743095262a9839", "32183": "fd8e3e773887c0ba9721406b3034494fff2c2567", "32184": "3f310c450d879cc4b85825e235616bf5076f0584", "32185": "cdb905a8b7e25433a3268951fc3ec68aa03914aa", "32186": "b48a73ff53a2c3414e38f5adf11f661dd7883cd1", "32187": "bfdf223133541da7e0002543e36bf71ba59af481", "32188": "bada58a00e873a66cdb3d23762ccc95216251643", "32189": "28da588f75e5ea094a2eba58b714b232b14230bb", "32190": "feea3261b2c95e8f555c8ed1eff8ac6395f16cdc", "32191": "c9fb01823bfc987581711bda8bf9625a8ed7fccf", "32192": "3ba6bccc3b13a1a5db1f4f737daccd94c685100c", "32194": "04db72145624ef8fb1405bf7dea6d9ae6bdbca9a", "32195": "8974a95ab30439a600639e94e38d219ecc7e89d3", "32196": "f2a91a0ed8c2f9198b39860c987a59cbdbcd9999", "32197": "060536de9f1e54bf6b41b7fa232cd5595eb171b5", "32198": "c6cf37af547d257eaf6a5f6e0766b1ce2112bbc4", "32199": "20bbd124170bc16f318c2040465c9b4528c242aa", "32200": "98323eec0e94ea103412a1a20a1e6b4c6fa0599b", "32201": "a97396b8e47620eab938a8e3d090535944b4fd04", "32202": "56d82a9bd654e91d14596e82e4d9c82215fa5bc8", "32203": "67d75f3715ed8bfb19edc6d99d16f39daba6e461", "32205": "834fe47d1f5488c2aae35e147a844b39413e93ff", "32206": "243a5e149b56ed197d650eef0f97887eb19c4eca", "32208": "c671f6ca3dba3f4e6f3077c00c1ff773d1ef7f45", "32210": "afbde4d71e36177c2dc3e3b24099b58481e13443", "32211": "51a869c14493c430d27d1a5d6f5ef4468bc02285", "32212": "7aa391ead0f8761219add833045f77a40a25effe", "32213": "0106c26529900bad0561efb9c9180f7f016365b0", "32215": "4b124de966496f7dfa73162cc597ac805be3a3d4", "32216": "e3d0126e8af9f0a23dd6609a23817f858825e089", "32218": "42a43e3b74665701abbbe31dc461ef38419274bf", "32219": "ac3e26fe7747da75dfcf4d5de1f41a018a3dbf72", "32220": "7751108ac5cb40e9dee257fcb88002663d7089a9", "32221": "b44520131aad12083863e483853c2aab24b6b2ac", "32222": "599f94f41f0847a478959d2b7df41df0280a980c", "32228": "a50ea1c6353b5f13c65e7dbaeee68aa7c542b49a", "32229": "7a910defc75ac8f8362bdfa5b547300a5a021b42", "32230": "a0156317ebb8d65027e6610dbb76558470b547d6", "32231": "cf0056d8f8936f7a4b930690ca10448b52516b5a", "32232": "fb19ddbf1f327d683bb4a42401cbb652cc149606", "32233": "90b4add77859d1349530fff3c8cadeef95f36f39", "32235": "6a52634efbf0d66aedd07991ef546dc9210dbc87", "32236": "4715d67eb6f7e30929f2d5c6c199c264c9e07b92", "32237": "1ef45fdf4e8b0d4349caf81da553122400bfe77c", "32238": "307c69a37b7f652450e2a3ba7578fdaa7b8d427d", "32239": "2f7dce4e6e5efcc8e4defd2edb5a0e7461469ab7", "32240": "822074bc5d4cca74cb2a26f0c476fe430e3d9400", "32241": "8608ac919fbad7fb656d6b9bc5ddf7f09ae7a430", "32243": "b07e31cfceed3df886f2674a6bb2df70bdce2dff", "32244": "7ebc3e809491cdec3ffe4dc8917ad9729f55b713", "32245": "9415ce2fa50232cb5104cd8db656bb83a218ee99", "32246": "523bf3414de1ad888669df8a53d423be719388f5", "32247": "856e1e2f3220ca51b2720592f9e233f48f3ad3e1", "32248": "e7e5df5167be28dfc00c900d24bb13c9827524d0", "32249": "0914e94584e6bd799088115797e03395994ddd1c", "32254": "f5a86fef41323a23e08f7452e7c2343f253bb19e", "32255": "48368ad6f9087e2e4e4c5236d5492a412ce9d826", "32256": "94e398730016f21ae3a6a6ea1a3d0bc6af0e7b62", "32257": "5a4339f686225ed5eadc5c4b7d2508c0765ef577", "32258": "4583a045e7123032dbf7856429ef411713a6937b", "32259": "4ba431f0b4e82319248663d9366c0fbfbd35ff1a", "32261": "a75ea75a0d4efaf273ac70b6269adbfa400d0844", "32262": "2e7f5a30abdfed4f34902ab1effee65e9fc48b4e", "32263": "91111fd99898d9dcaa6bf6bedb662db4108da6e6", "32264": "62e05f58b723d6d506574cc6752d33e494b77f61", "32265": "fbff58f5ef0450f5f5e7d2a4cdf14094d6a8f3d5", "32266": "eb2ff31a7e21efbcc1a0c6107ae45eedf56f3570", "32267": "4d41ccc2431f36a72c1701dd31be7139582baf71", "32268": "8b503a8ca06c6370fc3fbd972fc6b0a621df9531", "32269": "bbb1cdf13a1e9240b43d691aa0ec3ca1b37afee4", "32270": "75429df91ecafff0748816c414aea0a00eeb25b0", "32271": "b94f1a18d35ae516587ce9161eaaa5f9a16f505c", "32272": "145e527d717ada8d4648ac3d4b22a07d07143a31", "32273": "a17bd64a6ca0c4d71662d467536c49bde8df3d09", "32274": "a9acc52632219e09bdcd41fc6fe130da7c04e124", "32276": "91de4cca64a59f8905ed62aa5c40f428cf73e14a", "32277": "a04754e99f3203675847194304c12ee85c8cad69", "32281": "14b2b61b14b64bf3df98c5769581d92775366b79", "32282": "0ecd0ec25d77797674f1b41dee6075d6107b2a22", "32283": "c110f27decb686ae05f4ce0b5ca601ba76447531", "32284": "b4ff385bbbdaee684ee0d26b81a652aa1b2bc3de", "32285": "753ea2e53b4d3b23b8a9f43268c01132072e1c79", "32294": "8b75fda1bbfaaedae4df05acc6aef8a73443319d", "32297": "7a8d1654f04049ab20555c4fc2556c29082acd21", "32298": "61c671893219a5fea4bfa6756b065db8e66071af", "32299": "66ad6205574692ccf8189cc78d12eb2c426ba6b5", "32300": "890d09753492242bd30cc43c7ebd4e819ad89bf1", "32301": "1ceaee3333f427a97570eb87066ebba01448c770", "32302": "2be9661853f4e425e00e3a32d265fe889b242f44", "32303": "ca1b60715b69410897176ccac9e579a74c962be5", "32304": "93bd1a8ece37657e887808b1492d3715e25e8bd3", "32305": "4a2b06862c9e8aeab488098529eef69211ab00de", "32307": "0cf87d2ff2e686d24c376099cb6ef151812fc913", "32308": "84593e3749cd3411d022c065db1f2a9f2572f34e", "32315": "bb858daf707d5aa5f6371a2192c0151b9656041e", "32316": "ba5031e0131e13c6a0d34a5938c3fcc615179a5f", "32317": "0dce2853ee6395f37deb38ea532587386f294a8c", "32318": "c667fc41c1c8ab82ddc9df4a9c9735c5e748432a", "32319": "6c46013c549de053effc770faf210695f4312757", "32320": "edbac360fc97e639590fe6031aed165e7b8790af", "32321": "a19b98167ad5c68f36c1b0ef62c77cec996a5fa7", "32322": "d00928e80e7ed3fd40fec824f1c386670c51d4f0", "32323": "d0326528144600ad22e46816c54125e31559e446", "32324": "f11fac3b87335f5c80fdaaf81e4d549346225d9a", "32325": "5c51bc161db0f59dc3d02c738b7f381fd11152ca", "32326": "f8f9961527c7ea279351481cbbd8f3e068e65061", "32327": "3f4854f810b8a0ebf2c372c9e2bb7f20d7982c65", "32328": "a6e61fee393a612736b51af338cd738538694226", "32329": "886f841d0653020d418fe78dc4fd8e045e7448f1", "32330": "1294b193f0d00d53e160398803977287211ed180", "32339": "b44f1cd1a23463295b45cb6f8d5b9412e06f55fc", "32340": "57538192767547bd138020c9001a2fc6bb1ed004", "32341": "fd97a078531c8fc5c9e4fd2d5f49da5fa5ea16ad", "32342": "dbe0c10ce8d7d8682d13ca7fd46add489065ea9a", "32343": "0bd52be9f70209ec0bb5e04267ef3fdc3c955da3", "32344": "22e591f2d142b20ba294c40236954d377c7b22ed", "32345": "8427060d60d857f00c63b7de8672ae9f96e84bac", "32346": "8715d63141d093d48e67a7fecd44d8203b542331", "32347": "c368c320fcde19a6fb48a22ddaac4b7e19d41c4e", "32351": "6a1ae42bca296f8f1cf649e466dc8e11536a079f", "32352": "74c4cd1f25b81bb0e5afc70d063c785565fde7fd", "32353": "a7341b37a53f121262c07f373c4552b69673d25b", "32354": "0d95478c738afe96e78b66966edde490362ecf49", "32355": "bca35ff73f101b29106111703021fccc8781be7a", "32356": "eef20d32724e90d3a02b39798737f487913f1669", "32357": "62757c43ba506c62edeed300def524d6071dd79b", "32358": "5d9090b1a09dfae767dd41a4e8ba020cc9e07418", "32359": "c0b180014bcd6b51891057e4711b18351509ca3d", "32360": "1e5fee83f914db3775d931cbe289bcb2288531d0", "32369": "032316f631b4c29a3b1ddc266ea667dfa39aadcd", "32370": "7fddb30c82d70ef72fce6634bc26d1ab71312356", "32371": "2317bf08ed172048a66a0533645ebc1886939417", "32372": "9c9789c515f79d1a065ca6891464865d3cd16468", "32373": "2c775676b7f9facbd27fe6495599b7ef60f98c04", "32374": "201cac4c6a43496a31cb1156cad9bfea47eaeb60", "32375": "db1b45816d0871f75d90f9449757176573cbfec9", "32376": "b48735a6b025f99f4b03713e894003080df595bb", "32377": "05fb08ecca8850b71f659788183b48db9bc4e391", "32378": "bcb8346e8106be4267ec77dfc603d0d77a3fda81", "32379": "6b4fa02e10480c4ddae0714e36b7fe765fa42eac", "32380": "b74bf147f00dccda2165f0c36506ac946b2e6948", "32381": "30589f72a2c8cfbe4cd4e4d78161c18adca46212", "32382": "8564b701454c0cdd443b0a786f291e04b4f05359", "32383": "a393c98f0cc1f7985ed89229bfa107ebbc723157", "32384": "cb42e052416d0d0f33ff8ba9bdbaf8bfa383c15b", "32387": "0a5cb8f47712fec6009d0f0e3eaf5ef924b5fc57", "32388": "f1bb3b2a3ca65779baa732a86853227936b4404e", "32389": "1506ed559e14f7c8ddb24e623e27b07c97b2a197", "32390": "17e0e0642294acecef2d2909801758e1785bd701", "32391": "f9ff3796329e4bedb4a5477739f5eb8d2e40761d", "32392": "8ea52bb32a5a0956467b3532e6c2ac704c8b90e2", "32393": "ab6562a20bd894d02fb28675809698d5be0436f9", "32394": "8d615a34f2d462cb21714a0cc577849960fc83b7", "32395": "2c86d9f472f61226df429cb6f80495771aaa789d", "32396": "d97e7bed65b1389ad669f7b8d028f603e8760f2a", "32397": "7b393290f814e60a5fbecf4fce5e1ca2bd862201", "32398": "4b98e0b99ad3064463f9dc777e46d0b2f249e248", "32399": "3370c8179de16b3f0556891a1ff06131e186dfd1", "32400": "3872572512b4ea5af50618203331d9c7cc5d5fd8", "32401": "c45bc9a7b8b76324499ac52c957f3ee59c983342", "32402": "d2f376bc99cf1bad9308fbe0dcdf78df071bc55c", "32409": "278c69bca0b0480b9d33d6b9849106aad33daf3c", "32410": "cb57af0efaa87fe9198d0cf5ec3e0010140cd398", "32411": "ead5c756da231d971cde0627e88acb4b51588568", "32413": "60013a26634b581e34d967f76907de460b9adb93", "32414": "eb69d8943fdc2b551f083435a184b7899ad13548", "32415": "73483be93ffdd2d826e18e782dbed386cdb2d9c7", "32416": "46cb18c4a021f5058f9018aa9c3106cfc7914aa7", "32418": "c9fc7fc662a4f2d821f7f9abfa2cf5c1429a85f9", "32419": "eec47a1ebe57a31480125e2328b33f12be865d0b", "32420": "e6ce78dae8e1e60ed025c0700f501471378b972c", "32421": "76923d7b58d8f25329e779a40b87e2b6959f9cea", "32424": "6122c7de128fce3a84d91ef91b9dc3a914531745", "32431": "c0445543a10ae6c6abe5a3efc519fd9edcd2d276", "32433": "cb43a819d8e34f61ecb4121d154b1f9a9357eaea", "32434": "fb9b3451c4f70818604bd7afb7bbdd4c04d12667", "32435": "4e7ade7d3e50e2b04d2f9150b59cf6f2d1fefd6d", "32436": "a793802ca08ba159558e36db95f8242fb0f44156", "32449": "75d093dae92a68e6f979815ce131036055492d39", "32450": "53430f2299291ec7cd0c9b79bc68b2c9f3730598", "32451": "cdc8db6e0d3394e0aabbaf0740ab06e34bf67aa8", "32452": "e5961e2dcb9b8b84853c32ad4d1f6fb7d6f84454", "32453": "9820edc174730e11cb423d7869650c13100eb314", "32454": "6526e938a0405877e57a6bf57c36d7fc77449081", "32455": "7ccac683c074aaf5abaedd64f8aa5da4d9fe08ee", "32456": "e02133c6323ddfd886784d6a9d3a4e5c07c99557", "32457": "a215264d472e79c48433fa3a04fa492abc41e38d", "32466": "b77417832c76f0027723cad68ffd5654bbafe2a9", "32467": "aebd2293b9e80893f4bc6fbf5f870be5ae8c7ce0", "32468": "cedd1222e3b2ac60d1006bf09df4c8a4870773c5", "32469": "8188f6c1010fa80bbc15a152bc38e8d4eb50299a", "32470": "cf3043ec449137fca3619da5405590c15a87cccc", "32471": "d49eee36271ca3cd324384b7f8294e833b50ff14", "32472": "7b605f3033117826352e3770ec2bb1a25fcc418b", "32473": "f6204a57ef174d0058744dda1bfa3e6c67b5c639", "32474": "57d8d3a7cc2c4afc8746bf774b5062fa70c0f5fd", "32477": "28115430214ea6d520ab7b2d5243e86f3503c712", "32478": "586cc351b89cd299ecbf8f3ff0ab6dab1b799db0", "32479": "5a11eb5efc2390a3bcc80fb646496095c1da433d", "32480": "01b432c3537dd2fc910e682cd7c03370a67710c4", "32481": "cd38fa369d12e8390189f14fe7fcf6533998f5ce", "32484": "4d7d9217ba190c189f66c66149464dd493cd031b", "32485": "7e9ca6e8af2f97e62a69242d40159994ce1d6178", "32486": "6dc92ad0087984555f4204d2fe00384f5462837f", "32487": "081c06bfb0fc97a38ac1458d5b5154d8a9030e51", "32488": "16645fedb7d9895395488d4d90dc06bd47510057", "32489": "2a2daf787c5bf4015729f6660d189389d3d7dc47", "32490": "16baf871eebeaa604891893a395456c80293a092", "32491": "fa41c52c3dec0597a39910ade667084a16169b28", "32492": "f332143172c6345f28ea2a39f84a9bffef840ca6", "32493": "0b931173c842a3476646b627422cf943d15288f6", "32494": "a7da45d8335507f9a561a5d47e99c4b0de24b7e9", "32495": "85c2cb360741c87abbe4a2c39cb2999c929ab031", "32496": "1d8922e20b3384d56551646dfbae2f4c4e458da0", "32497": "f0d4694bf80fa9499880db34d5d3a13a8d073122", "32498": "72cb5498d7e92a28d1495365d5931d61c515f926", "32499": "ed1d1f9134185848795e78301ce6582df338e1b2", "32500": "9454e1210c57c0cb886a12913b0da349857b2564", "32507": "09b42d2afe679188d7b01ea8b65fe555f530bb87", "32508": "af4a11eb2066202bd79c1d42f96e02b0c184252a", "32509": "0aeac8ab2144f1687c2aa53caee091d78a8fb97a", "32510": "8b6b867f5a7b0a03f254516128c4055e5d234f8a", "32511": "ef23fc75b2adfffd0d82a75f6be8f87fb00a5892", "32512": "7bffe51982fbcaec4d72304ca2068428535ec418", "32513": "ca99c94ad9acaa894742f3d65eb5aea5b713c666", "32514": "bb7dd2c85dff62b7cce2262f6ba6c3ecb1013153", "32515": "67ce770ae4f7248df7384965e5b2cfdc350e3e5f", "32516": "d47e052379826ab6085e145e6ee2c654b0d1c471", "32518": "27138738a22edeaa644a3aff1a2cd98d1f954632", "32519": "25832bc479dd794c588938b5d650126f9d8d9bff", "32520": "5a36b5f5273f1c19fd0c9b6ca13d985a25316649", "32521": "4117f98592c1d1d671684c86e9a01bf48e1c2347", "32522": "d69e63d7b1e14b518a413fdff245e3329b92ceba", "32523": "e7a5c9295f5f3e81570cf2ce68c8071703cc12ef", "32524": "d56f6e2bca75f10bc490aa320c4e1bc295e367bd", "32528": "e8b43b612669e984cf9ba13abe257f068c00dc43", "32529": "7005f8c6f7683c1f022c20ae4143fbc1a37f44e2", "32530": "b8bcf50dc86a5ee2d60fc3b21b82ce9b1b919cf1", "32531": "60209e5d57b44a05044f942533e1c01c99445175", "32532": "61ba5f8ec1f5ce05a8c77a617fce3199e4f4b0ef", "32534": "8f869f3de0048d01fcf2f8198644fca72b926aa9", "32535": "b92267b2307c53b163f79239edb7c6c6e663cdf4", "32536": "b7ea7c6dfd100c40b0bc45aacf6d92c5c22f2e63", "32537": "f2f4d120307c179cd2e186ce54b7eab16d47facc", "32538": "f09d514cf0b09e65baf210a836de04e69b208cef", "32543": "f82b1c6329a1c2de20e453e6bae5fbe0beb69360", "32544": "9c059187893a6a45bf0d5430af5e4fe7f9a3ccb3", "32545": "72e923ed4d3bfd41b64dc763269f48fdf6727227", "32546": "f3c46cd0899d5e11e0602798d9390c90e51e9ba7", "32547": "f81f68720ed9d022c7f2416682d5485e609df9b6", "32549": "16a4a5fc5e20f5e4ff387a593e33df6b6b43662d", "32550": "9fefc8f7a92fe08583466c668e07585b4e421021", "32551": "6ba52161147f2543d6cd4194958b0071fec6d1dc", "32552": "e41b6d7827720df90a51ff05caa689333d7e02af", "32555": "a23eb834eca2c194d70d865e09bd2f57c51e5be8", "32556": "dbb2adc1f353d9b0835901c274cbe0d2f5a5664f", "32557": "9dbb7d747ddfb171d4c3591f24fc4b30288e4e98", "32558": "289f32df5a565848adbc0adc8949fa4066542316", "32560": "e634b345fdd8783ba86d57fa39ec699206fac66e", "32561": "f569301fef3d89d9041ba9a0375af0bb48b94beb", "32562": "6fac28d34e3fc19b97e922dc70faf81a84ad4cc0", "32563": "2f7b42dacd76f126310fc3c28d7bbba1ac4eebc2", "32564": "e7b044c558c7f763055b8ac1be359dcf787712bf", "32565": "2e55bff66d83b916152191935afcbe79a232f3f3", "32566": "9daf62f630a489a09e3f93e35c7d382271ed8fb6", "32567": "1f6e44a2354fa53b724eadb2c52ee84b02300500", "32568": "4dacf5661727a3738711f23df961abc9fa897148", "32569": "c7010a7adec1c47a4642fa068544699fc8e1ea6a", "32570": "b2b61af5c7b87bb5b0ceb31770165c9dc62a258a", "32571": "c96cd9b2a09c5a982d32d3563222402f10407fde", "32572": "97edd8e4ff89b4a3eedebd03bd718048fef339a3", "32573": "12ff4f4801cd60bf8351655abffe8a6c32f8c11f", "32574": "d3e84c5f9efccf439843138005ecee16ce532c17", "32575": "a9707295e87793b137965bb3a0707fc5701238dd", "32576": "86f182829d2cfe2f4c380d7f2ecd6ea27d6e0f1d", "32577": "7adc7d0e331bfa709b65c11f16009fe9c6f932f8", "32578": "b3db4b9844b9003fd7a8b5cf88c9fb82c1a8480d", "32579": "c60135c0749ada8508e315f1c04795d9c01a47dc", "32581": "6228771852092baa0ea05bb0c70f58aaed72afe4", "32582": "e3b0d4d74b1311f6a40ce1ae13c42cc7619178ab", "32584": "bf676a25e7d1170c467dfc2d0266ee08439e5364", "32590": "0a58c03f5dfe643a9ef7ad54bead679a82d2e63b", "32591": "ec5b62eff3d10e813d89750aca5e1778b86f11f2", "32592": "18aca9c0783035360893e8e8852cea04727981c1", "32593": "c04bba47d09f56101932d673db53a7ae37086132", "32594": "f6d3cb292e50e77e7cb624ea33167f943c5a2481", "32598": "96b57806a3779cb63287db5f0e4116020854092e", "32599": "25f89683495979828ec1407e5b5421c492407818", "32600": "b1f1f37e0fc78e80e9392929703cc6f527f3c308", "32601": "4a5d77f03bad3502a6504b03922807165881c630", "32602": "d2630d85d31d35f6d646c1ca10585631263c7d26", "32608": "cca262d35b881d327e26782da699c1fe405c1c24", "32609": "3d8cb79823bbf62a50245e9daccfa1e87c9396dd", "32610": "04c33d3b17e68602c77be0007df0665592a41151", "32611": "68e2c2ae8b714bc9bcbdf9e98793bb681048273a", "32612": "8020bf1b25ef50ae22f8c799df6982804a2bd543", "32613": "6b575b4644bd1808808ce0270413c6e75ff7427c", "32614": "c37dfc164ad880b89113326874a0578e81113b6c", "32615": "a45dcfd59bb33a4a506c55b899f15be1fe2ae752", "32616": "12aca3c80c10438e70f7b9a4eb254b54c77ee745", "32617": "fdb917f52b7063aa0488410b32cc5878fd395558", "32619": "4f3c3810003cf4c4e3700288adb24114ea99a77a", "32620": "a99c1ad4e53713322660c30733952fc9ef16dd2f", "32621": "d4e3963239a36fdba21825b37add4294771b0268", "32622": "b01cc53e82dcfb5022630c74f1581b0e2330f906", "32623": "606499dd4b054d107e3fadd0ab504d5b77898876", "32624": "42bb8fe60999db433d8f9e1d37117cd2011d291b", "32627": "cbade64f8dc66785aae75269a695c6132f0c37a0", "32629": "e660f2cf774c78d0d16b4af153b502a8abe49992", "32630": "a3c58cb275c017d0323a6fafd41f6449a43fcc57", "32631": "8f8b5b3b3f64bffc0a1096026cd45d3d79ae6668", "32632": "be79267e9b290221cb0adb6653f36c2ddef86327", "32634": "8dab54d6573f7186ff0c3b6364d5e4dd635ff3e7", "32636": "450f051a7934c908b7cef972a06a4a9f67b06317", "32637": "9ee33259e470bf32e58c5de1d771100cd54420a1", "32638": "025fbd05a1ae8973d5669bc1a3afac0b6bac602a", "32641": "6a5eb136c736b00a95535c97ee655d3596f9ac87", "32642": "7d7c818de14149d4b11f6a8448a3444ee521d2f7", "32643": "5e1b4b718d2a5eabf71d6371925e42d0f197e58f", "32644": "3e7cd5ea7ea5f26be0e4d88313b3cf812f7c8a35", "32645": "a6d3e13b3a3c0d2b902c6229a7261bc299f36a03", "32646": "22de537361af45a6b769eef8f3391f682b055110", "32647": "556848ef3ab29be24c7a4e493d7b8bd52646cd7c", "32648": "17c4e13a1548afdef3fef4bf459e43277573ae66", "32649": "9f687cbc2f696a652ee5362e18a4c61e57335ff0", "32650": "9691bbac886003ab8a4bc593e38ef0f2b9fadc4a", "32657": "d8cfbd2667d370423f32893cebdf4f998d300d0f", "32658": "b6736b449f3062cf05c224ad738c03cef62e248e", "32659": "c7460e5e8b679d38d7965b35e2ff7dd34adb3ee9", "32660": "beab917b99616d157b4bbd24b7a83f7432c9dc26", "32661": "a94e85213e286befec583555c039d556f22a0faa", "32668": "253daaa1a67918f5d71956282a29a14adf74bae7", "32669": "0a4440d90ee13b3afa294aa7585da1233648bf04", "32670": "3fffb6d49abe20ebc4a3380181f90103fb9ce22e", "32671": "005486fa6c2f065e25df3c244a2bd53abe80ffb3", "32672": "50a866708417dcba2226fb1d11d545727c167441", "32673": "f74f864ac00f24c5cec406d0802435c3aa2932ed", "32674": "d95bf9a04f10590fff41e75de94c321a8743af72", "32675": "8f479824974e3bdc980c721ee5a2bf5b89333b43", "32676": "b7708f00c7b61990521e9a0e03680ed45b59086b", "32677": "22363469b10f132e4cd5452bcfb15a51cb4a9461", "32678": "c6bbda551eaa04d555fbe34ff1c27628b9df1e1c", "32679": "70121c75a0e2a42e31746b6c205c7bb9e4b9b930", "32681": "0168e27843efb96b56202f22fbe5dd720c346368", "32682": "182ba5aa55dc842f8ff73a124e0ecf140fba053d", "32685": "0429b648709de4af526c8a65313b60a8f7419f1d", "32686": "3b09765bc9b141349a2f73edd15aaf4f436928bd", "32687": "adaffe9a9e39f3fd34f0a9bff3fb71487065e85e", "32688": "17c247fbd44520ce5231830a3df09726532edd34", "32689": "3c72d6f1c0b85313aba0902fbadbc735fe01623d", "32690": "0b47d85d016b6533f19285d81d03b2c8f8e10a75", "32691": "16b4e53ea8c6673a077205bc111cd123a65747d5", "32692": "9fe5ea45301e01c69792ecc8a02bd6115a9a4921", "32693": "61e0db25f5982063ba7bab062074d55d5e549586", "32694": "15e6abd81afdcca4a117686c9bf84d6a3b487b18", "32695": "094b2c0a183a96411b7ee2bc26a98e6d82c8cbb9", "32697": "b97316231ad9c1cfbedb671aa37ccd0f5fce50cd", "32698": "494025c2dfb933e6acd11b883891d016ec0633c0", "32699": "56f3aaaccbd941cc56db304a607c15a4b7a4e937", "32700": "3c4b9b945ff06c4aae54a994e2e320a0da3eb708", "32701": "0d2c579c51a8289c660070f80a635ccab15db7a5", "32707": "8b227f39cecc170ab2a14eaa1d6e349ba59528bf", "32708": "14dc069f09634054d2db95681fab96f5b9b30f18", "32709": "a0c3eef599dea71311bd00f709511ff5d4933dc1", "32710": "d52b6b334677aad76334b5246ce26728156c0d70", "32711": "82d271fef81be7063f47ad3f7f128499b0f23f3b", "32712": "c77aad21b8fd4126880fbce9f6a5125b03fc8a0a", "32714": "a7ac7d6a559e6b100484b8ac534c00a3b65b7979", "32715": "dc5e00d91dd515e7aeff1b84967afa0b4d39adca", "32717": "32b4222050c7d5eedfa8fa47d5a45fb1d6c966a5", "32718": "48e7b6ed41eb94a7792ebda8fa7999a8813948ae", "32719": "5422716d04959200b815621a4c100ac657c22f31", "32720": "c3a257c17a1f3558811016c76de1e4cd69f71cb2", "32721": "c872a8bf2392b7d74a1f3c7b57ca8f3219ee23f0", "32722": "7374a0dfec7c0eeeb4c7f54ebd49e3dfdd46d559", "32723": "c09ac01901854994a29c4aba755092cb31f2244a", "32724": "4d0a4365870893e232f639af13fea44c7d3ff9d4", "32725": "13f758c9678d062a404b4aa2210e224b27d9ebac", "32726": "41db57210c1be8f456912ee67c32d6f1b7084a0a", "32727": "284758d5108833852ba656cd1da53071e9356aed", "32728": "4d9145fed2c0d34c2dcc07fe6e7a400435e32ac7", "32729": "d1d8b666abdb03700703a39d6f9b48c5638d4d62", "32730": "e35c0c4d9522f114b2c495b3fecc738367b16434", "32731": "f26d2254ff53461ab919582e75f3f686a94e98e6", "32732": "163b003d400095afc340d7cb811a16de7c256622", "32733": "c65e3d25ff05b922a270117af99989601f655a10", "32734": "2804681c45b5f748d0977e3998bbfc91d4653b10", "32735": "d6918c10736b8c353ca2edddee83bf8a5111ca52", "32736": "176621a320fc858a5d8864115c5ca00fb7d284a1", "32737": "fc91090b824959833cf36fbe51ac7dbef6b22982", "32738": "e5fb655a74c828eb1bef026a54ba9be85de1f3e6", "32739": "2e3ffa60959480e773a6d654742c7a83aece9e15", "32740": "7f47d336b0a6689a9d333e332be7b9663a25f29f", "32742": "9e6bbdebb6f4f4f8da6e635508a15276bea5792e", "32743": "7e5a95cda77d2665d5bec2f4154bf72f041ac36b", "32744": "3d0d197cec32ed5ce30d28b922f329510c03f153", "32745": "5241bd05c229688404c8c23da32f242b5988e4f9", "32746": "3377a6d33d813e3817df0786117eaa08d5dcbf96", "32754": "90757dc6d1672ec9799e664c2094e42073e80eca", "32755": "0bcbdf954feadd7a9d010682d25a34a7a9d44958", "32756": "474a528ea3bcec82830661b7a41503c94fc8b5df", "32757": "ffd8b00e1b9d50d1ab0e4cbfa426da5c5a3b00ca", "32758": "de6a5cc21e59e61733be1b7f8ae7d3d4e15374f2", "32759": "13b6b59604a29dca616bbb7ec45777a0e75ccc4b", "32760": "a85a386b780856842dd81155f7ea066df5ccca6d", "32761": "f05d217066c02049caaf5c14e8859e9668c0286e", "32762": "470fee6f3e869b22bb9ee0a3661efd94dc262fa9", "32763": "5b85b433a9a21302a873c67e9ccb9be728700e50", "32764": "d88e0fb39830e321060111c6534d378ea1d259d2", "32765": "1d5ce5b3b42cebd4b49ef3b06b50b78e09b1d91b", "32766": "74f1e94a3882eb3fc73541875f3e04c37dd5e59e", "32767": "8da8743729118139910b9eeb27e27a1ceceb2c4f", "32768": "4c5db2e435d13c5ca91f98d07edde18a498ae6dd", "32769": "e7ed4cae8897de627c93703daf6a852831731bfc", "32770": "0cebd7508e252aa4aef7be7590537dc3e20a0282", "32771": "2411042dbc085845eeef27f0d3be6db36a356692", "32772": "0ca49fcf1e5d6a870f99624272a7e9332ea27593", "32773": "b2df890b65bc29ad387ebc61e45fbdcb2365e560", "32774": "6b0ac938279d2baec210641bfaf3719872f9a187", "32775": "22d9ffca7fe429554da2b42b170c616b29fcb400", "32776": "f7fad771eb1598b7ad43c1170a91178f49d0a93d", "32777": "dba2080af7647145ce82669c9d67cf2408b2a48a", "32778": "1c71d7db926f4247798a7182f85aba1124fa894f", "32779": "7d2337a34828e3ed645498d0ea37ca9ceb3fa31a", "32780": "1b23a7d779fd18b362c021d9ba58231908150438", "32781": "2d185e1d545157e08def82b202a1e8da67efc5ef", "32782": "d6608313e211be0a44608252a3a31cf5220963f4", "32785": "1fd894d734d2cc466918eba5b2a06837fbd8139d", "32786": "5206bb52c3d0daff00dde93e360920ad02995998", "32787": "7c208c8907f5ab18f807366c0c5e26ae1dbca299", "32788": "078c024981803aa1595349bd602d551f58cadcef", "32789": "bc987e708b9856f5d5c8cf3096e1e2bcf23e1121", "32790": "7c0278e533b8cf19a8b6bd367bcb26a06d08ab9e", "32791": "afca9f844d982b75778fa498e1c3f2feae742a6a", "32792": "e93ee07729afe0bc7661655755df6adad657c23b", "32793": "2d5d2def27fc34bc77d2a3d01de33bda67aaf92c", "32794": "3af7170292e579413b84424448fc98bd13dffd09", "32795": "8d1be809bdaf84e25ff4b66524197a20e54006bd", "32796": "56931c49bdfb22725f42a2323a0a4d4f71faf840", "32797": "03a981ae61e685bb6c35234a6fb78a68373af0c6", "32798": "0ad74d70d5a46bb548ec51ed551d9388ad9c40df", "32799": "e0b111b1d46f550d9c4272bf143dd2ea20a1ecf0", "32800": "e61e58ec7168e4ff8f8d091848ca651cad7ce8c8", "32801": "3ece807d6d85663cb0f9811ccabb8426f506bb5d", "32805": "0119bdc57c41a71ae3cdd5fc47f384e504c19208", "32807": "7d79cc6a8096579e0aef2918ec1889ebd5288022", "32808": "4eb4729fb47bd160a39ec49f6af89dabfc63d3ac", "32809": "14991df5ab3e5eca83adfd8f3fe6eae9a2ca888c", "32810": "49014106977c6425040a3c6ebd4817a925567191", "32811": "b9980b66b86489f0df88e09a93529d98e6371135", "32812": "a047fb6c101f6805de81d25c0062933987c7e832", "32813": "c35eca35d6070ea508a115ef1008ab40f33ed727", "32815": "cab77e3d6c122bc11e13dcbd700cbbfbdba31fa4", "32816": "eedcb5fb46730750140ba8bd10d765e8dbdfb44c", "32817": "5fad2e4e90be46c14e947ac1a7eba3275c4b656d", "32818": "f5323ab05eb7d75b1f2d4f4fa7f36bcc27693427", "32820": "e38daf0b6fe170772cf6518fec666e2872eb32eb", "32821": "5fe95c60c7b1db349a92e36b23816cfd4f2cc515", "32822": "eb2351205c9d63ffc82753df59881b9138349869", "32823": "ba74fee9be5317665379e6a56a5cb645c6061a86", "32824": "de4525b1845e85d21a670f7a1ff8abffb8ff85ba", "32825": "68537e354c0f44197c90535dfc076459e8bfa772", "32826": "a0ee90a22eac704d043ece58f551861c0bdbc071", "32827": "7ef6a71c5c41eadf9ebea514f4be502e83c95a6f", "32828": "16b9c98bfedcfae031df5d570ef68a2d126826b7", "32829": "7b2dd3892c1046ad5fa6354ddfab5a73927ba4c6", "32830": "e3143f6119c4745472d8291f72fc06121e72c699", "32832": "63e50d5f5db00e0018651b4f6b834046a04379b0", "32833": "49f93ed45a6390789551c96d5dc11e63b5ef7e43", "32834": "d27f47b718bf198cc7d322a36c0df8253b5d42dc", "32835": "5ee4dace4334f98147abcb42b5218e6d8f45f7f8", "32841": "18be7579e272f9219633824aea93fb3233825a33", "32842": "e476938e22d80ae924d3bc525cbc7e0e54a2e862", "32843": "43bff73ceca04702a0069c077162a05ed0774995", "32844": "1f836f16b15adc0838afe634df5bda3977b3ad10", "32845": "627d1b6ec79bd5dbd0f65e13df8e9d284b775a6c", "32848": "1d5f05c33c613508727ee7b971ad56723d474446", "32849": "65987973b4299004aa794f84ef187a1b6b58aec1", "32850": "bce995817caf00ab5e82cb4cf1b540f1530cf4ea", "32851": "d05040824e6ab4e1611590a38172880a45dbd92f", "32854": "749d59db6e5935f4b3ddf371e79dacc00fcad1c0", "32856": "e0b93cce7161cb31e6a24b0cffdd2dfbb952e0f2", "32857": "018967465f2b8994041b8e220118078682c08e63", "32858": "113bdb37694e2849a15c390fddd8f28986bf1863", "32859": "e17a7f8612f7f1e1eb180486afdb63fcef517041", "32860": "7b0d4dd2da6a5565e7fffdeec3a58750640c7f2f", "32861": "3029dc74e6dcd65d235f1aeebe0b4c0ef356f4b9", "32862": "bf5ee72d5b81962db91fa12f637b4369d3e30f77", "32863": "a5cbd1e52e9078637c899167f40a29b4bc8901b9", "32864": "00fa270c055383ffc07ce0c8c67f545389075129", "32865": "4846169970f2d184f4376faec2f66b6768e59028", "32867": "a8c2000b6a631017ac411b13fe13c7fd6a56215e", "32868": "f759c33d1bc95f8820cbdb3d3fbab4a8b438e931", "32869": "16405f6584137e69a52dfa98b901f1afb194e52a", "32872": "79b131e775271c79349b7bc412aab21cef6eca12", "32873": "14881577a2bd874ee45dde7230cf334b69f9026e", "32875": "026a83e06447b749385beddd3d03abe97d48e8f5", "32876": "e0cb0b31d666a60823f0b63d88c92399cccbe3f4", "32877": "70eef55e438823697515e834ee4ac350bdb0aaa7", "32878": "060eaac1b6d275fdbb02404ecb0635f0bd9d1377", "32879": "0986922d5cde3eb7c7664cbf37a9d1d2c75fa3f0", "32880": "e1dd15b41e02ec78ca61379dad74a99f5ec16aa0", "32881": "e413b91d601217238d7e3e701f2e92a4c5d215db", "32882": "22491dc041315d40e525b722a92202f656639957", "32883": "2f993c2e8ca76e723f59195edcac9f7476c3a8d8", "32884": "1613f26ff0ec75e30828996fd9ec3f9dd5119ca6", "32885": "12624716f85e7f12c64567ff259bfe632a42e7fc", "32886": "d3e5e058efe8d614fba4c1a8029aaa904e2731f4", "32893": "5f3c29e3e9caac70d6c3c2914b8b8038dcb4c52b", "32894": "cbf80c28916279b756a769aef1b4ac28ba2d8260", "32895": "075947f0a29459d2df04bf08314909390d5031f1", "32896": "8117a55618ade79272fc91edfdfdaed4d460b08e", "32897": "3da778cb04a2f62461f103c1669ff02f430f9171", "32898": "d0dbd9f7210a3c674018a3f4539cf5b5ac134c55", "32899": "cac2e8785f119369c89497647eb0e077ef12854b", "32900": "d80002440df612865e237d47794ff2ddc89081d9", "32901": "3c55eee968e702b340eb3220c132b4b821132c72", "32902": "083d030d473260456dabd7d4fd924830e557d97a", "32903": "608f49a1c7a6999366be459ae954a2ef605ea9f3", "32904": "2fbea3fe245cd2df0ec5758c92906cf5be43a382", "32911": "bf05f35d16afe2bfb8f82cb257ee9a982b95fee1", "32912": "d20c02b3fca0956174b6b1dd0e3a2d24cc700a65", "32913": "6cbd87b38b1d069fb83d3e094866a8192b5cdb63", "32914": "5237be554ac5b4618e22a9dbc48e136395607d13", "32915": "ca3e0c875fe0dd862afa88b905e8aa4a44815231", "32916": "f31da23cac7b06cfa81b0ba27ae103af7bc9da00", "32917": "b002462fb52356da5b493ef6fdf7b36598f7252b", "32918": "738564e6eb0f974a3bdb579e0fb644f909918581", "32919": "ca0434994ea944f81417e304203ca9fc494fd2a5", "32920": "8469f746de31aa40b409c143b3d542f09e2378a0", "32921": "50f19b6ed5f335d2396825ad5ec055f2607a39fa", "32922": "c49733c274cd7007231b77f0765209aaa02c624b", "32923": "280fbf6dd472b868e3849e81998db6f266b96514", "32925": "4bd55a40e082d311e4fcaa97a203c9348ba8df3a", "32926": "4e4be0bfa8f74b9d453aa4163d95660c04ffea0c", "32927": "bf7960d004d2e517d1183a790bab3911792b1ed4", "32928": "fabdd5d26de7adf05da5fdf874d2fa20f2250e94", "32929": "1ce4455424898eb08719295205faacb2f0d9a4b1", "32930": "be2a09e37ab74942378b8297a1ea5c7d6d78e3f3", "32931": "49ceb1b1066a3474684052aff229f7c7931a56e5", "32932": "cc478c4c815a85912c3fa8f4ec400f8b261b97e0", "32933": "7bc699fbb8dd94177d723dd637d7e99fe0eea65a", "32935": "9993ec4059f15758c72bf943ccbc63edfb709f90", "32941": "2e1206e112f126c7c8508cba44b5b7975e24ca91", "32942": "1b653b1c23f7a5f9fbaede993cf9370dba79b1fc", "32943": "9918c84043a340cc0a62625273c842c05f3d71b1", "32944": "4878dfe551da2fa8e2bc33e774b595f099bfa74e", "32945": "0971f55d27680245865eecb4f5d6270fdc45b130", "32946": "c54ce8e9d53433ed7513aa281f19ed4bcb79158f", "32947": "eff6566cdcc99b41234e0577ab92b779348695ac", "32948": "35a7f807ac9f02128333c1b5df0f03c897d13445", "32949": "38b4e966548980fdcd63dfa657bb5a2a0ca40e9f", "32958": "b233faa4d1a538466d122c720524973d417d3ec0", "32959": "029e098431628e409ec565dbcc809652e39dad26", "32960": "b0305f7b8b58c36450ed4b4c285dcf8743c93f42", "32961": "3bc2203b05ffbf3d18e912ce818f94bbf7820474", "32962": "483a4f58b48afdeebe0ed099e0c425d7b0f8cb52", "32963": "dd8b721adda09e09599b66181582417564ae9607", "32964": "5a9142ea2ceb223708999c88b2bc54338a5b8f62", "32965": "b6eecb392c803914a4f25bf08fe2824726945af4", "32966": "4e88c3f0389a1a7ecff8bfd23615c84ed92db951", "32967": "dd8b7186fd0647783e36795cfdcf7709f6029e65", "32973": "fa613b3268f7b6ed6ec2d833f4e96ffe2e8659f1", "32974": "032d112779bfe63af46df7a97e0927eb9f0e7583", "32975": "8d30b6eff4954aa0a8a7d31b275a02c0ef11ff7b", "32976": "2e224c7e57870196e47fc8656713834f3d8afa41", "32977": "af9b72af8816bcb5604b7a6371b2c4039a4de5db", "32978": "ddde1dd2e42b059754ca4686271e9345cfd4e870", "32979": "23c36765d9a884c815d1eef0d6d351d816853ffc", "32980": "17583b37013b21f65107796fb8fc592426f12bf3", "32981": "797f23efcf9c5eeeed06749493aa0a5c5baf5514", "32982": "2899f46f87a1dc254f331e6d6d5138a2a195703a", "32983": "0720b035a8eb947ea442debd2579f2431a2e869e", "32984": "502919e4b18e5d5aca584d4ebb84d663fcefffc9", "32985": "acd2f5f889df788be7c308bff7db282d71c80b3a", "32986": "42b0b7acde4fb34c813d5430dd396dc9fc8a3620", "32987": "d859ecc1b0e386a66a5e0650609a9e3154fa474c", "32988": "a28cadbeb6f21da6c768b84473b3415e6efb3115", "32989": "98efdc8ae551f44f35c497bb643afc1f1db4b40c", "32990": "5718de1a3e9555da03f4a0949c232233ce370318", "32991": "184e16741b8d7b4d67b579a5366c69df8fb2e52d", "32992": "99859e4e3d2d367cb58e9bfbd61731abeaaac790", "32993": "b29db1b5f81ce85e9b9c95e970e75729e62b308f", "32994": "c4a84ab20b5699302e6bfc6854a894a30383ee98", "32995": "f82bc3edcb5d110d92c07106be4b5ac5f45176c4", "32996": "32a261a39d83d8fcf72b09b9b46343e8baa980a4", "32997": "29e287b648027c974b9e5c741913befa3c58c947", "32998": "50973022cce562d1c2c5d80e75d27909d2ea6092", "32999": "179dc14af16c1738df262b1886cf9fb63cb2b849", "33007": "41ab44a4555eb6786dbfb5f6f813807979f53e77", "33008": "2c272e239c9fdaf6d3c59e141961a17cd310cc89", "33009": "d555c1d83b3ff1459e17d6940b594a5f1bbce8c3", "33010": "14c8336379a1c9c40d7538f98e2d31fedb3a2cd9", "33011": "3ea04c383bec5aa82a1f2c57c6d4da81ebd74755", "33012": "548444b3a472eca3b181c5c5b2692d50d96048af", "33013": "02d22f34af090615d382e8609e059a4e88c67408", "33014": "0a4ba64212bf440f37515b242e5746fea943c62d", "33015": "2da7128e3436db520b96ccb07e56811a4bfcc72f", "33016": "45bd6372f24edccf68c2a5d05224295e805bde80", "33025": "8912f96ff397abb359081f1f94b90bdfaef6536a", "33026": "7c4b98e7940a1d31bbdbd0011ab3ec027090abb1", "33027": "30587136e9e6563572eb87fdb9979aaf1310c15d", "33028": "209de2803c5d772a4b297ac696aa85f67582448a", "33030": "18bc585ae6eb6918911243b9486bb2c1a9dec570", "33031": "e16569a0041759e5bbb142636d3cc158dadd761f", "33032": "dab080e9ecc393ab2911440958f26133fe77959c", "33033": "f816fb97ee3b105a1e88a20f799a9128abe7d766", "33035": "3a0db109390ddf9ab331cc86e63449c7445aa8a7", "33036": "3b26841feb584e7d42d95b0b00b20362fd68ca2c", "33037": "1d73a567265c01e2acda0825f995f65bb2ed919e", "33038": "a82f90526c6304ee400323984f89a5a01bd3f412", "33039": "60dc3f544178e83660796133302cecbd8da28b91", "33040": "222e37ddc7cb3ac683666d11a1a1d0e74fbcc402", "33041": "5483590436972268faad830a70fbc46f7d19a053", "33042": "92e458d8037057b73724d10badfe3afd4580a262", "33043": "399a0ba9477a83dd89cdd2de9fbe183a42b2e4cc", "33044": "0ffeb2b5fb20d7b8f8ace55932170801dcbb7d6e", "33045": "fa78ea801392f4f0d37ea7ddbbfe44e9c8c102bd", "33047": "857bf379ce964dc9494e2fecd3468800fd7c295a", "33048": "18c43651b0497b5e93fd02e4f0bf6d254a25c316", "33049": "07822fa3788470d2fe23af301d0db8fbd74fc03e", "33055": "4520f84c9865bc75a63937594fe536cf46368d2b", "33056": "47c9ee7b32d8bde2ff8cf50288a8787b11d512cb", "33057": "37ff082139a0dc67f5cc91b519834db8d54df56b", "33058": "2ef976c4c8dc17fce889e2dc3847ae0b65a0b4a6", "33059": "53c14257926e230ea3bbd885db43a732d715f86c", "33061": "db4d3b09f68bc26704b8294c49ea05a8a6f72796", "33062": "76c39d547c42644f8ce42801d696334cd3e199a2", "33063": "01cbaeaff4eae2ce75477e6d249f6290082025ec", "33064": "1e4e624ea3ed8e6ac97c937a96e451063b412845", "33065": "18865cfa99c37408fb90bf2523d075b007a5dc2b", "33066": "f4136c041594721bd15c729cd1f95315aaee336c", "33067": "296cbda251ce71edd2ccc464b943f69f5c39193c", "33068": "059b2c182eae3d8ea994b388a39ce780e4a345b9", "33069": "f47a8b83ec10c906429bde6d198f563a869ed7ee", "33070": "b513776c20e5de892088e6d7b2c27f90abf9479a", "33071": "e7e3676f97ba443a5be3076b2b412de5c9b31b1a", "33072": "c2b2a49b6c9d7bbb8cef3609a1bdbe01cc183416", "33073": "5b1f72a046c14bf70d324c2f1a1c5dcbdc2aede9", "33082": "65baa5b1451078ee46344d7424fadf1968082809", "33083": "27e74676a6b10378e6b812da3f1a7b0ab6e5f7df", "33084": "d7714cdb15136e6dafda46f33029dc25dac5991f", "33085": "ef0eaa45a999d1ec0e1af0db66998e215f87a2dd", "33086": "5115f0964a47c116e3899156ec6ccfd02c58960e", "33087": "bad377488059aeb898bdf71dad88eb6010caadff", "33088": "59f7baffd4da90f748eed2afda6f816ece16c09b", "33089": "1d634743215b3eba4f15d458267b8f0ba4571e47", "33090": "939d0baa6a59c484b16214bb5e9c6451537accd3", "33091": "5535def388d3e82aa07977a37cd25d6343909e51", "33092": "05e93590e372454dc8ba9d7e198d845b3d93684f", "33093": "db8af0e767cb66a7b747984feec380822012cce9", "33094": "1bcf42e3547982cf04d6d5da0b3d8050f81d1f0c", "33095": "32b33085bf6eb278ac385cf7009140bd6012a51e", "33096": "6da42f3776bfbef245ff04028706f3be82329614", "33097": "9d8e7048affb31aa33bfe6f09b626b3045ee0d33", "33098": "4f42ecbd0569f645a881f15527709e2069c6672d", "33099": "d00b945e10c9edb6658b2f9cc3cc5ca0a0d74ae1", "33100": "aa789eaabe61a8f633cd852db208f503031e4028", "33101": "2797b84836051c6c366d98d1b3cc8acea6f0c7b8", "33102": "710b83bf29c90b0952e442d04c52a9fc1a4bc7fc", "33103": "279138cbc179b287b76d25082805dd47ee55eeb0", "33104": "7cb7592523380133f552e258f272a5694e37957a", "33105": "eddb6f459a6b32112f614a9118659ef763b50db1", "33106": "dc295d625e66e30917ad3f8fcecdc5d2f1602d8f", "33107": "dc7f851135a7200673f879facd3f3a05b3bf9117", "33110": "fdd71632615d1db02fb606667e90b632470fb4dc", "33113": "d67fad54f9656bc902a0838482529c7518dc18fe", "33114": "35ce27a914285a3bb059f245a73375a751cb8ac5", "33116": "bb18847e70cfc07fe0ea0908dd6eda6f18431187", "33123": "5e95673d6f958732132c305e1ed6a6d3918ae439", "33124": "2d6d744f9702b94a616890edc1543ac9bd246e49", "33125": "e27bded18aa8c84832b1cb977531cf0df2df9368", "33126": "8b96ef2b88f68b912c60563b588a01d7ab58c8f5", "33127": "d3995f76d4d366d44f3c29b9db8f33f23254dec6", "33128": "9991d5eb99d93a9d03368490379447ea6156a4c9", "33129": "829ae73243e44221d0b05415cdf45ea9e81a7261", "33130": "62521dac4f5aee007037f424198c525deb27743a", "33131": "954cf55938c50e34ddeced408d04bd04651eb96a", "33137": "627bc4044e21e093dd6245c83af2dcb5cd7f3c3f", "33139": "f15a65cf385c435b2d55daef80bfffda08f1036f", "33140": "01141ab8f3a1d74382890b53cfc2a00259055259", "33141": "7afbdf17f79ab2b4fa20461a0141a7ae3a76408b", "33143": "b37589ad7e33e326823486f6e97bb4971086393d", "33149": "99d367a6a03226a9cc9862b786a4987d255efa83", "33150": "2c994c7b67aa6a5c82df652e2f397f174381b100", "33151": "b173e7ba86aa0066b8ea8bb9c583d39e4284f1b3", "33152": "a38a24e69fd614cdab024f88e6f56bfaa5cb4e80", "33153": "384a603b14735d7673c88c16c77371f181e460e0", "33155": "9116f32d50a89560b064af278c5f96aa31468a19", "33156": "fd2c2315ee1798876f1685e250ea46b3421e9d4d", "33158": "5b6d6eba9ec372baa8c0755b59f72cfb9d4db873", "33159": "575dc38fd816228b391ab4b8a1f4eeebd14ee867", "33160": "d3f0e9a95d220cd349fbc2d9b107ebebc5d7b58a", "33161": "9e8a243c5b77429b662030cc0128a076eea192c8", "33162": "cb83712635b56aa061c4d9a8f3bfd8cd23716529", "33163": "a0071f9c9674b8ae24bbcaad95a9ba70dcdcd423", "33164": "316c8ba41209b460bfd4928a68b2a6c00fb065c2", "33165": "afb7635198b0f6a5516baae3fec2d9181f58f8e2", "33166": "cc1a8062b4e999500b020a2ceb57fe47b1588fa1", "33173": "35586f3b761d59421251e00ffc966516b27ffa0e", "33174": "3ff71e469ce796053311034680274f7314c4ef40", "33175": "89a76f6e9ebcb756cf232bf237ac23e295b19fb0", "33176": "9e5a62f56924e4a24ebffa4d78d2191aaafe5edb", "33177": "579e07093e95f01b454146b3cf9de18bdfb15635", "33178": "b0c0d8a8237f4109d2a97ee2a9719e6b8bcb619a", "33179": "c426dc0d8a6952f7d4689eaa6a5294aceae66e1e", "33180": "9012a9f49cf34b234babb3d166bc4a8fd4f8da62", "33181": "4a794851c3fa8fd8e0edc022c6a14b396937172b", "33183": "86cb9500419da51d4853b00cbe8bfcf1a29855d8", "33184": "affcdf95584ae4da7d605c5a1bcbefba5bb68739", "33185": "8d296f21f1fcee8e8b6438a2162cf0e84abbaa95", "33186": "f63e7b82177e8455d77e23359f3927a01b6ae76b", "33187": "06d074fba8b4690bd0233e81d2cc08acadb6dd36", "33189": "7f8baa0f0eecbbeb3d45b086665286ac406887cc", "33190": "0e0a4472c4403a4049ae345abbe7c7552096b7c5", "33191": "d72e244db5c77833caeebe5f8b38ffea867b1a95", "33193": "fe9810101cee7012a9e4451eae3ae6cd697ea46f", "33194": "9349e61f236d3cc94e05429930ecdd76872b6365", "33199": "96fc51f5ec678394373e2c779ccff37ddb966e75", "33200": "3f0af5e9f5970f723cd81bde47bf2a7ead0b8c80", "33202": "9bf60aa71651accb21850f392fe8ada37a7b2f67", "33203": "afdf0a3e409d02cdfff6c813f512717f1503a4d8", "33204": "a1babdc2f55f804692d6cacf15eb98bef33687d1", "33226": "ac3c010ad76ecdb7e0393116942655cec5e253e7", "33227": "9097263ad5b670dfc79f913d1520a451382aa1e2", "33228": "a063af0e6d443c4b5826eed2102a6d3c988da9a0", "33229": "305c938fabc0d66947b387ce6b8c4f365129bf87", "33230": "254660434b4bc90baa51b09a8e3bd7ce7524ee91", "33231": "2e218d10984e9919f0296931d92ea851c6a6faf5", "33232": "268bccd19d0d6e8d7448cd890b68cf6510246047", "33234": "d58bf120b9cf4149ab8b379ebc7db286115094b2", "33235": "cda7ba411efc5e123dd8381c3d30db4efa426de3", "33236": "0e484edf8ebc50a55f027f4c022815eb8ea28b5e", "33239": "4d0cc6f4a38092c1345f37a2bee732858b2ac982", "33240": "5e4ea2e1cc7adbc064577021e0a6c556a303d5aa", "33241": "ca41a7584545dceeb397d189423ca367d9d305e5", "33242": "0569760e09ea7da36e03b59a4f58f7cf18b5ae98", "33243": "05d12b5eb9ef3ef0ef697dac92e3548371b6dcd1", "33244": "1f1f645fa9216e59c542e3eea21b9073bef4f581", "33245": "3fa869ef9090281b7c6b595355a6795cc366876f", "33246": "86ae81c50e78119d10145d091ade0d1c2c83c141", "33247": "99f98de8af6addf10510b9933f60379988b19cb7", "33255": "da2b086a5f206414bc1ffeb95b70e52d253e8704", "33256": "f69efb6fb7d0ef2f181006ad19ae7de83b9e95d4", "33257": "6ecb52e5332a85fd5d7411486d6ffb8104ab3f90", "33258": "69a8150ee703485363f90ff9fb4a8f47e3ad1a57", "33259": "185c53f50e93e3326cee11fa5ae1e4cfe551f1a6", "33260": "d1b7244e8793c0eb10a5c6b88a2e2ef95739130c", "33261": "56c1b20eccf7cd7ad8b1d286dc08ee0577773646", "33262": "ce9e3d658d6efa3600a4563ca7a00e7a15b80272", "33263": "77afbccc0fe3ce6504898bb88fa418a3aec07a27", "33264": "e5021de3b22f89346c380ec18026fa10473be5f4", "33265": "1c17d94376523887d1113d001fa758d77b7d6eb2", "33266": "ef6c35cd571b833354824f5342ce1a899a3496cc", "33267": "e7f6a841c653f46bb46e72f7df26f14ac36b10e1", "33272": "76561d1c481c24bd31720f320ce75bd66a4eb82a", "33273": "448a023c9182318af8da29a652026defaccc9ef4", "33274": "08a7a9e249094f9f246c03180841210e447c26c4", "33275": "5120720687887687fd33506ca29a0d95d4eff3e3", "33276": "626b65101c875ae8462954c5a46cf43877057787", "33277": "3886ff75e194630ebf3f6bf4092f3648b7c33a9d", "33278": "be260f1482c4695d79725a99c490f3e0a1dae0d1", "33279": "1951b5117b22174abbc944b2e6efc41fe34f0a63", "33280": "5752494fc608bbf28b32a7c5c5a490120542a300", "33281": "73840ef221050af2588b079bd6ba45c8e291bcba", "33282": "2df4522a4ffa0ed62ff26a0b9cf656c9ea5cc317", "33283": "cf536db5b0cc3b7cfe07f5b9c58ccc3c3fd1dec2", "33284": "6d6917daae652ad7a92888f077c2de5a0244a164", "33285": "bf1d0082a3240845f76e697872634c80c8ca6a92", "33286": "859e4eb3e7158750b078dda7bb050bc9342e8821", "33287": "33f4f7b57b46bb295c1b71f3890377a5e541122e", "33288": "d50c3cc7fe728b79d49a82db7d9aec06e0163b41", "33289": "7f2aa8f46a4a36937b1be8ec2498c4ff2dd4cf34", "33290": "74b13fa8996f796cc487ebb12ef97e826386dd4d", "33291": "a82b8e2073ba3a3bdbfaa3c54c46375d6dd09977", "33292": "dba96f97abc96712946067efb63a587e47786caf", "33293": "fd9a9ea7b242093314384d134135ebdd721b5daf", "33294": "8448d39f25413d4d1246356d3843f6920c9aba56", "33295": "b39c78b54c193766c4fe7e7d3b265ed73f54d13e", "33298": "16801a1f4b836e2fbf49d623fe565457a3e375b3", "33299": "7aee076e47f3bc23ad9c1f771b88f7f592a76a75", "33300": "588a74931f7440da00f90a5576b13ed1ec7bf866", "33301": "1269a3ba3567772eab2271b660c064114ddbab18", "33302": "fdba1e67480779f976120f6c66d6f242232f4e6e", "33303": "a5042766a8c56a8d8d803e9654bb67dc6852389e", "33304": "7454934d40affa2f420e3c55c67996594d71df82", "33305": "ee03ed1d216830edf2e0154661097deebe2ed085", "33306": "14eaa428fe77a576dd6368d6d8a4546d11b064fe", "33307": "4ce3757a0295638990a452b11164a8ab46e6a1ea", "33308": "01693d64fe7b4335c327d62c5a5861f07c98f8c9", "33309": "57c6533d4d54326c7719a792aa9118dfc1079555", "33310": "2ddd338c03f9322a163285b6c5d5a3d65017a8da", "33311": "f4d1cd55632287e8d03497ad428fdbe9bfeef5a2", "33312": "22de62caf6780ae420685668857bed11408930d5", "33313": "2096725de083f1997c7e03aaad145be6d03418b2", "33314": "7674874ed3255098f47539c1cd6afddac4f107ac", "33315": "6dcec6ae7f88734cc951c39995f5b1f4319949f5", "33316": "73dfbf45b4f7b1063c7861b468a0210f6d9cd320", "33317": "b3cb116ad409588cbe867349eb915ec0c4380e3a", "33318": "852518eb293897d14c7a89afe4f14dbe0e30c160", "33322": "77e97d2608e533a5b397d2bba4935dfcccf8e540", "33323": "d6afc862a7e2e0f742ccd99a96198b2768091284", "33324": "ae1d9c91a77624515d8c4e4d3531fa0d014cdbf4", "33325": "0d43f683615e0e8eeb98ee5cff92494deb323f90", "33331": "8983b55e1bc5c482809af92308af841dff3459c0", "33332": "8aad1e7a4d5efd4254417cbf628ac9b6ab12927e", "33333": "fd0e2f1147f0e09b061e6d853386c0e3ef009d8e", "33334": "66de372df0b3693e1bc46ad2df58be3d06a5872c", "33335": "e4df678be8286f33fae7fae9a0145135412d6bbd", "33336": "d0221cb4449801dfc31108e019f668661dc56072", "33337": "cc6c9570aa2774038c6247455875186c3765d18a", "33339": "c73736cead833ae265d99c467978708dcc0ae5d7", "33340": "87f069a2f850dab81a4dab648f1d6fe3556df4f9", "33341": "541d0928fe0c785c774d0faef1cd5e6a41e4d5b2", "33346": "39f72da76f0ec5270c06043d0ab957e5f7495615", "33347": "07c3186a601d4b367eb3a5aa4a4b8d1abf446e10", "33348": "40331562064b0e83a0754337669926d002d647eb", "33349": "1d58928c799d7d36a767f01e860d310596b7faa9", "33350": "0d9fdd41ba9149c479fc3dc644fbd0070036cafc", "33351": "3770ddabc99f4edddea12c275dd316790b6a2a92", "33352": "d3f3d5d09011ef23b5c953b451d45223119a18c1", "33353": "01241481d590d2a22ec3e81ec98f5fd60a5269cd", "33355": "a3fbfe3629eeff0d10d12f86237e3738cfb3b190", "33356": "936da9e99731157025f1ed3ba5c2f103c5115600", "33357": "961314dc73382fe5d62e6d55310940971dbd0a3f", "33358": "dbe5927dff43e36a7117712a20dfcfbcb2cd0ea1", "33359": "bec92a43feb0057f06f4f9b9db26c1a09232b1c0", "33367": "337faf309eea63a92b0e662694b0a4d7f48121be", "33368": "3b941193d4dc6e2b6574ef3bcb4a0644756cd1bd", "33369": "80ecde4bfcb90a3fe5245319a0823ccf05a33358", "33370": "6478e70fa3297e6d923405061d85945cbda4809e", "33371": "10c51ba02014d4caefa8dc2d2ed2874759693b14", "33372": "f3015e39439920d3d00a328714c06b6805f7f32b", "33378": "37c9523888e3eec7a0d8a30d6c0bae03072fd2cc", "33379": "dbed1316d10ee699ad6d5c8205a3f4e0b1377e5d", "33380": "785691e474f7b5fc6b2a5f228f3c7b645e879232", "33381": "1acdf4b3bee6d3ad034ffb993968381d2c104f3d", "33382": "755a99b258ee885f1dadd4b6424d4d386e3519ca", "33383": "9277f93d37f207fe50d8318686fc59f637922fdd", "33384": "ac5bc67efca155a1c373dd3c61f64d0a3be37430", "33385": "f06c96a93fb2e21c9f801192d9ed5896c5ce3535", "33386": "fa7639e6757ebd7585c3123c84a7cc5a062e2742", "33387": "b65551c2d79cad75c50237d48bd39ee37a0d72b5", "33388": "8cb638273d7bb9097f4762129e1a5e117dedd59c", "33390": "5645847c042de58d6ea4f4c2fe0e28457f0e1ab0", "33391": "50d288e5804621212399a11fb461812695efee6c", "33392": "92e2379d6296e3e3c57a45b356fabec33d2beb7a", "33393": "1539aed5a47cb6f99065dcb7652f16534f3bd14b", "33394": "edad0368032bd7ba75cf1ad00d8edd0bef51da66", "33397": "385a6679d40a359ac93e9c81aef467bc561c1aef", "33398": "dc1c97c761b382f5b06d6bf40fe89e001d7ade1a", "33399": "d9b56b2142e96144ff0356dee67e2edd0866393d", "33400": "c75f5af033df07762888da522e26c6709571dd88", "33401": "0cedcbf6ec769fbc6075c3be1bed9087d85e2dec", "33402": "6d6cccc52da31284683364dbd4f5fcaed126b27b", "33403": "605d446135b2fdfd0ce68222720989a588af45da", "33404": "5c745bd7affd98b0e1418209bc1c38a337bedd2c", "33405": "ca9878e59f61dfbe402c138bd391c41765cd4b2d", "33406": "b161fa7eb4ef0f179546f6b623509b4f39d17ca6", "33407": "8deae52ff633a3e9f89e5543bd8585aa7bab5026", "33408": "1a48cd94d8f5abcb269237f952bf6a8e4262cd07", "33409": "30cb546447a0a132d2dbcedfdf2b41eefd00d1cf", "33410": "76025a637ddab18867a47c6487f287e588e1792e", "33411": "aebcfdf923d8eeb83e1932c5cc9b775ec0d09295", "33412": "808e56eb2a60685ba167bb2c523e8f844652f46b", "33413": "82ccccd50fa4030f2358e9c9c8a998ad14b87bdc", "33414": "b2a26ecc538cbd04ef256b6e0de78aac700ec286", "33415": "eec200dbc8d3986f00c54a4b0b99541dfcefd5e8", "33418": "af84a085b492533f286c486447c53b9739e27808", "33419": "15e258a8b5011adc3f71cf094768e3320977276c", "33420": "c64cc46a4cdec1b9827be07e2447f820fb9f61e8", "33421": "ad03e49f0cdd5b233eb0a17f705a072ab5f3888a", "33422": "9bd15db77343c90c8d7524af8fecc4f244e1db68", "33423": "1efc2d7464cc8f951b82106031acbe51f6febf69", "33424": "5b6c5d182b1cde1421040a7e2f2fe6e329f156f9", "33425": "8478cf63888d6571a2d27fc8c9dc9cf744d767a0", "33426": "d8a1a0d329205d825582a56eaad87c8702f99c87", "33427": "7f2f465fae88a005f2cb9c91e2b38ce54675ea90", "33428": "11d856f52689998bf8c5427e2f9168452a44f8e9", "33429": "61f09368580205a476f2cd46cf38afde503e4780", "33430": "44c30ac2be26cb86cb7750ccbe21c2c663c59b09", "33431": "6a83d3c943ea7cb5deb4caa572356b16cb6dcc15", "33432": "fcb8b809e91e7df47f3c20c457e9f6cb58c2f067", "33433": "5d17d73be969a7d004a7e1035afbf811a8fbf18a", "33434": "0d842ea2836a6f507bf54bc60f858a2a5c98c18c", "33435": "7e88122a2a829bc982b6471948c21cd1096ed980", "33442": "1bb128edb058815b66da327d4a9f28f3678c0d3f", "33443": "326de11f2bbdb98e0c0becd620af22e6db57d483", "33444": "99ebe28fd2e1cf5fc2fcae929bf88a835e1228ae", "33445": "bd4ece526b30fb30109de4d2f015df2aaed681e4", "33446": "fae47ff19afd4326549fe8c973f18b6c05f92efa", "33448": "409673359972653a2fde437cb2a608a66c5753d1", "33449": "48c99f21f86dd230191c819ddf0468c662406c58", "33450": "2a6d7b73aca3cf1922db59c0bc97def33f083c05", "33451": "b37321c7e02afba37bbef855a9096abe8771f569", "33452": "03088a973d0b5f15fbf41c53c32fdf0eb6320ca2", "33453": "d0fbeb49cb486bd06bca959649ea497f504c90e6", "33454": "13db83ad3f1245107151e6a626537a8ea7f72df1", "33455": "0e8331f85cde8db2841aad92054d8e896e88fcef", "33471": "3e8c3b04a1406652180edfdc291566820c8a75a6", "33472": "4510c6f16a2c70916079ed194b81617f71b9fe9f", "33473": "9bbb1c0cfd5e34b34e66faf847ace4b9dc4f773a", "33474": "c95b9e2019d69c9dcc87ac8dced879a2b97a37c5", "33475": "8661548d12fa6809e89e5771e87562867a5ad3a9", "33476": "ead9ced1ebd7a064bd99a2c6ec157caa0d06bd47", "33477": "f07e98b7e50ca9ecd8ac1a5782289d18825891b2", "33478": "4a168d0d0f8e2971fefbdaa11706df3fdb122699", "33479": "6f58d863056263ec6fad2be3effb931655364759", "33480": "35d76e95d4536e538dd8b950f45e073c8c1f56ef", "33481": "94f9412c85e27976debadf47c20265315abee125", "33482": "7bdf69f45f6ee6fae3d137ea2ab5651082c83c25", "33490": "fe0cc489d54dc089c9032ba002259c606ef43ae7", "33491": "180d81ff85732057e407426faf05020044e23ed6", "33492": "cf2d8f92576e546cc2fb894008503933b7ea0d99", "33493": "783a68e70530c6150acaa0dd396f472ba12733a6", "33494": "02a60884669fe46d0a39eb790c0528d5e20f19d0", "33497": "68305c132c61aca6a12eac7d1c0ba1ed2ed7010c", "33498": "ddceb8eeff8e6c81cef99876d1aef9a91de6b2ce", "33499": "d744bdb670c04bcf21c76e196c21d1fd4b6933e3", "33500": "14fc3ded86b875648b25ce924de0501ec6f924a0", "33501": "341b57984e6a376ba4a869e774e8cb71a49dd12c", "33504": "7986bc2385f9ae94b837123a97bc2e520a15a1e6", "33505": "3ea8389ff6f5e684f02f93881dc02848f1e86c26", "33506": "4b65e2f8ddc1a53c27b3d662bed2ad30ab8f7a42", "33507": "4bf16d2cd72872bf8a29460b8a57f00708d700a9", "33508": "031e9bbc3a9db4ab78be8b477b15d7173a1f625e", "33509": "c4caed6be59fa8f54f13ea7e963107404ad99da4", "33510": "9764f3dbf0173892aba5da4b122851ded43c09bc", "33511": "8cb1f22e5e54cb66f9a85fe7ea06dc3d20d8b2bb", "33512": "2a659f848a87bf077ce73be476e7471d957103c5", "33522": "aee3455b9ca94c5e507ee3c2078fce34f2759f30", "33523": "c7fa61113b4cf09581e8f31f6053f2e64b83a9fc", "33524": "89b510c36f3917d22b95e77315af3c7b6dd43147", "33525": "081167d5922642bf4a1a4d5de3f59e9e4a2da741", "33526": "f3d4113052e3d09f3a2cf288a9f1dcd17ab113a1", "33527": "d1095bcd5a43528e195e2d587e6a8691d5ed005f", "33528": "107c64f340c582cc8547f180555c85438da42e43", "33529": "28780a853971f84509d55d4f4fabf622c9efbdb8", "33530": "7d545f0849b8502974d119684bef744382cb55be", "33531": "ac9a768378d87d052462e137d22050f823a556e9", "33532": "985e89a1b507f91069cdea7a951e734a980cdc78", "33533": "c03ac846b091ef47a96dd04e55b5e98b605591eb", "33534": "8d1b7fc84a1766a44b524b84eb56838c9f77ff0c", "33535": "b196a09de231248b315a1ac2c76281c4c6e0b43d", "33536": "fe85cbfb20f3f360ebba62905b93a6f98bf655c1", "33537": "74d5c1950088c2dc0d7cefea382566ea42128765", "33538": "dd30415b6e569b66051d41172f86cce79244f519", "33539": "e9f90a25c67cddd74f3a53716cfd5e06a0264357", "33540": "0e12bfcd4b4d4e6f5ebe6cc6f99c0a5836df4478", "33542": "0788266d98b3eb467d197c761fa4026dc51f48ba", "33543": "6db4c479d719a400ef39bc59adc831c4f5425ad7", "33544": "fbefd525fff8576af17ef55fbf9ea637cff46f7d", "33545": "6e27efc650058b9d22d487af38278a56e648b8c8", "33546": "019731296e8b322cef68d3d33466ff859f6a6d42", "33552": "cefc6f85e34b14109075111196c511857d4e0eac", "33553": "047acde15fb96c9c543abdf921f05b38e93632ee", "33554": "0fb84aeece9119abf28043a5f3d5b82adea7db69", "33555": "07667f3210a5e4c2c61ea876b32b51e321a677ed", "33556": "0796d9d40d3d4f618081996718a35638f6dd8c3c", "33567": "dba9ddd65b3b3bc30e9081ee2ad93533e23d14f2", "33568": "a108ffae3eaa9d748da993ba37356836a6a0974a", "33569": "31d414124da03cc2f04f4050605ee299b9160ec8", "33570": "6057d7a93e6bb792508339dcf8e70998e7e78e1a", "33571": "7598f71993f442c6420456e1e2c3c8d3bc65c80b", "33572": "f15e31fed31fd64f2c07db6eee065c9b58647de3", "33573": "95a087dd11f5d3194afdb7b25d1ce613b4cffb41", "33574": "a131266c8ab7c83f73331b5be5ea49d9a628f075", "33575": "89bafd26c8f178e6364221710444fb53cbc5989a", "33576": "78cf4d7ffea814ac124bc2fa60485e4409fe96fe", "33577": "56dc87752a54a4f43766d0236684f3222ed202a8", "33578": "6e29dbfd291e5731e68226c3aca1604ce802f9e0", "33579": "a162c40de298f099b41bacb6ac953b71ffb143f0", "33580": "4965c51ef63dd06bcf460165a10bffa688142c46", "33581": "bab4f3051b886272e4bcc28f20664f2baa33fc3d", "33582": "41d937d44c156416881bedb79567600bf31344cd", "33583": "2070bb8daa1d3395f10d5e4748eea30fd8b98b35", "33584": "3fd020c5a7a343deb93a35cd4761a24a7c245354", "33585": "1beec6227711aaf35063787bd8ab7bc96f332a66", "33586": "b836a88f81c575e86a67b47208b1b5a1067b6b40", "33587": "0127d067d85fd30109f9bcaf10c0b1dc9ff3da9a", "33588": "450a1f04b7707ceb983a331768933861c09b3223", "33589": "6b4547671e4659c0856c61bc82c6ea203bbe2cc8", "33590": "592e34fe105afd3bc83c33faf9877e627e59d23c", "33591": "367d2a8627998eb54071f76fad9269f24f01b58a", "33592": "9a7bfe60f1d90804a5d706dab9cb374c1ba65ce5", "33593": "d35646f04b4f4b68b472180b555c665aa28addd0", "33594": "8159be6d2d1ad339aede34678e533920237a179f", "33595": "c133327c00553f966b09025f3846cb1cbec9f72c", "33596": "8275e8840d2fc302848a349b865d19041234567d", "33597": "3b295c9b4891cd995f40b2bf9856b960e957f73f", "33598": "1a2e300170efc08cb509a0b4ff6248f8d55ae777", "33599": "09c6351374ca45ab621f448d0d7d160f0becbd76", "33600": "cbad73ac9d68ca2595bb98e1979892545c7b2c11", "33601": "7f022b3aabda4c7e33335879c4ce8f6730f170d5", "33602": "8ae81738373e4fdb7db54de328c64a01f589d68c", "33603": "9a71cdbd7fdf994deee0b67c2bdccca3c65c6cf8", "33604": "8d2a4e11d136af439de92ef1a970a1ae0edde4dc", "33607": "18dc37d1642a9d0e2c0c02a0e60af1eb098acce3", "33608": "18ef7f1bf00db88d7e2d0f52d7a85e53c31f74b0", "33609": "c82ff3f796b03a3a37e716348ffb7f92c7d12ab4", "33610": "d2dc56ffabd8a669f9d81a91babe3898b84563b4", "33611": "a41fccd2213357688551d7e76cc8c0c24e2c78e7", "33620": "87fd0b5fe115dd14c572e03ba6fd732f9de67973", "33621": "2deba1994b56960b3f2dd8042cb8d40357913ebc", "33622": "dc947a459b094ccd087557db355cfde5ed97b454", "33623": "ec210cc4e26dc39d22fe7597c234f77051397738", "33624": "3e2ec509a85607b37d799c323d6fe3c7e543cf69", "33625": "3f3102b55458959481f4337e699ccd3b90460544", "33626": "a1c6a221790175197d2ffb81f82d364577c946f7", "33627": "fada873232ecb274f86c703770e41866084ae536", "33628": "2cf879d16844cda95cb5751cea78ad020688b80f", "33629": "1b5370a9dc901eeff25f3025c85927912a919ca0", "33630": "4f11580a4e63f1a3fcc99c4d558fffd012729bf9", "33640": "3f2b18aed1468d3643bf638f7859cacf3141c8f4", "33645": "ddae6946de41f000347a978877d653e749d028d6", "33646": "bf29272d6102a3f54657a79a9353165b83beb711", "33648": "b11e0db6089e9f8fca93ef3c1a6e2bdb41dc5882", "33649": "f26bf2726638a524d20a6416904e3fd83091d849", "33650": "d08d4510db5e79b8e65b35174a3bc3a968bb9189", "33653": "dff66e37fcad8f956618966a8153f4278d155f52", "33654": "65bca652cffaac5058dd216e6f905f7dc7cdfc0d", "33656": "fb80674bda32d6f1536057816f6bb3a95bc3cc97", "33657": "887d2c495d88ec403bb9ec4b6c04b44d09ec06e6", "33658": "c9017d95a0f9c5d2508f9015ca8922ab10216b6d", "33666": "c29567beb00fd4f2eb8662576cb971758a3ee194", "33667": "b070d87f118709f7493dfd065a17ed506c93b59a", "33668": "6d2b46d7a62f58a0428bf89f65615db4126f40a4", "33670": "f1acf8b0d6ef186670765fa1b5838e894cbe3dce", "33671": "b69bd0755d654c0dba42042df7b2251918274327", "33673": "f2a41faf9b58bf5f25e07dd3e4d88a1fb58711e9", "33674": "920c025c41be6ee8e1d0e0df7b47c1b10d2eee1a", "33675": "129108fe6cd114fd8a78f2bbe0c24c16f9d55277", "33676": "c239f54fdbab9a2bfc3c91c93a6662cb87e488a6", "33680": "ddb19e28b5370de52719fb6e235e823ff4c8bc9e", "33681": "8974ce628276b5af3f295ba1f701fab3d2406649", "33682": "2a3420a6a33ea32fc1b5efd4a281879caf95fc01", "33686": "e3c2a5e9f813f56ce1ff1f5f35d37ffe21e9d854", "33687": "21b019f275b08d7d5a9cdf8fe040ace91b38c09a", "33689": "efe896c0813a9edce9bb42eeb516c378527f6405", "33690": "f94386498f45de70d743a08ebcc334a3ef7c198d", "33693": "e057427f643f5904b9c2a245fb2d2c90ddce3798", "33694": "37d903f14562f01f25d5d2ba7024340b3936d5f8", "33695": "4088e8a718bcbafb82d9217726e37e71d762b45b", "33696": "a80ffdb19988d175f3e54a9c6e472e4ff6b8cbc0", "33697": "b99e2961e1aa89f80dbc9561d8ed47afbe4bc822", "33701": "4700a6101e6338fec437ed1222b9f827b4f66cd5", "33702": "89f6a1296531d446ac2d2a511968821e0925c347", "33703": "d05c0b92e3a2d7ec41300cd2afac4dff820bba15", "33704": "5de7c76ca9c34dd92461aa7b04fa07b980d9149e", "33706": "0dd39010869c7494006d434866eaff1c6693da88", "33708": "2baaaa60d698cb9fb63ef73f8387a04032b6da43", "33709": "9203f9e90a5548275769b17f85b1fa06ec69e011", "33710": "113036005dfaa4cb3ecc43d110a94eb06955b5bc", "33712": "444bb0dd6fd9360af7de5bb7b8d9146682f1dc67", "33713": "66c53fd0ec0d21b4d02bf35bcd7288d5a8a91e77", "33715": "44e07b25ec419d4de20de00edc54346f81d70011", "33717": "13f38245252382b4a1a5f25ebe9dd27c9fff43fb", "33718": "5dd6efc209f5a47aadc9813def6bb29695a14653", "33721": "29140d44f9e96197fc5c74f460e6b9d87f731ea9", "33722": "1ccad128b412b168224ce2e8d534578d5b6dd0d6", "33723": "ac70f230995aa1bbee97b5db7bfdc28e5c5ed14b", "33724": "aeafdd66e4f224f7dee84c40b211595c582c4509", "33726": "ced983358b06576af1a73c3e936171cc6dc98a6d", "33727": "7e410c166d298ba61d4e33af55968f6f7d25a005", "33728": "132fca0af1d56d4f41b6dbd04a31fd30e116f9e4", "33729": "b02728c19f2ef2cf44258ecc3a77371e70edcd4d", "33730": "3b632d97a1dd2717ed6c4552468e36fdd0bb12ef", "33731": "4179a4409239ceebb42987d245711b5bdc3c0521", "33732": "6bb8f73e75bb5d25ca752f34f54705cdc533da54", "33736": "4d18871d398248c5876035f5aa139292e6a05279", "33737": "cb04202de30f11730fac45f5206df1bf0ace2d28", "33740": "530e460ab67a949dfeb9789cc0ddb74374f71572", "33741": "d89f1622b06ef8f79687e7e1c18337e0ffc820ce", "33742": "02adb3dca764e0a3ec7a70f2455cb6165ba8a6bd", "33743": "ce3260110f8f5e17c604e7e1a67ed7f8fb07f5fc", "33744": "f298507b153a166bdd2a919274e039c45e740c5d", "33745": "f33b3c641b33c51017e2c5694bb5e54650d1caba", "33748": "1151e3b2dd6b2ce849360d5138c75fcf150ec290", "33749": "a344dc904bb3a3918dde1677e210cd970ef66c3a", "33750": "b056c63b2fee3418c872f7144128af8c4087f588", "33751": "d3854657e1c9842b8264b6cc90488ccfed0cd6a2", "33753": "b1dcfd5ce55c65ca08322dbb3a0dc1c39bfafe16", "33754": "005e0eb256fc524949a9e0cd24642e66e549eec8", "33756": "e1a42f36549510fc6b43c66ab40753b104a7767e", "33757": "a3ce35a8a01eec84885465030c8f8b64527b68a0", "33758": "56508fb9a5df3ab9d04057e25be959a00927d357", "33759": "455ffb2a8de132700e86fb6a3577613536003ed3", "33760": "d9ba285ac159d4113f1990ecfd13eeb2dda0ad29", "33761": "7f53afc69ceaabc47b1224e7c0fdd93dfb3faa7d", "33762": "19259187d5f1c381142cb3ab6215e63b7189dbee", "33764": "b39efd9364be19615fd39bfa80150eb6c04ed758", "33765": "3d47fb960892eac1b081fff1772d62131410c405", "33766": "02ab370845c3f41a2164f1e91bb7b0f6878ba667", "33767": "ff187c0ffe9088ae633787da32ea2b9bacae8fed", "33768": "b3913977ee03dbd19be92ec8adbc27a6ba237ee5", "33769": "4af57562b7d96cabd2383acfd80d8b083c7944f3", "33771": "c71645fff865c29e77bb81bd9510dba97d93a67c", "33773": "64da538b21d1c429f1dea585f5551951c10c5d99", "33774": "3b94ec55bfb5fb646855e60150bc044b96af4d66", "33775": "4ab1c76a4a28aca442410da173f91c42caa7c915", "33776": "dfd5d66b9131420b38ce37fef41d61f5f783fecc", "33777": "bb71ac8b9149ecc197581cb827215d6eac02f5fd", "33780": "db11fc0e1874ef7bca23a24fba11bd973113090c", "33781": "b1c6622bcfc0093ee1490d581dad724c431e1ea2", "33782": "75c1b9630aa089f66f24723a5b95a0d388773d6b", "33783": "852aa751fd4f2516a116e5d383dee357bac29d6a", "33784": "fa0187066bf8de71ad43055f59c71c0aff4f7f96", "33785": "d07931f183cdd9836c265222bf420320f9a940c5", "33786": "056edfaa6a4317280d9e10bb72e738ba5049ac37", "33787": "178e504c90ef2cfb6e2dccf5b409c3787e0a3bbe", "33788": "edf1ba13383e2dc296ee18f26206c5484e3ac3e3", "33789": "f9be5d90a6bb72f2d11f47046f483efbcd5a787e", "33790": "7b855c1b07ea05f599a8afb287a24f0cde499d91", "33791": "27f7365e3ea3d8827b7ccd210f2f9a39aa3cf601", "33793": "376f77da131bb45147ea67009b65ffbad59e4945", "33795": "4d102331d0b06d9e11c370da285867d4a1f993fd", "33796": "f7df8bf781b85649792052e778d5a76672011ffe", "33797": "948392b750cb0e557f2a2f2db8422327c48643b2", "33798": "aaa1b90df52295566fd171dd53c040365b8ab9e8", "33799": "161f7622cbf41075fcb1dd9d671359d74c7b05cb", "33800": "add6a4bde394ce5d777589f998a79c9b3a97dc99", "33801": "9312ddee46a04568ef607f28552e4fb557c3670e", "33802": "3e0c1dab6bcbe95ea1349f144e6f4bc606471ae0", "33803": "a07cb65459f24446e82354854ff6658f29414c0a", "33812": "ff9c8f4a56c243d4d7c101ed9d9d1da322eb5c59", "33813": "7389f03a5b274cca087221990b4bdbc4eafb2b9d", "33814": "bdbdab1d6c84b5ecd2f638b79491f652b57782f5", "33815": "6d6dc1a8b4f645e131799e9361541c2ce10e4564", "33818": "c7070353ed51ae7a66e5cdf67cc5400bf2f4f554", "33819": "f7f0df109f84ec70a61718b285b73a7527e65c91", "33820": "7ffb960f6d5a0e7a906ca7436e9136f1f59dd070", "33822": "f4f2d89724a07cff13b82cf4e477538b3b889ce1", "33823": "dd3914045aac8b2c603033367bad6754081d2a5a", "33824": "b3d18af7d7ae2c454b9dcef0f2c0c2ae89bea047", "33825": "a53cf8d479a72b4d0036116ec1df5b3394c75207", "33826": "acf3395aaafbc15ce461f6667f0b1d63bf3766d1", "33828": "5b9f980880776923d65d910935f10c2f4a7e42a3", "33830": "5d04432f2896ee3beeed73feb544e9c9c7086820", "33831": "c293caf2e94ca50d8036d43324d05b516392eb16", "33832": "eb7f903e2fe1cf4890e2407ddd3791d9ee9dae87", "33833": "9de579e3cfe28bcf2b1debfb8290e200c74d76e2", "33834": "78947dd9fb06da2a3945209ec661ca825a746cdf", "33835": "af43bfcddbd761ed8b7329cc1951c7cd4f9e61ca", "33837": "4a4e32dda39ebeb8f6c73dd3618a804ac8f37298", "33839": "d42757a0f95b02fd611802286e28936706b95c09", "33840": "83858b23ce172782a38d4408767615e560cb7a3c", "33843": "e9ea582ccc0c31088921a019770745be05e65d8d", "33844": "251b512ff7eeed4a34ff436c53b139229df8976c", "33845": "52c653b437db67815203872de6179b1f7adeb148", "33846": "3f48f28bde59f3a32977272e335e2d1dab1a9695", "33847": "4d74fbdfbdb8523ed4d73209d8c4c3753da8eb2f", "33848": "dee2bac09767f82531b02994ac29d854173c89e7", "33849": "2c996a620d8af05e84abc36ef1087303abba9ce7", "33850": "6169cba72dbe8c7e9c7f17ab38af15a256f083da", "33851": "b7a6133380cf6d60ba3b799cc6d724584be3b208", "33853": "ecc6ead06b54a6d5ac448f899f6c3136ef766ce9", "33855": "a7b9c5600f43609b29a21f6f2b75c43a0f347872", "33856": "bfa7e9fda1fdf87e60b198c4975ef4a30b2dc02f", "33857": "7888cf47e509bc61871c599ee1b636c0f98c9076", "33858": "ab76540ada429ffb6f10785f1623c47a997b5763", "33859": "26b17c21bf595a7a6f3d692bfcb25e2ece6c6671", "33870": "e316f5d8656cdb3c9f746468e6354a5c8408392d", "33871": "7c84082d54866c83f169683c2fd1712fed7fdfae", "33873": "c9b560c35d1a6f90ab1e9bb97aeaa85bfdfc64b7", "33874": "73dfc3009e13d86acc46509b65e6dffdfcac120a", "33875": "506fe537d7468b5fb853d6e06bfa0d22b84bd02d"}, "revision_to_date": {"288": 1298163988000, "862": 1315859521000, "874": 1316017084000, "926": 1317000085000, "933": 1317048249000, "981": 1317617173000, "1029": 1318197429000, "1084": 1318951906000, "1185": 1319509932000, "1194": 1320196542000, "1342": 1322277354000, "1440": 1323817436000, "1632": 1325734840000, "1812": 1327034032000, "2072": 1328826175000, "2077": 1328843532000, "2196": 1330553078000, "2247": 1330658997000, "2358": 1331927660000, "2539": 1334253112000, "2555": 1334276689000, "3074": 1338253482000, "3262": 1339519295000, "3266": 1339521874000, "3344": 1340247840000, "3360": 1340393682000, "3361": 1340394271000, "3393": 1340820112000, "3412": 1340986814000, "3418": 1340991466000, "3494": 1342184152000, "3551": 1342986141000, "3557": 1343003671000, "3912": 1348197360000, "3955": 1348710085000, "4026": 1349655420000, "4249": 1352505519000, "4289": 1352940069000, "4723": 1355269526000, "4816": 1355762888000, "5022": 1358831994000, "5767": 1365818352000, "5863": 1366678471000, "6664": 1373346771000, "6794": 1374697106000, "7983": 1385527286000, "8139": 1388422887000, "8234": 1389186315000, "8327": 1389878709000, "8680": 1391395738000, "9617": 1400278770000, "9713": 1401450122000, "10140": 1405035967000, "10501": 1410094321000, "10793": 1412642319000, "10853": 1413672736000, "10956": 1415452422000, "11042": 1416578711000, "11188": 1418306362000, "11528": 1426255236000, "11564": 1427031398000, "11906": 1431306604000, "12077": 1434192334000, "12091": 1434584708000, "12722": 1441988415000, "12860": 1443887330000, "12889": 1444306718000, "13158": 1448038103000, "13524": 1455378460000, "13615": 1457534291000, "13626": 1457732611000, "13836": 1462283462000, "14282": 1473277332000, "14330": 1475416385000, "14435": 1478182795000, "14706": 1482594798000, "15300": 1492832004000, "15357": 1493909668000, "15365": 1493951109000, "15371": 1494003581000, "15372": 1494012477000, "15574": 1496609647000, "15686": 1499446527000, "16095": 1507858703000, "16141": 1509117925000, "16142": 1509128814000, "16592": 1513050947000, "16694": 1514550565000, "16721": 1514663812000, "17530": 1525259813000, "17532": 1525272424000, "17589": 1526415166000, "17590": 1526438450000, "17746": 1528825328000, "17916": 1530828264000, "17943": 1530976196000, "18118": 1533316766000, "19274": 1547215888000, "19354": 1548430346000, "19355": 1548451808000, "19436": 1549228549000, "19671": 1552425131000, "20330": 1562213026000, "20423": 1563465802000, "20424": 1563479338000, "20697": 1566484565000, "21096": 1571414970000, "21232": 1572553014000, "22237": 1578605090000, "22238": 1578622290000, "22538": 1580334415000, "22700": 1580919329000, "23185": 1584024103000, "23272": 1584537529000, "24131": 1590671799000, "24338": 1592394604000, "24593": 1595012630000, "24603": 1595942099000, "24604": 1595964517000, "24770": 1597942487000, "24989": 1599582504000, "25339": 1601911652000, "25725": 1604062750000, "26258": 1607341330000, "26276": 1607430704000, "26277": 1607434178000, "26509": 1608990420000, "26847": 1611141662000, "27078": 1612868119000, "27326": 1614678216000, "27737": 1618243153000, "28350": 1623498340000, "28351": 1623500344000, "28359": 1623604768000, "28492": 1624355610000, "28584": 1625213575000, "28769": 1627203891000, "28954": 1629031534000, "29206": 1631440969000, "29489": 1634473678000, "29970": 1639304448000, "30182": 1641387616000, "30183": 1641391555000, "30391": 1642847731000, "30639": 1644656651000, "30963": 1648885576000, "31386": 1655980525000, "31689": 1660584073000, "31690": 1660584323000, "31691": 1660584477000, "31692": 1660585657000, "31693": 1660587184000, "31694": 1660597913000, "31695": 1660604949000, "31696": 1660605765000, "31697": 1660608420000, "31703": 1660674923000, "31704": 1660675099000, "31705": 1660675303000, "31706": 1660676637000, "31707": 1660685026000, "31712": 1660700310000, "31713": 1660701553000, "31714": 1660701572000, "31715": 1660701704000, "31716": 1660755064000, "31717": 1660770913000, "31718": 1660771179000, "31719": 1660773608000, "31720": 1660775584000, "31721": 1660803399000, "31727": 1660839948000, "31728": 1660847389000, "31729": 1660853637000, "31748": 1660954125000, "31749": 1660954481000, "31750": 1660963209000, "31751": 1660980586000, "31752": 1660998736000, "31754": 1661021123000, "31759": 1661198100000, "31760": 1661200583000, "31761": 1661200852000, "31764": 1661209097000, "31765": 1661213657000, "31775": 1661274765000, "31776": 1661275106000, "31777": 1661275563000, "31778": 1661341283000, "31779": 1661353248000, "31782": 1661373090000, "31783": 1661373200000, "31785": 1661426566000, "31789": 1661463476000, "31790": 1661463549000, "31791": 1661465147000, "31794": 1661466440000, "31795": 1661504846000, "31802": 1661540574000, "31803": 1661549885000, "31804": 1661550024000, "31805": 1661553641000, "31806": 1661554006000, "31807": 1661792874000, "31808": 1661792942000, "31809": 1661794855000, "31810": 1661796878000, "31811": 1661809443000, "31812": 1661813117000, "31814": 1661813314000, "31817": 1661861776000, "31818": 1661861887000, "31823": 1661880328000, "31824": 1661891970000, "31827": 1661897643000, "31828": 1661928513000, "31829": 1661936829000, "31833": 1661963410000, "31834": 1661966076000, "31835": 1661967256000, "31836": 1661973090000, "31837": 1661973206000, "31838": 1661979842000, "31839": 1661991522000, "31840": 1662016494000, "31841": 1662016580000, "31843": 1662022633000, "31845": 1662060476000, "31846": 1662063876000, "31847": 1662064506000, "31848": 1662065939000, "31849": 1662067710000, "31850": 1662102327000, "31853": 1662137657000, "31854": 1662137763000, "31855": 1662139607000, "31856": 1662146718000, "31857": 1662148093000, "31859": 1662153978000, "31860": 1662154364000, "31861": 1662219459000, "31862": 1662234797000, "31863": 1662292467000, "31864": 1662397638000, "31866": 1662455402000, "31867": 1662473035000, "31868": 1662473588000, "31869": 1662485500000, "31870": 1662486252000, "31875": 1662494929000, "31876": 1662495256000, "31877": 1662495676000, "31878": 1662495841000, "31879": 1662496790000, "31882": 1662534756000, "31885": 1662568141000, "31886": 1662572381000, "31887": 1662573514000, "31888": 1662574096000, "31889": 1662582244000, "31890": 1662582428000, "31892": 1662591015000, "31896": 1662622494000, "31898": 1662650041000, "31899": 1662650394000, "31900": 1662660399000, "31902": 1662662651000, "31903": 1662663299000, "31904": 1662663541000, "31908": 1662741681000, "31911": 1662744060000, "31912": 1662745246000, "31913": 1662745374000, "31914": 1662746972000, "31915": 1662750632000, "31917": 1662760978000, "31918": 1662807274000, "31919": 1662845595000, "31921": 1663001780000, "31922": 1663001868000, "31923": 1663002007000, "31930": 1663007512000, "31931": 1663007642000, "31933": 1663010678000, "31934": 1663027448000, "31935": 1663028025000, "31936": 1663054354000, "31937": 1663085553000, "31938": 1663085653000, "31939": 1663085769000, "31940": 1663087563000, "31942": 1663089871000, "31944": 1663096528000, "31946": 1663109917000, "31947": 1663171107000, "31948": 1663171224000, "31949": 1663171612000, "31950": 1663172357000, "31952": 1663177117000, "31953": 1663182149000, "31954": 1663191113000, "31957": 1663201007000, "31958": 1663201430000, "31960": 1663242248000, "31961": 1663242417000, "31964": 1663260362000, "31965": 1663260556000, "31966": 1663260901000, "31967": 1663263407000, "31971": 1663283989000, "31972": 1663348722000, "31973": 1663349423000, "31974": 1663349578000, "31978": 1663366275000, "31980": 1663500085000, "31982": 1663520091000, "31984": 1663538905000, "31985": 1663544674000, "31988": 1663583846000, "31989": 1663622240000, "32001": 1663628901000, "32002": 1663629067000, "32003": 1663629234000, "32004": 1663629494000, "32005": 1663629717000, "32006": 1663659759000, "32008": 1663681782000, "32009": 1663683620000, "32014": 1663695794000, "32015": 1663695895000, "32016": 1663696107000, "32017": 1663698709000, "32018": 1663699559000, "32019": 1663716189000, "32020": 1663780705000, "32021": 1663780904000, "32023": 1663781627000, "32025": 1663782881000, "32026": 1663783261000, "32027": 1663783358000, "32028": 1663786487000, "32030": 1663850991000, "32031": 1663862719000, "32032": 1663863260000, "32034": 1663864804000, "32035": 1663869013000, "32036": 1663869298000, "32037": 1663876833000, "32040": 1663929435000, "32041": 1663936071000, "32042": 1663953031000, "32045": 1663953855000, "32046": 1663955106000, "32047": 1663956055000, "32048": 1663956116000, "32049": 1663956408000, "32053": 1663969892000, "32055": 1663970803000, "32057": 1664152007000, "32058": 1664213568000, "32059": 1664214661000, "32060": 1664217363000, "32061": 1664221229000, "32065": 1664232211000, "32066": 1664232439000, "32067": 1664232538000, "32069": 1664233089000, "32070": 1664233243000, "32072": 1664265192000, "32074": 1664273119000, "32077": 1664281315000, "32078": 1664294527000, "32079": 1664296992000, "32080": 1664310084000, "32082": 1664317956000, "32084": 1664321597000, "32086": 1664372582000, "32087": 1664379630000, "32088": 1664407434000, "32089": 1664407545000, "32090": 1664456172000, "32091": 1664457739000, "32092": 1664458839000, "32093": 1664459258000, "32094": 1664459473000, "32104": 1664495671000, "32105": 1664495763000, "32106": 1664495990000, "32107": 1664499072000, "32108": 1664499140000, "32112": 1664522681000, "32113": 1664522884000, "32116": 1664538532000, "32118": 1664547535000, "32119": 1664554803000, "32122": 1664613067000, "32123": 1664716662000, "32124": 1664743717000, "32125": 1664809181000, "32126": 1664814563000, "32127": 1664814943000, "32128": 1664816993000, "32129": 1664818141000, "32130": 1664828850000, "32131": 1664830993000, "32132": 1664836173000, "32133": 1664844098000, "32135": 1664901576000, "32136": 1664906177000, "32137": 1664906521000, "32138": 1664907016000, "32139": 1664907721000, "32140": 1664908101000, "32141": 1664918589000, "32142": 1664924735000, "32144": 1664985779000, "32145": 1664986069000, "32146": 1664993041000, "32147": 1664993795000, "32150": 1665001244000, "32151": 1665005457000, "32152": 1665009018000, "32153": 1665009288000, "32154": 1665010711000, "32156": 1665043230000, "32157": 1665071960000, "32158": 1665072382000, "32159": 1665072966000, "32160": 1665074608000, "32161": 1665075381000, "32162": 1665092981000, "32163": 1665140504000, "32164": 1665142026000, "32165": 1665150868000, "32167": 1665160893000, "32168": 1665162882000, "32169": 1665163377000, "32170": 1665163439000, "32171": 1665163622000, "32173": 1665176729000, "32174": 1665188801000, "32175": 1665188925000, "32177": 1665418215000, "32178": 1665420768000, "32179": 1665420819000, "32180": 1665424953000, "32181": 1665425068000, "32183": 1665440003000, "32184": 1665440172000, "32185": 1665472127000, "32186": 1665505298000, "32187": 1665505750000, "32188": 1665505865000, "32189": 1665508631000, "32190": 1665510083000, "32191": 1665511251000, "32192": 1665520091000, "32194": 1665520946000, "32195": 1665521061000, "32196": 1665528163000, "32197": 1665595042000, "32198": 1665595356000, "32199": 1665596019000, "32200": 1665596832000, "32201": 1665615982000, "32202": 1665616717000, "32203": 1665644040000, "32205": 1665676105000, "32206": 1665676177000, "32208": 1665690385000, "32210": 1665699744000, "32211": 1665699903000, "32212": 1665700721000, "32213": 1665733418000, "32215": 1665738165000, "32216": 1665739206000, "32218": 1665766794000, "32219": 1665767069000, "32220": 1665767190000, "32221": 1665767981000, "32222": 1665769406000, "32228": 1665785838000, "32229": 1665785864000, "32230": 1665785929000, "32231": 1665786808000, "32232": 1665787196000, "32233": 1665831296000, "32235": 1665921584000, "32236": 1665921691000, "32237": 1665921789000, "32238": 1665921925000, "32239": 1665924791000, "32240": 1665990670000, "32241": 1665990891000, "32243": 1666000542000, "32244": 1666006179000, "32245": 1666021640000, "32246": 1666021969000, "32247": 1666023127000, "32248": 1666023511000, "32249": 1666023851000, "32254": 1666038212000, "32255": 1666039919000, "32256": 1666042811000, "32257": 1666043208000, "32258": 1666048937000, "32259": 1666077615000, "32261": 1666084960000, "32262": 1666085039000, "32263": 1666086298000, "32264": 1666116824000, "32265": 1666118252000, "32266": 1666118335000, "32267": 1666119030000, "32268": 1666129595000, "32269": 1666154560000, "32270": 1666167038000, "32271": 1666177197000, "32272": 1666190661000, "32273": 1666195788000, "32274": 1666196231000, "32276": 1666213941000, "32277": 1666214018000, "32281": 1666253578000, "32282": 1666253875000, "32283": 1666253983000, "32284": 1666254090000, "32285": 1666254535000, "32294": 1666285191000, "32297": 1666288704000, "32298": 1666289034000, "32299": 1666296145000, "32300": 1666296251000, "32301": 1666359725000, "32302": 1666360328000, "32303": 1666370836000, "32304": 1666372554000, "32305": 1666373375000, "32307": 1666376871000, "32308": 1666377011000, "32315": 1666394863000, "32316": 1666395089000, "32317": 1666399149000, "32318": 1666399197000, "32319": 1666400675000, "32320": 1666438930000, "32321": 1666546061000, "32322": 1666546293000, "32323": 1666563340000, "32324": 1666571012000, "32325": 1666590367000, "32326": 1666590502000, "32327": 1666590544000, "32328": 1666626066000, "32329": 1666628529000, "32330": 1666634758000, "32339": 1666645609000, "32340": 1666645811000, "32341": 1666646995000, "32342": 1666647048000, "32343": 1666647819000, "32344": 1666695394000, "32345": 1666706679000, "32346": 1666706797000, "32347": 1666706898000, "32351": 1666722903000, "32352": 1666723051000, "32353": 1666728011000, "32354": 1666731755000, "32355": 1666732063000, "32356": 1666769114000, "32357": 1666776789000, "32358": 1666776840000, "32359": 1666776906000, "32360": 1666777217000, "32369": 1666806154000, "32370": 1666806388000, "32371": 1666807089000, "32372": 1666811217000, "32373": 1666816440000, "32374": 1666823938000, "32375": 1666829347000, "32376": 1666862878000, "32377": 1666883640000, "32378": 1666887005000, "32379": 1666887832000, "32380": 1666887957000, "32381": 1666888638000, "32382": 1666928200000, "32383": 1666963099000, "32384": 1666963153000, "32387": 1666974684000, "32388": 1666975670000, "32389": 1666981662000, "32390": 1666982157000, "32391": 1666983162000, "32392": 1666999015000, "32393": 1667007740000, "32394": 1667062310000, "32395": 1667063473000, "32396": 1667065853000, "32397": 1667116675000, "32398": 1667132469000, "32399": 1667146700000, "32400": 1667226902000, "32401": 1667235957000, "32402": 1667236407000, "32409": 1667242054000, "32410": 1667242248000, "32411": 1667243879000, "32413": 1667252813000, "32414": 1667252899000, "32415": 1667304552000, "32416": 1667304616000, "32418": 1667314026000, "32419": 1667314086000, "32420": 1667314164000, "32421": 1667314459000, "32424": 1667324428000, "32431": 1667344835000, "32433": 1667349778000, "32434": 1667349990000, "32435": 1667350421000, "32436": 1667350937000, "32449": 1667413539000, "32450": 1667414632000, "32451": 1667415115000, "32452": 1667415215000, "32453": 1667415410000, "32454": 1667422815000, "32455": 1667423222000, "32456": 1667463919000, "32457": 1667464367000, "32466": 1667493125000, "32467": 1667493389000, "32468": 1667494194000, "32469": 1667496798000, "32470": 1667497665000, "32471": 1667501098000, "32472": 1667507363000, "32473": 1667541799000, "32474": 1667557055000, "32477": 1667580893000, "32478": 1667581014000, "32479": 1667582438000, "32480": 1667585381000, "32481": 1667585642000, "32484": 1667593843000, "32485": 1667595122000, "32486": 1667597205000, "32487": 1667605250000, "32488": 1667626270000, "32489": 1667645366000, "32490": 1667664879000, "32491": 1667667748000, "32492": 1667681548000, "32493": 1667720854000, "32494": 1667738950000, "32495": 1667746500000, "32496": 1667753624000, "32497": 1667806108000, "32498": 1667823803000, "32499": 1667842481000, "32500": 1667842761000, "32507": 1667848022000, "32508": 1667848114000, "32509": 1667849098000, "32510": 1667849922000, "32511": 1667854384000, "32512": 1667862262000, "32513": 1667862372000, "32514": 1667862480000, "32515": 1667897673000, "32516": 1667908245000, "32518": 1667932398000, "32519": 1667933329000, "32520": 1667937863000, "32521": 1667950864000, "32522": 1667950974000, "32523": 1667984936000, "32524": 1667990800000, "32528": 1668015465000, "32529": 1668016436000, "32530": 1668016736000, "32531": 1668018274000, "32532": 1668025166000, "32534": 1668027714000, "32535": 1668033441000, "32536": 1668034919000, "32537": 1668041966000, "32538": 1668043940000, "32543": 1668112402000, "32544": 1668112488000, "32545": 1668112599000, "32546": 1668113802000, "32547": 1668117551000, "32549": 1668127590000, "32550": 1668130781000, "32551": 1668136002000, "32552": 1668162276000, "32555": 1668188717000, "32556": 1668188925000, "32557": 1668191414000, "32558": 1668200038000, "32560": 1668275386000, "32561": 1668287155000, "32562": 1668326308000, "32563": 1668328211000, "32564": 1668337937000, "32565": 1668391024000, "32566": 1668452605000, "32567": 1668459124000, "32568": 1668460199000, "32569": 1668460288000, "32570": 1668487477000, "32571": 1668488136000, "32572": 1668513362000, "32573": 1668521987000, "32574": 1668536507000, "32575": 1668548911000, "32576": 1668552759000, "32577": 1668588215000, "32578": 1668589093000, "32579": 1668589353000, "32581": 1668593728000, "32582": 1668605544000, "32584": 1668613261000, "32590": 1668634172000, "32591": 1668636249000, "32592": 1668637152000, "32593": 1668638140000, "32594": 1668638740000, "32598": 1668659801000, "32599": 1668680822000, "32600": 1668680912000, "32601": 1668686391000, "32602": 1668691053000, "32608": 1668723218000, "32609": 1668727518000, "32610": 1668727963000, "32611": 1668735410000, "32612": 1668735586000, "32613": 1668793086000, "32614": 1668794185000, "32615": 1668796036000, "32616": 1668796857000, "32617": 1668797017000, "32619": 1668814279000, "32620": 1668814334000, "32621": 1668814656000, "32622": 1668815082000, "32623": 1668824470000, "32624": 1668842110000, "32627": 1668863136000, "32629": 1668886195000, "32630": 1668955665000, "32631": 1668962052000, "32632": 1669007830000, "32634": 1669008974000, "32636": 1669063680000, "32637": 1669067759000, "32638": 1669067834000, "32641": 1669082836000, "32642": 1669082973000, "32643": 1669082994000, "32644": 1669083178000, "32645": 1669083532000, "32646": 1669107326000, "32647": 1669107478000, "32648": 1669112169000, "32649": 1669112261000, "32650": 1669130514000, "32657": 1669161629000, "32658": 1669162187000, "32659": 1669170906000, "32660": 1669171888000, "32661": 1669171954000, "32668": 1669227090000, "32669": 1669229035000, "32670": 1669229331000, "32671": 1669229425000, "32672": 1669231422000, "32673": 1669237755000, "32674": 1669241351000, "32675": 1669242236000, "32676": 1669244264000, "32677": 1669251203000, "32678": 1669277142000, "32679": 1669291122000, "32681": 1669299057000, "32682": 1669301603000, "32685": 1669313020000, "32686": 1669318744000, "32687": 1669403609000, "32688": 1669403688000, "32689": 1669403784000, "32690": 1669479015000, "32691": 1669479656000, "32692": 1669500715000, "32693": 1669538749000, "32694": 1669565116000, "32695": 1669572641000, "32697": 1669625846000, "32698": 1669626498000, "32699": 1669654733000, "32700": 1669657503000, "32701": 1669659465000, "32707": 1669676148000, "32708": 1669676294000, "32709": 1669685670000, "32710": 1669690616000, "32711": 1669691918000, "32712": 1669695116000, "32714": 1669709556000, "32715": 1669710011000, "32717": 1669744276000, "32718": 1669744938000, "32719": 1669748377000, "32720": 1669748781000, "32721": 1669755101000, "32722": 1669761787000, "32723": 1669762824000, "32724": 1669763583000, "32725": 1669825891000, "32726": 1669850921000, "32727": 1669851340000, "32728": 1669851646000, "32729": 1669856437000, "32730": 1669865214000, "32731": 1669920238000, "32732": 1669921196000, "32733": 1669922786000, "32734": 1669924605000, "32735": 1669926662000, "32736": 1669927279000, "32737": 1669932397000, "32738": 1669941070000, "32739": 1669951520000, "32740": 1669951667000, "32742": 1669975398000, "32743": 1669979588000, "32744": 1669986847000, "32745": 1669994650000, "32746": 1669995006000, "32754": 1670011121000, "32755": 1670012993000, "32756": 1670015202000, "32757": 1670016447000, "32758": 1670022202000, "32759": 1670035700000, "32760": 1670045776000, "32761": 1670071631000, "32762": 1670093303000, "32763": 1670093366000, "32764": 1670097355000, "32765": 1670100616000, "32766": 1670166423000, "32767": 1670171597000, "32768": 1670174846000, "32769": 1670231902000, "32770": 1670232248000, "32771": 1670232321000, "32772": 1670232443000, "32773": 1670234398000, "32774": 1670240903000, "32775": 1670268904000, "32776": 1670269335000, "32777": 1670270879000, "32778": 1670283251000, "32779": 1670292352000, "32780": 1670346878000, "32781": 1670346909000, "32782": 1670347062000, "32785": 1670349030000, "32786": 1670351281000, "32787": 1670353331000, "32788": 1670360860000, "32789": 1670364117000, "32790": 1670415400000, "32791": 1670432658000, "32792": 1670432735000, "32793": 1670436940000, "32794": 1670437715000, "32795": 1670438513000, "32796": 1670439606000, "32797": 1670446166000, "32798": 1670459902000, "32799": 1670469790000, "32800": 1670470114000, "32801": 1670470845000, "32805": 1670512994000, "32807": 1670522690000, "32808": 1670523962000, "32809": 1670537045000, "32810": 1670545258000, "32811": 1670573744000, "32812": 1670575705000, "32813": 1670587896000, "32815": 1670601421000, "32816": 1670687050000, "32817": 1670691773000, "32818": 1670697298000, "32820": 1670699790000, "32821": 1670704384000, "32822": 1670709150000, "32823": 1670757140000, "32824": 1670767206000, "32825": 1670781734000, "32826": 1670795251000, "32827": 1670829783000, "32828": 1670864684000, "32829": 1670869361000, "32830": 1670869695000, "32832": 1670873634000, "32833": 1670877628000, "32834": 1670879647000, "32835": 1670879910000, "32841": 1670898217000, "32842": 1670899222000, "32843": 1670899863000, "32844": 1670900572000, "32845": 1670900802000, "32848": 1670934624000, "32849": 1670937777000, "32850": 1670938007000, "32851": 1670938197000, "32854": 1670948188000, "32856": 1670959506000, "32857": 1670961024000, "32858": 1671002631000, "32859": 1671032495000, "32860": 1671035332000, "32861": 1671040769000, "32862": 1671050450000, "32863": 1671091806000, "32864": 1671110338000, "32865": 1671111401000, "32867": 1671128549000, "32868": 1671128722000, "32869": 1671133399000, "32872": 1671135457000, "32873": 1671145494000, "32875": 1671161173000, "32876": 1671183379000, "32877": 1671183595000, "32878": 1671215303000, "32879": 1671217215000, "32880": 1671219691000, "32881": 1671262096000, "32882": 1671274137000, "32883": 1671285528000, "32884": 1671288289000, "32885": 1671302386000, "32886": 1671302603000, "32893": 1671310490000, "32894": 1671310732000, "32895": 1671310866000, "32896": 1671311037000, "32897": 1671316527000, "32898": 1671327883000, "32899": 1671340029000, "32900": 1671369010000, "32901": 1671440155000, "32902": 1671457381000, "32903": 1671475351000, "32904": 1671475593000, "32911": 1671478590000, "32912": 1671479841000, "32913": 1671479948000, "32914": 1671481065000, "32915": 1671486421000, "32916": 1671540944000, "32917": 1671559957000, "32918": 1671560893000, "32919": 1671572074000, "32920": 1671624383000, "32921": 1671629581000, "32922": 1671629861000, "32923": 1671630145000, "32925": 1671652152000, "32926": 1671652644000, "32927": 1671664460000, "32928": 1671709636000, "32929": 1671734029000, "32930": 1671735544000, "32931": 1671742787000, "32932": 1671744020000, "32933": 1671749354000, "32935": 1671817271000, "32941": 1671838313000, "32942": 1671865881000, "32943": 1671876071000, "32944": 1671911375000, "32945": 1671913128000, "32946": 1672120755000, "32947": 1672128967000, "32948": 1672165857000, "32949": 1672166049000, "32958": 1672173297000, "32959": 1672173426000, "32960": 1672173495000, "32961": 1672174333000, "32962": 1672180115000, "32963": 1672182660000, "32964": 1672182873000, "32965": 1672188534000, "32966": 1672211336000, "32967": 1672216073000, "32973": 1672250869000, "32974": 1672250988000, "32975": 1672251078000, "32976": 1672251123000, "32977": 1672257280000, "32978": 1672261810000, "32979": 1672263989000, "32980": 1672273068000, "32981": 1672273950000, "32982": 1672309768000, "32983": 1672327748000, "32984": 1672344903000, "32985": 1672357005000, "32986": 1672412795000, "32987": 1672412837000, "32988": 1672476906000, "32989": 1672650162000, "32990": 1672673634000, "32991": 1672684550000, "32992": 1672693021000, "32993": 1672733051000, "32994": 1672733717000, "32995": 1672748743000, "32996": 1672752124000, "32997": 1672760573000, "32998": 1672768330000, "32999": 1672771802000, "33007": 1672783821000, "33008": 1672783831000, "33009": 1672784662000, "33010": 1672784833000, "33011": 1672785724000, "33012": 1672795227000, "33013": 1672796239000, "33014": 1672796520000, "33015": 1672799812000, "33016": 1672824220000, "33025": 1672856918000, "33026": 1672858867000, "33027": 1672858960000, "33028": 1672859503000, "33030": 1672867591000, "33031": 1672886685000, "33032": 1672924530000, "33033": 1672926049000, "33035": 1672927699000, "33036": 1672953015000, "33037": 1672961252000, "33038": 1672961367000, "33039": 1672962084000, "33040": 1672962195000, "33041": 1672965550000, "33042": 1672965584000, "33043": 1672995183000, "33044": 1673001181000, "33045": 1673002480000, "33047": 1673030398000, "33048": 1673030469000, "33049": 1673031801000, "33055": 1673041421000, "33056": 1673046508000, "33057": 1673047018000, "33058": 1673047557000, "33059": 1673048879000, "33061": 1673083857000, "33062": 1673084398000, "33063": 1673113715000, "33064": 1673113807000, "33065": 1673125833000, "33066": 1673135862000, "33067": 1673172281000, "33068": 1673172431000, "33069": 1673196269000, "33070": 1673276710000, "33071": 1673286768000, "33072": 1673294357000, "33073": 1673294968000, "33082": 1673305507000, "33083": 1673307004000, "33084": 1673307541000, "33085": 1673308350000, "33086": 1673308497000, "33087": 1673339222000, "33088": 1673351283000, "33089": 1673357688000, "33090": 1673365277000, "33091": 1673369748000, "33092": 1673369898000, "33093": 1673375767000, "33094": 1673379381000, "33095": 1673384548000, "33096": 1673392135000, "33097": 1673392195000, "33098": 1673403716000, "33099": 1673434860000, "33100": 1673438035000, "33101": 1673441583000, "33102": 1673444668000, "33103": 1673480755000, "33104": 1673487906000, "33105": 1673511198000, "33106": 1673511244000, "33107": 1673515892000, "33110": 1673533468000, "33113": 1673539373000, "33114": 1673539477000, "33116": 1673543797000, "33123": 1673555701000, "33124": 1673557623000, "33125": 1673558937000, "33126": 1673559013000, "33127": 1673559586000, "33128": 1673569154000, "33129": 1673569544000, "33130": 1673596678000, "33131": 1673598090000, "33137": 1673619080000, "33139": 1673625411000, "33140": 1673628161000, "33141": 1673628266000, "33143": 1673628514000, "33149": 1673650879000, "33150": 1673651637000, "33151": 1673652422000, "33152": 1673654024000, "33153": 1673654324000, "33155": 1673694320000, "33156": 1673711565000, "33158": 1673723480000, "33159": 1673747460000, "33160": 1673796378000, "33161": 1673817236000, "33162": 1673827789000, "33163": 1673860228000, "33164": 1673881158000, "33165": 1673890433000, "33166": 1673890745000, "33173": 1673894533000, "33174": 1673895724000, "33175": 1673896693000, "33176": 1673896867000, "33177": 1673897613000, "33178": 1673928823000, "33179": 1673943744000, "33180": 1673956632000, "33181": 1673959396000, "33183": 1673976277000, "33184": 1673976922000, "33185": 1673977479000, "33186": 1673978008000, "33187": 1673978101000, "33189": 1673982468000, "33190": 1673982685000, "33191": 1673984518000, "33193": 1674003567000, "33194": 1674009280000, "33199": 1674035667000, "33200": 1674045109000, "33202": 1674053887000, "33203": 1674054777000, "33204": 1674057960000, "33226": 1674072457000, "33227": 1674072576000, "33228": 1674073779000, "33229": 1674084243000, "33230": 1674094850000, "33231": 1674098803000, "33232": 1674118190000, "33234": 1674150333000, "33235": 1674150391000, "33236": 1674150601000, "33239": 1674153433000, "33240": 1674158460000, "33241": 1674160818000, "33242": 1674162751000, "33243": 1674163891000, "33244": 1674214350000, "33245": 1674214450000, "33246": 1674234182000, "33247": 1674234194000, "33255": 1674239468000, "33256": 1674239781000, "33257": 1674240348000, "33258": 1674241006000, "33259": 1674241168000, "33260": 1674266694000, "33261": 1674288533000, "33262": 1674349360000, "33263": 1674349935000, "33264": 1674399168000, "33265": 1674413621000, "33266": 1674488591000, "33267": 1674496593000, "33272": 1674501387000, "33273": 1674501556000, "33274": 1674501912000, "33275": 1674502885000, "33276": 1674503157000, "33277": 1674547184000, "33278": 1674553911000, "33279": 1674567253000, "33280": 1674567303000, "33281": 1674573026000, "33282": 1674584493000, "33283": 1674585777000, "33284": 1674585950000, "33285": 1674586457000, "33286": 1674586953000, "33287": 1674596673000, "33288": 1674666086000, "33289": 1674667233000, "33290": 1674679904000, "33291": 1674686646000, "33292": 1674688528000, "33293": 1674693653000, "33294": 1674731055000, "33295": 1674751988000, "33298": 1674756571000, "33299": 1674759632000, "33300": 1674759739000, "33301": 1674760513000, "33302": 1674760745000, "33303": 1674761382000, "33304": 1674761778000, "33305": 1674761898000, "33306": 1674781903000, "33307": 1674783627000, "33308": 1674808417000, "33309": 1674855625000, "33310": 1674858069000, "33311": 1674858140000, "33312": 1674858455000, "33313": 1674862215000, "33314": 1674862659000, "33315": 1674867104000, "33316": 1674868450000, "33317": 1674875488000, "33318": 1674912918000, "33322": 1675071470000, "33323": 1675075866000, "33324": 1675091244000, "33325": 1675093674000, "33331": 1675105301000, "33332": 1675105541000, "33333": 1675106325000, "33334": 1675107134000, "33335": 1675107588000, "33336": 1675109087000, "33337": 1675109264000, "33339": 1675153145000, "33340": 1675179874000, "33341": 1675193010000, "33346": 1675196383000, "33347": 1675196441000, "33348": 1675200212000, "33349": 1675200512000, "33350": 1675200687000, "33351": 1675208724000, "33352": 1675225504000, "33353": 1675243825000, "33355": 1675253584000, "33356": 1675258621000, "33357": 1675258751000, "33358": 1675266688000, "33359": 1675267581000, "33367": 1675284825000, "33368": 1675288744000, "33369": 1675289727000, "33370": 1675294713000, "33371": 1675296730000, "33372": 1675345266000, "33378": 1675358266000, "33379": 1675358877000, "33380": 1675359853000, "33381": 1675360048000, "33382": 1675362306000, "33383": 1675363316000, "33384": 1675376205000, "33385": 1675385767000, "33386": 1675396031000, "33387": 1675417200000, "33388": 1675429339000, "33390": 1675440656000, "33391": 1675447967000, "33392": 1675448456000, "33393": 1675452102000, "33394": 1675452146000, "33397": 1675458426000, "33398": 1675458519000, "33399": 1675473054000, "33400": 1675473118000, "33401": 1675475201000, "33402": 1675538207000, "33403": 1675538373000, "33404": 1675538450000, "33405": 1675546525000, "33406": 1675548271000, "33407": 1675553485000, "33408": 1675603311000, "33409": 1675611510000, "33410": 1675628553000, "33411": 1675628941000, "33412": 1675638831000, "33413": 1675686801000, "33414": 1675691208000, "33415": 1675708930000, "33418": 1675712400000, "33419": 1675712972000, "33420": 1675713076000, "33421": 1675713815000, "33422": 1675717344000, "33423": 1675717766000, "33424": 1675724923000, "33425": 1675725134000, "33426": 1675735836000, "33427": 1675765607000, "33428": 1675778979000, "33429": 1675797760000, "33430": 1675798925000, "33431": 1675802092000, "33432": 1675802183000, "33433": 1675846868000, "33434": 1675865008000, "33435": 1675867303000, "33442": 1675876519000, "33443": 1675878404000, "33444": 1675878626000, "33445": 1675879062000, "33446": 1675879142000, "33448": 1675883692000, "33449": 1675893751000, "33450": 1675894387000, "33451": 1675904637000, "33452": 1675938677000, "33453": 1675938888000, "33454": 1675939743000, "33455": 1675945915000, "33471": 1675969769000, "33472": 1675978959000, "33473": 1675979198000, "33474": 1675979473000, "33475": 1675979754000, "33476": 1676004165000, "33477": 1676016011000, "33478": 1676024878000, "33479": 1676026054000, "33480": 1676031497000, "33481": 1676032004000, "33482": 1676036458000, "33490": 1676054109000, "33491": 1676055742000, "33492": 1676063950000, "33493": 1676063990000, "33494": 1676068574000, "33497": 1676091226000, "33498": 1676091343000, "33499": 1676112392000, "33500": 1676114726000, "33501": 1676115380000, "33504": 1676133059000, "33505": 1676137918000, "33506": 1676140468000, "33507": 1676142951000, "33508": 1676148528000, "33509": 1676192778000, "33510": 1676237490000, "33511": 1676310350000, "33512": 1676310494000, "33522": 1676315172000, "33523": 1676315732000, "33524": 1676321928000, "33525": 1676323209000, "33526": 1676324020000, "33527": 1676371466000, "33528": 1676373450000, "33529": 1676373938000, "33530": 1676373982000, "33531": 1676392449000, "33532": 1676400793000, "33533": 1676406989000, "33534": 1676407316000, "33535": 1676408288000, "33536": 1676408841000, "33537": 1676409304000, "33538": 1676455244000, "33539": 1676457492000, "33540": 1676458839000, "33542": 1676477701000, "33543": 1676479870000, "33544": 1676484001000, "33545": 1676484209000, "33546": 1676484502000, "33552": 1676496434000, "33553": 1676497695000, "33554": 1676501034000, "33555": 1676501698000, "33556": 1676513225000, "33567": 1676565513000, "33568": 1676565732000, "33569": 1676565872000, "33570": 1676566347000, "33571": 1676566625000, "33572": 1676581302000, "33573": 1676584794000, "33574": 1676591949000, "33575": 1676608438000, "33576": 1676629653000, "33577": 1676643053000, "33578": 1676656836000, "33579": 1676660534000, "33580": 1676661893000, "33581": 1676671392000, "33582": 1676671504000, "33583": 1676671589000, "33584": 1676682028000, "33585": 1676682253000, "33586": 1676682894000, "33587": 1676719896000, "33588": 1676741908000, "33589": 1676769551000, "33590": 1676814118000, "33591": 1676837716000, "33592": 1676863658000, "33593": 1676880667000, "33594": 1676887627000, "33595": 1676893361000, "33596": 1676910797000, "33597": 1676913330000, "33598": 1676924115000, "33599": 1676924793000, "33600": 1676926863000, "33601": 1676927124000, "33602": 1676927207000, "33603": 1676927431000, "33604": 1676929029000, "33607": 1676970295000, "33608": 1676970407000, "33609": 1676970712000, "33610": 1676971018000, "33611": 1676971113000, "33620": 1676988285000, "33621": 1677003888000, "33622": 1677005616000, "33623": 1677014040000, "33624": 1677016230000, "33625": 1677026654000, "33626": 1677057473000, "33627": 1677057863000, "33628": 1677059799000, "33629": 1677063782000, "33630": 1677074703000, "33640": 1677085796000, "33645": 1677101588000, "33646": 1677108653000, "33648": 1677110513000, "33649": 1677110607000, "33650": 1677111285000, "33653": 1677147456000, "33654": 1677147850000, "33656": 1677154038000, "33657": 1677161754000, "33658": 1677162455000, "33666": 1677195344000, "33667": 1677195486000, "33668": 1677197382000, "33670": 1677201188000, "33671": 1677201224000, "33673": 1677239790000, "33674": 1677253694000, "33675": 1677262090000, "33676": 1677262262000, "33680": 1677266001000, "33681": 1677266088000, "33682": 1677268172000, "33686": 1677276767000, "33687": 1677277309000, "33689": 1677291182000, "33690": 1677292101000, "33693": 1677346625000, "33694": 1677346837000, "33695": 1677347130000, "33696": 1677347191000, "33697": 1677347439000, "33701": 1677360194000, "33702": 1677361790000, "33703": 1677361857000, "33704": 1677365214000, "33706": 1677371033000, "33708": 1677399407000, "33709": 1677433391000, "33710": 1677436947000, "33712": 1677442849000, "33713": 1677448883000, "33715": 1677449772000, "33717": 1677458823000, "33718": 1677463921000, "33721": 1677511679000, "33722": 1677530125000, "33723": 1677532492000, "33724": 1677534781000, "33726": 1677569745000, "33727": 1677579875000, "33728": 1677581676000, "33729": 1677591219000, "33730": 1677605931000, "33731": 1677622502000, "33732": 1677624259000, "33736": 1677659439000, "33737": 1677673197000, "33740": 1677687730000, "33741": 1677687829000, "33742": 1677687901000, "33743": 1677707272000, "33744": 1677711253000, "33745": 1677711268000, "33748": 1677722653000, "33749": 1677725762000, "33750": 1677746160000, "33751": 1677747881000, "33753": 1677764541000, "33754": 1677795142000, "33756": 1677799874000, "33757": 1677800293000, "33758": 1677805775000, "33759": 1677810557000, "33760": 1677812420000, "33761": 1677835215000, "33762": 1677848007000, "33764": 1677870471000, "33765": 1677870510000, "33766": 1677893316000, "33767": 1677893458000, "33768": 1677896497000, "33769": 1677922997000, "33771": 1677947922000, "33773": 1678045040000, "33774": 1678087626000, "33775": 1678089031000, "33776": 1678091655000, "33777": 1678091941000, "33780": 1678103209000, "33781": 1678104195000, "33782": 1678111815000, "33783": 1678114649000, "33784": 1678122156000, "33785": 1678129529000, "33786": 1678139373000, "33787": 1678146200000, "33788": 1678184586000, "33789": 1678189656000, "33790": 1678213551000, "33791": 1678217999000, "33793": 1678221172000, "33795": 1678230713000, "33796": 1678230857000, "33797": 1678230989000, "33798": 1678233882000, "33799": 1678234253000, "33800": 1678249984000, "33801": 1678250084000, "33802": 1678266740000, "33803": 1678266785000, "33812": 1678311356000, "33813": 1678311893000, "33814": 1678312283000, "33815": 1678313089000, "33818": 1678319213000, "33819": 1678321296000, "33820": 1678356923000, "33822": 1678379508000, "33823": 1678381440000, "33824": 1678381907000, "33825": 1678382034000, "33826": 1678388850000, "33828": 1678398632000, "33830": 1678447926000, "33831": 1678450629000, "33832": 1678472219000, "33833": 1678472584000, "33834": 1678474623000, "33835": 1678477774000, "33837": 1678483818000, "33839": 1678495615000, "33840": 1678499878000, "33843": 1678531404000, "33844": 1678538064000, "33845": 1678538664000, "33846": 1678553542000, "33847": 1678563493000, "33848": 1678569984000, "33849": 1678588598000, "33850": 1678610541000, "33851": 1678708573000, "33853": 1678726195000, "33855": 1678727540000, "33856": 1678729791000, "33857": 1678729819000, "33858": 1678731640000, "33859": 1678735052000, "33870": 1678755227000, "33871": 1678760587000, "33873": 1678760710000, "33874": 1678760904000, "33875": 1678761102000}, "params": {"arch": ["x86_64"], "cpu": ["Intel(R) Core(TM) i7-4980HQ CPU @ 2.80GHz"], "machine": ["asv-runner"], "os": ["Linux 3.13.0-116-generic"], "ram": ["501692"], "python": ["3.8"], "numpy": ["", "1.23.5"], "Cython": ["0.29.32", "0.29.33"], "matplotlib": [""], "sqlalchemy": [""], "scipy": [""], "numba": [""], "numexpr": [""], "pytables": [""], "pyarrow": [""], "openpyxl": [""], "xlsxwriter": [""], "xlrd": [""], "xlwt": ["", null], "odfpy": [""], "jinja2": [""], "branch": ["main"]}, "graph_param_list": [{"arch": "x86_64", "cpu": "Intel(R) Core(TM) i7-4980HQ CPU @ 2.80GHz", "machine": "asv-runner", "os": "Linux 3.13.0-116-generic", "ram": "501692", "python": "3.8", "numpy": "", "Cython": "0.29.32", "matplotlib": "", "sqlalchemy": "", "scipy": "", "numba": "", "numexpr": "", "pytables": "", "pyarrow": "", "openpyxl": "", "xlsxwriter": "", "xlrd": "", "xlwt": "", "odfpy": "", "jinja2": "", "branch": "main"}, {"arch": "x86_64", "cpu": "Intel(R) Core(TM) i7-4980HQ CPU @ 2.80GHz", "machine": "asv-runner", "os": "Linux 3.13.0-116-generic", "ram": "501692", "python": "3.8", "numpy": "1.23.5", "Cython": "0.29.32", "matplotlib": "", "sqlalchemy": "", "scipy": "", "numba": "", "numexpr": "", "pytables": "", "pyarrow": "", "openpyxl": "", "xlsxwriter": "", "xlrd": "", "odfpy": "", "jinja2": "", "branch": "main", "xlwt": null}, {"arch": "x86_64", "cpu": "Intel(R) Core(TM) i7-4980HQ CPU @ 2.80GHz", "machine": "asv-runner", "os": "Linux 3.13.0-116-generic", "ram": "501692", "python": "3.8", "numpy": "", "Cython": "0.29.32", "matplotlib": "", "sqlalchemy": "", "scipy": "", "numba": "", "numexpr": "", "pytables": "", "pyarrow": "", "openpyxl": "", "xlsxwriter": "", "xlrd": "", "odfpy": "", "jinja2": "", "branch": "main", "xlwt": null}, {"arch": "x86_64", "cpu": "Intel(R) Core(TM) i7-4980HQ CPU @ 2.80GHz", "machine": "asv-runner", "os": "Linux 3.13.0-116-generic", "ram": "501692", "python": "3.8", "numpy": "", "Cython": "0.29.33", "matplotlib": "", "sqlalchemy": "", "scipy": "", "numba": "", "numexpr": "", "pytables": "", "pyarrow": "", "openpyxl": "", "xlsxwriter": "", "xlrd": "", "odfpy": "", "jinja2": "", "branch": "main", "xlwt": null}], "benchmarks": {"algorithms.Duplicated.time_duplicated": {"code": "class Duplicated:\n    def time_duplicated(self, unique, keep, dtype):\n        self.idx.duplicated(keep=keep)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Duplicated:\n    def setup(self, unique, keep, dtype):\n        N = 10**5\n        data = {\n            \"int\": pd.Index(np.arange(N), dtype=\"int64\"),\n            \"uint\": pd.Index(np.arange(N), dtype=\"uint64\"),\n            \"float\": pd.Index(np.random.randn(N), dtype=\"float64\"),\n            \"string\": tm.makeStringIndex(N),\n            \"datetime64[ns]\": pd.date_range(\"2011-01-01\", freq=\"H\", periods=N),\n            \"datetime64[ns, tz]\": pd.date_range(\n                \"2011-01-01\", freq=\"H\", periods=N, tz=\"Asia/Tokyo\"\n            ),\n        }[dtype]\n        if not unique:\n            data = data.repeat(5)\n        self.idx = data\n        # cache is_unique\n        self.idx.is_unique", "min_run_count": 2, "name": "algorithms.Duplicated.time_duplicated", "number": 0, "param_names": ["unique", "keep", "dtype"], "params": [["True", "False"], ["'first'", "'last'", "False"], ["'int'", "'uint'", "'float'", "'string'", "'datetime64[ns]'", "'datetime64[ns, tz]'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "efd324d844aa82bd271fc715e25ec9dedecea09cc7084df9dfbaac8eaaa2fc92", "warmup_time": -1}, "algorithms.DuplicatedMaskedArray.time_duplicated": {"code": "class DuplicatedMaskedArray:\n    def time_duplicated(self, unique, keep, dtype):\n        self.ser.duplicated(keep=keep)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass DuplicatedMaskedArray:\n    def setup(self, unique, keep, dtype):\n        N = 10**5\n        data = pd.Series(np.arange(N), dtype=dtype)\n        data[list(range(1, N, 100))] = pd.NA\n        if not unique:\n            data = data.repeat(5)\n        self.ser = data\n        # cache is_unique\n        self.ser.is_unique", "min_run_count": 2, "name": "algorithms.DuplicatedMaskedArray.time_duplicated", "number": 0, "param_names": ["unique", "keep", "dtype"], "params": [["True", "False"], ["'first'", "'last'", "False"], ["'Int64'", "'Float64'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "9401d32efa9cbe647d328e01c1b90df12183cdceba73825c1c4d98e81f254886", "warmup_time": -1}, "algorithms.Factorize.peakmem_factorize": {"code": "class Factorize:\n    def peakmem_factorize(self, unique, sort, dtype):\n        pd.factorize(self.data, sort=sort)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Factorize:\n    def setup(self, unique, sort, dtype):\n        N = 10**5\n        string_index = tm.makeStringIndex(N)\n        string_arrow = None\n        if dtype == \"string[pyarrow]\":\n            try:\n                string_arrow = pd.array(string_index, dtype=\"string[pyarrow]\")\n            except ImportError:\n                raise NotImplementedError\n    \n        data = {\n            \"int\": pd.Index(np.arange(N), dtype=\"int64\"),\n            \"uint\": pd.Index(np.arange(N), dtype=\"uint64\"),\n            \"float\": pd.Index(np.random.randn(N), dtype=\"float64\"),\n            \"object_str\": string_index,\n            \"object\": pd.Index(np.arange(N), dtype=\"object\"),\n            \"datetime64[ns]\": pd.date_range(\"2011-01-01\", freq=\"H\", periods=N),\n            \"datetime64[ns, tz]\": pd.date_range(\n                \"2011-01-01\", freq=\"H\", periods=N, tz=\"Asia/Tokyo\"\n            ),\n            \"Int64\": pd.array(np.arange(N), dtype=\"Int64\"),\n            \"boolean\": pd.array(np.random.randint(0, 2, N), dtype=\"boolean\"),\n            \"string[pyarrow]\": string_arrow,\n        }[dtype]\n        if not unique:\n            data = data.repeat(5)\n        self.data = data", "name": "algorithms.Factorize.peakmem_factorize", "param_names": ["unique", "sort", "dtype"], "params": [["True", "False"], ["True", "False"], ["'int'", "'uint'", "'float'", "'object'", "'object_str'", "'datetime64[ns]'", "'datetime64[ns, tz]'", "'Int64'", "'boolean'", "'string[pyarrow]'"]], "timeout": 60.0, "type": "peakmemory", "unit": "bytes", "version": "36dc082857ff9bd01f0eb79ac1205252afd19b24c1c6fd14f7ca5e630e735dbf"}, "algorithms.Factorize.time_factorize": {"code": "class Factorize:\n    def time_factorize(self, unique, sort, dtype):\n        pd.factorize(self.data, sort=sort)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Factorize:\n    def setup(self, unique, sort, dtype):\n        N = 10**5\n        string_index = tm.makeStringIndex(N)\n        string_arrow = None\n        if dtype == \"string[pyarrow]\":\n            try:\n                string_arrow = pd.array(string_index, dtype=\"string[pyarrow]\")\n            except ImportError:\n                raise NotImplementedError\n    \n        data = {\n            \"int\": pd.Index(np.arange(N), dtype=\"int64\"),\n            \"uint\": pd.Index(np.arange(N), dtype=\"uint64\"),\n            \"float\": pd.Index(np.random.randn(N), dtype=\"float64\"),\n            \"object_str\": string_index,\n            \"object\": pd.Index(np.arange(N), dtype=\"object\"),\n            \"datetime64[ns]\": pd.date_range(\"2011-01-01\", freq=\"H\", periods=N),\n            \"datetime64[ns, tz]\": pd.date_range(\n                \"2011-01-01\", freq=\"H\", periods=N, tz=\"Asia/Tokyo\"\n            ),\n            \"Int64\": pd.array(np.arange(N), dtype=\"Int64\"),\n            \"boolean\": pd.array(np.random.randint(0, 2, N), dtype=\"boolean\"),\n            \"string[pyarrow]\": string_arrow,\n        }[dtype]\n        if not unique:\n            data = data.repeat(5)\n        self.data = data", "min_run_count": 2, "name": "algorithms.Factorize.time_factorize", "number": 0, "param_names": ["unique", "sort", "dtype"], "params": [["True", "False"], ["True", "False"], ["'int'", "'uint'", "'float'", "'object'", "'object_str'", "'datetime64[ns]'", "'datetime64[ns, tz]'", "'Int64'", "'boolean'", "'string[pyarrow]'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "3162de2b854164086e1b9b79174c0c78d493058dba6bae396574bbf1f72a8406", "warmup_time": -1}, "algorithms.Hashing.time_frame": {"code": "class Hashing:\n    def time_frame(self, df):\n        hashing.hash_pandas_object(df)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Hashing:\n    def setup_cache(self):\n        N = 10**5\n    \n        df = pd.DataFrame(\n            {\n                \"strings\": pd.Series(\n                    tm.makeStringIndex(10000).take(np.random.randint(0, 10000, size=N))\n                ),\n                \"floats\": np.random.randn(N),\n                \"ints\": np.arange(N),\n                \"dates\": pd.date_range(\"20110101\", freq=\"s\", periods=N),\n                \"timedeltas\": pd.timedelta_range(\"1 day\", freq=\"s\", periods=N),\n            }\n        )\n        df[\"categories\"] = df[\"strings\"].astype(\"category\")\n        df.iloc[10:20] = np.nan\n        return df", "min_run_count": 2, "name": "algorithms.Hashing.time_frame", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "setup_cache_key": "algorithms:124", "timeout": 60.0, "type": "time", "unit": "seconds", "version": "39ab137b934c6fbbf67b23f0fad2713423fdddcf842dd999f29ff725db07d244", "warmup_time": -1}, "algorithms.Hashing.time_series_categorical": {"code": "class Hashing:\n    def time_series_categorical(self, df):\n        hashing.hash_pandas_object(df[\"categories\"])\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Hashing:\n    def setup_cache(self):\n        N = 10**5\n    \n        df = pd.DataFrame(\n            {\n                \"strings\": pd.Series(\n                    tm.makeStringIndex(10000).take(np.random.randint(0, 10000, size=N))\n                ),\n                \"floats\": np.random.randn(N),\n                \"ints\": np.arange(N),\n                \"dates\": pd.date_range(\"20110101\", freq=\"s\", periods=N),\n                \"timedeltas\": pd.timedelta_range(\"1 day\", freq=\"s\", periods=N),\n            }\n        )\n        df[\"categories\"] = df[\"strings\"].astype(\"category\")\n        df.iloc[10:20] = np.nan\n        return df", "min_run_count": 2, "name": "algorithms.Hashing.time_series_categorical", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "setup_cache_key": "algorithms:124", "timeout": 60.0, "type": "time", "unit": "seconds", "version": "5e830670618217aceeb110aff22e36bf66bd6a92a2f0c0e1160abf9eaaf6adea", "warmup_time": -1}, "algorithms.Hashing.time_series_dates": {"code": "class Hashing:\n    def time_series_dates(self, df):\n        hashing.hash_pandas_object(df[\"dates\"])\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Hashing:\n    def setup_cache(self):\n        N = 10**5\n    \n        df = pd.DataFrame(\n            {\n                \"strings\": pd.Series(\n                    tm.makeStringIndex(10000).take(np.random.randint(0, 10000, size=N))\n                ),\n                \"floats\": np.random.randn(N),\n                \"ints\": np.arange(N),\n                \"dates\": pd.date_range(\"20110101\", freq=\"s\", periods=N),\n                \"timedeltas\": pd.timedelta_range(\"1 day\", freq=\"s\", periods=N),\n            }\n        )\n        df[\"categories\"] = df[\"strings\"].astype(\"category\")\n        df.iloc[10:20] = np.nan\n        return df", "min_run_count": 2, "name": "algorithms.Hashing.time_series_dates", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "setup_cache_key": "algorithms:124", "timeout": 60.0, "type": "time", "unit": "seconds", "version": "486eae84e6ee886bb73983809fa61f1b8bb796c8c8a5c590fad3e8b3488938b2", "warmup_time": -1}, "algorithms.Hashing.time_series_float": {"code": "class Hashing:\n    def time_series_float(self, df):\n        hashing.hash_pandas_object(df[\"floats\"])\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Hashing:\n    def setup_cache(self):\n        N = 10**5\n    \n        df = pd.DataFrame(\n            {\n                \"strings\": pd.Series(\n                    tm.makeStringIndex(10000).take(np.random.randint(0, 10000, size=N))\n                ),\n                \"floats\": np.random.randn(N),\n                \"ints\": np.arange(N),\n                \"dates\": pd.date_range(\"20110101\", freq=\"s\", periods=N),\n                \"timedeltas\": pd.timedelta_range(\"1 day\", freq=\"s\", periods=N),\n            }\n        )\n        df[\"categories\"] = df[\"strings\"].astype(\"category\")\n        df.iloc[10:20] = np.nan\n        return df", "min_run_count": 2, "name": "algorithms.Hashing.time_series_float", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "setup_cache_key": "algorithms:124", "timeout": 60.0, "type": "time", "unit": "seconds", "version": "cb10acd4cf0e641bbc7c2d10d9817a3a810be311751ad949dd97e2456a0b3479", "warmup_time": -1}, "algorithms.Hashing.time_series_int": {"code": "class Hashing:\n    def time_series_int(self, df):\n        hashing.hash_pandas_object(df[\"ints\"])\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Hashing:\n    def setup_cache(self):\n        N = 10**5\n    \n        df = pd.DataFrame(\n            {\n                \"strings\": pd.Series(\n                    tm.makeStringIndex(10000).take(np.random.randint(0, 10000, size=N))\n                ),\n                \"floats\": np.random.randn(N),\n                \"ints\": np.arange(N),\n                \"dates\": pd.date_range(\"20110101\", freq=\"s\", periods=N),\n                \"timedeltas\": pd.timedelta_range(\"1 day\", freq=\"s\", periods=N),\n            }\n        )\n        df[\"categories\"] = df[\"strings\"].astype(\"category\")\n        df.iloc[10:20] = np.nan\n        return df", "min_run_count": 2, "name": "algorithms.Hashing.time_series_int", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "setup_cache_key": "algorithms:124", "timeout": 60.0, "type": "time", "unit": "seconds", "version": "96f737ab603080830fedcdff9c7c030fa0193129929a1212cdd6a576c0c11a0d", "warmup_time": -1}, "algorithms.Hashing.time_series_string": {"code": "class Hashing:\n    def time_series_string(self, df):\n        hashing.hash_pandas_object(df[\"strings\"])\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Hashing:\n    def setup_cache(self):\n        N = 10**5\n    \n        df = pd.DataFrame(\n            {\n                \"strings\": pd.Series(\n                    tm.makeStringIndex(10000).take(np.random.randint(0, 10000, size=N))\n                ),\n                \"floats\": np.random.randn(N),\n                \"ints\": np.arange(N),\n                \"dates\": pd.date_range(\"20110101\", freq=\"s\", periods=N),\n                \"timedeltas\": pd.timedelta_range(\"1 day\", freq=\"s\", periods=N),\n            }\n        )\n        df[\"categories\"] = df[\"strings\"].astype(\"category\")\n        df.iloc[10:20] = np.nan\n        return df", "min_run_count": 2, "name": "algorithms.Hashing.time_series_string", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "setup_cache_key": "algorithms:124", "timeout": 60.0, "type": "time", "unit": "seconds", "version": "2772704ed8ec91d04c176d36fdf88a5e2ba6bc1cf4d9eeb2e0e882d9f0d2642f", "warmup_time": -1}, "algorithms.Hashing.time_series_timedeltas": {"code": "class Hashing:\n    def time_series_timedeltas(self, df):\n        hashing.hash_pandas_object(df[\"timedeltas\"])\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Hashing:\n    def setup_cache(self):\n        N = 10**5\n    \n        df = pd.DataFrame(\n            {\n                \"strings\": pd.Series(\n                    tm.makeStringIndex(10000).take(np.random.randint(0, 10000, size=N))\n                ),\n                \"floats\": np.random.randn(N),\n                \"ints\": np.arange(N),\n                \"dates\": pd.date_range(\"20110101\", freq=\"s\", periods=N),\n                \"timedeltas\": pd.timedelta_range(\"1 day\", freq=\"s\", periods=N),\n            }\n        )\n        df[\"categories\"] = df[\"strings\"].astype(\"category\")\n        df.iloc[10:20] = np.nan\n        return df", "min_run_count": 2, "name": "algorithms.Hashing.time_series_timedeltas", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "setup_cache_key": "algorithms:124", "timeout": 60.0, "type": "time", "unit": "seconds", "version": "4c9241ce63b6ae3bd53d88eae799ef144585b04a1e7a41d142e82723462ce55c", "warmup_time": -1}, "algorithms.Quantile.time_quantile": {"code": "class Quantile:\n    def time_quantile(self, quantile, interpolation, dtype):\n        self.idx.quantile(quantile, interpolation=interpolation)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Quantile:\n    def setup(self, quantile, interpolation, dtype):\n        N = 10**5\n        data = {\n            \"int\": np.arange(N),\n            \"uint\": np.arange(N).astype(np.uint64),\n            \"float\": np.random.randn(N),\n        }\n        self.idx = pd.Series(data[dtype].repeat(5))", "min_run_count": 2, "name": "algorithms.Quantile.time_quantile", "number": 0, "param_names": ["quantile", "interpolation", "dtype"], "params": [["0", "0.5", "1"], ["'linear'", "'nearest'", "'lower'", "'higher'", "'midpoint'"], ["'float'", "'int'", "'uint'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "7b54ba8e7b23163b2873c51debf2e3a59d3e4dea1bd7a6595b410163038b7001", "warmup_time": -1}, "algorithms.SortIntegerArray.time_argsort": {"code": "class SortIntegerArray:\n    def time_argsort(self, N):\n        self.array.argsort()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass SortIntegerArray:\n    def setup(self, N):\n        data = np.arange(N, dtype=float)\n        data[40] = np.nan\n        self.array = pd.array(data, dtype=\"Int64\")", "min_run_count": 2, "name": "algorithms.SortIntegerArray.time_argsort", "number": 0, "param_names": ["param1"], "params": [["1000", "100000"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "712d4e0ba6b3b003618d30611818ce2c36c039fe0900eafca3896d3863ebbc51", "warmup_time": -1}, "algos.isin.IsIn.time_isin": {"code": "class IsIn:\n    def time_isin(self, dtype):\n        self.series.isin(self.values)\n\n    def setup(self, dtype):\n        N = 10000\n    \n        self.mismatched = [NaT.to_datetime64()] * 2\n    \n        if dtype in [\"boolean\", \"bool\"]:\n            self.series = Series(np.random.randint(0, 2, N)).astype(dtype)\n            self.values = [True, False]\n    \n        elif dtype == \"datetime64[ns]\":\n            # Note: values here is much larger than non-dt64ns cases\n    \n            # dti has length=115777\n            dti = date_range(start=\"2015-10-26\", end=\"2016-01-01\", freq=\"50s\")\n            self.series = Series(dti)\n            self.values = self.series._values[::3]\n            self.mismatched = [1, 2]\n    \n        elif dtype in [\"category[object]\", \"category[int]\"]:\n            # Note: sizes are different in this case than others\n            n = 5 * 10**5\n            sample_size = 100\n    \n            arr = list(np.random.randint(0, n // 10, size=n))\n            if dtype == \"category[object]\":\n                arr = [f\"s{i:04d}\" for i in arr]\n    \n            self.values = np.random.choice(arr, sample_size)\n            self.series = Series(arr).astype(\"category\")\n    \n        elif dtype in [\"str\", \"string[python]\", \"string[pyarrow]\"]:\n            try:\n                self.series = Series(tm.makeStringIndex(N), dtype=dtype)\n            except ImportError:\n                raise NotImplementedError\n            self.values = list(self.series[:2])\n    \n        else:\n            self.series = Series(np.random.randint(1, 10, N)).astype(dtype)\n            self.values = [1, 2]\n    \n        self.cat_values = Categorical(self.values)", "min_run_count": 2, "name": "algos.isin.IsIn.time_isin", "number": 0, "param_names": ["dtype"], "params": [["'int64'", "'uint64'", "'object'", "'Int64'", "'boolean'", "'bool'", "'datetime64[ns]'", "'category[object]'", "'category[int]'", "'str'", "'string[python]'", "'string[pyarrow]'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "1d3b4b62df926106d548de992f0de67319cafd3bff56b36bd5047eda9e89656a", "warmup_time": -1}, "algos.isin.IsIn.time_isin_categorical": {"code": "class IsIn:\n    def time_isin_categorical(self, dtype):\n        self.series.isin(self.cat_values)\n\n    def setup(self, dtype):\n        N = 10000\n    \n        self.mismatched = [NaT.to_datetime64()] * 2\n    \n        if dtype in [\"boolean\", \"bool\"]:\n            self.series = Series(np.random.randint(0, 2, N)).astype(dtype)\n            self.values = [True, False]\n    \n        elif dtype == \"datetime64[ns]\":\n            # Note: values here is much larger than non-dt64ns cases\n    \n            # dti has length=115777\n            dti = date_range(start=\"2015-10-26\", end=\"2016-01-01\", freq=\"50s\")\n            self.series = Series(dti)\n            self.values = self.series._values[::3]\n            self.mismatched = [1, 2]\n    \n        elif dtype in [\"category[object]\", \"category[int]\"]:\n            # Note: sizes are different in this case than others\n            n = 5 * 10**5\n            sample_size = 100\n    \n            arr = list(np.random.randint(0, n // 10, size=n))\n            if dtype == \"category[object]\":\n                arr = [f\"s{i:04d}\" for i in arr]\n    \n            self.values = np.random.choice(arr, sample_size)\n            self.series = Series(arr).astype(\"category\")\n    \n        elif dtype in [\"str\", \"string[python]\", \"string[pyarrow]\"]:\n            try:\n                self.series = Series(tm.makeStringIndex(N), dtype=dtype)\n            except ImportError:\n                raise NotImplementedError\n            self.values = list(self.series[:2])\n    \n        else:\n            self.series = Series(np.random.randint(1, 10, N)).astype(dtype)\n            self.values = [1, 2]\n    \n        self.cat_values = Categorical(self.values)", "min_run_count": 2, "name": "algos.isin.IsIn.time_isin_categorical", "number": 0, "param_names": ["dtype"], "params": [["'int64'", "'uint64'", "'object'", "'Int64'", "'boolean'", "'bool'", "'datetime64[ns]'", "'category[object]'", "'category[int]'", "'str'", "'string[python]'", "'string[pyarrow]'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "8159615f4f509fee3a8466431a74ec9dbd72ba4079912ea0c4cc69fc66619729", "warmup_time": -1}, "algos.isin.IsIn.time_isin_empty": {"code": "class IsIn:\n    def time_isin_empty(self, dtype):\n        self.series.isin([])\n\n    def setup(self, dtype):\n        N = 10000\n    \n        self.mismatched = [NaT.to_datetime64()] * 2\n    \n        if dtype in [\"boolean\", \"bool\"]:\n            self.series = Series(np.random.randint(0, 2, N)).astype(dtype)\n            self.values = [True, False]\n    \n        elif dtype == \"datetime64[ns]\":\n            # Note: values here is much larger than non-dt64ns cases\n    \n            # dti has length=115777\n            dti = date_range(start=\"2015-10-26\", end=\"2016-01-01\", freq=\"50s\")\n            self.series = Series(dti)\n            self.values = self.series._values[::3]\n            self.mismatched = [1, 2]\n    \n        elif dtype in [\"category[object]\", \"category[int]\"]:\n            # Note: sizes are different in this case than others\n            n = 5 * 10**5\n            sample_size = 100\n    \n            arr = list(np.random.randint(0, n // 10, size=n))\n            if dtype == \"category[object]\":\n                arr = [f\"s{i:04d}\" for i in arr]\n    \n            self.values = np.random.choice(arr, sample_size)\n            self.series = Series(arr).astype(\"category\")\n    \n        elif dtype in [\"str\", \"string[python]\", \"string[pyarrow]\"]:\n            try:\n                self.series = Series(tm.makeStringIndex(N), dtype=dtype)\n            except ImportError:\n                raise NotImplementedError\n            self.values = list(self.series[:2])\n    \n        else:\n            self.series = Series(np.random.randint(1, 10, N)).astype(dtype)\n            self.values = [1, 2]\n    \n        self.cat_values = Categorical(self.values)", "min_run_count": 2, "name": "algos.isin.IsIn.time_isin_empty", "number": 0, "param_names": ["dtype"], "params": [["'int64'", "'uint64'", "'object'", "'Int64'", "'boolean'", "'bool'", "'datetime64[ns]'", "'category[object]'", "'category[int]'", "'str'", "'string[python]'", "'string[pyarrow]'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "fe0221ec94010ba3b508260b876cb9a72152f03b3c316fcee3036f22a6645212", "warmup_time": -1}, "algos.isin.IsIn.time_isin_mismatched_dtype": {"code": "class IsIn:\n    def time_isin_mismatched_dtype(self, dtype):\n        self.series.isin(self.mismatched)\n\n    def setup(self, dtype):\n        N = 10000\n    \n        self.mismatched = [NaT.to_datetime64()] * 2\n    \n        if dtype in [\"boolean\", \"bool\"]:\n            self.series = Series(np.random.randint(0, 2, N)).astype(dtype)\n            self.values = [True, False]\n    \n        elif dtype == \"datetime64[ns]\":\n            # Note: values here is much larger than non-dt64ns cases\n    \n            # dti has length=115777\n            dti = date_range(start=\"2015-10-26\", end=\"2016-01-01\", freq=\"50s\")\n            self.series = Series(dti)\n            self.values = self.series._values[::3]\n            self.mismatched = [1, 2]\n    \n        elif dtype in [\"category[object]\", \"category[int]\"]:\n            # Note: sizes are different in this case than others\n            n = 5 * 10**5\n            sample_size = 100\n    \n            arr = list(np.random.randint(0, n // 10, size=n))\n            if dtype == \"category[object]\":\n                arr = [f\"s{i:04d}\" for i in arr]\n    \n            self.values = np.random.choice(arr, sample_size)\n            self.series = Series(arr).astype(\"category\")\n    \n        elif dtype in [\"str\", \"string[python]\", \"string[pyarrow]\"]:\n            try:\n                self.series = Series(tm.makeStringIndex(N), dtype=dtype)\n            except ImportError:\n                raise NotImplementedError\n            self.values = list(self.series[:2])\n    \n        else:\n            self.series = Series(np.random.randint(1, 10, N)).astype(dtype)\n            self.values = [1, 2]\n    \n        self.cat_values = Categorical(self.values)", "min_run_count": 2, "name": "algos.isin.IsIn.time_isin_mismatched_dtype", "number": 0, "param_names": ["dtype"], "params": [["'int64'", "'uint64'", "'object'", "'Int64'", "'boolean'", "'bool'", "'datetime64[ns]'", "'category[object]'", "'category[int]'", "'str'", "'string[python]'", "'string[pyarrow]'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "08126169ec22d6c64941bfff0094dd3149d1b57a51aefdc8416824b4446a553d", "warmup_time": -1}, "algos.isin.IsInFloat64.time_isin": {"code": "class IsInFloat64:\n    def time_isin(self, dtype, title):\n        self.series.isin(self.values)\n\n    def setup(self, dtype, title):\n        N_many = 10**5\n        N_few = 10**6\n        self.series = Series([1, 2], dtype=dtype)\n    \n        if title == \"many_different_values\":\n            # runtime is dominated by creation of the lookup-table\n            self.values = np.arange(N_many, dtype=np.float64)\n        elif title == \"few_different_values\":\n            # runtime is dominated by creation of the lookup-table\n            self.values = np.zeros(N_few, dtype=np.float64)\n        elif title == \"only_nans_values\":\n            # runtime is dominated by creation of the lookup-table\n            self.values = np.full(N_few, np.nan, dtype=np.float64)\n        else:\n            raise ValueError(title)", "min_run_count": 2, "name": "algos.isin.IsInFloat64.time_isin", "number": 0, "param_names": ["dtype", "title"], "params": [["<class 'numpy.float64'>", "'Float64'"], ["'many_different_values'", "'few_different_values'", "'only_nans_values'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "59baee11ef880339f8490c7d07fdf4f25b649d22624afd1242eefd4877e7c0bd", "warmup_time": -1}, "algos.isin.IsInForObjects.time_isin": {"code": "class IsInForObjects:\n    def time_isin(self, series_type, vals_type):\n        self.series.isin(self.values)\n\n    def setup(self, series_type, vals_type):\n        N_many = 10**5\n    \n        if series_type == \"nans\":\n            ser_vals = np.full(10**4, np.nan)\n        elif series_type == \"short\":\n            ser_vals = np.arange(2)\n        elif series_type == \"long\":\n            ser_vals = np.arange(N_many)\n        elif series_type == \"long_floats\":\n            ser_vals = np.arange(N_many, dtype=np.float_)\n    \n        self.series = Series(ser_vals).astype(object)\n    \n        if vals_type == \"nans\":\n            values = np.full(10**4, np.nan)\n        elif vals_type == \"short\":\n            values = np.arange(2)\n        elif vals_type == \"long\":\n            values = np.arange(N_many)\n        elif vals_type == \"long_floats\":\n            values = np.arange(N_many, dtype=np.float_)\n    \n        self.values = values.astype(object)", "min_run_count": 2, "name": "algos.isin.IsInForObjects.time_isin", "number": 0, "param_names": ["series_type", "vals_type"], "params": [["'nans'", "'short'", "'long'", "'long_floats'"], ["'nans'", "'short'", "'long'", "'long_floats'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "39526666de18260b25ad3274e7728782887d472b2ab17bc35c95c522e76de43c", "warmup_time": -1}, "algos.isin.IsInIndexes.time_isin_index": {"code": "class IsInIndexes:\n    def time_isin_index(self):\n        self.series.isin(self.index)\n\n    def setup(self):\n        self.range_idx = Index(range(1000))\n        self.index = Index(list(range(1000)))\n        self.series = Series(np.random.randint(100_000, size=1000))", "min_run_count": 2, "name": "algos.isin.IsInIndexes.time_isin_index", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "ce5b0b4c6a85e2c007c90998aa18d4db0fb69a82cefb1549856c75004e42fbec", "warmup_time": -1}, "algos.isin.IsInIndexes.time_isin_range_index": {"code": "class IsInIndexes:\n    def time_isin_range_index(self):\n        self.series.isin(self.range_idx)\n\n    def setup(self):\n        self.range_idx = Index(range(1000))\n        self.index = Index(list(range(1000)))\n        self.series = Series(np.random.randint(100_000, size=1000))", "min_run_count": 2, "name": "algos.isin.IsInIndexes.time_isin_range_index", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "f37d428d46aff6ec8ce8a340df54e194946db8454b6da0c7a39c2e85139b4efb", "warmup_time": -1}, "algos.isin.IsInLongSeriesLookUpDominates.time_isin": {"code": "class IsInLongSeriesLookUpDominates:\n    def time_isin(self, dtypes, MaxNumber, series_type):\n        self.series.isin(self.values)\n\n    def setup(self, dtype, MaxNumber, series_type):\n        N = 10**7\n    \n        if series_type == \"random_hits\":\n            array = np.random.randint(0, MaxNumber, N)\n        if series_type == \"random_misses\":\n            array = np.random.randint(0, MaxNumber, N) + MaxNumber\n        if series_type == \"monotone_hits\":\n            array = np.repeat(np.arange(MaxNumber), N // MaxNumber)\n        if series_type == \"monotone_misses\":\n            array = np.arange(N) + MaxNumber\n    \n        self.series = Series(array).astype(dtype)\n    \n        self.values = np.arange(MaxNumber).astype(dtype.lower())", "min_run_count": 2, "name": "algos.isin.IsInLongSeriesLookUpDominates.time_isin", "number": 0, "param_names": ["dtype", "MaxNumber", "series_type"], "params": [["'int64'", "'int32'", "'float64'", "'float32'", "'object'", "'Int64'", "'Float64'"], ["5", "1000"], ["'random_hits'", "'random_misses'", "'monotone_hits'", "'monotone_misses'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "0634a100f682c1a73f9cb5d84afc1695f117d58377c8ac19e9a1d4ecf3918bc4", "warmup_time": -1}, "algos.isin.IsInLongSeriesValuesDominate.time_isin": {"code": "class IsInLongSeriesValuesDominate:\n    def time_isin(self, dtypes, series_type):\n        self.series.isin(self.values)\n\n    def setup(self, dtype, series_type):\n        N = 10**7\n    \n        if series_type == \"random\":\n            vals = np.random.randint(0, 10 * N, N)\n        if series_type == \"monotone\":\n            vals = np.arange(N)\n    \n        self.values = vals.astype(dtype.lower())\n        M = 10**6 + 1\n        self.series = Series(np.arange(M)).astype(dtype)", "min_run_count": 2, "name": "algos.isin.IsInLongSeriesValuesDominate.time_isin", "number": 0, "param_names": ["dtype", "series_type"], "params": [["'int64'", "'int32'", "'float64'", "'float32'", "'object'", "'Int64'", "'Float64'"], ["'random'", "'monotone'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "8202afa03ab08eab3d80cdb10c821a35f6b73f1b178354429054668f213b8920", "warmup_time": -1}, "algos.isin.IsInWithLongTupples.time_isin": {"code": "class IsInWithLongTupples:\n    def time_isin(self):\n        self.series.isin(self.values)\n\n    def setup(self):\n        t = tuple(range(1000))\n        self.series = Series([t] * 1000)\n        self.values = [t]", "min_run_count": 2, "name": "algos.isin.IsInWithLongTupples.time_isin", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "55c634e065a928f8f1e9146932290a0b894f6f9f6f25b0d57ab2597ce60972ad", "warmup_time": -1}, "algos.isin.IsinAlmostFullWithRandomInt.time_isin": {"code": "class IsinAlmostFullWithRandomInt:\n    def time_isin(self, dtype, exponent, title):\n        self.series.isin(self.values)\n\n    def setup(self, dtype, exponent, title):\n        M = 3 * 2 ** (exponent - 2)\n        # 0.77-the maximal share of occupied buckets\n        self.series = Series(np.random.randint(0, M, M)).astype(dtype)\n    \n        values = np.random.randint(0, M, M).astype(dtype)\n        if title == \"inside\":\n            self.values = values\n        elif title == \"outside\":\n            self.values = values + M\n        else:\n            raise ValueError(title)", "min_run_count": 2, "name": "algos.isin.IsinAlmostFullWithRandomInt.time_isin", "number": 0, "param_names": ["dtype", "exponent", "title"], "params": [["<class 'numpy.float64'>", "<class 'numpy.int64'>", "<class 'numpy.uint64'>", "<class 'numpy.object_'>"], ["10", "11", "12", "13", "14", "15", "16", "17", "18", "19", "20"], ["'inside'", "'outside'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "4511839e6a4402d9c6a3c41e95fbfd6c61eb07d38c9d0069b10c837a5dfb0bb4", "warmup_time": -1}, "algos.isin.IsinWithArange.time_isin": {"code": "class IsinWithArange:\n    def time_isin(self, dtype, M, offset_factor):\n        self.series.isin(self.values)\n\n    def setup(self, dtype, M, offset_factor):\n        offset = int(M * offset_factor)\n        tmp = Series(np.random.randint(offset, M + offset, 10**6))\n        self.series = tmp.astype(dtype)\n        self.values = np.arange(M).astype(dtype)", "min_run_count": 2, "name": "algos.isin.IsinWithArange.time_isin", "number": 0, "param_names": ["dtype", "M", "offset_factor"], "params": [["<class 'numpy.float64'>", "<class 'numpy.int64'>", "<class 'numpy.uint64'>", "<class 'numpy.object_'>"], ["1000", "2000", "8000"], ["-2", "0", "2"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "a595ea736176046325e6461769d666e50df44bc5ea923058dfbdf81bc2fa9848", "warmup_time": -1}, "algos.isin.IsinWithArangeSorted.time_isin": {"code": "class IsinWithArangeSorted:\n    def time_isin(self, dtype, size):\n        self.series.isin(self.values)\n\n    def setup(self, dtype, size):\n        self.series = Series(np.arange(size)).astype(dtype)\n        self.values = np.arange(size).astype(dtype)", "min_run_count": 2, "name": "algos.isin.IsinWithArangeSorted.time_isin", "number": 0, "param_names": ["dtype", "size"], "params": [["<class 'numpy.float64'>", "<class 'numpy.int64'>", "<class 'numpy.uint64'>", "<class 'numpy.object_'>"], ["1000", "2000", "8000", "100000", "1000000"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "b3b173cabf5fb2d94e06a9a5bce98458bf646cecae54b0966cfe66adcded0fdf", "warmup_time": -1}, "algos.isin.IsinWithRandomFloat.time_isin": {"code": "class IsinWithRandomFloat:\n    def time_isin(self, dtype, size, title):\n        self.series.isin(self.values)\n\n    def setup(self, dtype, size, title):\n        self.values = np.random.rand(size)\n        self.series = Series(self.values).astype(dtype)\n        np.random.shuffle(self.values)\n    \n        if title == \"outside\":\n            self.values = self.values + 0.1", "min_run_count": 2, "name": "algos.isin.IsinWithRandomFloat.time_isin", "number": 0, "param_names": ["dtype", "size", "title"], "params": [["<class 'numpy.float64'>", "<class 'numpy.object_'>"], ["1300", "2000", "7000", "8000", "70000", "80000", "750000", "900000"], ["'inside'", "'outside'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "15f9f9bb41efd706d95b1a43ff72e5572dedbb074050cd2b857e7a91213c60a8", "warmup_time": -1}, "arithmetic.AddOverflowArray.time_add_overflow_arr_mask_nan": {"code": "class AddOverflowArray:\n    def time_add_overflow_arr_mask_nan(self):\n        checked_add_with_arr(self.arr, self.arr_mixed, arr_mask=self.arr_nan_1)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass AddOverflowArray:\n    def setup(self):\n        N = 10**6\n        self.arr = np.arange(N)\n        self.arr_rev = np.arange(-N, 0)\n        self.arr_mixed = np.array([1, -1]).repeat(N / 2)\n        self.arr_nan_1 = np.random.choice([True, False], size=N)\n        self.arr_nan_2 = np.random.choice([True, False], size=N)", "min_run_count": 2, "name": "arithmetic.AddOverflowArray.time_add_overflow_arr_mask_nan", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "8239edcba7a87bbd5b7ad90e6984ad659b40e10d1f7452a931a73ba6c20f4fce", "warmup_time": -1}, "arithmetic.AddOverflowArray.time_add_overflow_arr_rev": {"code": "class AddOverflowArray:\n    def time_add_overflow_arr_rev(self):\n        checked_add_with_arr(self.arr, self.arr_rev)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass AddOverflowArray:\n    def setup(self):\n        N = 10**6\n        self.arr = np.arange(N)\n        self.arr_rev = np.arange(-N, 0)\n        self.arr_mixed = np.array([1, -1]).repeat(N / 2)\n        self.arr_nan_1 = np.random.choice([True, False], size=N)\n        self.arr_nan_2 = np.random.choice([True, False], size=N)", "min_run_count": 2, "name": "arithmetic.AddOverflowArray.time_add_overflow_arr_rev", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "360f19c562afa0b4a5f5f824a89e9dd8ba7aac5488be7fbdbcd13d9a90480005", "warmup_time": -1}, "arithmetic.AddOverflowArray.time_add_overflow_b_mask_nan": {"code": "class AddOverflowArray:\n    def time_add_overflow_b_mask_nan(self):\n        checked_add_with_arr(self.arr, self.arr_mixed, b_mask=self.arr_nan_1)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass AddOverflowArray:\n    def setup(self):\n        N = 10**6\n        self.arr = np.arange(N)\n        self.arr_rev = np.arange(-N, 0)\n        self.arr_mixed = np.array([1, -1]).repeat(N / 2)\n        self.arr_nan_1 = np.random.choice([True, False], size=N)\n        self.arr_nan_2 = np.random.choice([True, False], size=N)", "min_run_count": 2, "name": "arithmetic.AddOverflowArray.time_add_overflow_b_mask_nan", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "b9eb6c38ea268a9cb9b11fdaf1e05ccadf4b50f95ab7f577704a0d4719cf8585", "warmup_time": -1}, "arithmetic.AddOverflowArray.time_add_overflow_both_arg_nan": {"code": "class AddOverflowArray:\n    def time_add_overflow_both_arg_nan(self):\n        checked_add_with_arr(\n            self.arr, self.arr_mixed, arr_mask=self.arr_nan_1, b_mask=self.arr_nan_2\n        )\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass AddOverflowArray:\n    def setup(self):\n        N = 10**6\n        self.arr = np.arange(N)\n        self.arr_rev = np.arange(-N, 0)\n        self.arr_mixed = np.array([1, -1]).repeat(N / 2)\n        self.arr_nan_1 = np.random.choice([True, False], size=N)\n        self.arr_nan_2 = np.random.choice([True, False], size=N)", "min_run_count": 2, "name": "arithmetic.AddOverflowArray.time_add_overflow_both_arg_nan", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "aaaa959d6e5d577911f421cbcb3ef98c6f8683ce13e9e35c7b9e0e07e8786df1", "warmup_time": -1}, "arithmetic.AddOverflowScalar.time_add_overflow_scalar": {"code": "class AddOverflowScalar:\n    def time_add_overflow_scalar(self, scalar):\n        checked_add_with_arr(self.arr, scalar)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass AddOverflowScalar:\n    def setup(self, scalar):\n        N = 10**6\n        self.arr = np.arange(N)", "min_run_count": 2, "name": "arithmetic.AddOverflowScalar.time_add_overflow_scalar", "number": 0, "param_names": ["scalar"], "params": [["1", "-1", "0"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "12a2c5f714ec02d305161bc955cf6f6059cdd51998b6b50cc1e8b1643729e4df", "warmup_time": -1}, "arithmetic.ApplyIndex.time_apply_index": {"code": "class ApplyIndex:\n    def time_apply_index(self, offset):\n        self.rng + offset\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ApplyIndex:\n    def setup(self, offset):\n        N = 10000\n        rng = date_range(start=\"1/1/2000\", periods=N, freq=\"T\")\n        self.rng = rng", "min_run_count": 2, "name": "arithmetic.ApplyIndex.time_apply_index", "number": 0, "param_names": ["offset"], "params": [["<YearEnd: month=12>", "<YearBegin: month=1>", "<QuarterEnd: startingMonth=3>", "<QuarterBegin: startingMonth=3>", "<MonthEnd>", "<MonthBegin>", "<DateOffset: days=2, months=2>", "<BusinessDay>", "<SemiMonthEnd: day_of_month=15>", "<SemiMonthBegin: day_of_month=15>"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "a6729281b396d4c9142d8d7bf9895744ae38a81ae5043ffc0c87c5a9db183a49", "warmup_time": -1}, "arithmetic.BinaryOpsMultiIndex.time_binary_op_multiindex": {"code": "class BinaryOpsMultiIndex:\n    def time_binary_op_multiindex(self, func):\n        getattr(self.df, func)(self.arg_df, level=0)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass BinaryOpsMultiIndex:\n    def setup(self, func):\n        array = date_range(\"20200101 00:00\", \"20200102 0:00\", freq=\"S\")\n        level_0_names = [str(i) for i in range(30)]\n    \n        index = pd.MultiIndex.from_product([level_0_names, array])\n        column_names = [\"col_1\", \"col_2\"]\n    \n        self.df = DataFrame(\n            np.random.rand(len(index), 2), index=index, columns=column_names\n        )\n    \n        self.arg_df = DataFrame(\n            np.random.randint(1, 10, (len(level_0_names), 2)),\n            index=level_0_names,\n            columns=column_names,\n        )", "min_run_count": 2, "name": "arithmetic.BinaryOpsMultiIndex.time_binary_op_multiindex", "number": 0, "param_names": ["func"], "params": [["'sub'", "'add'", "'mul'", "'div'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "dd1b12ce1ffea7a16927ee5c6f080ab8565b7a68ff05e1e4a40c2508ff1e660e", "warmup_time": -1}, "arithmetic.CategoricalComparisons.time_categorical_op": {"code": "class CategoricalComparisons:\n    def time_categorical_op(self, op):\n        getattr(self.cat, op)(\"b\")\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass CategoricalComparisons:\n    def setup(self, op):\n        N = 10**5\n        self.cat = pd.Categorical(list(\"aabbcd\") * N, ordered=True)", "min_run_count": 2, "name": "arithmetic.CategoricalComparisons.time_categorical_op", "number": 0, "param_names": ["op"], "params": [["'__lt__'", "'__le__'", "'__eq__'", "'__ne__'", "'__ge__'", "'__gt__'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "2f0300d246b7a2099eaf59bd3d8baf6c12093061ade66b97a650fa54a8b028f1", "warmup_time": -1}, "arithmetic.DateInferOps.time_add_timedeltas": {"code": "class DateInferOps:\n    def time_add_timedeltas(self, df):\n        df[\"timedelta\"] + df[\"timedelta\"]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass DateInferOps:\n    def setup_cache(self):\n        N = 5 * 10**5\n        df = DataFrame({\"datetime64\": np.arange(N).astype(\"datetime64[ms]\")})\n        df[\"timedelta\"] = df[\"datetime64\"] - df[\"datetime64\"]\n        return df", "min_run_count": 2, "name": "arithmetic.DateInferOps.time_add_timedeltas", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "setup_cache_key": "arithmetic:370", "timeout": 60.0, "type": "time", "unit": "seconds", "version": "d304b19271ea5e636b026bf3da9f4297f153721c9a2c3e0173d635d70bf17047", "warmup_time": -1}, "arithmetic.DateInferOps.time_subtract_datetimes": {"code": "class DateInferOps:\n    def time_subtract_datetimes(self, df):\n        df[\"datetime64\"] - df[\"datetime64\"]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass DateInferOps:\n    def setup_cache(self):\n        N = 5 * 10**5\n        df = DataFrame({\"datetime64\": np.arange(N).astype(\"datetime64[ms]\")})\n        df[\"timedelta\"] = df[\"datetime64\"] - df[\"datetime64\"]\n        return df", "min_run_count": 2, "name": "arithmetic.DateInferOps.time_subtract_datetimes", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "setup_cache_key": "arithmetic:370", "timeout": 60.0, "type": "time", "unit": "seconds", "version": "0d0d777174d233a423d74dfef6d81ae5628aaf0098dd2ba538d20b71fa74a3a4", "warmup_time": -1}, "arithmetic.DateInferOps.time_timedelta_plus_datetime": {"code": "class DateInferOps:\n    def time_timedelta_plus_datetime(self, df):\n        df[\"timedelta\"] + df[\"datetime64\"]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass DateInferOps:\n    def setup_cache(self):\n        N = 5 * 10**5\n        df = DataFrame({\"datetime64\": np.arange(N).astype(\"datetime64[ms]\")})\n        df[\"timedelta\"] = df[\"datetime64\"] - df[\"datetime64\"]\n        return df", "min_run_count": 2, "name": "arithmetic.DateInferOps.time_timedelta_plus_datetime", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "setup_cache_key": "arithmetic:370", "timeout": 60.0, "type": "time", "unit": "seconds", "version": "d88c202e97a70579bbbc882c3e1887e44880bc361f354c724dfce863a33f80b3", "warmup_time": -1}, "arithmetic.FrameWithFrameWide.time_op_different_blocks": {"code": "class FrameWithFrameWide:\n    def time_op_different_blocks(self, op, shape):\n        # blocks (and dtypes) are not aligned\n        op(self.left, self.right)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass FrameWithFrameWide:\n    def setup(self, op, shape):\n        # we choose dtypes so as to make the blocks\n        #  a) not perfectly match between right and left\n        #  b) appreciably bigger than single columns\n        n_rows, n_cols = shape\n    \n        if op is operator.floordiv:\n            # floordiv is much slower than the other operations -> use less data\n            n_rows = n_rows // 10\n    \n        # construct dataframe with 2 blocks\n        arr1 = np.random.randn(n_rows, n_cols // 2).astype(\"f8\")\n        arr2 = np.random.randn(n_rows, n_cols // 2).astype(\"f4\")\n        df = pd.concat([DataFrame(arr1), DataFrame(arr2)], axis=1, ignore_index=True)\n        # should already be the case, but just to be sure\n        df._consolidate_inplace()\n    \n        # TODO: GH#33198 the setting here shouldn't need two steps\n        arr1 = np.random.randn(n_rows, max(n_cols // 4, 3)).astype(\"f8\")\n        arr2 = np.random.randn(n_rows, n_cols // 2).astype(\"i8\")\n        arr3 = np.random.randn(n_rows, n_cols // 4).astype(\"f8\")\n        df2 = pd.concat(\n            [DataFrame(arr1), DataFrame(arr2), DataFrame(arr3)],\n            axis=1,\n            ignore_index=True,\n        )\n        # should already be the case, but just to be sure\n        df2._consolidate_inplace()\n    \n        self.left = df\n        self.right = df2", "min_run_count": 2, "name": "arithmetic.FrameWithFrameWide.time_op_different_blocks", "number": 0, "param_names": ["op", "shape"], "params": [["<built-in function add>", "<built-in function floordiv>", "<built-in function gt>"], ["(1000000, 10)", "(100000, 100)", "(10000, 1000)", "(1000, 10000)"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "08d4888de43a21340c4ca998981b96bc41102332e11cc5e9f3fa24786b3387df", "warmup_time": -1}, "arithmetic.FrameWithFrameWide.time_op_same_blocks": {"code": "class FrameWithFrameWide:\n    def time_op_same_blocks(self, op, shape):\n        # blocks (and dtypes) are aligned\n        op(self.left, self.left)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass FrameWithFrameWide:\n    def setup(self, op, shape):\n        # we choose dtypes so as to make the blocks\n        #  a) not perfectly match between right and left\n        #  b) appreciably bigger than single columns\n        n_rows, n_cols = shape\n    \n        if op is operator.floordiv:\n            # floordiv is much slower than the other operations -> use less data\n            n_rows = n_rows // 10\n    \n        # construct dataframe with 2 blocks\n        arr1 = np.random.randn(n_rows, n_cols // 2).astype(\"f8\")\n        arr2 = np.random.randn(n_rows, n_cols // 2).astype(\"f4\")\n        df = pd.concat([DataFrame(arr1), DataFrame(arr2)], axis=1, ignore_index=True)\n        # should already be the case, but just to be sure\n        df._consolidate_inplace()\n    \n        # TODO: GH#33198 the setting here shouldn't need two steps\n        arr1 = np.random.randn(n_rows, max(n_cols // 4, 3)).astype(\"f8\")\n        arr2 = np.random.randn(n_rows, n_cols // 2).astype(\"i8\")\n        arr3 = np.random.randn(n_rows, n_cols // 4).astype(\"f8\")\n        df2 = pd.concat(\n            [DataFrame(arr1), DataFrame(arr2), DataFrame(arr3)],\n            axis=1,\n            ignore_index=True,\n        )\n        # should already be the case, but just to be sure\n        df2._consolidate_inplace()\n    \n        self.left = df\n        self.right = df2", "min_run_count": 2, "name": "arithmetic.FrameWithFrameWide.time_op_same_blocks", "number": 0, "param_names": ["op", "shape"], "params": [["<built-in function add>", "<built-in function floordiv>", "<built-in function gt>"], ["(1000000, 10)", "(100000, 100)", "(10000, 1000)", "(1000, 10000)"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "5a9a092d047b1965d0bc9f942b0cf7c15def8265241bbeedb67e2fceab345e22", "warmup_time": -1}, "arithmetic.IndexArithmetic.time_add": {"code": "class IndexArithmetic:\n    def time_add(self, dtype):\n        self.index + 2\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass IndexArithmetic:\n    def setup(self, dtype):\n        N = 10**6\n        indexes = {\"int\": \"makeIntIndex\", \"float\": \"makeFloatIndex\"}\n        self.index = getattr(tm, indexes[dtype])(N)", "min_run_count": 2, "name": "arithmetic.IndexArithmetic.time_add", "number": 0, "param_names": ["dtype"], "params": [["'float'", "'int'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "20c9bc1e9df60a74d785ff2b606452515c7a38fc2676ecfda78279b9780b1e90", "warmup_time": -1}, "arithmetic.IndexArithmetic.time_divide": {"code": "class IndexArithmetic:\n    def time_divide(self, dtype):\n        self.index / 2\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass IndexArithmetic:\n    def setup(self, dtype):\n        N = 10**6\n        indexes = {\"int\": \"makeIntIndex\", \"float\": \"makeFloatIndex\"}\n        self.index = getattr(tm, indexes[dtype])(N)", "min_run_count": 2, "name": "arithmetic.IndexArithmetic.time_divide", "number": 0, "param_names": ["dtype"], "params": [["'float'", "'int'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "d1643ca993a28d2f37852ee101aa0cd3c40c232cce6a4683acdc4af946649dac", "warmup_time": -1}, "arithmetic.IndexArithmetic.time_modulo": {"code": "class IndexArithmetic:\n    def time_modulo(self, dtype):\n        self.index % 2\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass IndexArithmetic:\n    def setup(self, dtype):\n        N = 10**6\n        indexes = {\"int\": \"makeIntIndex\", \"float\": \"makeFloatIndex\"}\n        self.index = getattr(tm, indexes[dtype])(N)", "min_run_count": 2, "name": "arithmetic.IndexArithmetic.time_modulo", "number": 0, "param_names": ["dtype"], "params": [["'float'", "'int'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "8b67d70054e2af3b83be7b256f957955232e04868885c79928c0ea15b4150b65", "warmup_time": -1}, "arithmetic.IndexArithmetic.time_multiply": {"code": "class IndexArithmetic:\n    def time_multiply(self, dtype):\n        self.index * 2\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass IndexArithmetic:\n    def setup(self, dtype):\n        N = 10**6\n        indexes = {\"int\": \"makeIntIndex\", \"float\": \"makeFloatIndex\"}\n        self.index = getattr(tm, indexes[dtype])(N)", "min_run_count": 2, "name": "arithmetic.IndexArithmetic.time_multiply", "number": 0, "param_names": ["dtype"], "params": [["'float'", "'int'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "7aa6b45c50c2b5600cf20f700259c4ea09a36e8115b39a025fee3afb013c5dda", "warmup_time": -1}, "arithmetic.IndexArithmetic.time_subtract": {"code": "class IndexArithmetic:\n    def time_subtract(self, dtype):\n        self.index - 2\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass IndexArithmetic:\n    def setup(self, dtype):\n        N = 10**6\n        indexes = {\"int\": \"makeIntIndex\", \"float\": \"makeFloatIndex\"}\n        self.index = getattr(tm, indexes[dtype])(N)", "min_run_count": 2, "name": "arithmetic.IndexArithmetic.time_subtract", "number": 0, "param_names": ["dtype"], "params": [["'float'", "'int'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "351586b3eb5e0e70890542dbd6c75404014bba85f77b6c67921345eef1ceb70a", "warmup_time": -1}, "arithmetic.IntFrameWithScalar.time_frame_op_with_scalar": {"code": "class IntFrameWithScalar:\n    def time_frame_op_with_scalar(self, dtype, scalar, op):\n        op(self.df, scalar)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass IntFrameWithScalar:\n    def setup(self, dtype, scalar, op):\n        arr = np.random.randn(20000, 100)\n        self.df = DataFrame(arr.astype(dtype))", "min_run_count": 2, "name": "arithmetic.IntFrameWithScalar.time_frame_op_with_scalar", "number": 0, "param_names": ["dtype", "scalar", "op"], "params": [["<class 'numpy.float64'>", "<class 'numpy.int64'>"], ["2", "3.0", "4", "5.0"], ["<built-in function add>", "<built-in function sub>", "<built-in function mul>", "<built-in function truediv>", "<built-in function floordiv>", "<built-in function pow>", "<built-in function mod>", "<built-in function eq>", "<built-in function ne>", "<built-in function gt>", "<built-in function ge>", "<built-in function lt>", "<built-in function le>"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "17cc3015c45764be50024cbe52247cfe2100d4020bdf03e0b04bea2f932fe975", "warmup_time": -1}, "arithmetic.IrregularOps.time_add": {"code": "class IrregularOps:\n    def time_add(self):\n        self.left + self.right\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass IrregularOps:\n    def setup(self):\n        N = 10**5\n        idx = date_range(start=\"1/1/2000\", periods=N, freq=\"s\")\n        s = Series(np.random.randn(N), index=idx)\n        self.left = s.sample(frac=1)\n        self.right = s.sample(frac=1)", "min_run_count": 2, "name": "arithmetic.IrregularOps.time_add", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "c48f5ee66f4fba32ce66ca585b4550f976b5632cf96bb22e9be34d3c2ea0a194", "warmup_time": -1}, "arithmetic.MixedFrameWithSeriesAxis.time_frame_op_with_series_axis0": {"code": "class MixedFrameWithSeriesAxis:\n    def time_frame_op_with_series_axis0(self, opname):\n        getattr(self.df, opname)(self.ser, axis=0)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass MixedFrameWithSeriesAxis:\n    def setup(self, opname):\n        arr = np.arange(10**6).reshape(1000, -1)\n        df = DataFrame(arr)\n        df[\"C\"] = 1.0\n        self.df = df\n        self.ser = df[0]\n        self.row = df.iloc[0]", "min_run_count": 2, "name": "arithmetic.MixedFrameWithSeriesAxis.time_frame_op_with_series_axis0", "number": 0, "param_names": ["opname"], "params": [["'eq'", "'ne'", "'lt'", "'le'", "'ge'", "'gt'", "'add'", "'sub'", "'truediv'", "'floordiv'", "'mul'", "'pow'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "2ec044d527bdcad8450ef35a26f4caee5ca2d8cf69f36b99665adedc140d4b71", "warmup_time": -1}, "arithmetic.MixedFrameWithSeriesAxis.time_frame_op_with_series_axis1": {"code": "class MixedFrameWithSeriesAxis:\n    def time_frame_op_with_series_axis1(self, opname):\n        getattr(operator, opname)(self.df, self.ser)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass MixedFrameWithSeriesAxis:\n    def setup(self, opname):\n        arr = np.arange(10**6).reshape(1000, -1)\n        df = DataFrame(arr)\n        df[\"C\"] = 1.0\n        self.df = df\n        self.ser = df[0]\n        self.row = df.iloc[0]", "min_run_count": 2, "name": "arithmetic.MixedFrameWithSeriesAxis.time_frame_op_with_series_axis1", "number": 0, "param_names": ["opname"], "params": [["'add'", "'sub'", "'truediv'", "'floordiv'", "'mul'", "'pow'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "1c5761284f2cd8adf60d3f65efee5881b415f0c986cfbbc8e313f298eb349a3e", "warmup_time": -1}, "arithmetic.NumericInferOps.time_add": {"code": "class NumericInferOps:\n    def time_add(self, dtype):\n        self.df[\"A\"] + self.df[\"B\"]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass NumericInferOps:\n    def setup(self, dtype):\n        N = 5 * 10**5\n        self.df = DataFrame(\n            {\"A\": np.arange(N).astype(dtype), \"B\": np.arange(N).astype(dtype)}\n        )", "min_run_count": 2, "name": "arithmetic.NumericInferOps.time_add", "number": 0, "param_names": ["dtype"], "params": [["<class 'numpy.int64'>", "<class 'numpy.int32'>", "<class 'numpy.uint32'>", "<class 'numpy.uint64'>", "<class 'numpy.float32'>", "<class 'numpy.float64'>", "<class 'numpy.int16'>", "<class 'numpy.int8'>", "<class 'numpy.uint16'>", "<class 'numpy.uint8'>"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "d8c4f5e6dc0c54cff731395cacf041f5ccf4d5fdf6605e5aea2767fdea959165", "warmup_time": -1}, "arithmetic.NumericInferOps.time_divide": {"code": "class NumericInferOps:\n    def time_divide(self, dtype):\n        self.df[\"A\"] / self.df[\"B\"]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass NumericInferOps:\n    def setup(self, dtype):\n        N = 5 * 10**5\n        self.df = DataFrame(\n            {\"A\": np.arange(N).astype(dtype), \"B\": np.arange(N).astype(dtype)}\n        )", "min_run_count": 2, "name": "arithmetic.NumericInferOps.time_divide", "number": 0, "param_names": ["dtype"], "params": [["<class 'numpy.int64'>", "<class 'numpy.int32'>", "<class 'numpy.uint32'>", "<class 'numpy.uint64'>", "<class 'numpy.float32'>", "<class 'numpy.float64'>", "<class 'numpy.int16'>", "<class 'numpy.int8'>", "<class 'numpy.uint16'>", "<class 'numpy.uint8'>"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "a435004455cc72252be9ec940814e96fbe3afb17fb5329b5d7c51208c9796979", "warmup_time": -1}, "arithmetic.NumericInferOps.time_modulo": {"code": "class NumericInferOps:\n    def time_modulo(self, dtype):\n        self.df[\"A\"] % self.df[\"B\"]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass NumericInferOps:\n    def setup(self, dtype):\n        N = 5 * 10**5\n        self.df = DataFrame(\n            {\"A\": np.arange(N).astype(dtype), \"B\": np.arange(N).astype(dtype)}\n        )", "min_run_count": 2, "name": "arithmetic.NumericInferOps.time_modulo", "number": 0, "param_names": ["dtype"], "params": [["<class 'numpy.int64'>", "<class 'numpy.int32'>", "<class 'numpy.uint32'>", "<class 'numpy.uint64'>", "<class 'numpy.float32'>", "<class 'numpy.float64'>", "<class 'numpy.int16'>", "<class 'numpy.int8'>", "<class 'numpy.uint16'>", "<class 'numpy.uint8'>"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "44d71d818e38047c0a9a5903a9d5707c2ff4eae84631c776e3dba9448493a767", "warmup_time": -1}, "arithmetic.NumericInferOps.time_multiply": {"code": "class NumericInferOps:\n    def time_multiply(self, dtype):\n        self.df[\"A\"] * self.df[\"B\"]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass NumericInferOps:\n    def setup(self, dtype):\n        N = 5 * 10**5\n        self.df = DataFrame(\n            {\"A\": np.arange(N).astype(dtype), \"B\": np.arange(N).astype(dtype)}\n        )", "min_run_count": 2, "name": "arithmetic.NumericInferOps.time_multiply", "number": 0, "param_names": ["dtype"], "params": [["<class 'numpy.int64'>", "<class 'numpy.int32'>", "<class 'numpy.uint32'>", "<class 'numpy.uint64'>", "<class 'numpy.float32'>", "<class 'numpy.float64'>", "<class 'numpy.int16'>", "<class 'numpy.int8'>", "<class 'numpy.uint16'>", "<class 'numpy.uint8'>"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "fe621ddecbe036b8b2a50405324b8024f35d0412d89bf916c6adec56d4c5f360", "warmup_time": -1}, "arithmetic.NumericInferOps.time_subtract": {"code": "class NumericInferOps:\n    def time_subtract(self, dtype):\n        self.df[\"A\"] - self.df[\"B\"]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass NumericInferOps:\n    def setup(self, dtype):\n        N = 5 * 10**5\n        self.df = DataFrame(\n            {\"A\": np.arange(N).astype(dtype), \"B\": np.arange(N).astype(dtype)}\n        )", "min_run_count": 2, "name": "arithmetic.NumericInferOps.time_subtract", "number": 0, "param_names": ["dtype"], "params": [["<class 'numpy.int64'>", "<class 'numpy.int32'>", "<class 'numpy.uint32'>", "<class 'numpy.uint64'>", "<class 'numpy.float32'>", "<class 'numpy.float64'>", "<class 'numpy.int16'>", "<class 'numpy.int8'>", "<class 'numpy.uint16'>", "<class 'numpy.uint8'>"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "2e26ca6727d932af0269ec66a57701c64b061d05601a076e2524ebf79e1b5cd6", "warmup_time": -1}, "arithmetic.OffsetArrayArithmetic.time_add_dti_offset": {"code": "class OffsetArrayArithmetic:\n    def time_add_dti_offset(self, offset):\n        with warnings.catch_warnings(record=True):\n            self.rng + offset\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass OffsetArrayArithmetic:\n    def setup(self, offset):\n        N = 10000\n        rng = date_range(start=\"1/1/2000\", periods=N, freq=\"T\")\n        self.rng = rng\n        self.ser = Series(rng)", "min_run_count": 2, "name": "arithmetic.OffsetArrayArithmetic.time_add_dti_offset", "number": 0, "param_names": ["offset"], "params": [["<Day>", "<BYearEnd: month=12>", "<BYearBegin: month=1>", "<BusinessQuarterEnd: startingMonth=3>", "<BusinessQuarterBegin: startingMonth=3>", "<BusinessMonthEnd>", "<BusinessMonthBegin>", "<CustomBusinessDay> (0)", "<CustomBusinessDay> (1)", "<CustomBusinessMonthBegin>", "<CustomBusinessMonthEnd> (0)", "<CustomBusinessMonthEnd> (1)", "<YearEnd: month=12>", "<YearBegin: month=1>", "<QuarterEnd: startingMonth=3>", "<QuarterBegin: startingMonth=3>", "<MonthEnd>", "<MonthBegin>", "<DateOffset: days=2, months=2>", "<BusinessDay>", "<SemiMonthEnd: day_of_month=15>", "<SemiMonthBegin: day_of_month=15>"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "1ba2a2ca36b167967741333eb7366ad1b1e4c8b9ee5db0ddbd9632e934f16e8e", "warmup_time": -1}, "arithmetic.OffsetArrayArithmetic.time_add_series_offset": {"code": "class OffsetArrayArithmetic:\n    def time_add_series_offset(self, offset):\n        with warnings.catch_warnings(record=True):\n            self.ser + offset\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass OffsetArrayArithmetic:\n    def setup(self, offset):\n        N = 10000\n        rng = date_range(start=\"1/1/2000\", periods=N, freq=\"T\")\n        self.rng = rng\n        self.ser = Series(rng)", "min_run_count": 2, "name": "arithmetic.OffsetArrayArithmetic.time_add_series_offset", "number": 0, "param_names": ["offset"], "params": [["<Day>", "<BYearEnd: month=12>", "<BYearBegin: month=1>", "<BusinessQuarterEnd: startingMonth=3>", "<BusinessQuarterBegin: startingMonth=3>", "<BusinessMonthEnd>", "<BusinessMonthBegin>", "<CustomBusinessDay> (0)", "<CustomBusinessDay> (1)", "<CustomBusinessMonthBegin>", "<CustomBusinessMonthEnd> (0)", "<CustomBusinessMonthEnd> (1)", "<YearEnd: month=12>", "<YearBegin: month=1>", "<QuarterEnd: startingMonth=3>", "<QuarterBegin: startingMonth=3>", "<MonthEnd>", "<MonthBegin>", "<DateOffset: days=2, months=2>", "<BusinessDay>", "<SemiMonthEnd: day_of_month=15>", "<SemiMonthBegin: day_of_month=15>"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "9e3db5d52584da2030628a2b3dfc64d1cffd727b1978f718616940ebb40403bb", "warmup_time": -1}, "arithmetic.OpWithFillValue.time_frame_op_with_fill_value_no_nas": {"code": "class OpWithFillValue:\n    def time_frame_op_with_fill_value_no_nas(self):\n        self.df.add(self.df, fill_value=4)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass OpWithFillValue:\n    def setup(self):\n        # GH#31300\n        arr = np.arange(10**6)\n        df = DataFrame({\"A\": arr})\n        ser = df[\"A\"]\n    \n        self.df = df\n        self.ser = ser", "min_run_count": 2, "name": "arithmetic.OpWithFillValue.time_frame_op_with_fill_value_no_nas", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "162ff770e3fdcbc51f2d5140c2cf46f028d48a27268957104ac69d7d800cc1a0", "warmup_time": -1}, "arithmetic.OpWithFillValue.time_series_op_with_fill_value_no_nas": {"code": "class OpWithFillValue:\n    def time_series_op_with_fill_value_no_nas(self):\n        self.ser.add(self.ser, fill_value=4)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass OpWithFillValue:\n    def setup(self):\n        # GH#31300\n        arr = np.arange(10**6)\n        df = DataFrame({\"A\": arr})\n        ser = df[\"A\"]\n    \n        self.df = df\n        self.ser = ser", "min_run_count": 2, "name": "arithmetic.OpWithFillValue.time_series_op_with_fill_value_no_nas", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "81d51758d1b72e5df11be69874e29ffab5fdbe1e4cd1816754c197a4833d5d8e", "warmup_time": -1}, "arithmetic.Ops.time_frame_add": {"code": "class Ops:\n    def time_frame_add(self, use_numexpr, threads):\n        self.df + self.df2\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Ops:\n    def setup(self, use_numexpr, threads):\n        self.df = DataFrame(np.random.randn(20000, 100))\n        self.df2 = DataFrame(np.random.randn(20000, 100))\n    \n        if threads != \"default\":\n            expr.set_numexpr_threads(threads)\n        if not use_numexpr:\n            expr.set_use_numexpr(False)", "min_run_count": 2, "name": "arithmetic.Ops.time_frame_add", "number": 0, "param_names": ["use_numexpr", "threads"], "params": [["True", "False"], ["'default'", "1"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "173dfb8c14d4f1e45058ae77d74a28966785fc801b28902fd8448d30ac4ff7d8", "warmup_time": -1}, "arithmetic.Ops.time_frame_comparison": {"code": "class Ops:\n    def time_frame_comparison(self, use_numexpr, threads):\n        self.df > self.df2\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Ops:\n    def setup(self, use_numexpr, threads):\n        self.df = DataFrame(np.random.randn(20000, 100))\n        self.df2 = DataFrame(np.random.randn(20000, 100))\n    \n        if threads != \"default\":\n            expr.set_numexpr_threads(threads)\n        if not use_numexpr:\n            expr.set_use_numexpr(False)", "min_run_count": 2, "name": "arithmetic.Ops.time_frame_comparison", "number": 0, "param_names": ["use_numexpr", "threads"], "params": [["True", "False"], ["'default'", "1"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "b9edf1afa79c0a69d8e9647b98beb73e32760b78ff938a190dc6b42ccac38b11", "warmup_time": -1}, "arithmetic.Ops.time_frame_mult": {"code": "class Ops:\n    def time_frame_mult(self, use_numexpr, threads):\n        self.df * self.df2\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Ops:\n    def setup(self, use_numexpr, threads):\n        self.df = DataFrame(np.random.randn(20000, 100))\n        self.df2 = DataFrame(np.random.randn(20000, 100))\n    \n        if threads != \"default\":\n            expr.set_numexpr_threads(threads)\n        if not use_numexpr:\n            expr.set_use_numexpr(False)", "min_run_count": 2, "name": "arithmetic.Ops.time_frame_mult", "number": 0, "param_names": ["use_numexpr", "threads"], "params": [["True", "False"], ["'default'", "1"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "911cfaa0ecf7737245490bf8a69723a5301ce60c296a33915a8eb9c09d7cd279", "warmup_time": -1}, "arithmetic.Ops.time_frame_multi_and": {"code": "class Ops:\n    def time_frame_multi_and(self, use_numexpr, threads):\n        self.df[(self.df > 0) & (self.df2 > 0)]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Ops:\n    def setup(self, use_numexpr, threads):\n        self.df = DataFrame(np.random.randn(20000, 100))\n        self.df2 = DataFrame(np.random.randn(20000, 100))\n    \n        if threads != \"default\":\n            expr.set_numexpr_threads(threads)\n        if not use_numexpr:\n            expr.set_use_numexpr(False)", "min_run_count": 2, "name": "arithmetic.Ops.time_frame_multi_and", "number": 0, "param_names": ["use_numexpr", "threads"], "params": [["True", "False"], ["'default'", "1"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "27fe96278213fdc7fe35ca52941a5bf4e3def23517666891d790d2d443a98ef2", "warmup_time": -1}, "arithmetic.Ops2.time_frame_dot": {"code": "class Ops2:\n    def time_frame_dot(self):\n        self.df.dot(self.df2)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Ops2:\n    def setup(self):\n        N = 10**3\n        self.df = DataFrame(np.random.randn(N, N))\n        self.df2 = DataFrame(np.random.randn(N, N))\n    \n        self.df_int = DataFrame(\n            np.random.randint(\n                np.iinfo(np.int16).min, np.iinfo(np.int16).max, size=(N, N)\n            )\n        )\n        self.df2_int = DataFrame(\n            np.random.randint(\n                np.iinfo(np.int16).min, np.iinfo(np.int16).max, size=(N, N)\n            )\n        )\n    \n        self.s = Series(np.random.randn(N))", "min_run_count": 2, "name": "arithmetic.Ops2.time_frame_dot", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "efdf52d3f6066f576d98f9b78aef45d706022d5fdf431ac33a3d411c8915c028", "warmup_time": -1}, "arithmetic.Ops2.time_frame_float_div": {"code": "class Ops2:\n    def time_frame_float_div(self):\n        self.df // self.df2\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Ops2:\n    def setup(self):\n        N = 10**3\n        self.df = DataFrame(np.random.randn(N, N))\n        self.df2 = DataFrame(np.random.randn(N, N))\n    \n        self.df_int = DataFrame(\n            np.random.randint(\n                np.iinfo(np.int16).min, np.iinfo(np.int16).max, size=(N, N)\n            )\n        )\n        self.df2_int = DataFrame(\n            np.random.randint(\n                np.iinfo(np.int16).min, np.iinfo(np.int16).max, size=(N, N)\n            )\n        )\n    \n        self.s = Series(np.random.randn(N))", "min_run_count": 2, "name": "arithmetic.Ops2.time_frame_float_div", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "859b0f256d5a19376ac8c740779c53fb2287fd0c6f8f0d2f48052d7a57050a0a", "warmup_time": -1}, "arithmetic.Ops2.time_frame_float_div_by_zero": {"code": "class Ops2:\n    def time_frame_float_div_by_zero(self):\n        self.df / 0\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Ops2:\n    def setup(self):\n        N = 10**3\n        self.df = DataFrame(np.random.randn(N, N))\n        self.df2 = DataFrame(np.random.randn(N, N))\n    \n        self.df_int = DataFrame(\n            np.random.randint(\n                np.iinfo(np.int16).min, np.iinfo(np.int16).max, size=(N, N)\n            )\n        )\n        self.df2_int = DataFrame(\n            np.random.randint(\n                np.iinfo(np.int16).min, np.iinfo(np.int16).max, size=(N, N)\n            )\n        )\n    \n        self.s = Series(np.random.randn(N))", "min_run_count": 2, "name": "arithmetic.Ops2.time_frame_float_div_by_zero", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "bacba426dd7890d79b38fd7575e9ba633c7ebc2252b393414e19e8838317b7a9", "warmup_time": -1}, "arithmetic.Ops2.time_frame_float_floor_by_zero": {"code": "class Ops2:\n    def time_frame_float_floor_by_zero(self):\n        self.df // 0\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Ops2:\n    def setup(self):\n        N = 10**3\n        self.df = DataFrame(np.random.randn(N, N))\n        self.df2 = DataFrame(np.random.randn(N, N))\n    \n        self.df_int = DataFrame(\n            np.random.randint(\n                np.iinfo(np.int16).min, np.iinfo(np.int16).max, size=(N, N)\n            )\n        )\n        self.df2_int = DataFrame(\n            np.random.randint(\n                np.iinfo(np.int16).min, np.iinfo(np.int16).max, size=(N, N)\n            )\n        )\n    \n        self.s = Series(np.random.randn(N))", "min_run_count": 2, "name": "arithmetic.Ops2.time_frame_float_floor_by_zero", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "5096a00c147e73e2a7a0be3156a440a3dd813fff99c8ed11456981814df947a2", "warmup_time": -1}, "arithmetic.Ops2.time_frame_float_mod": {"code": "class Ops2:\n    def time_frame_float_mod(self):\n        self.df % self.df2\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Ops2:\n    def setup(self):\n        N = 10**3\n        self.df = DataFrame(np.random.randn(N, N))\n        self.df2 = DataFrame(np.random.randn(N, N))\n    \n        self.df_int = DataFrame(\n            np.random.randint(\n                np.iinfo(np.int16).min, np.iinfo(np.int16).max, size=(N, N)\n            )\n        )\n        self.df2_int = DataFrame(\n            np.random.randint(\n                np.iinfo(np.int16).min, np.iinfo(np.int16).max, size=(N, N)\n            )\n        )\n    \n        self.s = Series(np.random.randn(N))", "min_run_count": 2, "name": "arithmetic.Ops2.time_frame_float_mod", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "72aa4cef09d38e4af67ae6e35e15b1304bd371e85fc3613e817cedd372852517", "warmup_time": -1}, "arithmetic.Ops2.time_frame_int_div_by_zero": {"code": "class Ops2:\n    def time_frame_int_div_by_zero(self):\n        self.df_int / 0\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Ops2:\n    def setup(self):\n        N = 10**3\n        self.df = DataFrame(np.random.randn(N, N))\n        self.df2 = DataFrame(np.random.randn(N, N))\n    \n        self.df_int = DataFrame(\n            np.random.randint(\n                np.iinfo(np.int16).min, np.iinfo(np.int16).max, size=(N, N)\n            )\n        )\n        self.df2_int = DataFrame(\n            np.random.randint(\n                np.iinfo(np.int16).min, np.iinfo(np.int16).max, size=(N, N)\n            )\n        )\n    \n        self.s = Series(np.random.randn(N))", "min_run_count": 2, "name": "arithmetic.Ops2.time_frame_int_div_by_zero", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "cdab6c35545be907f3db670b2114ccd527c652b9b3992d2ef767b26d538cc342", "warmup_time": -1}, "arithmetic.Ops2.time_frame_int_mod": {"code": "class Ops2:\n    def time_frame_int_mod(self):\n        self.df_int % self.df2_int\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Ops2:\n    def setup(self):\n        N = 10**3\n        self.df = DataFrame(np.random.randn(N, N))\n        self.df2 = DataFrame(np.random.randn(N, N))\n    \n        self.df_int = DataFrame(\n            np.random.randint(\n                np.iinfo(np.int16).min, np.iinfo(np.int16).max, size=(N, N)\n            )\n        )\n        self.df2_int = DataFrame(\n            np.random.randint(\n                np.iinfo(np.int16).min, np.iinfo(np.int16).max, size=(N, N)\n            )\n        )\n    \n        self.s = Series(np.random.randn(N))", "min_run_count": 2, "name": "arithmetic.Ops2.time_frame_int_mod", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "cb4f4230cb2354cccaed2ae0cd0fdfaf8ef908fbcf616544289f44a42a0f2eb4", "warmup_time": -1}, "arithmetic.Ops2.time_frame_series_dot": {"code": "class Ops2:\n    def time_frame_series_dot(self):\n        self.df.dot(self.s)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Ops2:\n    def setup(self):\n        N = 10**3\n        self.df = DataFrame(np.random.randn(N, N))\n        self.df2 = DataFrame(np.random.randn(N, N))\n    \n        self.df_int = DataFrame(\n            np.random.randint(\n                np.iinfo(np.int16).min, np.iinfo(np.int16).max, size=(N, N)\n            )\n        )\n        self.df2_int = DataFrame(\n            np.random.randint(\n                np.iinfo(np.int16).min, np.iinfo(np.int16).max, size=(N, N)\n            )\n        )\n    \n        self.s = Series(np.random.randn(N))", "min_run_count": 2, "name": "arithmetic.Ops2.time_frame_series_dot", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "30c45d8348c1f30ed5962671b11e5a31ae976f64b960b8cbe8eceb8c1f3716b8", "warmup_time": -1}, "arithmetic.Ops2.time_series_dot": {"code": "class Ops2:\n    def time_series_dot(self):\n        self.s.dot(self.s)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Ops2:\n    def setup(self):\n        N = 10**3\n        self.df = DataFrame(np.random.randn(N, N))\n        self.df2 = DataFrame(np.random.randn(N, N))\n    \n        self.df_int = DataFrame(\n            np.random.randint(\n                np.iinfo(np.int16).min, np.iinfo(np.int16).max, size=(N, N)\n            )\n        )\n        self.df2_int = DataFrame(\n            np.random.randint(\n                np.iinfo(np.int16).min, np.iinfo(np.int16).max, size=(N, N)\n            )\n        )\n    \n        self.s = Series(np.random.randn(N))", "min_run_count": 2, "name": "arithmetic.Ops2.time_series_dot", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "524f0eb5deba6ae021936a6721c4fec9cb92fccf0ac27c1799ab70139a436fdc", "warmup_time": -1}, "arithmetic.TimedeltaOps.time_add_td_ts": {"code": "class TimedeltaOps:\n    def time_add_td_ts(self):\n        self.td + self.ts\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass TimedeltaOps:\n    def setup(self):\n        self.td = to_timedelta(np.arange(1000000))\n        self.ts = Timestamp(\"2000\")", "min_run_count": 2, "name": "arithmetic.TimedeltaOps.time_add_td_ts", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "ee3abda2771a3808efc316e236cd6de15f8678b03e2a27e6f75792edbbe543ec", "warmup_time": -1}, "arithmetic.Timeseries.time_series_timestamp_compare": {"code": "class Timeseries:\n    def time_series_timestamp_compare(self, tz):\n        self.s <= self.ts\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Timeseries:\n    def setup(self, tz):\n        N = 10**6\n        halfway = (N // 2) - 1\n        self.s = Series(date_range(\"20010101\", periods=N, freq=\"T\", tz=tz))\n        self.ts = self.s[halfway]\n    \n        self.s2 = Series(date_range(\"20010101\", periods=N, freq=\"s\", tz=tz))", "min_run_count": 2, "name": "arithmetic.Timeseries.time_series_timestamp_compare", "number": 0, "param_names": ["tz"], "params": [["None", "'US/Eastern'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "d77a34cad0b4787f7176625231f25dca0d358bdc56e49ced85666cc21f84319b", "warmup_time": -1}, "arithmetic.Timeseries.time_timestamp_ops_diff": {"code": "class Timeseries:\n    def time_timestamp_ops_diff(self, tz):\n        self.s2.diff()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Timeseries:\n    def setup(self, tz):\n        N = 10**6\n        halfway = (N // 2) - 1\n        self.s = Series(date_range(\"20010101\", periods=N, freq=\"T\", tz=tz))\n        self.ts = self.s[halfway]\n    \n        self.s2 = Series(date_range(\"20010101\", periods=N, freq=\"s\", tz=tz))", "min_run_count": 2, "name": "arithmetic.Timeseries.time_timestamp_ops_diff", "number": 0, "param_names": ["tz"], "params": [["None", "'US/Eastern'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "b2761c68b5b4cec28c405d6a271f9d4185b5974864b2909f1f6d564dbbcc3b42", "warmup_time": -1}, "arithmetic.Timeseries.time_timestamp_ops_diff_with_shift": {"code": "class Timeseries:\n    def time_timestamp_ops_diff_with_shift(self, tz):\n        self.s - self.s.shift()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Timeseries:\n    def setup(self, tz):\n        N = 10**6\n        halfway = (N // 2) - 1\n        self.s = Series(date_range(\"20010101\", periods=N, freq=\"T\", tz=tz))\n        self.ts = self.s[halfway]\n    \n        self.s2 = Series(date_range(\"20010101\", periods=N, freq=\"s\", tz=tz))", "min_run_count": 2, "name": "arithmetic.Timeseries.time_timestamp_ops_diff_with_shift", "number": 0, "param_names": ["tz"], "params": [["None", "'US/Eastern'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "a3d6d80200703b3a90962b4a282e712ed33ee8f47766e64a907c2dbd9c6adc3b", "warmup_time": -1}, "arithmetic.Timeseries.time_timestamp_series_compare": {"code": "class Timeseries:\n    def time_timestamp_series_compare(self, tz):\n        self.ts >= self.s\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Timeseries:\n    def setup(self, tz):\n        N = 10**6\n        halfway = (N // 2) - 1\n        self.s = Series(date_range(\"20010101\", periods=N, freq=\"T\", tz=tz))\n        self.ts = self.s[halfway]\n    \n        self.s2 = Series(date_range(\"20010101\", periods=N, freq=\"s\", tz=tz))", "min_run_count": 2, "name": "arithmetic.Timeseries.time_timestamp_series_compare", "number": 0, "param_names": ["tz"], "params": [["None", "'US/Eastern'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "d87c7cb38711f5769b1660d3c1bb12855c79bd6667f61a9af105565d966c2356", "warmup_time": -1}, "array.ArrowExtensionArray.time_to_numpy": {"code": "class ArrowExtensionArray:\n    def time_to_numpy(self, dtype, hasna):\n        self.arr.to_numpy()\n\n    def setup(self, dtype, hasna):\n        N = 100_000\n        if dtype == \"boolean[pyarrow]\":\n            data = np.random.choice([True, False], N, replace=True)\n        elif dtype == \"float64[pyarrow]\":\n            data = np.random.randn(N)\n        elif dtype == \"int64[pyarrow]\":\n            data = np.arange(N)\n        elif dtype == \"string[pyarrow]\":\n            data = tm.rands_array(10, N)\n        elif dtype == \"timestamp[ns][pyarrow]\":\n            data = pd.date_range(\"2000-01-01\", freq=\"s\", periods=N)\n        else:\n            raise NotImplementedError\n    \n        arr = pd.array(data, dtype=dtype)\n        if hasna:\n            arr[::2] = pd.NA\n        self.arr = arr", "min_run_count": 2, "name": "array.ArrowExtensionArray.time_to_numpy", "number": 0, "param_names": ["dtype", "hasna"], "params": [["'boolean[pyarrow]'", "'float64[pyarrow]'", "'int64[pyarrow]'", "'string[pyarrow]'", "'timestamp[ns][pyarrow]'"], ["False", "True"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "140328207d6cf774b7b31c2c594ba6a219e5aded7d236105992866afca3660f4", "warmup_time": -1}, "array.ArrowStringArray.time_setitem": {"code": "class ArrowStringArray:\n    def time_setitem(self, multiple_chunks):\n        for i in range(200):\n            self.array[i] = \"foo\"\n\n    def setup(self, multiple_chunks):\n        try:\n            import pyarrow as pa\n        except ImportError:\n            raise NotImplementedError\n        strings = tm.rands_array(3, 10_000)\n        if multiple_chunks:\n            chunks = [strings[i : i + 100] for i in range(0, len(strings), 100)]\n            self.array = pd.arrays.ArrowStringArray(pa.chunked_array(chunks))\n        else:\n            self.array = pd.arrays.ArrowStringArray(pa.array(strings))", "min_run_count": 2, "name": "array.ArrowStringArray.time_setitem", "number": 0, "param_names": ["multiple_chunks"], "params": [["False", "True"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "e972e8af2b999d25a430d9305393fa46699dbc6badfe04c0efa6bbd6f618af3c", "warmup_time": -1}, "array.ArrowStringArray.time_setitem_list": {"code": "class ArrowStringArray:\n    def time_setitem_list(self, multiple_chunks):\n        indexer = list(range(0, 50)) + list(range(-1000, 0, 50))\n        self.array[indexer] = [\"foo\"] * len(indexer)\n\n    def setup(self, multiple_chunks):\n        try:\n            import pyarrow as pa\n        except ImportError:\n            raise NotImplementedError\n        strings = tm.rands_array(3, 10_000)\n        if multiple_chunks:\n            chunks = [strings[i : i + 100] for i in range(0, len(strings), 100)]\n            self.array = pd.arrays.ArrowStringArray(pa.chunked_array(chunks))\n        else:\n            self.array = pd.arrays.ArrowStringArray(pa.array(strings))", "min_run_count": 2, "name": "array.ArrowStringArray.time_setitem_list", "number": 0, "param_names": ["multiple_chunks"], "params": [["False", "True"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "4a3f56f5608e8cf0050c6df938599bce1aab1bb9fda9165e3b9cefcc9700e268", "warmup_time": -1}, "array.ArrowStringArray.time_setitem_null_slice": {"code": "class ArrowStringArray:\n    def time_setitem_null_slice(self, multiple_chunks):\n        self.array[:] = \"foo\"\n\n    def setup(self, multiple_chunks):\n        try:\n            import pyarrow as pa\n        except ImportError:\n            raise NotImplementedError\n        strings = tm.rands_array(3, 10_000)\n        if multiple_chunks:\n            chunks = [strings[i : i + 100] for i in range(0, len(strings), 100)]\n            self.array = pd.arrays.ArrowStringArray(pa.chunked_array(chunks))\n        else:\n            self.array = pd.arrays.ArrowStringArray(pa.array(strings))", "min_run_count": 2, "name": "array.ArrowStringArray.time_setitem_null_slice", "number": 0, "param_names": ["multiple_chunks"], "params": [["False", "True"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "086dc565f5767164f630df5e58851c39b07dc872fdc94c4ace31492ed9dd4c2d", "warmup_time": -1}, "array.ArrowStringArray.time_setitem_slice": {"code": "class ArrowStringArray:\n    def time_setitem_slice(self, multiple_chunks):\n        self.array[::10] = \"foo\"\n\n    def setup(self, multiple_chunks):\n        try:\n            import pyarrow as pa\n        except ImportError:\n            raise NotImplementedError\n        strings = tm.rands_array(3, 10_000)\n        if multiple_chunks:\n            chunks = [strings[i : i + 100] for i in range(0, len(strings), 100)]\n            self.array = pd.arrays.ArrowStringArray(pa.chunked_array(chunks))\n        else:\n            self.array = pd.arrays.ArrowStringArray(pa.array(strings))", "min_run_count": 2, "name": "array.ArrowStringArray.time_setitem_slice", "number": 0, "param_names": ["multiple_chunks"], "params": [["False", "True"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "6e7a72dd371857d02a89c8d285268ecec5bd3ffbda6d78c35b88457fd2f28314", "warmup_time": -1}, "array.ArrowStringArray.time_tolist": {"code": "class ArrowStringArray:\n    def time_tolist(self, multiple_chunks):\n        self.array.tolist()\n\n    def setup(self, multiple_chunks):\n        try:\n            import pyarrow as pa\n        except ImportError:\n            raise NotImplementedError\n        strings = tm.rands_array(3, 10_000)\n        if multiple_chunks:\n            chunks = [strings[i : i + 100] for i in range(0, len(strings), 100)]\n            self.array = pd.arrays.ArrowStringArray(pa.chunked_array(chunks))\n        else:\n            self.array = pd.arrays.ArrowStringArray(pa.array(strings))", "min_run_count": 2, "name": "array.ArrowStringArray.time_tolist", "number": 0, "param_names": ["multiple_chunks"], "params": [["False", "True"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "eb2856090ac593a10abd505f2d476df89dafe5d00db34aaf1e003326bba67fdd", "warmup_time": -1}, "array.BooleanArray.time_constructor": {"code": "class BooleanArray:\n    def time_constructor(self):\n        pd.arrays.BooleanArray(self.data, self.mask)\n\n    def setup(self):\n        self.values_bool = np.array([True, False, True, False])\n        self.values_float = np.array([1.0, 0.0, 1.0, 0.0])\n        self.values_integer = np.array([1, 0, 1, 0])\n        self.values_integer_like = [1, 0, 1, 0]\n        self.data = np.array([True, False, True, False])\n        self.mask = np.array([False, False, True, False])", "min_run_count": 2, "name": "array.BooleanArray.time_constructor", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "31f0c0638e5908b3b2f79ec954e3e3c5f9b247f04708fe2a8ba53b4df1b161d5", "warmup_time": -1}, "array.BooleanArray.time_from_bool_array": {"code": "class BooleanArray:\n    def time_from_bool_array(self):\n        pd.array(self.values_bool, dtype=\"boolean\")\n\n    def setup(self):\n        self.values_bool = np.array([True, False, True, False])\n        self.values_float = np.array([1.0, 0.0, 1.0, 0.0])\n        self.values_integer = np.array([1, 0, 1, 0])\n        self.values_integer_like = [1, 0, 1, 0]\n        self.data = np.array([True, False, True, False])\n        self.mask = np.array([False, False, True, False])", "min_run_count": 2, "name": "array.BooleanArray.time_from_bool_array", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "49de818c0d3213d4624b41ad1583ffa3da28d65f2dd89a30c9ed9ce4d8902300", "warmup_time": -1}, "array.BooleanArray.time_from_float_array": {"code": "class BooleanArray:\n    def time_from_float_array(self):\n        pd.array(self.values_float, dtype=\"boolean\")\n\n    def setup(self):\n        self.values_bool = np.array([True, False, True, False])\n        self.values_float = np.array([1.0, 0.0, 1.0, 0.0])\n        self.values_integer = np.array([1, 0, 1, 0])\n        self.values_integer_like = [1, 0, 1, 0]\n        self.data = np.array([True, False, True, False])\n        self.mask = np.array([False, False, True, False])", "min_run_count": 2, "name": "array.BooleanArray.time_from_float_array", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "00f65facf261a9f506e825a7a84d17cc35d7f00ff17f090622cbbdb8e6a538dc", "warmup_time": -1}, "array.BooleanArray.time_from_integer_array": {"code": "class BooleanArray:\n    def time_from_integer_array(self):\n        pd.array(self.values_integer, dtype=\"boolean\")\n\n    def setup(self):\n        self.values_bool = np.array([True, False, True, False])\n        self.values_float = np.array([1.0, 0.0, 1.0, 0.0])\n        self.values_integer = np.array([1, 0, 1, 0])\n        self.values_integer_like = [1, 0, 1, 0]\n        self.data = np.array([True, False, True, False])\n        self.mask = np.array([False, False, True, False])", "min_run_count": 2, "name": "array.BooleanArray.time_from_integer_array", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "d27d54d2b7793c51154ffb049d0e1508e27dc0b3cdfa4f734789da01a48e0abf", "warmup_time": -1}, "array.BooleanArray.time_from_integer_like": {"code": "class BooleanArray:\n    def time_from_integer_like(self):\n        pd.array(self.values_integer_like, dtype=\"boolean\")\n\n    def setup(self):\n        self.values_bool = np.array([True, False, True, False])\n        self.values_float = np.array([1.0, 0.0, 1.0, 0.0])\n        self.values_integer = np.array([1, 0, 1, 0])\n        self.values_integer_like = [1, 0, 1, 0]\n        self.data = np.array([True, False, True, False])\n        self.mask = np.array([False, False, True, False])", "min_run_count": 2, "name": "array.BooleanArray.time_from_integer_like", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "6c37947cc0814a4fabfcf5fc4ebcb76a3e8d231c4fb5ca15eb3d0f502617a17d", "warmup_time": -1}, "array.IntegerArray.time_constructor": {"code": "class IntegerArray:\n    def time_constructor(self):\n        pd.arrays.IntegerArray(self.data, self.mask)\n\n    def setup(self):\n        N = 250_000\n        self.values_integer = np.array([1, 0, 1, 0] * N)\n        self.data = np.array([1, 2, 3, 4] * N, dtype=\"int64\")\n        self.mask = np.array([False, False, True, False] * N)", "min_run_count": 2, "name": "array.IntegerArray.time_constructor", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "4316e4d2f325cf40918df7a8ccc1a7ea45ba1d6d6993f1351532368832b8396b", "warmup_time": -1}, "array.IntegerArray.time_from_integer_array": {"code": "class IntegerArray:\n    def time_from_integer_array(self):\n        pd.array(self.values_integer, dtype=\"Int64\")\n\n    def setup(self):\n        N = 250_000\n        self.values_integer = np.array([1, 0, 1, 0] * N)\n        self.data = np.array([1, 2, 3, 4] * N, dtype=\"int64\")\n        self.mask = np.array([False, False, True, False] * N)", "min_run_count": 2, "name": "array.IntegerArray.time_from_integer_array", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "df91c421ea05e0536821588b93b04e18b2ed59872d1ea443964ce233a64d5cec", "warmup_time": -1}, "array.IntervalArray.time_from_tuples": {"code": "class IntervalArray:\n    def time_from_tuples(self):\n        pd.arrays.IntervalArray.from_tuples(self.tuples)\n\n    def setup(self):\n        N = 10_000\n        self.tuples = [(i, i + 1) for i in range(N)]", "min_run_count": 2, "name": "array.IntervalArray.time_from_tuples", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "ba4b21278924821c6bf31f74072230f7b2a24d7c87f7b4f0e1f99025ff60cdb8", "warmup_time": -1}, "array.StringArray.time_from_list": {"code": "class StringArray:\n    def time_from_list(self):\n        pd.array(self.values_list, dtype=\"string\")\n\n    def setup(self):\n        N = 100_000\n        values = tm.rands_array(3, N)\n        self.values_obj = np.array(values, dtype=\"object\")\n        self.values_str = np.array(values, dtype=\"U\")\n        self.values_list = values.tolist()", "min_run_count": 2, "name": "array.StringArray.time_from_list", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "89146348c60e2e079ca68b12278ed5e9be153fdd0adb4774e4f945098864ffa1", "warmup_time": -1}, "array.StringArray.time_from_np_object_array": {"code": "class StringArray:\n    def time_from_np_object_array(self):\n        pd.array(self.values_obj, dtype=\"string\")\n\n    def setup(self):\n        N = 100_000\n        values = tm.rands_array(3, N)\n        self.values_obj = np.array(values, dtype=\"object\")\n        self.values_str = np.array(values, dtype=\"U\")\n        self.values_list = values.tolist()", "min_run_count": 2, "name": "array.StringArray.time_from_np_object_array", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "73762664b3ae801e205fccd6c42278f72aee2a131b9093a3783654573915d891", "warmup_time": -1}, "array.StringArray.time_from_np_str_array": {"code": "class StringArray:\n    def time_from_np_str_array(self):\n        pd.array(self.values_str, dtype=\"string\")\n\n    def setup(self):\n        N = 100_000\n        values = tm.rands_array(3, N)\n        self.values_obj = np.array(values, dtype=\"object\")\n        self.values_str = np.array(values, dtype=\"U\")\n        self.values_list = values.tolist()", "min_run_count": 2, "name": "array.StringArray.time_from_np_str_array", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "be5ceb7cd13a9d96a465c9ceb4b1223df032e8d3983c59ae1ed8b5142ad09479", "warmup_time": -1}, "attrs_caching.DataFrameAttributes.time_get_index": {"code": "class DataFrameAttributes:\n    def time_get_index(self):\n        self.df.index\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass DataFrameAttributes:\n    def setup(self):\n        self.df = DataFrame(np.random.randn(10, 6))\n        self.cur_index = self.df.index", "min_run_count": 2, "name": "attrs_caching.DataFrameAttributes.time_get_index", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "3246f297f11fb6074032907dde5fb9690d93465c80b45bc0b29e284fd5c9c17c", "warmup_time": -1}, "attrs_caching.DataFrameAttributes.time_set_index": {"code": "class DataFrameAttributes:\n    def time_set_index(self):\n        self.df.index = self.cur_index\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass DataFrameAttributes:\n    def setup(self):\n        self.df = DataFrame(np.random.randn(10, 6))\n        self.cur_index = self.df.index", "min_run_count": 2, "name": "attrs_caching.DataFrameAttributes.time_set_index", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "b34bb7eb8426bdd2eb9d8e0550ea2573475694ddc9f971fd9a29f15bf16732b0", "warmup_time": -1}, "attrs_caching.SeriesArrayAttribute.time_array": {"code": "class SeriesArrayAttribute:\n    def time_array(self, dtype):\n        self.series.array\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass SeriesArrayAttribute:\n    def setup(self, dtype):\n        if dtype == \"numeric\":\n            self.series = pd.Series([1, 2, 3])\n        elif dtype == \"object\":\n            self.series = pd.Series([\"a\", \"b\", \"c\"], dtype=object)\n        elif dtype == \"category\":\n            self.series = pd.Series([\"a\", \"b\", \"c\"], dtype=\"category\")\n        elif dtype == \"datetime64\":\n            self.series = pd.Series(pd.date_range(\"2013\", periods=3))\n        elif dtype == \"datetime64tz\":\n            self.series = pd.Series(pd.date_range(\"2013\", periods=3, tz=\"UTC\"))", "min_run_count": 2, "name": "attrs_caching.SeriesArrayAttribute.time_array", "number": 0, "param_names": ["dtype"], "params": [["'numeric'", "'object'", "'category'", "'datetime64'", "'datetime64tz'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "71871bee8b7f7a74c594352ad1177b3201818e5ffe6296b02844d93f2e74c57b", "warmup_time": -1}, "attrs_caching.SeriesArrayAttribute.time_extract_array": {"code": "class SeriesArrayAttribute:\n    def time_extract_array(self, dtype):\n        extract_array(self.series)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass SeriesArrayAttribute:\n    def setup(self, dtype):\n        if dtype == \"numeric\":\n            self.series = pd.Series([1, 2, 3])\n        elif dtype == \"object\":\n            self.series = pd.Series([\"a\", \"b\", \"c\"], dtype=object)\n        elif dtype == \"category\":\n            self.series = pd.Series([\"a\", \"b\", \"c\"], dtype=\"category\")\n        elif dtype == \"datetime64\":\n            self.series = pd.Series(pd.date_range(\"2013\", periods=3))\n        elif dtype == \"datetime64tz\":\n            self.series = pd.Series(pd.date_range(\"2013\", periods=3, tz=\"UTC\"))", "min_run_count": 2, "name": "attrs_caching.SeriesArrayAttribute.time_extract_array", "number": 0, "param_names": ["dtype"], "params": [["'numeric'", "'object'", "'category'", "'datetime64'", "'datetime64tz'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "5c9e10a019a9c3c1a6f4016572eac561387c3cc14086cde81066ae5d495b6bae", "warmup_time": -1}, "attrs_caching.SeriesArrayAttribute.time_extract_array_numpy": {"code": "class SeriesArrayAttribute:\n    def time_extract_array_numpy(self, dtype):\n        extract_array(self.series, extract_numpy=True)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass SeriesArrayAttribute:\n    def setup(self, dtype):\n        if dtype == \"numeric\":\n            self.series = pd.Series([1, 2, 3])\n        elif dtype == \"object\":\n            self.series = pd.Series([\"a\", \"b\", \"c\"], dtype=object)\n        elif dtype == \"category\":\n            self.series = pd.Series([\"a\", \"b\", \"c\"], dtype=\"category\")\n        elif dtype == \"datetime64\":\n            self.series = pd.Series(pd.date_range(\"2013\", periods=3))\n        elif dtype == \"datetime64tz\":\n            self.series = pd.Series(pd.date_range(\"2013\", periods=3, tz=\"UTC\"))", "min_run_count": 2, "name": "attrs_caching.SeriesArrayAttribute.time_extract_array_numpy", "number": 0, "param_names": ["dtype"], "params": [["'numeric'", "'object'", "'category'", "'datetime64'", "'datetime64tz'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "34310e30090bb516b844f357295ebbe46f2980040632e1178dffc041a7635892", "warmup_time": -1}, "boolean.TimeLogicalOps.time_and_array": {"code": "class TimeLogicalOps:\n    def time_and_array(self):\n        self.left & self.right\n\n    def setup(self):\n        N = 10_000\n        left, right, lmask, rmask = np.random.randint(0, 2, size=(4, N)).astype(\"bool\")\n        self.left = pd.arrays.BooleanArray(left, lmask)\n        self.right = pd.arrays.BooleanArray(right, rmask)", "min_run_count": 2, "name": "boolean.TimeLogicalOps.time_and_array", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "6f948c075c42597b3abbe166b111d3f02c0aa11a2fd01b376b96547a7a0ece18", "warmup_time": -1}, "boolean.TimeLogicalOps.time_and_scalar": {"code": "class TimeLogicalOps:\n    def time_and_scalar(self):\n        self.left & True\n        self.left & False\n\n    def setup(self):\n        N = 10_000\n        left, right, lmask, rmask = np.random.randint(0, 2, size=(4, N)).astype(\"bool\")\n        self.left = pd.arrays.BooleanArray(left, lmask)\n        self.right = pd.arrays.BooleanArray(right, rmask)", "min_run_count": 2, "name": "boolean.TimeLogicalOps.time_and_scalar", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "73483ccace6f6debdb2fd885f8fd8ffee9883f4e6dad1587a13239b8be135868", "warmup_time": -1}, "boolean.TimeLogicalOps.time_or_array": {"code": "class TimeLogicalOps:\n    def time_or_array(self):\n        self.left | self.right\n\n    def setup(self):\n        N = 10_000\n        left, right, lmask, rmask = np.random.randint(0, 2, size=(4, N)).astype(\"bool\")\n        self.left = pd.arrays.BooleanArray(left, lmask)\n        self.right = pd.arrays.BooleanArray(right, rmask)", "min_run_count": 2, "name": "boolean.TimeLogicalOps.time_or_array", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "dc01bb9cbcdc979b4fbe050df208268a15ff5f328081a7fd09c41283c33bfa5d", "warmup_time": -1}, "boolean.TimeLogicalOps.time_or_scalar": {"code": "class TimeLogicalOps:\n    def time_or_scalar(self):\n        self.left | True\n        self.left | False\n\n    def setup(self):\n        N = 10_000\n        left, right, lmask, rmask = np.random.randint(0, 2, size=(4, N)).astype(\"bool\")\n        self.left = pd.arrays.BooleanArray(left, lmask)\n        self.right = pd.arrays.BooleanArray(right, rmask)", "min_run_count": 2, "name": "boolean.TimeLogicalOps.time_or_scalar", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "a9dcf90a110c0c703887ee44358e18a6930758987f7f1e9f921dd5ff4c84234e", "warmup_time": -1}, "boolean.TimeLogicalOps.time_xor_array": {"code": "class TimeLogicalOps:\n    def time_xor_array(self):\n        self.left ^ self.right\n\n    def setup(self):\n        N = 10_000\n        left, right, lmask, rmask = np.random.randint(0, 2, size=(4, N)).astype(\"bool\")\n        self.left = pd.arrays.BooleanArray(left, lmask)\n        self.right = pd.arrays.BooleanArray(right, rmask)", "min_run_count": 2, "name": "boolean.TimeLogicalOps.time_xor_array", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "e093e59c2f51a4998acf114ad54d2ab5d62d38548aab71f3f5c6adbe6bc46792", "warmup_time": -1}, "boolean.TimeLogicalOps.time_xor_scalar": {"code": "class TimeLogicalOps:\n    def time_xor_scalar(self):\n        self.left ^ True\n        self.left ^ False\n\n    def setup(self):\n        N = 10_000\n        left, right, lmask, rmask = np.random.randint(0, 2, size=(4, N)).astype(\"bool\")\n        self.left = pd.arrays.BooleanArray(left, lmask)\n        self.right = pd.arrays.BooleanArray(right, rmask)", "min_run_count": 2, "name": "boolean.TimeLogicalOps.time_xor_scalar", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "eb50d9fee1d2beff8da51a2f128bb84bfa76379e9a699ae60dec8e82655bef3c", "warmup_time": -1}, "categoricals.CategoricalSlicing.time_getitem_bool_array": {"code": "class CategoricalSlicing:\n    def time_getitem_bool_array(self, index):\n        self.data[self.data == self.cat_scalar]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass CategoricalSlicing:\n    def setup(self, index):\n        N = 10**6\n        categories = [\"a\", \"b\", \"c\"]\n        values = [0] * N + [1] * N + [2] * N\n        if index == \"monotonic_incr\":\n            self.data = pd.Categorical.from_codes(values, categories=categories)\n        elif index == \"monotonic_decr\":\n            self.data = pd.Categorical.from_codes(\n                list(reversed(values)), categories=categories\n            )\n        elif index == \"non_monotonic\":\n            self.data = pd.Categorical.from_codes([0, 1, 2] * N, categories=categories)\n        else:\n            raise ValueError(f\"Invalid index param: {index}\")\n    \n        self.scalar = 10000\n        self.list = list(range(10000))\n        self.cat_scalar = \"b\"", "min_run_count": 2, "name": "categoricals.CategoricalSlicing.time_getitem_bool_array", "number": 0, "param_names": ["index"], "params": [["'monotonic_incr'", "'monotonic_decr'", "'non_monotonic'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "769b65f5ea8394c47c35a3fc005bd0b2c513bbf7ff46efeef4580cae74db66c7", "warmup_time": -1}, "categoricals.CategoricalSlicing.time_getitem_list": {"code": "class CategoricalSlicing:\n    def time_getitem_list(self, index):\n        self.data[self.list]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass CategoricalSlicing:\n    def setup(self, index):\n        N = 10**6\n        categories = [\"a\", \"b\", \"c\"]\n        values = [0] * N + [1] * N + [2] * N\n        if index == \"monotonic_incr\":\n            self.data = pd.Categorical.from_codes(values, categories=categories)\n        elif index == \"monotonic_decr\":\n            self.data = pd.Categorical.from_codes(\n                list(reversed(values)), categories=categories\n            )\n        elif index == \"non_monotonic\":\n            self.data = pd.Categorical.from_codes([0, 1, 2] * N, categories=categories)\n        else:\n            raise ValueError(f\"Invalid index param: {index}\")\n    \n        self.scalar = 10000\n        self.list = list(range(10000))\n        self.cat_scalar = \"b\"", "min_run_count": 2, "name": "categoricals.CategoricalSlicing.time_getitem_list", "number": 0, "param_names": ["index"], "params": [["'monotonic_incr'", "'monotonic_decr'", "'non_monotonic'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "916fd9b1ffffb5893e1ca7a72627015a8acd94be0bdc143eca8f50d39e9122a9", "warmup_time": -1}, "categoricals.CategoricalSlicing.time_getitem_list_like": {"code": "class CategoricalSlicing:\n    def time_getitem_list_like(self, index):\n        self.data[[self.scalar]]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass CategoricalSlicing:\n    def setup(self, index):\n        N = 10**6\n        categories = [\"a\", \"b\", \"c\"]\n        values = [0] * N + [1] * N + [2] * N\n        if index == \"monotonic_incr\":\n            self.data = pd.Categorical.from_codes(values, categories=categories)\n        elif index == \"monotonic_decr\":\n            self.data = pd.Categorical.from_codes(\n                list(reversed(values)), categories=categories\n            )\n        elif index == \"non_monotonic\":\n            self.data = pd.Categorical.from_codes([0, 1, 2] * N, categories=categories)\n        else:\n            raise ValueError(f\"Invalid index param: {index}\")\n    \n        self.scalar = 10000\n        self.list = list(range(10000))\n        self.cat_scalar = \"b\"", "min_run_count": 2, "name": "categoricals.CategoricalSlicing.time_getitem_list_like", "number": 0, "param_names": ["index"], "params": [["'monotonic_incr'", "'monotonic_decr'", "'non_monotonic'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "68d5f2e40482277a18de4cda382eaf8990d3e79c6e9b2f55d17dfa5a70b8d549", "warmup_time": -1}, "categoricals.CategoricalSlicing.time_getitem_scalar": {"code": "class CategoricalSlicing:\n    def time_getitem_scalar(self, index):\n        self.data[self.scalar]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass CategoricalSlicing:\n    def setup(self, index):\n        N = 10**6\n        categories = [\"a\", \"b\", \"c\"]\n        values = [0] * N + [1] * N + [2] * N\n        if index == \"monotonic_incr\":\n            self.data = pd.Categorical.from_codes(values, categories=categories)\n        elif index == \"monotonic_decr\":\n            self.data = pd.Categorical.from_codes(\n                list(reversed(values)), categories=categories\n            )\n        elif index == \"non_monotonic\":\n            self.data = pd.Categorical.from_codes([0, 1, 2] * N, categories=categories)\n        else:\n            raise ValueError(f\"Invalid index param: {index}\")\n    \n        self.scalar = 10000\n        self.list = list(range(10000))\n        self.cat_scalar = \"b\"", "min_run_count": 2, "name": "categoricals.CategoricalSlicing.time_getitem_scalar", "number": 0, "param_names": ["index"], "params": [["'monotonic_incr'", "'monotonic_decr'", "'non_monotonic'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "fe7dc7a8a5d11a4709f9904a75eb1123ee25b128949e123162a83893e7e91c3b", "warmup_time": -1}, "categoricals.CategoricalSlicing.time_getitem_slice": {"code": "class CategoricalSlicing:\n    def time_getitem_slice(self, index):\n        self.data[: self.scalar]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass CategoricalSlicing:\n    def setup(self, index):\n        N = 10**6\n        categories = [\"a\", \"b\", \"c\"]\n        values = [0] * N + [1] * N + [2] * N\n        if index == \"monotonic_incr\":\n            self.data = pd.Categorical.from_codes(values, categories=categories)\n        elif index == \"monotonic_decr\":\n            self.data = pd.Categorical.from_codes(\n                list(reversed(values)), categories=categories\n            )\n        elif index == \"non_monotonic\":\n            self.data = pd.Categorical.from_codes([0, 1, 2] * N, categories=categories)\n        else:\n            raise ValueError(f\"Invalid index param: {index}\")\n    \n        self.scalar = 10000\n        self.list = list(range(10000))\n        self.cat_scalar = \"b\"", "min_run_count": 2, "name": "categoricals.CategoricalSlicing.time_getitem_slice", "number": 0, "param_names": ["index"], "params": [["'monotonic_incr'", "'monotonic_decr'", "'non_monotonic'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "4d0d7546d903d9ceb8f8129acce462eb99fc242a19d70a16809644ad1b3947e3", "warmup_time": -1}, "categoricals.Concat.time_append_non_overlapping_index": {"code": "class Concat:\n    def time_append_non_overlapping_index(self):\n        self.idx_a.append(self.idx_b)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Concat:\n    def setup(self):\n        N = 10**5\n        self.s = pd.Series(list(\"aabbcd\") * N).astype(\"category\")\n    \n        self.a = pd.Categorical(list(\"aabbcd\") * N)\n        self.b = pd.Categorical(list(\"bbcdjk\") * N)\n    \n        self.idx_a = pd.CategoricalIndex(range(N), range(N))\n        self.idx_b = pd.CategoricalIndex(range(N + 1), range(N + 1))\n        self.df_a = pd.DataFrame(range(N), columns=[\"a\"], index=self.idx_a)\n        self.df_b = pd.DataFrame(range(N + 1), columns=[\"a\"], index=self.idx_b)", "min_run_count": 2, "name": "categoricals.Concat.time_append_non_overlapping_index", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "7c08f6f4a37c69d20540206d1bb4eac69032087283c327ea354e4e58b28e8e8a", "warmup_time": -1}, "categoricals.Concat.time_append_overlapping_index": {"code": "class Concat:\n    def time_append_overlapping_index(self):\n        self.idx_a.append(self.idx_a)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Concat:\n    def setup(self):\n        N = 10**5\n        self.s = pd.Series(list(\"aabbcd\") * N).astype(\"category\")\n    \n        self.a = pd.Categorical(list(\"aabbcd\") * N)\n        self.b = pd.Categorical(list(\"bbcdjk\") * N)\n    \n        self.idx_a = pd.CategoricalIndex(range(N), range(N))\n        self.idx_b = pd.CategoricalIndex(range(N + 1), range(N + 1))\n        self.df_a = pd.DataFrame(range(N), columns=[\"a\"], index=self.idx_a)\n        self.df_b = pd.DataFrame(range(N + 1), columns=[\"a\"], index=self.idx_b)", "min_run_count": 2, "name": "categoricals.Concat.time_append_overlapping_index", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "86138129674bef3e164dd5e409ec0b275c1168e83dd747378cf52b02eb2311ea", "warmup_time": -1}, "categoricals.Concat.time_concat": {"code": "class Concat:\n    def time_concat(self):\n        pd.concat([self.s, self.s])\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Concat:\n    def setup(self):\n        N = 10**5\n        self.s = pd.Series(list(\"aabbcd\") * N).astype(\"category\")\n    \n        self.a = pd.Categorical(list(\"aabbcd\") * N)\n        self.b = pd.Categorical(list(\"bbcdjk\") * N)\n    \n        self.idx_a = pd.CategoricalIndex(range(N), range(N))\n        self.idx_b = pd.CategoricalIndex(range(N + 1), range(N + 1))\n        self.df_a = pd.DataFrame(range(N), columns=[\"a\"], index=self.idx_a)\n        self.df_b = pd.DataFrame(range(N + 1), columns=[\"a\"], index=self.idx_b)", "min_run_count": 2, "name": "categoricals.Concat.time_concat", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "60e2b37af13d3ba791a2c5fa40b92f67b1d3f6421e301d9dfcfcd4ff1da10041", "warmup_time": -1}, "categoricals.Concat.time_concat_non_overlapping_index": {"code": "class Concat:\n    def time_concat_non_overlapping_index(self):\n        pd.concat([self.df_a, self.df_b])\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Concat:\n    def setup(self):\n        N = 10**5\n        self.s = pd.Series(list(\"aabbcd\") * N).astype(\"category\")\n    \n        self.a = pd.Categorical(list(\"aabbcd\") * N)\n        self.b = pd.Categorical(list(\"bbcdjk\") * N)\n    \n        self.idx_a = pd.CategoricalIndex(range(N), range(N))\n        self.idx_b = pd.CategoricalIndex(range(N + 1), range(N + 1))\n        self.df_a = pd.DataFrame(range(N), columns=[\"a\"], index=self.idx_a)\n        self.df_b = pd.DataFrame(range(N + 1), columns=[\"a\"], index=self.idx_b)", "min_run_count": 2, "name": "categoricals.Concat.time_concat_non_overlapping_index", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "471ef66a2a2b2f051d1de9ad1ff46d1f9db09d862d97bedea6868f6ddd1f19f8", "warmup_time": -1}, "categoricals.Concat.time_concat_overlapping_index": {"code": "class Concat:\n    def time_concat_overlapping_index(self):\n        pd.concat([self.df_a, self.df_a])\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Concat:\n    def setup(self):\n        N = 10**5\n        self.s = pd.Series(list(\"aabbcd\") * N).astype(\"category\")\n    \n        self.a = pd.Categorical(list(\"aabbcd\") * N)\n        self.b = pd.Categorical(list(\"bbcdjk\") * N)\n    \n        self.idx_a = pd.CategoricalIndex(range(N), range(N))\n        self.idx_b = pd.CategoricalIndex(range(N + 1), range(N + 1))\n        self.df_a = pd.DataFrame(range(N), columns=[\"a\"], index=self.idx_a)\n        self.df_b = pd.DataFrame(range(N + 1), columns=[\"a\"], index=self.idx_b)", "min_run_count": 2, "name": "categoricals.Concat.time_concat_overlapping_index", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "ecdea66fab8e41b9f198da14c16f2281c65bcff35fb98ddab2baf37924133287", "warmup_time": -1}, "categoricals.Concat.time_union": {"code": "class Concat:\n    def time_union(self):\n        union_categoricals([self.a, self.b])\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Concat:\n    def setup(self):\n        N = 10**5\n        self.s = pd.Series(list(\"aabbcd\") * N).astype(\"category\")\n    \n        self.a = pd.Categorical(list(\"aabbcd\") * N)\n        self.b = pd.Categorical(list(\"bbcdjk\") * N)\n    \n        self.idx_a = pd.CategoricalIndex(range(N), range(N))\n        self.idx_b = pd.CategoricalIndex(range(N + 1), range(N + 1))\n        self.df_a = pd.DataFrame(range(N), columns=[\"a\"], index=self.idx_a)\n        self.df_b = pd.DataFrame(range(N + 1), columns=[\"a\"], index=self.idx_b)", "min_run_count": 2, "name": "categoricals.Concat.time_union", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "b7637f08baccfad51b169c40b0d317647c40413dadb0068206d81bc916c9d71b", "warmup_time": -1}, "categoricals.Constructor.time_all_nan": {"code": "class Constructor:\n    def time_all_nan(self):\n        pd.Categorical(self.values_all_nan)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Constructor:\n    def setup(self):\n        N = 10**5\n        self.categories = list(\"abcde\")\n        self.cat_idx = pd.Index(self.categories)\n        self.values = np.tile(self.categories, N)\n        self.codes = np.tile(range(len(self.categories)), N)\n    \n        self.datetimes = pd.Series(\n            pd.date_range(\"1995-01-01 00:00:00\", periods=N / 10, freq=\"s\")\n        )\n        self.datetimes_with_nat = self.datetimes.copy()\n        self.datetimes_with_nat.iloc[-1] = pd.NaT\n    \n        self.values_some_nan = list(np.tile(self.categories + [np.nan], N))\n        self.values_all_nan = [np.nan] * len(self.values)\n        self.values_all_int8 = np.ones(N, \"int8\")\n        self.categorical = pd.Categorical(self.values, self.categories)\n        self.series = pd.Series(self.categorical)\n        self.intervals = pd.interval_range(0, 1, periods=N // 10)", "min_run_count": 2, "name": "categoricals.Constructor.time_all_nan", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "7313e9ac9f46adb8c4a7b2e56649b840805b73f2e8ad314e3c6c25aba2ae4765", "warmup_time": -1}, "categoricals.Constructor.time_datetimes": {"code": "class Constructor:\n    def time_datetimes(self):\n        pd.Categorical(self.datetimes)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Constructor:\n    def setup(self):\n        N = 10**5\n        self.categories = list(\"abcde\")\n        self.cat_idx = pd.Index(self.categories)\n        self.values = np.tile(self.categories, N)\n        self.codes = np.tile(range(len(self.categories)), N)\n    \n        self.datetimes = pd.Series(\n            pd.date_range(\"1995-01-01 00:00:00\", periods=N / 10, freq=\"s\")\n        )\n        self.datetimes_with_nat = self.datetimes.copy()\n        self.datetimes_with_nat.iloc[-1] = pd.NaT\n    \n        self.values_some_nan = list(np.tile(self.categories + [np.nan], N))\n        self.values_all_nan = [np.nan] * len(self.values)\n        self.values_all_int8 = np.ones(N, \"int8\")\n        self.categorical = pd.Categorical(self.values, self.categories)\n        self.series = pd.Series(self.categorical)\n        self.intervals = pd.interval_range(0, 1, periods=N // 10)", "min_run_count": 2, "name": "categoricals.Constructor.time_datetimes", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "1a19b241eb3585b2ce56b672e956326b957375a6810b9d068ceceedc180eb0b3", "warmup_time": -1}, "categoricals.Constructor.time_datetimes_with_nat": {"code": "class Constructor:\n    def time_datetimes_with_nat(self):\n        pd.Categorical(self.datetimes_with_nat)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Constructor:\n    def setup(self):\n        N = 10**5\n        self.categories = list(\"abcde\")\n        self.cat_idx = pd.Index(self.categories)\n        self.values = np.tile(self.categories, N)\n        self.codes = np.tile(range(len(self.categories)), N)\n    \n        self.datetimes = pd.Series(\n            pd.date_range(\"1995-01-01 00:00:00\", periods=N / 10, freq=\"s\")\n        )\n        self.datetimes_with_nat = self.datetimes.copy()\n        self.datetimes_with_nat.iloc[-1] = pd.NaT\n    \n        self.values_some_nan = list(np.tile(self.categories + [np.nan], N))\n        self.values_all_nan = [np.nan] * len(self.values)\n        self.values_all_int8 = np.ones(N, \"int8\")\n        self.categorical = pd.Categorical(self.values, self.categories)\n        self.series = pd.Series(self.categorical)\n        self.intervals = pd.interval_range(0, 1, periods=N // 10)", "min_run_count": 2, "name": "categoricals.Constructor.time_datetimes_with_nat", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "bd3372456db022df20c40a27e9a9aedf7b42eaafc8f781ecb6e058823ac427b7", "warmup_time": -1}, "categoricals.Constructor.time_existing_categorical": {"code": "class Constructor:\n    def time_existing_categorical(self):\n        pd.Categorical(self.categorical)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Constructor:\n    def setup(self):\n        N = 10**5\n        self.categories = list(\"abcde\")\n        self.cat_idx = pd.Index(self.categories)\n        self.values = np.tile(self.categories, N)\n        self.codes = np.tile(range(len(self.categories)), N)\n    \n        self.datetimes = pd.Series(\n            pd.date_range(\"1995-01-01 00:00:00\", periods=N / 10, freq=\"s\")\n        )\n        self.datetimes_with_nat = self.datetimes.copy()\n        self.datetimes_with_nat.iloc[-1] = pd.NaT\n    \n        self.values_some_nan = list(np.tile(self.categories + [np.nan], N))\n        self.values_all_nan = [np.nan] * len(self.values)\n        self.values_all_int8 = np.ones(N, \"int8\")\n        self.categorical = pd.Categorical(self.values, self.categories)\n        self.series = pd.Series(self.categorical)\n        self.intervals = pd.interval_range(0, 1, periods=N // 10)", "min_run_count": 2, "name": "categoricals.Constructor.time_existing_categorical", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "35dcdd523b144b1c390233fb583c57670ee350c63b2a314559c14d3f4356744c", "warmup_time": -1}, "categoricals.Constructor.time_existing_series": {"code": "class Constructor:\n    def time_existing_series(self):\n        pd.Categorical(self.series)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Constructor:\n    def setup(self):\n        N = 10**5\n        self.categories = list(\"abcde\")\n        self.cat_idx = pd.Index(self.categories)\n        self.values = np.tile(self.categories, N)\n        self.codes = np.tile(range(len(self.categories)), N)\n    \n        self.datetimes = pd.Series(\n            pd.date_range(\"1995-01-01 00:00:00\", periods=N / 10, freq=\"s\")\n        )\n        self.datetimes_with_nat = self.datetimes.copy()\n        self.datetimes_with_nat.iloc[-1] = pd.NaT\n    \n        self.values_some_nan = list(np.tile(self.categories + [np.nan], N))\n        self.values_all_nan = [np.nan] * len(self.values)\n        self.values_all_int8 = np.ones(N, \"int8\")\n        self.categorical = pd.Categorical(self.values, self.categories)\n        self.series = pd.Series(self.categorical)\n        self.intervals = pd.interval_range(0, 1, periods=N // 10)", "min_run_count": 2, "name": "categoricals.Constructor.time_existing_series", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "7f95670c86db933fe267eeef555e4402ede21b4de4b9a4d97a33a2f209c49417", "warmup_time": -1}, "categoricals.Constructor.time_fastpath": {"code": "class Constructor:\n    def time_fastpath(self):\n        pd.Categorical(self.codes, self.cat_idx, fastpath=True)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Constructor:\n    def setup(self):\n        N = 10**5\n        self.categories = list(\"abcde\")\n        self.cat_idx = pd.Index(self.categories)\n        self.values = np.tile(self.categories, N)\n        self.codes = np.tile(range(len(self.categories)), N)\n    \n        self.datetimes = pd.Series(\n            pd.date_range(\"1995-01-01 00:00:00\", periods=N / 10, freq=\"s\")\n        )\n        self.datetimes_with_nat = self.datetimes.copy()\n        self.datetimes_with_nat.iloc[-1] = pd.NaT\n    \n        self.values_some_nan = list(np.tile(self.categories + [np.nan], N))\n        self.values_all_nan = [np.nan] * len(self.values)\n        self.values_all_int8 = np.ones(N, \"int8\")\n        self.categorical = pd.Categorical(self.values, self.categories)\n        self.series = pd.Series(self.categorical)\n        self.intervals = pd.interval_range(0, 1, periods=N // 10)", "min_run_count": 2, "name": "categoricals.Constructor.time_fastpath", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "e8655c6dead7fc308da465b0422585297b5f4ef81cec67c0e14d3139db098baa", "warmup_time": -1}, "categoricals.Constructor.time_from_codes_all_int8": {"code": "class Constructor:\n    def time_from_codes_all_int8(self):\n        pd.Categorical.from_codes(self.values_all_int8, self.categories)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Constructor:\n    def setup(self):\n        N = 10**5\n        self.categories = list(\"abcde\")\n        self.cat_idx = pd.Index(self.categories)\n        self.values = np.tile(self.categories, N)\n        self.codes = np.tile(range(len(self.categories)), N)\n    \n        self.datetimes = pd.Series(\n            pd.date_range(\"1995-01-01 00:00:00\", periods=N / 10, freq=\"s\")\n        )\n        self.datetimes_with_nat = self.datetimes.copy()\n        self.datetimes_with_nat.iloc[-1] = pd.NaT\n    \n        self.values_some_nan = list(np.tile(self.categories + [np.nan], N))\n        self.values_all_nan = [np.nan] * len(self.values)\n        self.values_all_int8 = np.ones(N, \"int8\")\n        self.categorical = pd.Categorical(self.values, self.categories)\n        self.series = pd.Series(self.categorical)\n        self.intervals = pd.interval_range(0, 1, periods=N // 10)", "min_run_count": 2, "name": "categoricals.Constructor.time_from_codes_all_int8", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "8e99b2ce968c4ca587be75672cad6d5c2ddfeff553b10b26fc0727a493194172", "warmup_time": -1}, "categoricals.Constructor.time_interval": {"code": "class Constructor:\n    def time_interval(self):\n        pd.Categorical(self.datetimes, categories=self.datetimes)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Constructor:\n    def setup(self):\n        N = 10**5\n        self.categories = list(\"abcde\")\n        self.cat_idx = pd.Index(self.categories)\n        self.values = np.tile(self.categories, N)\n        self.codes = np.tile(range(len(self.categories)), N)\n    \n        self.datetimes = pd.Series(\n            pd.date_range(\"1995-01-01 00:00:00\", periods=N / 10, freq=\"s\")\n        )\n        self.datetimes_with_nat = self.datetimes.copy()\n        self.datetimes_with_nat.iloc[-1] = pd.NaT\n    \n        self.values_some_nan = list(np.tile(self.categories + [np.nan], N))\n        self.values_all_nan = [np.nan] * len(self.values)\n        self.values_all_int8 = np.ones(N, \"int8\")\n        self.categorical = pd.Categorical(self.values, self.categories)\n        self.series = pd.Series(self.categorical)\n        self.intervals = pd.interval_range(0, 1, periods=N // 10)", "min_run_count": 2, "name": "categoricals.Constructor.time_interval", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "792e5ccdfd0875754cf88f95cc59fff6ce96143d5dcc3ea942241c2f0f71a428", "warmup_time": -1}, "categoricals.Constructor.time_regular": {"code": "class Constructor:\n    def time_regular(self):\n        pd.Categorical(self.values, self.categories)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Constructor:\n    def setup(self):\n        N = 10**5\n        self.categories = list(\"abcde\")\n        self.cat_idx = pd.Index(self.categories)\n        self.values = np.tile(self.categories, N)\n        self.codes = np.tile(range(len(self.categories)), N)\n    \n        self.datetimes = pd.Series(\n            pd.date_range(\"1995-01-01 00:00:00\", periods=N / 10, freq=\"s\")\n        )\n        self.datetimes_with_nat = self.datetimes.copy()\n        self.datetimes_with_nat.iloc[-1] = pd.NaT\n    \n        self.values_some_nan = list(np.tile(self.categories + [np.nan], N))\n        self.values_all_nan = [np.nan] * len(self.values)\n        self.values_all_int8 = np.ones(N, \"int8\")\n        self.categorical = pd.Categorical(self.values, self.categories)\n        self.series = pd.Series(self.categorical)\n        self.intervals = pd.interval_range(0, 1, periods=N // 10)", "min_run_count": 2, "name": "categoricals.Constructor.time_regular", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "6872d6c509be44733c6d83cf8a3a6c718329853cd6a5d15ba5c56398c96499e9", "warmup_time": -1}, "categoricals.Constructor.time_with_nan": {"code": "class Constructor:\n    def time_with_nan(self):\n        pd.Categorical(self.values_some_nan)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Constructor:\n    def setup(self):\n        N = 10**5\n        self.categories = list(\"abcde\")\n        self.cat_idx = pd.Index(self.categories)\n        self.values = np.tile(self.categories, N)\n        self.codes = np.tile(range(len(self.categories)), N)\n    \n        self.datetimes = pd.Series(\n            pd.date_range(\"1995-01-01 00:00:00\", periods=N / 10, freq=\"s\")\n        )\n        self.datetimes_with_nat = self.datetimes.copy()\n        self.datetimes_with_nat.iloc[-1] = pd.NaT\n    \n        self.values_some_nan = list(np.tile(self.categories + [np.nan], N))\n        self.values_all_nan = [np.nan] * len(self.values)\n        self.values_all_int8 = np.ones(N, \"int8\")\n        self.categorical = pd.Categorical(self.values, self.categories)\n        self.series = pd.Series(self.categorical)\n        self.intervals = pd.interval_range(0, 1, periods=N // 10)", "min_run_count": 2, "name": "categoricals.Constructor.time_with_nan", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "fcb1339a8633427497fc1fdea3d103b6575a5914b056831f806bec409ab545cc", "warmup_time": -1}, "categoricals.Contains.time_categorical_contains": {"code": "class Contains:\n    def time_categorical_contains(self):\n        self.key in self.c\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Contains:\n    def setup(self):\n        N = 10**5\n        self.ci = tm.makeCategoricalIndex(N)\n        self.c = self.ci.values\n        self.key = self.ci.categories[0]", "min_run_count": 2, "name": "categoricals.Contains.time_categorical_contains", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "77f3b4e31f05649f19d29f65b21b80fba3de57272fa920e1bf4e976e4e4575fb", "warmup_time": -1}, "categoricals.Contains.time_categorical_index_contains": {"code": "class Contains:\n    def time_categorical_index_contains(self):\n        self.key in self.ci\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Contains:\n    def setup(self):\n        N = 10**5\n        self.ci = tm.makeCategoricalIndex(N)\n        self.c = self.ci.values\n        self.key = self.ci.categories[0]", "min_run_count": 2, "name": "categoricals.Contains.time_categorical_index_contains", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "a3e10d785a7669bb81bffd50f26920bd45d77b72776c719896b1cca37b589164", "warmup_time": -1}, "categoricals.Indexing.time_align": {"code": "class Indexing:\n    def time_align(self):\n        pd.DataFrame({\"a\": self.series, \"b\": self.series[:500]})\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Indexing:\n    def setup(self):\n        N = 10**5\n        self.index = pd.CategoricalIndex(range(N), range(N))\n        self.series = pd.Series(range(N), index=self.index).sort_index()\n        self.category = self.index[500]", "min_run_count": 2, "name": "categoricals.Indexing.time_align", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "f218e6d543ab19db3fea1db2b664146198dd39dadac2966494426b556613d32d", "warmup_time": -1}, "categoricals.Indexing.time_get_loc": {"code": "class Indexing:\n    def time_get_loc(self):\n        self.index.get_loc(self.category)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Indexing:\n    def setup(self):\n        N = 10**5\n        self.index = pd.CategoricalIndex(range(N), range(N))\n        self.series = pd.Series(range(N), index=self.index).sort_index()\n        self.category = self.index[500]", "min_run_count": 2, "name": "categoricals.Indexing.time_get_loc", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "5f38e85f8450cba2264bb47680c1a9cd76458677f62e8ec8b53aac9e29c4fe62", "warmup_time": -1}, "categoricals.Indexing.time_intersection": {"code": "class Indexing:\n    def time_intersection(self):\n        self.index[:750].intersection(self.index[250:])\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Indexing:\n    def setup(self):\n        N = 10**5\n        self.index = pd.CategoricalIndex(range(N), range(N))\n        self.series = pd.Series(range(N), index=self.index).sort_index()\n        self.category = self.index[500]", "min_run_count": 2, "name": "categoricals.Indexing.time_intersection", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "a413f3ef1a42a84770cc263a3ffc018c0623a71a70d26e58676660ab47210939", "warmup_time": -1}, "categoricals.Indexing.time_reindex": {"code": "class Indexing:\n    def time_reindex(self):\n        self.index.reindex(self.index[:500])\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Indexing:\n    def setup(self):\n        N = 10**5\n        self.index = pd.CategoricalIndex(range(N), range(N))\n        self.series = pd.Series(range(N), index=self.index).sort_index()\n        self.category = self.index[500]", "min_run_count": 2, "name": "categoricals.Indexing.time_reindex", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "f068d9fbc3b599870598bc5ca8891b88762d7882d98234cd287b7021ae6ebdc2", "warmup_time": -1}, "categoricals.Indexing.time_reindex_missing": {"code": "class Indexing:\n    def time_reindex_missing(self):\n        self.index.reindex([\"a\", \"b\", \"c\", \"d\"])\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Indexing:\n    def setup(self):\n        N = 10**5\n        self.index = pd.CategoricalIndex(range(N), range(N))\n        self.series = pd.Series(range(N), index=self.index).sort_index()\n        self.category = self.index[500]", "min_run_count": 2, "name": "categoricals.Indexing.time_reindex_missing", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "8b7b5234b7e636fd26fb1d2ab98bfc3f744be66628ba69f7642a1f723887547f", "warmup_time": -1}, "categoricals.Indexing.time_shallow_copy": {"code": "class Indexing:\n    def time_shallow_copy(self):\n        self.index._view()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Indexing:\n    def setup(self):\n        N = 10**5\n        self.index = pd.CategoricalIndex(range(N), range(N))\n        self.series = pd.Series(range(N), index=self.index).sort_index()\n        self.category = self.index[500]", "min_run_count": 2, "name": "categoricals.Indexing.time_shallow_copy", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "a719f97efeb6e929cfd555a6be02dce8108efd04f1f5bda591f52a642f5adbf9", "warmup_time": -1}, "categoricals.Indexing.time_sort_values": {"code": "class Indexing:\n    def time_sort_values(self):\n        self.index.sort_values(ascending=False)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Indexing:\n    def setup(self):\n        N = 10**5\n        self.index = pd.CategoricalIndex(range(N), range(N))\n        self.series = pd.Series(range(N), index=self.index).sort_index()\n        self.category = self.index[500]", "min_run_count": 2, "name": "categoricals.Indexing.time_sort_values", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "57dcf263eeda37b74d296554b77303db6387683cbff9d7e4ec8fbd03cab2f4d4", "warmup_time": -1}, "categoricals.Indexing.time_unique": {"code": "class Indexing:\n    def time_unique(self):\n        self.index.unique()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Indexing:\n    def setup(self):\n        N = 10**5\n        self.index = pd.CategoricalIndex(range(N), range(N))\n        self.series = pd.Series(range(N), index=self.index).sort_index()\n        self.category = self.index[500]", "min_run_count": 2, "name": "categoricals.Indexing.time_unique", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "410cd9935506da614c2c46ec84a159befdeefe6b74e61c91bd5daa01f7d3e677", "warmup_time": -1}, "categoricals.IsMonotonic.time_categorical_index_is_monotonic_decreasing": {"code": "class IsMonotonic:\n    def time_categorical_index_is_monotonic_decreasing(self):\n        self.c.is_monotonic_decreasing\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass IsMonotonic:\n    def setup(self):\n        N = 1000\n        self.c = pd.CategoricalIndex(list(\"a\" * N + \"b\" * N + \"c\" * N))\n        self.s = pd.Series(self.c)", "min_run_count": 2, "name": "categoricals.IsMonotonic.time_categorical_index_is_monotonic_decreasing", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "c4d103c6279f0b80ce554b92ebb3e5bc2c44dc1e40f2fa4ab07455ea280ab8cb", "warmup_time": -1}, "categoricals.IsMonotonic.time_categorical_index_is_monotonic_increasing": {"code": "class IsMonotonic:\n    def time_categorical_index_is_monotonic_increasing(self):\n        self.c.is_monotonic_increasing\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass IsMonotonic:\n    def setup(self):\n        N = 1000\n        self.c = pd.CategoricalIndex(list(\"a\" * N + \"b\" * N + \"c\" * N))\n        self.s = pd.Series(self.c)", "min_run_count": 2, "name": "categoricals.IsMonotonic.time_categorical_index_is_monotonic_increasing", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "fcebf885784c8e801b36cabd669598864a44b3d464eaef9eda7ca74df92105ad", "warmup_time": -1}, "categoricals.IsMonotonic.time_categorical_series_is_monotonic_decreasing": {"code": "class IsMonotonic:\n    def time_categorical_series_is_monotonic_decreasing(self):\n        self.s.is_monotonic_decreasing\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass IsMonotonic:\n    def setup(self):\n        N = 1000\n        self.c = pd.CategoricalIndex(list(\"a\" * N + \"b\" * N + \"c\" * N))\n        self.s = pd.Series(self.c)", "min_run_count": 2, "name": "categoricals.IsMonotonic.time_categorical_series_is_monotonic_decreasing", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "fa8a5687d97343fae36bb22d0c776cfb090faec43b933d9f88facde7ba72c762", "warmup_time": -1}, "categoricals.IsMonotonic.time_categorical_series_is_monotonic_increasing": {"code": "class IsMonotonic:\n    def time_categorical_series_is_monotonic_increasing(self):\n        self.s.is_monotonic_increasing\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass IsMonotonic:\n    def setup(self):\n        N = 1000\n        self.c = pd.CategoricalIndex(list(\"a\" * N + \"b\" * N + \"c\" * N))\n        self.s = pd.Series(self.c)", "min_run_count": 2, "name": "categoricals.IsMonotonic.time_categorical_series_is_monotonic_increasing", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "834fbde98d28981a9f726086c81fcfaed2914996bff27fdcdafe4769d95bb3d3", "warmup_time": -1}, "categoricals.Rank.time_rank_int": {"code": "class Rank:\n    def time_rank_int(self):\n        self.s_int.rank()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Rank:\n    def setup(self):\n        N = 10**5\n        ncats = 15\n    \n        self.s_str = pd.Series(tm.makeCategoricalIndex(N, ncats)).astype(str)\n        self.s_str_cat = pd.Series(self.s_str, dtype=\"category\")\n        with warnings.catch_warnings(record=True):\n            str_cat_type = pd.CategoricalDtype(set(self.s_str), ordered=True)\n            self.s_str_cat_ordered = self.s_str.astype(str_cat_type)\n    \n        self.s_int = pd.Series(np.random.randint(0, ncats, size=N))\n        self.s_int_cat = pd.Series(self.s_int, dtype=\"category\")\n        with warnings.catch_warnings(record=True):\n            int_cat_type = pd.CategoricalDtype(set(self.s_int), ordered=True)\n            self.s_int_cat_ordered = self.s_int.astype(int_cat_type)", "min_run_count": 2, "name": "categoricals.Rank.time_rank_int", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "727cc8393680f3e828ec5afdc39bebbff30da62e42a3e6d68dcdb61912a62f0b", "warmup_time": -1}, "categoricals.Rank.time_rank_int_cat": {"code": "class Rank:\n    def time_rank_int_cat(self):\n        self.s_int_cat.rank()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Rank:\n    def setup(self):\n        N = 10**5\n        ncats = 15\n    \n        self.s_str = pd.Series(tm.makeCategoricalIndex(N, ncats)).astype(str)\n        self.s_str_cat = pd.Series(self.s_str, dtype=\"category\")\n        with warnings.catch_warnings(record=True):\n            str_cat_type = pd.CategoricalDtype(set(self.s_str), ordered=True)\n            self.s_str_cat_ordered = self.s_str.astype(str_cat_type)\n    \n        self.s_int = pd.Series(np.random.randint(0, ncats, size=N))\n        self.s_int_cat = pd.Series(self.s_int, dtype=\"category\")\n        with warnings.catch_warnings(record=True):\n            int_cat_type = pd.CategoricalDtype(set(self.s_int), ordered=True)\n            self.s_int_cat_ordered = self.s_int.astype(int_cat_type)", "min_run_count": 2, "name": "categoricals.Rank.time_rank_int_cat", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "0e8180441f26d94cb45c63a7a7ac3b16c4467717780755e99ec4f079770e60cb", "warmup_time": -1}, "categoricals.Rank.time_rank_int_cat_ordered": {"code": "class Rank:\n    def time_rank_int_cat_ordered(self):\n        self.s_int_cat_ordered.rank()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Rank:\n    def setup(self):\n        N = 10**5\n        ncats = 15\n    \n        self.s_str = pd.Series(tm.makeCategoricalIndex(N, ncats)).astype(str)\n        self.s_str_cat = pd.Series(self.s_str, dtype=\"category\")\n        with warnings.catch_warnings(record=True):\n            str_cat_type = pd.CategoricalDtype(set(self.s_str), ordered=True)\n            self.s_str_cat_ordered = self.s_str.astype(str_cat_type)\n    \n        self.s_int = pd.Series(np.random.randint(0, ncats, size=N))\n        self.s_int_cat = pd.Series(self.s_int, dtype=\"category\")\n        with warnings.catch_warnings(record=True):\n            int_cat_type = pd.CategoricalDtype(set(self.s_int), ordered=True)\n            self.s_int_cat_ordered = self.s_int.astype(int_cat_type)", "min_run_count": 2, "name": "categoricals.Rank.time_rank_int_cat_ordered", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "d88301ede87cccb5179176ecc7f31726a8314ed6b8df94ad20f26e25d06dfc92", "warmup_time": -1}, "categoricals.Rank.time_rank_string": {"code": "class Rank:\n    def time_rank_string(self):\n        self.s_str.rank()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Rank:\n    def setup(self):\n        N = 10**5\n        ncats = 15\n    \n        self.s_str = pd.Series(tm.makeCategoricalIndex(N, ncats)).astype(str)\n        self.s_str_cat = pd.Series(self.s_str, dtype=\"category\")\n        with warnings.catch_warnings(record=True):\n            str_cat_type = pd.CategoricalDtype(set(self.s_str), ordered=True)\n            self.s_str_cat_ordered = self.s_str.astype(str_cat_type)\n    \n        self.s_int = pd.Series(np.random.randint(0, ncats, size=N))\n        self.s_int_cat = pd.Series(self.s_int, dtype=\"category\")\n        with warnings.catch_warnings(record=True):\n            int_cat_type = pd.CategoricalDtype(set(self.s_int), ordered=True)\n            self.s_int_cat_ordered = self.s_int.astype(int_cat_type)", "min_run_count": 2, "name": "categoricals.Rank.time_rank_string", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "4a5398fec159ba005c62023243dca67edc108b1c64b8e4fccb2f9f4c615ef395", "warmup_time": -1}, "categoricals.Rank.time_rank_string_cat": {"code": "class Rank:\n    def time_rank_string_cat(self):\n        self.s_str_cat.rank()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Rank:\n    def setup(self):\n        N = 10**5\n        ncats = 15\n    \n        self.s_str = pd.Series(tm.makeCategoricalIndex(N, ncats)).astype(str)\n        self.s_str_cat = pd.Series(self.s_str, dtype=\"category\")\n        with warnings.catch_warnings(record=True):\n            str_cat_type = pd.CategoricalDtype(set(self.s_str), ordered=True)\n            self.s_str_cat_ordered = self.s_str.astype(str_cat_type)\n    \n        self.s_int = pd.Series(np.random.randint(0, ncats, size=N))\n        self.s_int_cat = pd.Series(self.s_int, dtype=\"category\")\n        with warnings.catch_warnings(record=True):\n            int_cat_type = pd.CategoricalDtype(set(self.s_int), ordered=True)\n            self.s_int_cat_ordered = self.s_int.astype(int_cat_type)", "min_run_count": 2, "name": "categoricals.Rank.time_rank_string_cat", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "20d23dbe271dc4b637d4cd95879a731931f873a58666b5be47f62f1ab12893e2", "warmup_time": -1}, "categoricals.Rank.time_rank_string_cat_ordered": {"code": "class Rank:\n    def time_rank_string_cat_ordered(self):\n        self.s_str_cat_ordered.rank()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Rank:\n    def setup(self):\n        N = 10**5\n        ncats = 15\n    \n        self.s_str = pd.Series(tm.makeCategoricalIndex(N, ncats)).astype(str)\n        self.s_str_cat = pd.Series(self.s_str, dtype=\"category\")\n        with warnings.catch_warnings(record=True):\n            str_cat_type = pd.CategoricalDtype(set(self.s_str), ordered=True)\n            self.s_str_cat_ordered = self.s_str.astype(str_cat_type)\n    \n        self.s_int = pd.Series(np.random.randint(0, ncats, size=N))\n        self.s_int_cat = pd.Series(self.s_int, dtype=\"category\")\n        with warnings.catch_warnings(record=True):\n            int_cat_type = pd.CategoricalDtype(set(self.s_int), ordered=True)\n            self.s_int_cat_ordered = self.s_int.astype(int_cat_type)", "min_run_count": 2, "name": "categoricals.Rank.time_rank_string_cat_ordered", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "982524b5ec0f4973491e4744c9720f4735eaa76eaf855602436e513d2760f0da", "warmup_time": -1}, "categoricals.RemoveCategories.time_remove_categories": {"code": "class RemoveCategories:\n    def time_remove_categories(self):\n        self.ts.cat.remove_categories(self.ts.cat.categories[::2])\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass RemoveCategories:\n    def setup(self):\n        n = 5 * 10**5\n        arr = [f\"s{i:04d}\" for i in np.random.randint(0, n // 10, size=n)]\n        self.ts = pd.Series(arr).astype(\"category\")", "min_run_count": 2, "name": "categoricals.RemoveCategories.time_remove_categories", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "f41a55fefb120d979e5bcb1f387b4b8b8929b1b97c1b49370b42482deb07b426", "warmup_time": -1}, "categoricals.Repr.time_rendering": {"code": "class Repr:\n    def time_rendering(self):\n        str(self.sel)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Repr:\n    def setup(self):\n        self.sel = pd.Series([\"s1234\"]).astype(\"category\")", "min_run_count": 2, "name": "categoricals.Repr.time_rendering", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "8d10d682b8918c4fac813851a9bf9304346e145623189c433d8d75ac72c1e1e6", "warmup_time": -1}, "categoricals.SearchSorted.time_categorical_contains": {"code": "class SearchSorted:\n    def time_categorical_contains(self):\n        self.c.searchsorted(self.key)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass SearchSorted:\n    def setup(self):\n        N = 10**5\n        self.ci = tm.makeCategoricalIndex(N).sort_values()\n        self.c = self.ci.values\n        self.key = self.ci.categories[1]", "min_run_count": 2, "name": "categoricals.SearchSorted.time_categorical_contains", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "11cb9f6950193f3d0d4f822757ea5a30da0832409ee4a14ba3bf7d106a2a38ad", "warmup_time": -1}, "categoricals.SearchSorted.time_categorical_index_contains": {"code": "class SearchSorted:\n    def time_categorical_index_contains(self):\n        self.ci.searchsorted(self.key)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass SearchSorted:\n    def setup(self):\n        N = 10**5\n        self.ci = tm.makeCategoricalIndex(N).sort_values()\n        self.c = self.ci.values\n        self.key = self.ci.categories[1]", "min_run_count": 2, "name": "categoricals.SearchSorted.time_categorical_index_contains", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "0880ec83250d415454d024b26342e3db3b461139b9c6b824976ea019afaa3a5b", "warmup_time": -1}, "categoricals.SetCategories.time_set_categories": {"code": "class SetCategories:\n    def time_set_categories(self):\n        self.ts.cat.set_categories(self.ts.cat.categories[::2])\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass SetCategories:\n    def setup(self):\n        n = 5 * 10**5\n        arr = [f\"s{i:04d}\" for i in np.random.randint(0, n // 10, size=n)]\n        self.ts = pd.Series(arr).astype(\"category\")", "min_run_count": 2, "name": "categoricals.SetCategories.time_set_categories", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "ee0d827baaa17c4f7f69783df06df5805e927698ff8dca902182228231f975c1", "warmup_time": -1}, "categoricals.ValueCounts.time_value_counts": {"code": "class ValueCounts:\n    def time_value_counts(self, dropna):\n        self.ts.value_counts(dropna=dropna)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ValueCounts:\n    def setup(self, dropna):\n        n = 5 * 10**5\n        arr = [f\"s{i:04d}\" for i in np.random.randint(0, n // 10, size=n)]\n        self.ts = pd.Series(arr).astype(\"category\")", "min_run_count": 2, "name": "categoricals.ValueCounts.time_value_counts", "number": 0, "param_names": ["dropna"], "params": [["True", "False"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "4866939b81ce70129183c8d44e1a9d6b42c864346912c27670eb457cdf9fcfbb", "warmup_time": -1}, "ctors.DatetimeIndexConstructor.time_from_list_of_dates": {"code": "class DatetimeIndexConstructor:\n    def time_from_list_of_dates(self):\n        DatetimeIndex(self.list_of_dates)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass DatetimeIndexConstructor:\n    def setup(self):\n        N = 20_000\n        dti = date_range(\"1900-01-01\", periods=N)\n    \n        self.list_of_timestamps = dti.tolist()\n        self.list_of_dates = dti.date.tolist()\n        self.list_of_datetimes = dti.to_pydatetime().tolist()\n        self.list_of_str = dti.strftime(\"%Y-%m-%d\").tolist()", "min_run_count": 2, "name": "ctors.DatetimeIndexConstructor.time_from_list_of_dates", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "bacd3eaca4814bb06e43ffa8586971974452ebd4e463efae8cac42b893d58a82", "warmup_time": -1}, "ctors.DatetimeIndexConstructor.time_from_list_of_datetimes": {"code": "class DatetimeIndexConstructor:\n    def time_from_list_of_datetimes(self):\n        DatetimeIndex(self.list_of_datetimes)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass DatetimeIndexConstructor:\n    def setup(self):\n        N = 20_000\n        dti = date_range(\"1900-01-01\", periods=N)\n    \n        self.list_of_timestamps = dti.tolist()\n        self.list_of_dates = dti.date.tolist()\n        self.list_of_datetimes = dti.to_pydatetime().tolist()\n        self.list_of_str = dti.strftime(\"%Y-%m-%d\").tolist()", "min_run_count": 2, "name": "ctors.DatetimeIndexConstructor.time_from_list_of_datetimes", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "365ef0bfc846c299de2e9ec59316033adc76ea95a7f73a97d4ca958b3d6e913e", "warmup_time": -1}, "ctors.DatetimeIndexConstructor.time_from_list_of_str": {"code": "class DatetimeIndexConstructor:\n    def time_from_list_of_str(self):\n        DatetimeIndex(self.list_of_str)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass DatetimeIndexConstructor:\n    def setup(self):\n        N = 20_000\n        dti = date_range(\"1900-01-01\", periods=N)\n    \n        self.list_of_timestamps = dti.tolist()\n        self.list_of_dates = dti.date.tolist()\n        self.list_of_datetimes = dti.to_pydatetime().tolist()\n        self.list_of_str = dti.strftime(\"%Y-%m-%d\").tolist()", "min_run_count": 2, "name": "ctors.DatetimeIndexConstructor.time_from_list_of_str", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "11575c62b8c3127835edd05f4d19329b690f6ef06c30d58b8e772d2b7e7f0abf", "warmup_time": -1}, "ctors.DatetimeIndexConstructor.time_from_list_of_timestamps": {"code": "class DatetimeIndexConstructor:\n    def time_from_list_of_timestamps(self):\n        DatetimeIndex(self.list_of_timestamps)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass DatetimeIndexConstructor:\n    def setup(self):\n        N = 20_000\n        dti = date_range(\"1900-01-01\", periods=N)\n    \n        self.list_of_timestamps = dti.tolist()\n        self.list_of_dates = dti.date.tolist()\n        self.list_of_datetimes = dti.to_pydatetime().tolist()\n        self.list_of_str = dti.strftime(\"%Y-%m-%d\").tolist()", "min_run_count": 2, "name": "ctors.DatetimeIndexConstructor.time_from_list_of_timestamps", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "1aba152c467ee66bcd374fe2d77743a9eef413d7057a74818aa8426b86441b71", "warmup_time": -1}, "ctors.MultiIndexConstructor.time_multiindex_from_iterables": {"code": "class MultiIndexConstructor:\n    def time_multiindex_from_iterables(self):\n        MultiIndex.from_product(self.iterables)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass MultiIndexConstructor:\n    def setup(self):\n        N = 10**4\n        self.iterables = [tm.makeStringIndex(N), range(20)]", "min_run_count": 2, "name": "ctors.MultiIndexConstructor.time_multiindex_from_iterables", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "d7103a965c615d41e3167c290707c976203fff8c1245caf9c9b814491a2fbfa4", "warmup_time": -1}, "ctors.SeriesConstructors.time_series_constructor": {"code": "class SeriesConstructors:\n    def time_series_constructor(self, data_fmt, with_index, dtype):\n        Series(self.data, index=self.index)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass SeriesConstructors:\n    def setup(self, data_fmt, with_index, dtype):\n        if data_fmt in (gen_of_str, gen_of_tuples) and with_index:\n            raise NotImplementedError(\n                \"Series constructors do not support using generators with indexes\"\n            )\n        N = 10**4\n        if dtype == \"float\":\n            arr = np.random.randn(N)\n        else:\n            arr = np.arange(N)\n        self.data = data_fmt(arr)\n        self.index = np.arange(N) if with_index else None", "min_run_count": 2, "name": "ctors.SeriesConstructors.time_series_constructor", "number": 1, "param_names": ["data_fmt", "with_index", "dtype"], "params": [["<function no_change>", "<class 'list'>", "<function list_of_str>", "<function gen_of_str>", "<function arr_dict>", "<function list_of_tuples>", "<function gen_of_tuples>", "<function list_of_lists>", "<function list_of_tuples_with_none>", "<function list_of_lists_with_none>"], ["False", "True"], ["'float'", "'int'"]], "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "796b7e6dd06a06983968b54d6752714fff49f711f0da87ab239d7c33fe9306ba", "warmup_time": -1}, "ctors.SeriesDtypesConstructors.time_dtindex_from_index_with_series": {"code": "class SeriesDtypesConstructors:\n    def time_dtindex_from_index_with_series(self):\n        Index(self.s)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass SeriesDtypesConstructors:\n    def setup(self):\n        N = 10**4\n        self.arr = np.random.randn(N)\n        self.arr_str = np.array([\"foo\", \"bar\", \"baz\"], dtype=object)\n        self.s = Series(\n            [Timestamp(\"20110101\"), Timestamp(\"20120101\"), Timestamp(\"20130101\")]\n            * N\n            * 10\n        )", "min_run_count": 2, "name": "ctors.SeriesDtypesConstructors.time_dtindex_from_index_with_series", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "33f43d3855a48b47442f806cad0e6e7466e35fc29158753066509c648f173543", "warmup_time": -1}, "ctors.SeriesDtypesConstructors.time_dtindex_from_series": {"code": "class SeriesDtypesConstructors:\n    def time_dtindex_from_series(self):\n        DatetimeIndex(self.s)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass SeriesDtypesConstructors:\n    def setup(self):\n        N = 10**4\n        self.arr = np.random.randn(N)\n        self.arr_str = np.array([\"foo\", \"bar\", \"baz\"], dtype=object)\n        self.s = Series(\n            [Timestamp(\"20110101\"), Timestamp(\"20120101\"), Timestamp(\"20130101\")]\n            * N\n            * 10\n        )", "min_run_count": 2, "name": "ctors.SeriesDtypesConstructors.time_dtindex_from_series", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "158ae6c81517f39c972e1bc3b7aab12bf753c0b37a15ca694e51998994283273", "warmup_time": -1}, "ctors.SeriesDtypesConstructors.time_index_from_array_floats": {"code": "class SeriesDtypesConstructors:\n    def time_index_from_array_floats(self):\n        Index(self.arr)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass SeriesDtypesConstructors:\n    def setup(self):\n        N = 10**4\n        self.arr = np.random.randn(N)\n        self.arr_str = np.array([\"foo\", \"bar\", \"baz\"], dtype=object)\n        self.s = Series(\n            [Timestamp(\"20110101\"), Timestamp(\"20120101\"), Timestamp(\"20130101\")]\n            * N\n            * 10\n        )", "min_run_count": 2, "name": "ctors.SeriesDtypesConstructors.time_index_from_array_floats", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "e0189b13b8400123e9a8d5d5c5d55240f975dd207efd63375f6fb000e228d534", "warmup_time": -1}, "ctors.SeriesDtypesConstructors.time_index_from_array_string": {"code": "class SeriesDtypesConstructors:\n    def time_index_from_array_string(self):\n        Index(self.arr_str)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass SeriesDtypesConstructors:\n    def setup(self):\n        N = 10**4\n        self.arr = np.random.randn(N)\n        self.arr_str = np.array([\"foo\", \"bar\", \"baz\"], dtype=object)\n        self.s = Series(\n            [Timestamp(\"20110101\"), Timestamp(\"20120101\"), Timestamp(\"20130101\")]\n            * N\n            * 10\n        )", "min_run_count": 2, "name": "ctors.SeriesDtypesConstructors.time_index_from_array_string", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "1403f63eb248697b83050c2515ddca96862bb42fdcd2fd7d5453bcafb3a9881e", "warmup_time": -1}, "dtypes.CheckDtypes.time_is_extension_array_dtype_false": {"code": "class CheckDtypes:\n    def time_is_extension_array_dtype_false(self):\n        is_extension_array_dtype(self.np_dtype)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass CheckDtypes:\n    def setup(self):\n        self.ext_dtype = pd.Int64Dtype()\n        self.np_dtype = np.dtype(\"int64\")", "min_run_count": 2, "name": "dtypes.CheckDtypes.time_is_extension_array_dtype_false", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "81c7f57fc1b501fb5fe42b1928b850081d7fc62c6bda218e1faf99d2623a9dd7", "warmup_time": -1}, "dtypes.CheckDtypes.time_is_extension_array_dtype_true": {"code": "class CheckDtypes:\n    def time_is_extension_array_dtype_true(self):\n        is_extension_array_dtype(self.ext_dtype)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass CheckDtypes:\n    def setup(self):\n        self.ext_dtype = pd.Int64Dtype()\n        self.np_dtype = np.dtype(\"int64\")", "min_run_count": 2, "name": "dtypes.CheckDtypes.time_is_extension_array_dtype_true", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "23b5bb2e01f5d1546ced81b111d6d84415d3945fe1392317283755c6205327cf", "warmup_time": -1}, "dtypes.Dtypes.time_pandas_dtype": {"code": "class Dtypes:\n    def time_pandas_dtype(self, dtype):\n        pandas_dtype(dtype)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)", "min_run_count": 2, "name": "dtypes.Dtypes.time_pandas_dtype", "number": 0, "param_names": ["dtype"], "params": [["dtype('int64')", "dtype('int32')", "dtype('uint32')", "dtype('uint64')", "dtype('float32')", "dtype('float64')", "dtype('int16')", "dtype('int8')", "dtype('uint16')", "dtype('uint8')", "dtype('<M8')", "dtype('<m8')", "dtype('O')", "<class 'pandas.core.arrays.integer.Int8Dtype'>", "<class 'pandas.core.arrays.integer.Int16Dtype'>", "<class 'pandas.core.arrays.integer.Int32Dtype'>", "<class 'pandas.core.arrays.integer.Int64Dtype'>", "<class 'pandas.core.arrays.integer.UInt8Dtype'>", "<class 'pandas.core.arrays.integer.UInt16Dtype'>", "<class 'pandas.core.arrays.integer.UInt32Dtype'>", "<class 'pandas.core.arrays.integer.UInt64Dtype'>", "<class 'pandas.core.dtypes.dtypes.CategoricalDtype'>", "<class 'pandas.core.dtypes.dtypes.IntervalDtype'>", "datetime64[ns, UTC]", "period[D]", "'int64'", "'int32'", "'uint32'", "'uint64'", "'float32'", "'float64'", "'int16'", "'int8'", "'uint16'", "'uint8'", "'datetime64'", "'timedelta64'", "'object'", "'Int8'", "'Int16'", "'Int32'", "'Int64'", "'UInt8'", "'UInt16'", "'UInt32'", "'UInt64'", "'category'", "'interval'", "'datetime64[ns, UTC]'", "'period[D]'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "fd9b99f460a442066f655fd285e96e7bc3a2fd5599a6e62433c98e0811c6d2ad", "warmup_time": -1}, "dtypes.DtypesInvalid.time_pandas_dtype_invalid": {"code": "class DtypesInvalid:\n    def time_pandas_dtype_invalid(self, dtype):\n        try:\n            pandas_dtype(self.data_dict[dtype])\n        except TypeError:\n            pass\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)", "min_run_count": 2, "name": "dtypes.DtypesInvalid.time_pandas_dtype_invalid", "number": 0, "param_names": ["dtype"], "params": [["'scalar-string'", "'scalar-int'", "'list-string'", "'array-string'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "7f3ba4b4c7fbd54b7a1820ab3b4dd151e482f73fe3403b9bc5250c8abb048f3b", "warmup_time": -1}, "dtypes.SelectDtypes.time_select_dtype_bool_exclude": {"code": "class SelectDtypes:\n    def time_select_dtype_bool_exclude(self, dtype):\n        self.df_bool.select_dtypes(exclude=dtype)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass SelectDtypes:\n    def setup(self, dtype):\n        N, K = 5000, 50\n        self.index = tm.makeStringIndex(N)\n        self.columns = tm.makeStringIndex(K)\n    \n        def create_df(data):\n            return DataFrame(data, index=self.index, columns=self.columns)\n    \n        self.df_int = create_df(np.random.randint(low=100, size=(N, K)))\n        self.df_float = create_df(np.random.randn(N, K))\n        self.df_bool = create_df(np.random.choice([True, False], size=(N, K)))\n        self.df_string = create_df(\n            np.random.choice(list(string.ascii_letters), size=(N, K))\n        )", "min_run_count": 2, "name": "dtypes.SelectDtypes.time_select_dtype_bool_exclude", "number": 0, "param_names": ["dtype"], "params": [["'uint8'", "'uint16'", "'uint32'", "'uint64'", "<class 'int'>", "'int8'", "'int16'", "'int32'", "'int64'", "'UInt8'", "'UInt16'", "'UInt32'", "'UInt64'", "'Int8'", "'Int16'", "'Int32'", "'Int64'", "<class 'float'>", "'float32'", "'float64'", "<class 'complex'>", "'complex64'", "'complex128'", "'datetime64[ns]'", "'M8[ns]'", "'timedelta64[ns]'", "'m8[ns]'", "<class 'bool'>", "'bool'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "a126b236c856d0f38d1511b5cb8add61b60a1345ecaa48c81144e3c0500b91d2", "warmup_time": -1}, "dtypes.SelectDtypes.time_select_dtype_bool_include": {"code": "class SelectDtypes:\n    def time_select_dtype_bool_include(self, dtype):\n        self.df_bool.select_dtypes(include=dtype)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass SelectDtypes:\n    def setup(self, dtype):\n        N, K = 5000, 50\n        self.index = tm.makeStringIndex(N)\n        self.columns = tm.makeStringIndex(K)\n    \n        def create_df(data):\n            return DataFrame(data, index=self.index, columns=self.columns)\n    \n        self.df_int = create_df(np.random.randint(low=100, size=(N, K)))\n        self.df_float = create_df(np.random.randn(N, K))\n        self.df_bool = create_df(np.random.choice([True, False], size=(N, K)))\n        self.df_string = create_df(\n            np.random.choice(list(string.ascii_letters), size=(N, K))\n        )", "min_run_count": 2, "name": "dtypes.SelectDtypes.time_select_dtype_bool_include", "number": 0, "param_names": ["dtype"], "params": [["'uint8'", "'uint16'", "'uint32'", "'uint64'", "<class 'int'>", "'int8'", "'int16'", "'int32'", "'int64'", "'UInt8'", "'UInt16'", "'UInt32'", "'UInt64'", "'Int8'", "'Int16'", "'Int32'", "'Int64'", "<class 'float'>", "'float32'", "'float64'", "<class 'complex'>", "'complex64'", "'complex128'", "'datetime64[ns]'", "'M8[ns]'", "'timedelta64[ns]'", "'m8[ns]'", "<class 'bool'>", "'bool'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "d7eb6b76e29e30340bd1522aed61c3bffbec125b995524b0f1735c57b1e2abe8", "warmup_time": -1}, "dtypes.SelectDtypes.time_select_dtype_float_exclude": {"code": "class SelectDtypes:\n    def time_select_dtype_float_exclude(self, dtype):\n        self.df_float.select_dtypes(exclude=dtype)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass SelectDtypes:\n    def setup(self, dtype):\n        N, K = 5000, 50\n        self.index = tm.makeStringIndex(N)\n        self.columns = tm.makeStringIndex(K)\n    \n        def create_df(data):\n            return DataFrame(data, index=self.index, columns=self.columns)\n    \n        self.df_int = create_df(np.random.randint(low=100, size=(N, K)))\n        self.df_float = create_df(np.random.randn(N, K))\n        self.df_bool = create_df(np.random.choice([True, False], size=(N, K)))\n        self.df_string = create_df(\n            np.random.choice(list(string.ascii_letters), size=(N, K))\n        )", "min_run_count": 2, "name": "dtypes.SelectDtypes.time_select_dtype_float_exclude", "number": 0, "param_names": ["dtype"], "params": [["'uint8'", "'uint16'", "'uint32'", "'uint64'", "<class 'int'>", "'int8'", "'int16'", "'int32'", "'int64'", "'UInt8'", "'UInt16'", "'UInt32'", "'UInt64'", "'Int8'", "'Int16'", "'Int32'", "'Int64'", "<class 'float'>", "'float32'", "'float64'", "<class 'complex'>", "'complex64'", "'complex128'", "'datetime64[ns]'", "'M8[ns]'", "'timedelta64[ns]'", "'m8[ns]'", "<class 'bool'>", "'bool'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "98778f2a3b7961510ff9312ec0b9a5d48e6878572553ec2beefa443d3fa4fe03", "warmup_time": -1}, "dtypes.SelectDtypes.time_select_dtype_float_include": {"code": "class SelectDtypes:\n    def time_select_dtype_float_include(self, dtype):\n        self.df_float.select_dtypes(include=dtype)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass SelectDtypes:\n    def setup(self, dtype):\n        N, K = 5000, 50\n        self.index = tm.makeStringIndex(N)\n        self.columns = tm.makeStringIndex(K)\n    \n        def create_df(data):\n            return DataFrame(data, index=self.index, columns=self.columns)\n    \n        self.df_int = create_df(np.random.randint(low=100, size=(N, K)))\n        self.df_float = create_df(np.random.randn(N, K))\n        self.df_bool = create_df(np.random.choice([True, False], size=(N, K)))\n        self.df_string = create_df(\n            np.random.choice(list(string.ascii_letters), size=(N, K))\n        )", "min_run_count": 2, "name": "dtypes.SelectDtypes.time_select_dtype_float_include", "number": 0, "param_names": ["dtype"], "params": [["'uint8'", "'uint16'", "'uint32'", "'uint64'", "<class 'int'>", "'int8'", "'int16'", "'int32'", "'int64'", "'UInt8'", "'UInt16'", "'UInt32'", "'UInt64'", "'Int8'", "'Int16'", "'Int32'", "'Int64'", "<class 'float'>", "'float32'", "'float64'", "<class 'complex'>", "'complex64'", "'complex128'", "'datetime64[ns]'", "'M8[ns]'", "'timedelta64[ns]'", "'m8[ns]'", "<class 'bool'>", "'bool'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "36a44f47f6cfd5df6c8dc4ae00f64951f2b7479eb2fd0fad09e8171212a77dff", "warmup_time": -1}, "dtypes.SelectDtypes.time_select_dtype_int_exclude": {"code": "class SelectDtypes:\n    def time_select_dtype_int_exclude(self, dtype):\n        self.df_int.select_dtypes(exclude=dtype)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass SelectDtypes:\n    def setup(self, dtype):\n        N, K = 5000, 50\n        self.index = tm.makeStringIndex(N)\n        self.columns = tm.makeStringIndex(K)\n    \n        def create_df(data):\n            return DataFrame(data, index=self.index, columns=self.columns)\n    \n        self.df_int = create_df(np.random.randint(low=100, size=(N, K)))\n        self.df_float = create_df(np.random.randn(N, K))\n        self.df_bool = create_df(np.random.choice([True, False], size=(N, K)))\n        self.df_string = create_df(\n            np.random.choice(list(string.ascii_letters), size=(N, K))\n        )", "min_run_count": 2, "name": "dtypes.SelectDtypes.time_select_dtype_int_exclude", "number": 0, "param_names": ["dtype"], "params": [["'uint8'", "'uint16'", "'uint32'", "'uint64'", "<class 'int'>", "'int8'", "'int16'", "'int32'", "'int64'", "'UInt8'", "'UInt16'", "'UInt32'", "'UInt64'", "'Int8'", "'Int16'", "'Int32'", "'Int64'", "<class 'float'>", "'float32'", "'float64'", "<class 'complex'>", "'complex64'", "'complex128'", "'datetime64[ns]'", "'M8[ns]'", "'timedelta64[ns]'", "'m8[ns]'", "<class 'bool'>", "'bool'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "6ac11a0d05d4ccc0fe72a34ad7bd247f211ef4822002464bf01f2b3d55660ea0", "warmup_time": -1}, "dtypes.SelectDtypes.time_select_dtype_int_include": {"code": "class SelectDtypes:\n    def time_select_dtype_int_include(self, dtype):\n        self.df_int.select_dtypes(include=dtype)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass SelectDtypes:\n    def setup(self, dtype):\n        N, K = 5000, 50\n        self.index = tm.makeStringIndex(N)\n        self.columns = tm.makeStringIndex(K)\n    \n        def create_df(data):\n            return DataFrame(data, index=self.index, columns=self.columns)\n    \n        self.df_int = create_df(np.random.randint(low=100, size=(N, K)))\n        self.df_float = create_df(np.random.randn(N, K))\n        self.df_bool = create_df(np.random.choice([True, False], size=(N, K)))\n        self.df_string = create_df(\n            np.random.choice(list(string.ascii_letters), size=(N, K))\n        )", "min_run_count": 2, "name": "dtypes.SelectDtypes.time_select_dtype_int_include", "number": 0, "param_names": ["dtype"], "params": [["'uint8'", "'uint16'", "'uint32'", "'uint64'", "<class 'int'>", "'int8'", "'int16'", "'int32'", "'int64'", "'UInt8'", "'UInt16'", "'UInt32'", "'UInt64'", "'Int8'", "'Int16'", "'Int32'", "'Int64'", "<class 'float'>", "'float32'", "'float64'", "<class 'complex'>", "'complex64'", "'complex128'", "'datetime64[ns]'", "'M8[ns]'", "'timedelta64[ns]'", "'m8[ns]'", "<class 'bool'>", "'bool'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "2c7425e1f54120813675e43e009cc1cf5daa37d008cec3de897a48522711bc16", "warmup_time": -1}, "dtypes.SelectDtypes.time_select_dtype_string_exclude": {"code": "class SelectDtypes:\n    def time_select_dtype_string_exclude(self, dtype):\n        self.df_string.select_dtypes(exclude=dtype)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass SelectDtypes:\n    def setup(self, dtype):\n        N, K = 5000, 50\n        self.index = tm.makeStringIndex(N)\n        self.columns = tm.makeStringIndex(K)\n    \n        def create_df(data):\n            return DataFrame(data, index=self.index, columns=self.columns)\n    \n        self.df_int = create_df(np.random.randint(low=100, size=(N, K)))\n        self.df_float = create_df(np.random.randn(N, K))\n        self.df_bool = create_df(np.random.choice([True, False], size=(N, K)))\n        self.df_string = create_df(\n            np.random.choice(list(string.ascii_letters), size=(N, K))\n        )", "min_run_count": 2, "name": "dtypes.SelectDtypes.time_select_dtype_string_exclude", "number": 0, "param_names": ["dtype"], "params": [["'uint8'", "'uint16'", "'uint32'", "'uint64'", "<class 'int'>", "'int8'", "'int16'", "'int32'", "'int64'", "'UInt8'", "'UInt16'", "'UInt32'", "'UInt64'", "'Int8'", "'Int16'", "'Int32'", "'Int64'", "<class 'float'>", "'float32'", "'float64'", "<class 'complex'>", "'complex64'", "'complex128'", "'datetime64[ns]'", "'M8[ns]'", "'timedelta64[ns]'", "'m8[ns]'", "<class 'bool'>", "'bool'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "ae4e0ee446d7fcdf34fe0341cee6f367c65996d84da64f23414569849d34c93c", "warmup_time": -1}, "dtypes.SelectDtypes.time_select_dtype_string_include": {"code": "class SelectDtypes:\n    def time_select_dtype_string_include(self, dtype):\n        self.df_string.select_dtypes(include=dtype)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass SelectDtypes:\n    def setup(self, dtype):\n        N, K = 5000, 50\n        self.index = tm.makeStringIndex(N)\n        self.columns = tm.makeStringIndex(K)\n    \n        def create_df(data):\n            return DataFrame(data, index=self.index, columns=self.columns)\n    \n        self.df_int = create_df(np.random.randint(low=100, size=(N, K)))\n        self.df_float = create_df(np.random.randn(N, K))\n        self.df_bool = create_df(np.random.choice([True, False], size=(N, K)))\n        self.df_string = create_df(\n            np.random.choice(list(string.ascii_letters), size=(N, K))\n        )", "min_run_count": 2, "name": "dtypes.SelectDtypes.time_select_dtype_string_include", "number": 0, "param_names": ["dtype"], "params": [["'uint8'", "'uint16'", "'uint32'", "'uint64'", "<class 'int'>", "'int8'", "'int16'", "'int32'", "'int64'", "'UInt8'", "'UInt16'", "'UInt32'", "'UInt64'", "'Int8'", "'Int16'", "'Int32'", "'Int64'", "<class 'float'>", "'float32'", "'float64'", "<class 'complex'>", "'complex64'", "'complex128'", "'datetime64[ns]'", "'M8[ns]'", "'timedelta64[ns]'", "'m8[ns]'", "<class 'bool'>", "'bool'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "39dae1d8edd77b15d13397cb4c4f637c5aeac236b2f599aa7f42bdb9e57c8cd7", "warmup_time": -1}, "eval.Eval.time_add": {"code": "class Eval:\n    def time_add(self, engine, threads):\n        pd.eval(\"self.df + self.df2 + self.df3 + self.df4\", engine=engine)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Eval:\n    def setup(self, engine, threads):\n        self.df = pd.DataFrame(np.random.randn(20000, 100))\n        self.df2 = pd.DataFrame(np.random.randn(20000, 100))\n        self.df3 = pd.DataFrame(np.random.randn(20000, 100))\n        self.df4 = pd.DataFrame(np.random.randn(20000, 100))\n    \n        if threads == 1:\n            expr.set_numexpr_threads(1)", "min_run_count": 2, "name": "eval.Eval.time_add", "number": 0, "param_names": ["engine", "threads"], "params": [["'numexpr'", "'python'"], ["1", "'all'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "3b50f88f4cebf64200f50ab348ee13f8589e7dfb5962f7176004d30730f99112", "warmup_time": -1}, "eval.Eval.time_and": {"code": "class Eval:\n    def time_and(self, engine, threads):\n        pd.eval(\n            \"(self.df > 0) & (self.df2 > 0) & (self.df3 > 0) & (self.df4 > 0)\",\n            engine=engine,\n        )\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Eval:\n    def setup(self, engine, threads):\n        self.df = pd.DataFrame(np.random.randn(20000, 100))\n        self.df2 = pd.DataFrame(np.random.randn(20000, 100))\n        self.df3 = pd.DataFrame(np.random.randn(20000, 100))\n        self.df4 = pd.DataFrame(np.random.randn(20000, 100))\n    \n        if threads == 1:\n            expr.set_numexpr_threads(1)", "min_run_count": 2, "name": "eval.Eval.time_and", "number": 0, "param_names": ["engine", "threads"], "params": [["'numexpr'", "'python'"], ["1", "'all'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "e48d6e775f144cea8cd29b74723eb86f939c566bd1c688845dd864d16d60de1b", "warmup_time": -1}, "eval.Eval.time_chained_cmp": {"code": "class Eval:\n    def time_chained_cmp(self, engine, threads):\n        pd.eval(\"self.df < self.df2 < self.df3 < self.df4\", engine=engine)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Eval:\n    def setup(self, engine, threads):\n        self.df = pd.DataFrame(np.random.randn(20000, 100))\n        self.df2 = pd.DataFrame(np.random.randn(20000, 100))\n        self.df3 = pd.DataFrame(np.random.randn(20000, 100))\n        self.df4 = pd.DataFrame(np.random.randn(20000, 100))\n    \n        if threads == 1:\n            expr.set_numexpr_threads(1)", "min_run_count": 2, "name": "eval.Eval.time_chained_cmp", "number": 0, "param_names": ["engine", "threads"], "params": [["'numexpr'", "'python'"], ["1", "'all'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "0fe4b18c6cfabf06e6e4cac4c651276743a49df6a947913f8cabba517ba91786", "warmup_time": -1}, "eval.Eval.time_mult": {"code": "class Eval:\n    def time_mult(self, engine, threads):\n        pd.eval(\"self.df * self.df2 * self.df3 * self.df4\", engine=engine)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Eval:\n    def setup(self, engine, threads):\n        self.df = pd.DataFrame(np.random.randn(20000, 100))\n        self.df2 = pd.DataFrame(np.random.randn(20000, 100))\n        self.df3 = pd.DataFrame(np.random.randn(20000, 100))\n        self.df4 = pd.DataFrame(np.random.randn(20000, 100))\n    \n        if threads == 1:\n            expr.set_numexpr_threads(1)", "min_run_count": 2, "name": "eval.Eval.time_mult", "number": 0, "param_names": ["engine", "threads"], "params": [["'numexpr'", "'python'"], ["1", "'all'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "a2085f987e1ce9ac0c43a0fe2cba5ad5be060d477671017c4323e892a23899a2", "warmup_time": -1}, "eval.Query.time_query_datetime_column": {"code": "class Query:\n    def time_query_datetime_column(self):\n        self.df.query(\"dates < @self.ts\")\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Query:\n    def setup(self):\n        N = 10**6\n        halfway = (N // 2) - 1\n        index = pd.date_range(\"20010101\", periods=N, freq=\"T\")\n        s = pd.Series(index)\n        self.ts = s.iloc[halfway]\n        self.df = pd.DataFrame({\"a\": np.random.randn(N), \"dates\": index}, index=index)\n        data = np.random.randn(N)\n        self.min_val = data.min()\n        self.max_val = data.max()", "min_run_count": 2, "name": "eval.Query.time_query_datetime_column", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "e678b3e6fbcb395d5e64511896db4df8b7269fec84ed7db82064952066b1a539", "warmup_time": -1}, "eval.Query.time_query_datetime_index": {"code": "class Query:\n    def time_query_datetime_index(self):\n        self.df.query(\"index < @self.ts\")\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Query:\n    def setup(self):\n        N = 10**6\n        halfway = (N // 2) - 1\n        index = pd.date_range(\"20010101\", periods=N, freq=\"T\")\n        s = pd.Series(index)\n        self.ts = s.iloc[halfway]\n        self.df = pd.DataFrame({\"a\": np.random.randn(N), \"dates\": index}, index=index)\n        data = np.random.randn(N)\n        self.min_val = data.min()\n        self.max_val = data.max()", "min_run_count": 2, "name": "eval.Query.time_query_datetime_index", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "7214b231e694aae8bd0bc25ba92e3aaa3cf019dc04fc443d43462b4bcbe0263c", "warmup_time": -1}, "eval.Query.time_query_with_boolean_selection": {"code": "class Query:\n    def time_query_with_boolean_selection(self):\n        self.df.query(\"(a >= @self.min_val) & (a <= @self.max_val)\")\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Query:\n    def setup(self):\n        N = 10**6\n        halfway = (N // 2) - 1\n        index = pd.date_range(\"20010101\", periods=N, freq=\"T\")\n        s = pd.Series(index)\n        self.ts = s.iloc[halfway]\n        self.df = pd.DataFrame({\"a\": np.random.randn(N), \"dates\": index}, index=index)\n        data = np.random.randn(N)\n        self.min_val = data.min()\n        self.max_val = data.max()", "min_run_count": 2, "name": "eval.Query.time_query_with_boolean_selection", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "268bb656309368f91162de7dcd37206c9f25f2f47a0e1a802b0ba25a5dcc3b61", "warmup_time": -1}, "finalize.Finalize.time_finalize_micro": {"code": "class Finalize:\n    def time_finalize_micro(self, param):\n        self.obj.__finalize__(self.obj, method=\"__finalize__\")\n\n    def setup(self, param):\n        N = 1000\n        obj = param(dtype=float)\n        for i in range(N):\n            obj.attrs[i] = i\n        self.obj = obj", "min_run_count": 2, "name": "finalize.Finalize.time_finalize_micro", "number": 0, "param_names": ["series"], "params": [["<class 'pandas.core.series.Series'>", "<class 'pandas.core.frame.DataFrame'>"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "bd2eab1eb436d45e913e54877c33d964695d4ac5fd0e7fd575f97eb347240a13", "warmup_time": -1}, "frame_ctor.FromArrays.time_frame_from_arrays_float": {"code": "class FromArrays:\n    def time_frame_from_arrays_float(self):\n        self.df = DataFrame._from_arrays(\n            self.float_arrays,\n            index=self.index,\n            columns=self.columns,\n            verify_integrity=False,\n        )\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass FromArrays:\n    def setup(self):\n        N_rows = 1000\n        N_cols = 1000\n        self.float_arrays = [np.random.randn(N_rows) for _ in range(N_cols)]\n        self.sparse_arrays = [\n            pd.arrays.SparseArray(np.random.randint(0, 2, N_rows), dtype=\"float64\")\n            for _ in range(N_cols)\n        ]\n        self.int_arrays = [\n            pd.array(np.random.randint(1000, size=N_rows), dtype=\"Int64\")\n            for _ in range(N_cols)\n        ]\n        self.index = pd.Index(range(N_rows))\n        self.columns = pd.Index(range(N_cols))", "min_run_count": 2, "name": "frame_ctor.FromArrays.time_frame_from_arrays_float", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "325f63d87ecbf9ad645d78740a1aa8328bbd4c29f349c5b13a9117e526ce3866", "warmup_time": -1}, "frame_ctor.FromArrays.time_frame_from_arrays_int": {"code": "class FromArrays:\n    def time_frame_from_arrays_int(self):\n        self.df = DataFrame._from_arrays(\n            self.int_arrays,\n            index=self.index,\n            columns=self.columns,\n            verify_integrity=False,\n        )\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass FromArrays:\n    def setup(self):\n        N_rows = 1000\n        N_cols = 1000\n        self.float_arrays = [np.random.randn(N_rows) for _ in range(N_cols)]\n        self.sparse_arrays = [\n            pd.arrays.SparseArray(np.random.randint(0, 2, N_rows), dtype=\"float64\")\n            for _ in range(N_cols)\n        ]\n        self.int_arrays = [\n            pd.array(np.random.randint(1000, size=N_rows), dtype=\"Int64\")\n            for _ in range(N_cols)\n        ]\n        self.index = pd.Index(range(N_rows))\n        self.columns = pd.Index(range(N_cols))", "min_run_count": 2, "name": "frame_ctor.FromArrays.time_frame_from_arrays_int", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "0ea63af2ba6a6bc03ab7882f007240ed2d5183ed6fa7b85d15c9eb6f3c6f67f7", "warmup_time": -1}, "frame_ctor.FromArrays.time_frame_from_arrays_sparse": {"code": "class FromArrays:\n    def time_frame_from_arrays_sparse(self):\n        self.df = DataFrame._from_arrays(\n            self.sparse_arrays,\n            index=self.index,\n            columns=self.columns,\n            verify_integrity=False,\n        )\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass FromArrays:\n    def setup(self):\n        N_rows = 1000\n        N_cols = 1000\n        self.float_arrays = [np.random.randn(N_rows) for _ in range(N_cols)]\n        self.sparse_arrays = [\n            pd.arrays.SparseArray(np.random.randint(0, 2, N_rows), dtype=\"float64\")\n            for _ in range(N_cols)\n        ]\n        self.int_arrays = [\n            pd.array(np.random.randint(1000, size=N_rows), dtype=\"Int64\")\n            for _ in range(N_cols)\n        ]\n        self.index = pd.Index(range(N_rows))\n        self.columns = pd.Index(range(N_cols))", "min_run_count": 2, "name": "frame_ctor.FromArrays.time_frame_from_arrays_sparse", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "225c22c0601994be668586bdb257030c2fd0d83e6dec0712bd820db812484318", "warmup_time": -1}, "frame_ctor.FromDicts.time_dict_of_categoricals": {"code": "class FromDicts:\n    def time_dict_of_categoricals(self):\n        # dict of arrays that we won't consolidate\n        DataFrame(self.dict_of_categoricals)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass FromDicts:\n    def setup(self):\n        N, K = 5000, 50\n        self.index = tm.makeStringIndex(N)\n        self.columns = tm.makeStringIndex(K)\n        frame = DataFrame(np.random.randn(N, K), index=self.index, columns=self.columns)\n        self.data = frame.to_dict()\n        self.dict_list = frame.to_dict(orient=\"records\")\n        self.data2 = {i: {j: float(j) for j in range(100)} for i in range(2000)}\n    \n        # arrays which we won't consolidate\n        self.dict_of_categoricals = {i: Categorical(np.arange(N)) for i in range(K)}", "min_run_count": 2, "name": "frame_ctor.FromDicts.time_dict_of_categoricals", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "9d79067d17d35aeffa34a71b605b22664d64bb5b217ed23db884c13d24de0e20", "warmup_time": -1}, "frame_ctor.FromDicts.time_list_of_dict": {"code": "class FromDicts:\n    def time_list_of_dict(self):\n        DataFrame(self.dict_list)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass FromDicts:\n    def setup(self):\n        N, K = 5000, 50\n        self.index = tm.makeStringIndex(N)\n        self.columns = tm.makeStringIndex(K)\n        frame = DataFrame(np.random.randn(N, K), index=self.index, columns=self.columns)\n        self.data = frame.to_dict()\n        self.dict_list = frame.to_dict(orient=\"records\")\n        self.data2 = {i: {j: float(j) for j in range(100)} for i in range(2000)}\n    \n        # arrays which we won't consolidate\n        self.dict_of_categoricals = {i: Categorical(np.arange(N)) for i in range(K)}", "min_run_count": 2, "name": "frame_ctor.FromDicts.time_list_of_dict", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "6f83a80b5278ee92dd45342b953f1bab5849c72ea0f400a19b783aca3e42cd51", "warmup_time": -1}, "frame_ctor.FromDicts.time_nested_dict": {"code": "class FromDicts:\n    def time_nested_dict(self):\n        DataFrame(self.data)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass FromDicts:\n    def setup(self):\n        N, K = 5000, 50\n        self.index = tm.makeStringIndex(N)\n        self.columns = tm.makeStringIndex(K)\n        frame = DataFrame(np.random.randn(N, K), index=self.index, columns=self.columns)\n        self.data = frame.to_dict()\n        self.dict_list = frame.to_dict(orient=\"records\")\n        self.data2 = {i: {j: float(j) for j in range(100)} for i in range(2000)}\n    \n        # arrays which we won't consolidate\n        self.dict_of_categoricals = {i: Categorical(np.arange(N)) for i in range(K)}", "min_run_count": 2, "name": "frame_ctor.FromDicts.time_nested_dict", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "407d9d178e4cf34e1bf593038e14bc2403dc5a3b9deaaefe820a52cfedcfb295", "warmup_time": -1}, "frame_ctor.FromDicts.time_nested_dict_columns": {"code": "class FromDicts:\n    def time_nested_dict_columns(self):\n        DataFrame(self.data, columns=self.columns)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass FromDicts:\n    def setup(self):\n        N, K = 5000, 50\n        self.index = tm.makeStringIndex(N)\n        self.columns = tm.makeStringIndex(K)\n        frame = DataFrame(np.random.randn(N, K), index=self.index, columns=self.columns)\n        self.data = frame.to_dict()\n        self.dict_list = frame.to_dict(orient=\"records\")\n        self.data2 = {i: {j: float(j) for j in range(100)} for i in range(2000)}\n    \n        # arrays which we won't consolidate\n        self.dict_of_categoricals = {i: Categorical(np.arange(N)) for i in range(K)}", "min_run_count": 2, "name": "frame_ctor.FromDicts.time_nested_dict_columns", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "7fe761a587afd70cec590c480e4bc7452e170d6fc559139385117adcf7ec1e3e", "warmup_time": -1}, "frame_ctor.FromDicts.time_nested_dict_index": {"code": "class FromDicts:\n    def time_nested_dict_index(self):\n        DataFrame(self.data, index=self.index)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass FromDicts:\n    def setup(self):\n        N, K = 5000, 50\n        self.index = tm.makeStringIndex(N)\n        self.columns = tm.makeStringIndex(K)\n        frame = DataFrame(np.random.randn(N, K), index=self.index, columns=self.columns)\n        self.data = frame.to_dict()\n        self.dict_list = frame.to_dict(orient=\"records\")\n        self.data2 = {i: {j: float(j) for j in range(100)} for i in range(2000)}\n    \n        # arrays which we won't consolidate\n        self.dict_of_categoricals = {i: Categorical(np.arange(N)) for i in range(K)}", "min_run_count": 2, "name": "frame_ctor.FromDicts.time_nested_dict_index", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "00e524d858a5986fc699881ecfb3592f44fa708651a6bec95e445bcc7152ceae", "warmup_time": -1}, "frame_ctor.FromDicts.time_nested_dict_index_columns": {"code": "class FromDicts:\n    def time_nested_dict_index_columns(self):\n        DataFrame(self.data, index=self.index, columns=self.columns)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass FromDicts:\n    def setup(self):\n        N, K = 5000, 50\n        self.index = tm.makeStringIndex(N)\n        self.columns = tm.makeStringIndex(K)\n        frame = DataFrame(np.random.randn(N, K), index=self.index, columns=self.columns)\n        self.data = frame.to_dict()\n        self.dict_list = frame.to_dict(orient=\"records\")\n        self.data2 = {i: {j: float(j) for j in range(100)} for i in range(2000)}\n    \n        # arrays which we won't consolidate\n        self.dict_of_categoricals = {i: Categorical(np.arange(N)) for i in range(K)}", "min_run_count": 2, "name": "frame_ctor.FromDicts.time_nested_dict_index_columns", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "6e9484e27fb40eed7a6cf62101e6aad5ce6f68386ef842f42088289024d25f94", "warmup_time": -1}, "frame_ctor.FromDicts.time_nested_dict_int64": {"code": "class FromDicts:\n    def time_nested_dict_int64(self):\n        # nested dict, integer indexes, regression described in #621\n        DataFrame(self.data2)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass FromDicts:\n    def setup(self):\n        N, K = 5000, 50\n        self.index = tm.makeStringIndex(N)\n        self.columns = tm.makeStringIndex(K)\n        frame = DataFrame(np.random.randn(N, K), index=self.index, columns=self.columns)\n        self.data = frame.to_dict()\n        self.dict_list = frame.to_dict(orient=\"records\")\n        self.data2 = {i: {j: float(j) for j in range(100)} for i in range(2000)}\n    \n        # arrays which we won't consolidate\n        self.dict_of_categoricals = {i: Categorical(np.arange(N)) for i in range(K)}", "min_run_count": 2, "name": "frame_ctor.FromDicts.time_nested_dict_int64", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "1e03669685aebd93046ceaf009fe83c0527863751432d5f7aa45aa30924cf672", "warmup_time": -1}, "frame_ctor.FromDictwithTimestamp.time_dict_with_timestamp_offsets": {"code": "class FromDictwithTimestamp:\n    def time_dict_with_timestamp_offsets(self, offset):\n        DataFrame(self.d)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass FromDictwithTimestamp:\n    def setup(self, offset):\n        N = 10**3\n        idx = date_range(Timestamp(\"1/1/1900\"), freq=offset, periods=N)\n        df = DataFrame(np.random.randn(N, 10), index=idx)\n        self.d = df.to_dict()", "min_run_count": 2, "name": "frame_ctor.FromDictwithTimestamp.time_dict_with_timestamp_offsets", "number": 0, "param_names": ["offset"], "params": [["<Nano>", "<Hour>"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "edbcf77be1e9f491a8866f3f510790d47d2c68aa69eb8e349b4662c23e071ce4", "warmup_time": -1}, "frame_ctor.FromLists.time_frame_from_lists": {"code": "class FromLists:\n    def time_frame_from_lists(self):\n        self.df = DataFrame(self.data)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass FromLists:\n    def setup(self):\n        N = 1000\n        M = 100\n        self.data = [list(range(M)) for i in range(N)]", "min_run_count": 2, "name": "frame_ctor.FromLists.time_frame_from_lists", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "31e3e4ee69561a2f18687d4fe38117db21e57a6862eba4174561ab425ca7791a", "warmup_time": -1}, "frame_ctor.FromNDArray.time_frame_from_ndarray": {"code": "class FromNDArray:\n    def time_frame_from_ndarray(self):\n        self.df = DataFrame(self.data)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass FromNDArray:\n    def setup(self):\n        N = 100000\n        self.data = np.random.randn(N)", "min_run_count": 2, "name": "frame_ctor.FromNDArray.time_frame_from_ndarray", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "42412f191926bccd17fde73d100476018ba3e35421ee311ca6a8d71ef8817e04", "warmup_time": -1}, "frame_ctor.FromRange.time_frame_from_range": {"code": "class FromRange:\n    def time_frame_from_range(self):\n        self.df = DataFrame(self.data)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass FromRange:\n    def setup(self):\n        N = 1_000_000\n        self.data = range(N)", "min_run_count": 2, "name": "frame_ctor.FromRange.time_frame_from_range", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "8eac1f82a2a2f08e5f9e50dfcf68b362211c18712ce5adbbc12bc772d7d7f156", "warmup_time": -1}, "frame_ctor.FromRecords.time_frame_from_records_generator": {"code": "class FromRecords:\n    def time_frame_from_records_generator(self, nrows):\n        # issue-6700\n        self.df = DataFrame.from_records(self.gen, nrows=nrows)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass FromRecords:\n    def setup(self, nrows):\n        N = 100000\n        self.gen = ((x, (x * 20), (x * 100)) for x in range(N))", "min_run_count": 2, "name": "frame_ctor.FromRecords.time_frame_from_records_generator", "number": 1, "param_names": ["nrows"], "params": [["None", "1000"]], "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "37ac2364875f70b5e255d9371c8fd77229fbb2bb221090c4004cce2af1f510b4", "warmup_time": -1}, "frame_ctor.FromScalar.time_frame_from_scalar_ea_float64": {"code": "class FromScalar:\n    def time_frame_from_scalar_ea_float64(self):\n        DataFrame(\n            1.0,\n            index=range(self.nrows),\n            columns=list(\"abc\"),\n            dtype=Float64Dtype(),\n        )\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass FromScalar:\n    def setup(self):\n        self.nrows = 100_000", "min_run_count": 2, "name": "frame_ctor.FromScalar.time_frame_from_scalar_ea_float64", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "c0971ae1b0ebe91e20c2c53f71217475a9812d27e00b303f343bae2612d9828d", "warmup_time": -1}, "frame_ctor.FromScalar.time_frame_from_scalar_ea_float64_na": {"code": "class FromScalar:\n    def time_frame_from_scalar_ea_float64_na(self):\n        DataFrame(\n            NA,\n            index=range(self.nrows),\n            columns=list(\"abc\"),\n            dtype=Float64Dtype(),\n        )\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass FromScalar:\n    def setup(self):\n        self.nrows = 100_000", "min_run_count": 2, "name": "frame_ctor.FromScalar.time_frame_from_scalar_ea_float64_na", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "9075f068d48f77d734b775cec79405c4847fd0a6e1abfac3461c0dc12981f0b0", "warmup_time": -1}, "frame_ctor.FromSeries.time_mi_series": {"code": "class FromSeries:\n    def time_mi_series(self):\n        DataFrame(self.s)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass FromSeries:\n    def setup(self):\n        mi = MultiIndex.from_product([range(100), range(100)])\n        self.s = Series(np.random.randn(10000), index=mi)", "min_run_count": 2, "name": "frame_ctor.FromSeries.time_mi_series", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "00d66d6b3fb76fd4030a0096f492a7b2040615acbd38000c2317b116f3156fa2", "warmup_time": -1}, "frame_methods.Apply.time_apply_axis_1": {"code": "class Apply:\n    def time_apply_axis_1(self):\n        self.df.apply(lambda x: x + 1, axis=1)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Apply:\n    def setup(self):\n        self.df = DataFrame(np.random.randn(1000, 100))\n    \n        self.s = Series(np.arange(1028.0))\n        self.df2 = DataFrame({i: self.s for i in range(1028)})\n        self.df3 = DataFrame(np.random.randn(1000, 3), columns=list(\"ABC\"))", "min_run_count": 2, "name": "frame_methods.Apply.time_apply_axis_1", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "1abb619fc583026b4a26e477881f01094dbeb880dded525e7cbea1815b8c3c7b", "warmup_time": -1}, "frame_methods.Apply.time_apply_lambda_mean": {"code": "class Apply:\n    def time_apply_lambda_mean(self):\n        self.df.apply(lambda x: x.mean())\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Apply:\n    def setup(self):\n        self.df = DataFrame(np.random.randn(1000, 100))\n    \n        self.s = Series(np.arange(1028.0))\n        self.df2 = DataFrame({i: self.s for i in range(1028)})\n        self.df3 = DataFrame(np.random.randn(1000, 3), columns=list(\"ABC\"))", "min_run_count": 2, "name": "frame_methods.Apply.time_apply_lambda_mean", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "e070e421516f44eee71e66e3fbf7ef0021872ca7eb578f4d11231ed83d441a64", "warmup_time": -1}, "frame_methods.Apply.time_apply_np_mean": {"code": "class Apply:\n    def time_apply_np_mean(self):\n        self.df.apply(np.mean)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Apply:\n    def setup(self):\n        self.df = DataFrame(np.random.randn(1000, 100))\n    \n        self.s = Series(np.arange(1028.0))\n        self.df2 = DataFrame({i: self.s for i in range(1028)})\n        self.df3 = DataFrame(np.random.randn(1000, 3), columns=list(\"ABC\"))", "min_run_count": 2, "name": "frame_methods.Apply.time_apply_np_mean", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "12564ba656f7bfdd2a8512fdf104ec41ceeefa22d3d678027728b15df26038a9", "warmup_time": -1}, "frame_methods.Apply.time_apply_pass_thru": {"code": "class Apply:\n    def time_apply_pass_thru(self):\n        self.df.apply(lambda x: x)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Apply:\n    def setup(self):\n        self.df = DataFrame(np.random.randn(1000, 100))\n    \n        self.s = Series(np.arange(1028.0))\n        self.df2 = DataFrame({i: self.s for i in range(1028)})\n        self.df3 = DataFrame(np.random.randn(1000, 3), columns=list(\"ABC\"))", "min_run_count": 2, "name": "frame_methods.Apply.time_apply_pass_thru", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "7ab6875c70f560ff825c524d780a53db1cad1e43c32e17fe6707f66113694e4c", "warmup_time": -1}, "frame_methods.Apply.time_apply_ref_by_name": {"code": "class Apply:\n    def time_apply_ref_by_name(self):\n        self.df3.apply(lambda x: x[\"A\"] + x[\"B\"], axis=1)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Apply:\n    def setup(self):\n        self.df = DataFrame(np.random.randn(1000, 100))\n    \n        self.s = Series(np.arange(1028.0))\n        self.df2 = DataFrame({i: self.s for i in range(1028)})\n        self.df3 = DataFrame(np.random.randn(1000, 3), columns=list(\"ABC\"))", "min_run_count": 2, "name": "frame_methods.Apply.time_apply_ref_by_name", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "2195dd01ad2f3a289b3754239166687e0753c2a9d5efc0d8be4978c886628236", "warmup_time": -1}, "frame_methods.Apply.time_apply_user_func": {"code": "class Apply:\n    def time_apply_user_func(self):\n        self.df2.apply(lambda x: np.corrcoef(x, self.s)[(0, 1)])\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Apply:\n    def setup(self):\n        self.df = DataFrame(np.random.randn(1000, 100))\n    \n        self.s = Series(np.arange(1028.0))\n        self.df2 = DataFrame({i: self.s for i in range(1028)})\n        self.df3 = DataFrame(np.random.randn(1000, 3), columns=list(\"ABC\"))", "min_run_count": 2, "name": "frame_methods.Apply.time_apply_user_func", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "f52de9d070093a84321a5d00e1ff6810b8c4b83e274a1daabf52699c0244b257", "warmup_time": -1}, "frame_methods.Clip.time_clip": {"code": "class Clip:\n    def time_clip(self, dtype):\n        self.df.clip(-1.0, 1.0)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Clip:\n    def setup(self, dtype):\n        data = np.random.randn(100_000, 10)\n        df = DataFrame(data, dtype=dtype)\n        self.df = df", "min_run_count": 2, "name": "frame_methods.Clip.time_clip", "number": 0, "param_names": ["dtype"], "params": [["'float64'", "'Float64'", "'float64[pyarrow]'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "e377218cbb14d1e57e275faade93ca8bb525a9a1b596836b7b181b935186f968", "warmup_time": -1}, "frame_methods.Count.time_count_level_mixed_dtypes_multi": {"code": "class Count:\n    def time_count_level_mixed_dtypes_multi(self, axis):\n        self.df_mixed.count(axis=axis)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Count:\n    def setup(self, axis):\n        self.df = DataFrame(np.random.randn(10000, 1000))\n        self.df.iloc[50:1000, 20:50] = np.nan\n        self.df.iloc[2000:3000] = np.nan\n        self.df.iloc[:, 60:70] = np.nan\n        self.df_mixed = self.df.copy()\n        self.df_mixed[\"foo\"] = \"bar\"\n    \n        self.df.index = MultiIndex.from_arrays([self.df.index, self.df.index])\n        self.df.columns = MultiIndex.from_arrays([self.df.columns, self.df.columns])\n        self.df_mixed.index = MultiIndex.from_arrays(\n            [self.df_mixed.index, self.df_mixed.index]\n        )\n        self.df_mixed.columns = MultiIndex.from_arrays(\n            [self.df_mixed.columns, self.df_mixed.columns]\n        )", "min_run_count": 2, "name": "frame_methods.Count.time_count_level_mixed_dtypes_multi", "number": 0, "param_names": ["axis"], "params": [["0", "1"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "a87253717124dc363a1eac2491505ab2266465c4c3e707879ae10c3ed605eba1", "warmup_time": -1}, "frame_methods.Count.time_count_level_multi": {"code": "class Count:\n    def time_count_level_multi(self, axis):\n        self.df.count(axis=axis)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Count:\n    def setup(self, axis):\n        self.df = DataFrame(np.random.randn(10000, 1000))\n        self.df.iloc[50:1000, 20:50] = np.nan\n        self.df.iloc[2000:3000] = np.nan\n        self.df.iloc[:, 60:70] = np.nan\n        self.df_mixed = self.df.copy()\n        self.df_mixed[\"foo\"] = \"bar\"\n    \n        self.df.index = MultiIndex.from_arrays([self.df.index, self.df.index])\n        self.df.columns = MultiIndex.from_arrays([self.df.columns, self.df.columns])\n        self.df_mixed.index = MultiIndex.from_arrays(\n            [self.df_mixed.index, self.df_mixed.index]\n        )\n        self.df_mixed.columns = MultiIndex.from_arrays(\n            [self.df_mixed.columns, self.df_mixed.columns]\n        )", "min_run_count": 2, "name": "frame_methods.Count.time_count_level_multi", "number": 0, "param_names": ["axis"], "params": [["0", "1"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "78b9f83fa788ad16a49260282eab542b4643fe2e3ebefad6fcb1b11e23d1018e", "warmup_time": -1}, "frame_methods.Describe.time_dataframe_describe": {"code": "class Describe:\n    def time_dataframe_describe(self):\n        self.df.describe()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Describe:\n    def setup(self):\n        self.df = DataFrame(\n            {\n                \"a\": np.random.randint(0, 100, 10**6),\n                \"b\": np.random.randint(0, 100, 10**6),\n                \"c\": np.random.randint(0, 100, 10**6),\n            }\n        )", "min_run_count": 2, "name": "frame_methods.Describe.time_dataframe_describe", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "a874bed44cb683ca51210e26724792fcdf88f6ff721f785384c8fb834049538a", "warmup_time": -1}, "frame_methods.Describe.time_series_describe": {"code": "class Describe:\n    def time_series_describe(self):\n        self.df[\"a\"].describe()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Describe:\n    def setup(self):\n        self.df = DataFrame(\n            {\n                \"a\": np.random.randint(0, 100, 10**6),\n                \"b\": np.random.randint(0, 100, 10**6),\n                \"c\": np.random.randint(0, 100, 10**6),\n            }\n        )", "min_run_count": 2, "name": "frame_methods.Describe.time_series_describe", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "bec8143392a0ea823e7bb51cdbc8e7e85a7655f739b8e049e7568f9d33a744f4", "warmup_time": -1}, "frame_methods.Dropna.time_dropna": {"code": "class Dropna:\n    def time_dropna(self, how, axis):\n        self.df.dropna(how=how, axis=axis)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Dropna:\n    def setup(self, how, axis):\n        self.df = DataFrame(np.random.randn(10000, 1000))\n        self.df.iloc[50:1000, 20:50] = np.nan\n        self.df.iloc[2000:3000] = np.nan\n        self.df.iloc[:, 60:70] = np.nan\n        self.df_mixed = self.df.copy()\n        self.df_mixed[\"foo\"] = \"bar\"", "min_run_count": 2, "name": "frame_methods.Dropna.time_dropna", "number": 0, "param_names": ["how", "axis"], "params": [["'all'", "'any'"], ["0", "1"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "0ae9be10365366634edb6b6490363a365b53e5bb30376f429aa6cd8501e99f60", "warmup_time": -1}, "frame_methods.Dropna.time_dropna_axis_mixed_dtypes": {"code": "class Dropna:\n    def time_dropna_axis_mixed_dtypes(self, how, axis):\n        self.df_mixed.dropna(how=how, axis=axis)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Dropna:\n    def setup(self, how, axis):\n        self.df = DataFrame(np.random.randn(10000, 1000))\n        self.df.iloc[50:1000, 20:50] = np.nan\n        self.df.iloc[2000:3000] = np.nan\n        self.df.iloc[:, 60:70] = np.nan\n        self.df_mixed = self.df.copy()\n        self.df_mixed[\"foo\"] = \"bar\"", "min_run_count": 2, "name": "frame_methods.Dropna.time_dropna_axis_mixed_dtypes", "number": 0, "param_names": ["how", "axis"], "params": [["'all'", "'any'"], ["0", "1"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "211ec5d6bd6568e1ab93ad31c07d7ea015f9540b948fa60ae1ce9846c9d0aaf8", "warmup_time": -1}, "frame_methods.Dtypes.time_frame_dtypes": {"code": "class Dtypes:\n    def time_frame_dtypes(self):\n        self.df.dtypes\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Dtypes:\n    def setup(self):\n        self.df = DataFrame(np.random.randn(1000, 1000))", "min_run_count": 2, "name": "frame_methods.Dtypes.time_frame_dtypes", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "a32eaac056e26349ac255f6354f2a8916b634a88bcf2fd8439b28dc9a21e4ff4", "warmup_time": -1}, "frame_methods.Duplicated.time_frame_duplicated": {"code": "class Duplicated:\n    def time_frame_duplicated(self):\n        self.df.duplicated()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Duplicated:\n    def setup(self):\n        n = 1 << 20\n        t = date_range(\"2015-01-01\", freq=\"S\", periods=(n // 64))\n        xs = np.random.randn(n // 64).round(2)\n        self.df = DataFrame(\n            {\n                \"a\": np.random.randint(-1 << 8, 1 << 8, n),\n                \"b\": np.random.choice(t, n),\n                \"c\": np.random.choice(xs, n),\n            }\n        )\n        self.df2 = DataFrame(np.random.randn(1000, 100).astype(str)).T", "min_run_count": 2, "name": "frame_methods.Duplicated.time_frame_duplicated", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "99bba024a25c09ca8f6eeb24a51d6e635c2eed9ae4e5b8a21bd29a094f8c2b3e", "warmup_time": -1}, "frame_methods.Duplicated.time_frame_duplicated_subset": {"code": "class Duplicated:\n    def time_frame_duplicated_subset(self):\n        self.df.duplicated(subset=[\"a\"])\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Duplicated:\n    def setup(self):\n        n = 1 << 20\n        t = date_range(\"2015-01-01\", freq=\"S\", periods=(n // 64))\n        xs = np.random.randn(n // 64).round(2)\n        self.df = DataFrame(\n            {\n                \"a\": np.random.randint(-1 << 8, 1 << 8, n),\n                \"b\": np.random.choice(t, n),\n                \"c\": np.random.choice(xs, n),\n            }\n        )\n        self.df2 = DataFrame(np.random.randn(1000, 100).astype(str)).T", "min_run_count": 2, "name": "frame_methods.Duplicated.time_frame_duplicated_subset", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "49350395c4664780c3127da6f97ccfe3b51aa94e1f29de6795fa71e003781d8d", "warmup_time": -1}, "frame_methods.Duplicated.time_frame_duplicated_wide": {"code": "class Duplicated:\n    def time_frame_duplicated_wide(self):\n        self.df2.duplicated()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Duplicated:\n    def setup(self):\n        n = 1 << 20\n        t = date_range(\"2015-01-01\", freq=\"S\", periods=(n // 64))\n        xs = np.random.randn(n // 64).round(2)\n        self.df = DataFrame(\n            {\n                \"a\": np.random.randint(-1 << 8, 1 << 8, n),\n                \"b\": np.random.choice(t, n),\n                \"c\": np.random.choice(xs, n),\n            }\n        )\n        self.df2 = DataFrame(np.random.randn(1000, 100).astype(str)).T", "min_run_count": 2, "name": "frame_methods.Duplicated.time_frame_duplicated_wide", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "073055405e57cdf74471451142dc08fb4fa449f9e29e1f95a52cb97825d9de14", "warmup_time": -1}, "frame_methods.Equals.time_frame_float_equal": {"code": "class Equals:\n    def time_frame_float_equal(self):\n        self.float_df.equals(self.float_df)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Equals:\n    def setup(self):\n        N = 10**3\n        self.float_df = DataFrame(np.random.randn(N, N))\n        self.float_df_nan = self.float_df.copy()\n        self.float_df_nan.iloc[-1, -1] = np.nan\n    \n        self.object_df = DataFrame(\"foo\", index=range(N), columns=range(N))\n        self.object_df_nan = self.object_df.copy()\n        self.object_df_nan.iloc[-1, -1] = np.nan\n    \n        self.nonunique_cols = self.object_df.copy()\n        self.nonunique_cols.columns = [\"A\"] * len(self.nonunique_cols.columns)\n        self.nonunique_cols_nan = self.nonunique_cols.copy()\n        self.nonunique_cols_nan.iloc[-1, -1] = np.nan", "min_run_count": 2, "name": "frame_methods.Equals.time_frame_float_equal", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "3e43e40c9afb93fdb9e4dc0b1153cb7e251f37639262f67e949b58d4cdec6de6", "warmup_time": -1}, "frame_methods.Equals.time_frame_float_unequal": {"code": "class Equals:\n    def time_frame_float_unequal(self):\n        self.float_df.equals(self.float_df_nan)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Equals:\n    def setup(self):\n        N = 10**3\n        self.float_df = DataFrame(np.random.randn(N, N))\n        self.float_df_nan = self.float_df.copy()\n        self.float_df_nan.iloc[-1, -1] = np.nan\n    \n        self.object_df = DataFrame(\"foo\", index=range(N), columns=range(N))\n        self.object_df_nan = self.object_df.copy()\n        self.object_df_nan.iloc[-1, -1] = np.nan\n    \n        self.nonunique_cols = self.object_df.copy()\n        self.nonunique_cols.columns = [\"A\"] * len(self.nonunique_cols.columns)\n        self.nonunique_cols_nan = self.nonunique_cols.copy()\n        self.nonunique_cols_nan.iloc[-1, -1] = np.nan", "min_run_count": 2, "name": "frame_methods.Equals.time_frame_float_unequal", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "096c7821b123d68c85d2ed32adda440daf4043608ac9a04e121f66aef041e33a", "warmup_time": -1}, "frame_methods.Equals.time_frame_nonunique_equal": {"code": "class Equals:\n    def time_frame_nonunique_equal(self):\n        self.nonunique_cols.equals(self.nonunique_cols)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Equals:\n    def setup(self):\n        N = 10**3\n        self.float_df = DataFrame(np.random.randn(N, N))\n        self.float_df_nan = self.float_df.copy()\n        self.float_df_nan.iloc[-1, -1] = np.nan\n    \n        self.object_df = DataFrame(\"foo\", index=range(N), columns=range(N))\n        self.object_df_nan = self.object_df.copy()\n        self.object_df_nan.iloc[-1, -1] = np.nan\n    \n        self.nonunique_cols = self.object_df.copy()\n        self.nonunique_cols.columns = [\"A\"] * len(self.nonunique_cols.columns)\n        self.nonunique_cols_nan = self.nonunique_cols.copy()\n        self.nonunique_cols_nan.iloc[-1, -1] = np.nan", "min_run_count": 2, "name": "frame_methods.Equals.time_frame_nonunique_equal", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "ea0c51f42ef266ee9b0fafafaa48a2192674cd615ae9f7b648b83aafbc5dcdce", "warmup_time": -1}, "frame_methods.Equals.time_frame_nonunique_unequal": {"code": "class Equals:\n    def time_frame_nonunique_unequal(self):\n        self.nonunique_cols.equals(self.nonunique_cols_nan)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Equals:\n    def setup(self):\n        N = 10**3\n        self.float_df = DataFrame(np.random.randn(N, N))\n        self.float_df_nan = self.float_df.copy()\n        self.float_df_nan.iloc[-1, -1] = np.nan\n    \n        self.object_df = DataFrame(\"foo\", index=range(N), columns=range(N))\n        self.object_df_nan = self.object_df.copy()\n        self.object_df_nan.iloc[-1, -1] = np.nan\n    \n        self.nonunique_cols = self.object_df.copy()\n        self.nonunique_cols.columns = [\"A\"] * len(self.nonunique_cols.columns)\n        self.nonunique_cols_nan = self.nonunique_cols.copy()\n        self.nonunique_cols_nan.iloc[-1, -1] = np.nan", "min_run_count": 2, "name": "frame_methods.Equals.time_frame_nonunique_unequal", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "0afac18ed2411295c0adc10e398c9e4b02682bb882a28427a848f9b9455ad7dd", "warmup_time": -1}, "frame_methods.Equals.time_frame_object_equal": {"code": "class Equals:\n    def time_frame_object_equal(self):\n        self.object_df.equals(self.object_df)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Equals:\n    def setup(self):\n        N = 10**3\n        self.float_df = DataFrame(np.random.randn(N, N))\n        self.float_df_nan = self.float_df.copy()\n        self.float_df_nan.iloc[-1, -1] = np.nan\n    \n        self.object_df = DataFrame(\"foo\", index=range(N), columns=range(N))\n        self.object_df_nan = self.object_df.copy()\n        self.object_df_nan.iloc[-1, -1] = np.nan\n    \n        self.nonunique_cols = self.object_df.copy()\n        self.nonunique_cols.columns = [\"A\"] * len(self.nonunique_cols.columns)\n        self.nonunique_cols_nan = self.nonunique_cols.copy()\n        self.nonunique_cols_nan.iloc[-1, -1] = np.nan", "min_run_count": 2, "name": "frame_methods.Equals.time_frame_object_equal", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "fcfdbbe9b7bbe39721d77c9ea49fde74df25c32913469a26570f9cedeeebe789", "warmup_time": -1}, "frame_methods.Equals.time_frame_object_unequal": {"code": "class Equals:\n    def time_frame_object_unequal(self):\n        self.object_df.equals(self.object_df_nan)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Equals:\n    def setup(self):\n        N = 10**3\n        self.float_df = DataFrame(np.random.randn(N, N))\n        self.float_df_nan = self.float_df.copy()\n        self.float_df_nan.iloc[-1, -1] = np.nan\n    \n        self.object_df = DataFrame(\"foo\", index=range(N), columns=range(N))\n        self.object_df_nan = self.object_df.copy()\n        self.object_df_nan.iloc[-1, -1] = np.nan\n    \n        self.nonunique_cols = self.object_df.copy()\n        self.nonunique_cols.columns = [\"A\"] * len(self.nonunique_cols.columns)\n        self.nonunique_cols_nan = self.nonunique_cols.copy()\n        self.nonunique_cols_nan.iloc[-1, -1] = np.nan", "min_run_count": 2, "name": "frame_methods.Equals.time_frame_object_unequal", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "8bb79f98af91ebb0756c6d77ad92778236c4b7ac8b01c041ed655dfb3fed7ce7", "warmup_time": -1}, "frame_methods.Fillna.time_frame_fillna": {"code": "class Fillna:\n    def time_frame_fillna(self, inplace, method, dtype):\n        self.df.fillna(inplace=inplace, method=method)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Fillna:\n    def setup(self, inplace, method, dtype):\n        N, M = 10000, 100\n        if dtype in (\"datetime64[ns]\", \"datetime64[ns, tz]\", \"timedelta64[ns]\"):\n            data = {\n                \"datetime64[ns]\": date_range(\"2011-01-01\", freq=\"H\", periods=N),\n                \"datetime64[ns, tz]\": date_range(\n                    \"2011-01-01\", freq=\"H\", periods=N, tz=\"Asia/Tokyo\"\n                ),\n                \"timedelta64[ns]\": timedelta_range(start=\"1 day\", periods=N, freq=\"1D\"),\n            }\n            self.df = DataFrame({f\"col_{i}\": data[dtype] for i in range(M)})\n            self.df[::2] = None\n        else:\n            values = np.random.randn(N, M)\n            values[::2] = np.nan\n            if dtype == \"Int64\":\n                values = values.round()\n            self.df = DataFrame(values, dtype=dtype)", "min_run_count": 2, "name": "frame_methods.Fillna.time_frame_fillna", "number": 0, "param_names": ["inplace", "method", "dtype"], "params": [["True", "False"], ["'pad'", "'bfill'"], ["'float64'", "'float32'", "'object'", "'Int64'", "'Float64'", "'datetime64[ns]'", "'datetime64[ns, tz]'", "'timedelta64[ns]'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "b79dc8788fab8b156f8613739c351a00636c8a3baa37c1bd67d2b6f3b61a22b7", "warmup_time": -1}, "frame_methods.FindValidIndex.time_first_valid_index": {"code": "class FindValidIndex:\n    def time_first_valid_index(self, dtype):\n        self.df.first_valid_index()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass FindValidIndex:\n    def setup(self, dtype):\n        df = DataFrame(\n            np.random.randn(100000, 2),\n            columns=list(\"AB\"),\n            dtype=dtype,\n        )\n        df.iloc[:100, 0] = None\n        df.iloc[:200, 1] = None\n        df.iloc[-100:, 0] = None\n        df.iloc[-200:, 1] = None\n        self.df = df", "min_run_count": 2, "name": "frame_methods.FindValidIndex.time_first_valid_index", "number": 0, "param_names": ["dtype"], "params": [["'float'", "'Float64'", "'float64[pyarrow]'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "25a643509f423207f4a1c6d8a57a39a4a2fb113489c72c587ab77425b9d0ed8c", "warmup_time": -1}, "frame_methods.FindValidIndex.time_last_valid_index": {"code": "class FindValidIndex:\n    def time_last_valid_index(self, dtype):\n        self.df.last_valid_index()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass FindValidIndex:\n    def setup(self, dtype):\n        df = DataFrame(\n            np.random.randn(100000, 2),\n            columns=list(\"AB\"),\n            dtype=dtype,\n        )\n        df.iloc[:100, 0] = None\n        df.iloc[:200, 1] = None\n        df.iloc[-100:, 0] = None\n        df.iloc[-200:, 1] = None\n        self.df = df", "min_run_count": 2, "name": "frame_methods.FindValidIndex.time_last_valid_index", "number": 0, "param_names": ["dtype"], "params": [["'float'", "'Float64'", "'float64[pyarrow]'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "7aa1cbbe0fc10c07e441950795f86f657072d95abb3fc53a6cd08af9ca145bb5", "warmup_time": -1}, "frame_methods.GetDtypeCounts.time_frame_get_dtype_counts": {"code": "class GetDtypeCounts:\n    def time_frame_get_dtype_counts(self):\n        with warnings.catch_warnings(record=True):\n            self.df.dtypes.value_counts()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass GetDtypeCounts:\n    def setup(self):\n        self.df = DataFrame(np.random.randn(10, 10000))", "min_run_count": 2, "name": "frame_methods.GetDtypeCounts.time_frame_get_dtype_counts", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "d1e0466afc9058166debec31e7ff688df837d407655e8faf0621969115aee0dd", "warmup_time": -1}, "frame_methods.GetDtypeCounts.time_info": {"code": "class GetDtypeCounts:\n    def time_info(self):\n        self.df.info()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass GetDtypeCounts:\n    def setup(self):\n        self.df = DataFrame(np.random.randn(10, 10000))", "min_run_count": 2, "name": "frame_methods.GetDtypeCounts.time_info", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "e08ed8e2402f26a376b2c946606fe2bc255214bd7eebee091fe34b3aa4df80db", "warmup_time": -1}, "frame_methods.GetNumericData.time_frame_get_numeric_data": {"code": "class GetNumericData:\n    def time_frame_get_numeric_data(self):\n        self.df._get_numeric_data()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass GetNumericData:\n    def setup(self):\n        self.df = DataFrame(np.random.randn(10000, 25))\n        self.df[\"foo\"] = \"bar\"\n        self.df[\"bar\"] = \"baz\"\n        self.df = self.df._consolidate()", "min_run_count": 2, "name": "frame_methods.GetNumericData.time_frame_get_numeric_data", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "a6f6ccd03d2a3e6a5b9533bf09fd1f3d852fb8c066e10da43dee6c5b1b958b16", "warmup_time": -1}, "frame_methods.Interpolate.time_interpolate": {"code": "class Interpolate:\n    def time_interpolate(self, downcast):\n        self.df.interpolate(downcast=downcast)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Interpolate:\n    def setup(self, downcast):\n        N = 10000\n        # this is the worst case, where every column has NaNs.\n        arr = np.random.randn(N, 100)\n        # NB: we need to set values in array, not in df.values, otherwise\n        #  the benchmark will be misleading for ArrayManager\n        arr[::2] = np.nan\n    \n        self.df = DataFrame(arr)\n    \n        self.df2 = DataFrame(\n            {\n                \"A\": np.arange(0, N),\n                \"B\": np.random.randint(0, 100, N),\n                \"C\": np.random.randn(N),\n                \"D\": np.random.randn(N),\n            }\n        )\n        self.df2.loc[1::5, \"A\"] = np.nan\n        self.df2.loc[1::5, \"C\"] = np.nan", "min_run_count": 2, "name": "frame_methods.Interpolate.time_interpolate", "number": 0, "param_names": ["downcast"], "params": [["None", "'infer'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "772e1716ebd0b46c5a1414657afc3917f5a8ea0f258df3ea3261ce0eaf02ee55", "warmup_time": -1}, "frame_methods.Interpolate.time_interpolate_some_good": {"code": "class Interpolate:\n    def time_interpolate_some_good(self, downcast):\n        self.df2.interpolate(downcast=downcast)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Interpolate:\n    def setup(self, downcast):\n        N = 10000\n        # this is the worst case, where every column has NaNs.\n        arr = np.random.randn(N, 100)\n        # NB: we need to set values in array, not in df.values, otherwise\n        #  the benchmark will be misleading for ArrayManager\n        arr[::2] = np.nan\n    \n        self.df = DataFrame(arr)\n    \n        self.df2 = DataFrame(\n            {\n                \"A\": np.arange(0, N),\n                \"B\": np.random.randint(0, 100, N),\n                \"C\": np.random.randn(N),\n                \"D\": np.random.randn(N),\n            }\n        )\n        self.df2.loc[1::5, \"A\"] = np.nan\n        self.df2.loc[1::5, \"C\"] = np.nan", "min_run_count": 2, "name": "frame_methods.Interpolate.time_interpolate_some_good", "number": 0, "param_names": ["downcast"], "params": [["None", "'infer'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "815fbe5f668a27ab8708fc47157cc8edac28bf78e7cfc2776ef6a1c5c73832ae", "warmup_time": -1}, "frame_methods.Isna.time_isna": {"code": "class Isna:\n    def time_isna(self, dtype):\n        self.df.isna()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Isna:\n    def setup(self, dtype):\n        data = np.random.randn(10000, 1000)\n        # all-na columns\n        data[:, 600:800] = np.nan\n        # partial-na columns\n        data[800:1000, 4000:5000] = np.nan\n        self.df = DataFrame(data, dtype=dtype)", "min_run_count": 2, "name": "frame_methods.Isna.time_isna", "number": 0, "param_names": ["dtype"], "params": [["'float64'", "'Float64'", "'float64[pyarrow]'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "16c807e189d1c06f5c7693f87fb8211e7206b4807b9eba3c390f1dd2c5e5cf37", "warmup_time": -1}, "frame_methods.Isnull.time_isnull": {"code": "class Isnull:\n    def time_isnull(self):\n        isnull(self.df)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Isnull:\n    def setup(self):\n        N = 10**3\n        self.df_no_null = DataFrame(np.random.randn(N, N))\n    \n        sample = np.array([np.nan, 1.0])\n        data = np.random.choice(sample, (N, N))\n        self.df = DataFrame(data)\n    \n        sample = np.array(list(string.ascii_letters + string.whitespace))\n        data = np.random.choice(sample, (N, N))\n        self.df_strings = DataFrame(data)\n    \n        sample = np.array(\n            [\n                NaT,\n                np.nan,\n                None,\n                np.datetime64(\"NaT\"),\n                np.timedelta64(\"NaT\"),\n                0,\n                1,\n                2.0,\n                \"\",\n                \"abcd\",\n            ]\n        )\n        data = np.random.choice(sample, (N, N))\n        self.df_obj = DataFrame(data)", "min_run_count": 2, "name": "frame_methods.Isnull.time_isnull", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "de22a45fa388dfa02f30c3a7cb1acae9fe966c2d1e68671882fa38eda4e52b3e", "warmup_time": -1}, "frame_methods.Isnull.time_isnull_floats_no_null": {"code": "class Isnull:\n    def time_isnull_floats_no_null(self):\n        isnull(self.df_no_null)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Isnull:\n    def setup(self):\n        N = 10**3\n        self.df_no_null = DataFrame(np.random.randn(N, N))\n    \n        sample = np.array([np.nan, 1.0])\n        data = np.random.choice(sample, (N, N))\n        self.df = DataFrame(data)\n    \n        sample = np.array(list(string.ascii_letters + string.whitespace))\n        data = np.random.choice(sample, (N, N))\n        self.df_strings = DataFrame(data)\n    \n        sample = np.array(\n            [\n                NaT,\n                np.nan,\n                None,\n                np.datetime64(\"NaT\"),\n                np.timedelta64(\"NaT\"),\n                0,\n                1,\n                2.0,\n                \"\",\n                \"abcd\",\n            ]\n        )\n        data = np.random.choice(sample, (N, N))\n        self.df_obj = DataFrame(data)", "min_run_count": 2, "name": "frame_methods.Isnull.time_isnull_floats_no_null", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "d52c0900c393b15f62670fa1ccbc7018957cad8e340de411ad4bd5b33da9ee72", "warmup_time": -1}, "frame_methods.Isnull.time_isnull_obj": {"code": "class Isnull:\n    def time_isnull_obj(self):\n        isnull(self.df_obj)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Isnull:\n    def setup(self):\n        N = 10**3\n        self.df_no_null = DataFrame(np.random.randn(N, N))\n    \n        sample = np.array([np.nan, 1.0])\n        data = np.random.choice(sample, (N, N))\n        self.df = DataFrame(data)\n    \n        sample = np.array(list(string.ascii_letters + string.whitespace))\n        data = np.random.choice(sample, (N, N))\n        self.df_strings = DataFrame(data)\n    \n        sample = np.array(\n            [\n                NaT,\n                np.nan,\n                None,\n                np.datetime64(\"NaT\"),\n                np.timedelta64(\"NaT\"),\n                0,\n                1,\n                2.0,\n                \"\",\n                \"abcd\",\n            ]\n        )\n        data = np.random.choice(sample, (N, N))\n        self.df_obj = DataFrame(data)", "min_run_count": 2, "name": "frame_methods.Isnull.time_isnull_obj", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "02fc103a644b76b012203138d72c1aedc60734a2ca5eaa97a80a3cac46bcf039", "warmup_time": -1}, "frame_methods.Isnull.time_isnull_strngs": {"code": "class Isnull:\n    def time_isnull_strngs(self):\n        isnull(self.df_strings)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Isnull:\n    def setup(self):\n        N = 10**3\n        self.df_no_null = DataFrame(np.random.randn(N, N))\n    \n        sample = np.array([np.nan, 1.0])\n        data = np.random.choice(sample, (N, N))\n        self.df = DataFrame(data)\n    \n        sample = np.array(list(string.ascii_letters + string.whitespace))\n        data = np.random.choice(sample, (N, N))\n        self.df_strings = DataFrame(data)\n    \n        sample = np.array(\n            [\n                NaT,\n                np.nan,\n                None,\n                np.datetime64(\"NaT\"),\n                np.timedelta64(\"NaT\"),\n                0,\n                1,\n                2.0,\n                \"\",\n                \"abcd\",\n            ]\n        )\n        data = np.random.choice(sample, (N, N))\n        self.df_obj = DataFrame(data)", "min_run_count": 2, "name": "frame_methods.Isnull.time_isnull_strngs", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "ff2d41de239a32889b66173e7caa3c0017fac8052762ae9703e5f9e07e1ef5a5", "warmup_time": -1}, "frame_methods.Iteration.mem_itertuples_raw_start": {"code": "class Iteration:\n    def mem_itertuples_raw_start(self):\n        return self.df4.itertuples(index=False, name=None)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Iteration:\n    def setup(self):\n        N = 1000\n        self.df = DataFrame(np.random.randn(N * 10, N))\n        self.df2 = DataFrame(np.random.randn(N * 50, 10))\n        self.df3 = DataFrame(\n            np.random.randn(N, 5 * N), columns=[\"C\" + str(c) for c in range(N * 5)]\n        )\n        self.df4 = DataFrame(np.random.randn(N * 1000, 10))", "name": "frame_methods.Iteration.mem_itertuples_raw_start", "param_names": [], "params": [], "timeout": 120, "type": "memory", "unit": "bytes", "version": "bde9d2373c7953bbf4a4d7fe73bd19e60eb7c15b50f8978637098fec3d837ed1"}, "frame_methods.Iteration.mem_itertuples_raw_to_list": {"code": "class Iteration:\n    def mem_itertuples_raw_to_list(self):\n        return list(self.df4.itertuples(index=False, name=None))\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Iteration:\n    def setup(self):\n        N = 1000\n        self.df = DataFrame(np.random.randn(N * 10, N))\n        self.df2 = DataFrame(np.random.randn(N * 50, 10))\n        self.df3 = DataFrame(\n            np.random.randn(N, 5 * N), columns=[\"C\" + str(c) for c in range(N * 5)]\n        )\n        self.df4 = DataFrame(np.random.randn(N * 1000, 10))", "name": "frame_methods.Iteration.mem_itertuples_raw_to_list", "param_names": [], "params": [], "timeout": 120, "type": "memory", "unit": "bytes", "version": "14959ad0e6b16ce24b2986d509e67eeccc6ad44f09ce481e44781dd903d37a04"}, "frame_methods.Iteration.mem_itertuples_read_first": {"code": "class Iteration:\n    def mem_itertuples_read_first(self):\n        return next(self.df4.itertuples())\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Iteration:\n    def setup(self):\n        N = 1000\n        self.df = DataFrame(np.random.randn(N * 10, N))\n        self.df2 = DataFrame(np.random.randn(N * 50, 10))\n        self.df3 = DataFrame(\n            np.random.randn(N, 5 * N), columns=[\"C\" + str(c) for c in range(N * 5)]\n        )\n        self.df4 = DataFrame(np.random.randn(N * 1000, 10))", "name": "frame_methods.Iteration.mem_itertuples_read_first", "param_names": [], "params": [], "timeout": 120, "type": "memory", "unit": "bytes", "version": "fa14a67958421e77045287ab0dfe58c2d22462f3b77070715024772201c64770"}, "frame_methods.Iteration.mem_itertuples_start": {"code": "class Iteration:\n    def mem_itertuples_start(self):\n        return self.df4.itertuples()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Iteration:\n    def setup(self):\n        N = 1000\n        self.df = DataFrame(np.random.randn(N * 10, N))\n        self.df2 = DataFrame(np.random.randn(N * 50, 10))\n        self.df3 = DataFrame(\n            np.random.randn(N, 5 * N), columns=[\"C\" + str(c) for c in range(N * 5)]\n        )\n        self.df4 = DataFrame(np.random.randn(N * 1000, 10))", "name": "frame_methods.Iteration.mem_itertuples_start", "param_names": [], "params": [], "timeout": 120, "type": "memory", "unit": "bytes", "version": "cf2518d7a524f33405fe8b9f5e7dd8af1e52820e56cf14f92d6ff79ca33bbca9"}, "frame_methods.Iteration.mem_itertuples_to_list": {"code": "class Iteration:\n    def mem_itertuples_to_list(self):\n        return list(self.df4.itertuples())\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Iteration:\n    def setup(self):\n        N = 1000\n        self.df = DataFrame(np.random.randn(N * 10, N))\n        self.df2 = DataFrame(np.random.randn(N * 50, 10))\n        self.df3 = DataFrame(\n            np.random.randn(N, 5 * N), columns=[\"C\" + str(c) for c in range(N * 5)]\n        )\n        self.df4 = DataFrame(np.random.randn(N * 1000, 10))", "name": "frame_methods.Iteration.mem_itertuples_to_list", "param_names": [], "params": [], "timeout": 120, "type": "memory", "unit": "bytes", "version": "fc2c86822b2a65a5dd8df96b9003fe69eb2c82b3b8543140d1744b7d7fbc099f"}, "frame_methods.Iteration.peakmem_itertuples": {"code": "class Iteration:\n    def peakmem_itertuples(self):\n        for row in self.df4.itertuples():\n            pass\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Iteration:\n    def setup(self):\n        N = 1000\n        self.df = DataFrame(np.random.randn(N * 10, N))\n        self.df2 = DataFrame(np.random.randn(N * 50, 10))\n        self.df3 = DataFrame(\n            np.random.randn(N, 5 * N), columns=[\"C\" + str(c) for c in range(N * 5)]\n        )\n        self.df4 = DataFrame(np.random.randn(N * 1000, 10))", "name": "frame_methods.Iteration.peakmem_itertuples", "param_names": [], "params": [], "timeout": 120, "type": "peakmemory", "unit": "bytes", "version": "f8c4bb246773a09f62d6963200ac6dd08accf63f8701099b39f34450db0baa76"}, "frame_methods.Iteration.peakmem_itertuples_raw": {"code": "class Iteration:\n    def peakmem_itertuples_raw(self):\n        for row in self.df4.itertuples(index=False, name=None):\n            pass\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Iteration:\n    def setup(self):\n        N = 1000\n        self.df = DataFrame(np.random.randn(N * 10, N))\n        self.df2 = DataFrame(np.random.randn(N * 50, 10))\n        self.df3 = DataFrame(\n            np.random.randn(N, 5 * N), columns=[\"C\" + str(c) for c in range(N * 5)]\n        )\n        self.df4 = DataFrame(np.random.randn(N * 1000, 10))", "name": "frame_methods.Iteration.peakmem_itertuples_raw", "param_names": [], "params": [], "timeout": 120, "type": "peakmemory", "unit": "bytes", "version": "51be24a7edeb484ceaa5e24c608c890c59c56b210c778564af1c40cde9c6582b"}, "frame_methods.Iteration.peakmem_itertuples_raw_read_first": {"code": "class Iteration:\n    def peakmem_itertuples_raw_read_first(self):\n        next(self.df4.itertuples(index=False, name=None))\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Iteration:\n    def setup(self):\n        N = 1000\n        self.df = DataFrame(np.random.randn(N * 10, N))\n        self.df2 = DataFrame(np.random.randn(N * 50, 10))\n        self.df3 = DataFrame(\n            np.random.randn(N, 5 * N), columns=[\"C\" + str(c) for c in range(N * 5)]\n        )\n        self.df4 = DataFrame(np.random.randn(N * 1000, 10))", "name": "frame_methods.Iteration.peakmem_itertuples_raw_read_first", "param_names": [], "params": [], "timeout": 120, "type": "peakmemory", "unit": "bytes", "version": "3bcec70cbf3d3ea880425ba6e3a7a604504d19716e82dbbb4a70fb8351eda7f3"}, "frame_methods.Iteration.peakmem_itertuples_raw_start": {"code": "class Iteration:\n    def peakmem_itertuples_raw_start(self):\n        self.df4.itertuples(index=False, name=None)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Iteration:\n    def setup(self):\n        N = 1000\n        self.df = DataFrame(np.random.randn(N * 10, N))\n        self.df2 = DataFrame(np.random.randn(N * 50, 10))\n        self.df3 = DataFrame(\n            np.random.randn(N, 5 * N), columns=[\"C\" + str(c) for c in range(N * 5)]\n        )\n        self.df4 = DataFrame(np.random.randn(N * 1000, 10))", "name": "frame_methods.Iteration.peakmem_itertuples_raw_start", "param_names": [], "params": [], "timeout": 120, "type": "peakmemory", "unit": "bytes", "version": "8d85d7a2d0ceb456c1eae16a3f138a7ea0a13edf1bd76492d262b00cc32013cf"}, "frame_methods.Iteration.peakmem_itertuples_raw_to_list": {"code": "class Iteration:\n    def peakmem_itertuples_raw_to_list(self):\n        list(self.df4.itertuples(index=False, name=None))\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Iteration:\n    def setup(self):\n        N = 1000\n        self.df = DataFrame(np.random.randn(N * 10, N))\n        self.df2 = DataFrame(np.random.randn(N * 50, 10))\n        self.df3 = DataFrame(\n            np.random.randn(N, 5 * N), columns=[\"C\" + str(c) for c in range(N * 5)]\n        )\n        self.df4 = DataFrame(np.random.randn(N * 1000, 10))", "name": "frame_methods.Iteration.peakmem_itertuples_raw_to_list", "param_names": [], "params": [], "timeout": 120, "type": "peakmemory", "unit": "bytes", "version": "702541458ae59bd0fa6a7654edf93ba6de30013419a4591073b4077ffaaa9ec1"}, "frame_methods.Iteration.peakmem_itertuples_start": {"code": "class Iteration:\n    def peakmem_itertuples_start(self):\n        self.df4.itertuples()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Iteration:\n    def setup(self):\n        N = 1000\n        self.df = DataFrame(np.random.randn(N * 10, N))\n        self.df2 = DataFrame(np.random.randn(N * 50, 10))\n        self.df3 = DataFrame(\n            np.random.randn(N, 5 * N), columns=[\"C\" + str(c) for c in range(N * 5)]\n        )\n        self.df4 = DataFrame(np.random.randn(N * 1000, 10))", "name": "frame_methods.Iteration.peakmem_itertuples_start", "param_names": [], "params": [], "timeout": 120, "type": "peakmemory", "unit": "bytes", "version": "2e9870eb171bfbc3718dac5dc495cf2a5fc860a65acca33db4110a97d819f905"}, "frame_methods.Iteration.peakmem_itertuples_to_list": {"code": "class Iteration:\n    def peakmem_itertuples_to_list(self):\n        list(self.df4.itertuples())\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Iteration:\n    def setup(self):\n        N = 1000\n        self.df = DataFrame(np.random.randn(N * 10, N))\n        self.df2 = DataFrame(np.random.randn(N * 50, 10))\n        self.df3 = DataFrame(\n            np.random.randn(N, 5 * N), columns=[\"C\" + str(c) for c in range(N * 5)]\n        )\n        self.df4 = DataFrame(np.random.randn(N * 1000, 10))", "name": "frame_methods.Iteration.peakmem_itertuples_to_list", "param_names": [], "params": [], "timeout": 120, "type": "peakmemory", "unit": "bytes", "version": "3b1c891c821d3baa961e2ac7bbba794eaaa5fdde90643e15273782165349694d"}, "frame_methods.Iteration.time_items": {"code": "class Iteration:\n    def time_items(self):\n        # (monitor no-copying behaviour)\n        if hasattr(self.df, \"_item_cache\"):\n            self.df._item_cache.clear()\n        for name, col in self.df.items():\n            pass\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Iteration:\n    def setup(self):\n        N = 1000\n        self.df = DataFrame(np.random.randn(N * 10, N))\n        self.df2 = DataFrame(np.random.randn(N * 50, 10))\n        self.df3 = DataFrame(\n            np.random.randn(N, 5 * N), columns=[\"C\" + str(c) for c in range(N * 5)]\n        )\n        self.df4 = DataFrame(np.random.randn(N * 1000, 10))", "min_run_count": 2, "name": "frame_methods.Iteration.time_items", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 120, "type": "time", "unit": "seconds", "version": "61a76eb1cc78a07500c444849ab0ff0f8e5db1091090d34b6a1cdaee55952a78", "warmup_time": -1}, "frame_methods.Iteration.time_items_cached": {"code": "class Iteration:\n    def time_items_cached(self):\n        for name, col in self.df.items():\n            pass\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Iteration:\n    def setup(self):\n        N = 1000\n        self.df = DataFrame(np.random.randn(N * 10, N))\n        self.df2 = DataFrame(np.random.randn(N * 50, 10))\n        self.df3 = DataFrame(\n            np.random.randn(N, 5 * N), columns=[\"C\" + str(c) for c in range(N * 5)]\n        )\n        self.df4 = DataFrame(np.random.randn(N * 1000, 10))", "min_run_count": 2, "name": "frame_methods.Iteration.time_items_cached", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 120, "type": "time", "unit": "seconds", "version": "c306e5ac3eb89a326c9bc3a472c6040fc7e21e71d498483a3aa5263ed417b87a", "warmup_time": -1}, "frame_methods.Iteration.time_iteritems_indexing": {"code": "class Iteration:\n    def time_iteritems_indexing(self):\n        for col in self.df3:\n            self.df3[col]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Iteration:\n    def setup(self):\n        N = 1000\n        self.df = DataFrame(np.random.randn(N * 10, N))\n        self.df2 = DataFrame(np.random.randn(N * 50, 10))\n        self.df3 = DataFrame(\n            np.random.randn(N, 5 * N), columns=[\"C\" + str(c) for c in range(N * 5)]\n        )\n        self.df4 = DataFrame(np.random.randn(N * 1000, 10))", "min_run_count": 2, "name": "frame_methods.Iteration.time_iteritems_indexing", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 120, "type": "time", "unit": "seconds", "version": "32a0d9e470a05a943e062be7e53224b0a8d3c4753f3ea203564451fe73e00be6", "warmup_time": -1}, "frame_methods.Iteration.time_iterrows": {"code": "class Iteration:\n    def time_iterrows(self):\n        for row in self.df.iterrows():\n            pass\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Iteration:\n    def setup(self):\n        N = 1000\n        self.df = DataFrame(np.random.randn(N * 10, N))\n        self.df2 = DataFrame(np.random.randn(N * 50, 10))\n        self.df3 = DataFrame(\n            np.random.randn(N, 5 * N), columns=[\"C\" + str(c) for c in range(N * 5)]\n        )\n        self.df4 = DataFrame(np.random.randn(N * 1000, 10))", "min_run_count": 2, "name": "frame_methods.Iteration.time_iterrows", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 120, "type": "time", "unit": "seconds", "version": "1872356d18d8d38838ccef4e38aea113cb033fcd589da146758d76d6aba725c1", "warmup_time": -1}, "frame_methods.Iteration.time_itertuples": {"code": "class Iteration:\n    def time_itertuples(self):\n        for row in self.df4.itertuples():\n            pass\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Iteration:\n    def setup(self):\n        N = 1000\n        self.df = DataFrame(np.random.randn(N * 10, N))\n        self.df2 = DataFrame(np.random.randn(N * 50, 10))\n        self.df3 = DataFrame(\n            np.random.randn(N, 5 * N), columns=[\"C\" + str(c) for c in range(N * 5)]\n        )\n        self.df4 = DataFrame(np.random.randn(N * 1000, 10))", "min_run_count": 2, "name": "frame_methods.Iteration.time_itertuples", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 120, "type": "time", "unit": "seconds", "version": "bc1f6d845378bd6d1c53d1ef7b8e0f725f9a6ca74b0b1bfe928c5a21e6829fd9", "warmup_time": -1}, "frame_methods.Iteration.time_itertuples_raw_read_first": {"code": "class Iteration:\n    def time_itertuples_raw_read_first(self):\n        next(self.df4.itertuples(index=False, name=None))\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Iteration:\n    def setup(self):\n        N = 1000\n        self.df = DataFrame(np.random.randn(N * 10, N))\n        self.df2 = DataFrame(np.random.randn(N * 50, 10))\n        self.df3 = DataFrame(\n            np.random.randn(N, 5 * N), columns=[\"C\" + str(c) for c in range(N * 5)]\n        )\n        self.df4 = DataFrame(np.random.randn(N * 1000, 10))", "min_run_count": 2, "name": "frame_methods.Iteration.time_itertuples_raw_read_first", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 120, "type": "time", "unit": "seconds", "version": "78a787f4a6eb7dd27f3ac2434d4d26567eca763890c14bd2b86b54d88ade5db4", "warmup_time": -1}, "frame_methods.Iteration.time_itertuples_raw_start": {"code": "class Iteration:\n    def time_itertuples_raw_start(self):\n        self.df4.itertuples(index=False, name=None)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Iteration:\n    def setup(self):\n        N = 1000\n        self.df = DataFrame(np.random.randn(N * 10, N))\n        self.df2 = DataFrame(np.random.randn(N * 50, 10))\n        self.df3 = DataFrame(\n            np.random.randn(N, 5 * N), columns=[\"C\" + str(c) for c in range(N * 5)]\n        )\n        self.df4 = DataFrame(np.random.randn(N * 1000, 10))", "min_run_count": 2, "name": "frame_methods.Iteration.time_itertuples_raw_start", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 120, "type": "time", "unit": "seconds", "version": "e34eb99379456d0e4ff1da68c34d436747af447b5d80f49bca78a9095da18426", "warmup_time": -1}, "frame_methods.Iteration.time_itertuples_raw_tuples": {"code": "class Iteration:\n    def time_itertuples_raw_tuples(self):\n        for row in self.df4.itertuples(index=False, name=None):\n            pass\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Iteration:\n    def setup(self):\n        N = 1000\n        self.df = DataFrame(np.random.randn(N * 10, N))\n        self.df2 = DataFrame(np.random.randn(N * 50, 10))\n        self.df3 = DataFrame(\n            np.random.randn(N, 5 * N), columns=[\"C\" + str(c) for c in range(N * 5)]\n        )\n        self.df4 = DataFrame(np.random.randn(N * 1000, 10))", "min_run_count": 2, "name": "frame_methods.Iteration.time_itertuples_raw_tuples", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 120, "type": "time", "unit": "seconds", "version": "ef2cf1b3767b908e25cbd488502ea2b91b43cfcd491b12389acfbea37699cc95", "warmup_time": -1}, "frame_methods.Iteration.time_itertuples_raw_tuples_to_list": {"code": "class Iteration:\n    def time_itertuples_raw_tuples_to_list(self):\n        list(self.df4.itertuples(index=False, name=None))\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Iteration:\n    def setup(self):\n        N = 1000\n        self.df = DataFrame(np.random.randn(N * 10, N))\n        self.df2 = DataFrame(np.random.randn(N * 50, 10))\n        self.df3 = DataFrame(\n            np.random.randn(N, 5 * N), columns=[\"C\" + str(c) for c in range(N * 5)]\n        )\n        self.df4 = DataFrame(np.random.randn(N * 1000, 10))", "min_run_count": 2, "name": "frame_methods.Iteration.time_itertuples_raw_tuples_to_list", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 120, "type": "time", "unit": "seconds", "version": "f372d26bf89b90dd1e24ac2a01493a7435fdf11710e9e65324adc1d350725816", "warmup_time": -1}, "frame_methods.Iteration.time_itertuples_read_first": {"code": "class Iteration:\n    def time_itertuples_read_first(self):\n        next(self.df4.itertuples())\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Iteration:\n    def setup(self):\n        N = 1000\n        self.df = DataFrame(np.random.randn(N * 10, N))\n        self.df2 = DataFrame(np.random.randn(N * 50, 10))\n        self.df3 = DataFrame(\n            np.random.randn(N, 5 * N), columns=[\"C\" + str(c) for c in range(N * 5)]\n        )\n        self.df4 = DataFrame(np.random.randn(N * 1000, 10))", "min_run_count": 2, "name": "frame_methods.Iteration.time_itertuples_read_first", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 120, "type": "time", "unit": "seconds", "version": "9ed674f5820c7707be515d2f9a891d84a09efcf8f785fc428335dac028a682a6", "warmup_time": -1}, "frame_methods.Iteration.time_itertuples_start": {"code": "class Iteration:\n    def time_itertuples_start(self):\n        self.df4.itertuples()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Iteration:\n    def setup(self):\n        N = 1000\n        self.df = DataFrame(np.random.randn(N * 10, N))\n        self.df2 = DataFrame(np.random.randn(N * 50, 10))\n        self.df3 = DataFrame(\n            np.random.randn(N, 5 * N), columns=[\"C\" + str(c) for c in range(N * 5)]\n        )\n        self.df4 = DataFrame(np.random.randn(N * 1000, 10))", "min_run_count": 2, "name": "frame_methods.Iteration.time_itertuples_start", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 120, "type": "time", "unit": "seconds", "version": "beae2a24376ed50a9a214101ac7828899ca3db4436d6f61cc38ac099202d2dfd", "warmup_time": -1}, "frame_methods.Iteration.time_itertuples_to_list": {"code": "class Iteration:\n    def time_itertuples_to_list(self):\n        list(self.df4.itertuples())\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Iteration:\n    def setup(self):\n        N = 1000\n        self.df = DataFrame(np.random.randn(N * 10, N))\n        self.df2 = DataFrame(np.random.randn(N * 50, 10))\n        self.df3 = DataFrame(\n            np.random.randn(N, 5 * N), columns=[\"C\" + str(c) for c in range(N * 5)]\n        )\n        self.df4 = DataFrame(np.random.randn(N * 1000, 10))", "min_run_count": 2, "name": "frame_methods.Iteration.time_itertuples_to_list", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 120, "type": "time", "unit": "seconds", "version": "a5fc1a49acb90aa9c123ba866a88ff4f8c508c4cfef59faa117d0da770f63698", "warmup_time": -1}, "frame_methods.MaskBool.time_frame_mask_bools": {"code": "class MaskBool:\n    def time_frame_mask_bools(self):\n        self.bools.mask(self.mask)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass MaskBool:\n    def setup(self):\n        data = np.random.randn(1000, 500)\n        df = DataFrame(data)\n        df = df.where(df > 0)\n        self.bools = df > 0\n        self.mask = isnull(df)", "min_run_count": 2, "name": "frame_methods.MaskBool.time_frame_mask_bools", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "75d26deea512c14af4e7569f5dc1e43324ed79283c789db2fb4999d0d7853441", "warmup_time": -1}, "frame_methods.MaskBool.time_frame_mask_floats": {"code": "class MaskBool:\n    def time_frame_mask_floats(self):\n        self.bools.astype(float).mask(self.mask)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass MaskBool:\n    def setup(self):\n        data = np.random.randn(1000, 500)\n        df = DataFrame(data)\n        df = df.where(df > 0)\n        self.bools = df > 0\n        self.mask = isnull(df)", "min_run_count": 2, "name": "frame_methods.MaskBool.time_frame_mask_floats", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "77725b9d5309bb967bcd8a8abd4d5a8168f1759ac192d051fe68d191166e9b7e", "warmup_time": -1}, "frame_methods.MemoryUsage.time_memory_usage": {"code": "class MemoryUsage:\n    def time_memory_usage(self):\n        self.df.memory_usage(deep=True)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass MemoryUsage:\n    def setup(self):\n        self.df = DataFrame(np.random.randn(100000, 2), columns=list(\"AB\"))\n        self.df2 = self.df.copy()\n        self.df2[\"A\"] = self.df2[\"A\"].astype(\"object\")", "min_run_count": 2, "name": "frame_methods.MemoryUsage.time_memory_usage", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "abaa03ed61b94b958c09bee89d52d1b87d72796639ec7588559d5b158f8dede9", "warmup_time": -1}, "frame_methods.MemoryUsage.time_memory_usage_object_dtype": {"code": "class MemoryUsage:\n    def time_memory_usage_object_dtype(self):\n        self.df2.memory_usage(deep=True)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass MemoryUsage:\n    def setup(self):\n        self.df = DataFrame(np.random.randn(100000, 2), columns=list(\"AB\"))\n        self.df2 = self.df.copy()\n        self.df2[\"A\"] = self.df2[\"A\"].astype(\"object\")", "min_run_count": 2, "name": "frame_methods.MemoryUsage.time_memory_usage_object_dtype", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "f25a399ce1ee970c20943c1c0c1d8359a80848bf10be1b7912eae51ee454231a", "warmup_time": -1}, "frame_methods.NSort.time_nlargest_one_column": {"code": "class NSort:\n    def time_nlargest_one_column(self, keep):\n        self.df.nlargest(100, \"A\", keep=keep)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass NSort:\n    def setup(self, keep):\n        self.df = DataFrame(np.random.randn(100000, 3), columns=list(\"ABC\"))", "min_run_count": 2, "name": "frame_methods.NSort.time_nlargest_one_column", "number": 0, "param_names": ["keep"], "params": [["'first'", "'last'", "'all'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "ae8ee646412a2720d7755ec64e5f1a787ddb6242469e44c8e3f548a93c55eb32", "warmup_time": -1}, "frame_methods.NSort.time_nlargest_two_columns": {"code": "class NSort:\n    def time_nlargest_two_columns(self, keep):\n        self.df.nlargest(100, [\"A\", \"B\"], keep=keep)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass NSort:\n    def setup(self, keep):\n        self.df = DataFrame(np.random.randn(100000, 3), columns=list(\"ABC\"))", "min_run_count": 2, "name": "frame_methods.NSort.time_nlargest_two_columns", "number": 0, "param_names": ["keep"], "params": [["'first'", "'last'", "'all'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "fb06c1f8251bd2a6af6ab02b7dbf651402818b3898c88c5f634d4999eb180730", "warmup_time": -1}, "frame_methods.NSort.time_nsmallest_one_column": {"code": "class NSort:\n    def time_nsmallest_one_column(self, keep):\n        self.df.nsmallest(100, \"A\", keep=keep)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass NSort:\n    def setup(self, keep):\n        self.df = DataFrame(np.random.randn(100000, 3), columns=list(\"ABC\"))", "min_run_count": 2, "name": "frame_methods.NSort.time_nsmallest_one_column", "number": 0, "param_names": ["keep"], "params": [["'first'", "'last'", "'all'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "602770ac5530f5b88477e395308b8146dcf5adb79187c8d34b0201ba44680a2e", "warmup_time": -1}, "frame_methods.NSort.time_nsmallest_two_columns": {"code": "class NSort:\n    def time_nsmallest_two_columns(self, keep):\n        self.df.nsmallest(100, [\"A\", \"B\"], keep=keep)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass NSort:\n    def setup(self, keep):\n        self.df = DataFrame(np.random.randn(100000, 3), columns=list(\"ABC\"))", "min_run_count": 2, "name": "frame_methods.NSort.time_nsmallest_two_columns", "number": 0, "param_names": ["keep"], "params": [["'first'", "'last'", "'all'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "27757c983389573bb278541de8a55e9ac92f47fc4c94a64054207953192b17d7", "warmup_time": -1}, "frame_methods.Nunique.time_frame_nunique": {"code": "class Nunique:\n    def time_frame_nunique(self):\n        self.df.nunique()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Nunique:\n    def setup(self):\n        self.df = DataFrame(np.random.randn(10000, 1000))", "min_run_count": 2, "name": "frame_methods.Nunique.time_frame_nunique", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "7b4f1bb3132faa41cd11750a8882705594d2e2437af6d28e1c6648950e7d0c46", "warmup_time": -1}, "frame_methods.Quantile.time_frame_quantile": {"code": "class Quantile:\n    def time_frame_quantile(self, axis):\n        self.df.quantile([0.1, 0.5], axis=axis)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Quantile:\n    def setup(self, axis):\n        self.df = DataFrame(np.random.randn(1000, 3), columns=list(\"ABC\"))", "min_run_count": 2, "name": "frame_methods.Quantile.time_frame_quantile", "number": 0, "param_names": ["axis"], "params": [["0", "1"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "e46972758e099994281698947a2e05eda1f226d307e25f58fb72796cedd8908f", "warmup_time": -1}, "frame_methods.Rank.time_rank": {"code": "class Rank:\n    def time_rank(self, dtype):\n        self.df.rank()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Rank:\n    def setup(self, dtype):\n        self.df = DataFrame(\n            np.random.randn(10000, 10).astype(dtype), columns=range(10), dtype=dtype\n        )", "min_run_count": 2, "name": "frame_methods.Rank.time_rank", "number": 0, "param_names": ["dtype"], "params": [["'int'", "'uint'", "'float'", "'object'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "4512f531d4398c0997ffb9c0b076476cab3bef280e5662032d20d3b76f2e26cb", "warmup_time": -1}, "frame_methods.Reindex.time_reindex_axis0": {"code": "class Reindex:\n    def time_reindex_axis0(self):\n        self.df.reindex(self.idx)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Reindex:\n    def setup(self):\n        N = 10**3\n        self.df = DataFrame(np.random.randn(N * 10, N))\n        self.idx = np.arange(4 * N, 7 * N)\n        self.idx_cols = np.random.randint(0, N, N)\n        self.df2 = DataFrame(\n            {\n                c: {\n                    0: np.random.randint(0, 2, N).astype(np.bool_),\n                    1: np.random.randint(0, N, N).astype(np.int16),\n                    2: np.random.randint(0, N, N).astype(np.int32),\n                    3: np.random.randint(0, N, N).astype(np.int64),\n                }[np.random.randint(0, 4)]\n                for c in range(N)\n            }\n        )", "min_run_count": 2, "name": "frame_methods.Reindex.time_reindex_axis0", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "8e312cd3e03e3d1f3c1440ed72a1f0a6056d79a9045d8f1ee844b2188f613054", "warmup_time": -1}, "frame_methods.Reindex.time_reindex_axis1": {"code": "class Reindex:\n    def time_reindex_axis1(self):\n        self.df.reindex(columns=self.idx_cols)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Reindex:\n    def setup(self):\n        N = 10**3\n        self.df = DataFrame(np.random.randn(N * 10, N))\n        self.idx = np.arange(4 * N, 7 * N)\n        self.idx_cols = np.random.randint(0, N, N)\n        self.df2 = DataFrame(\n            {\n                c: {\n                    0: np.random.randint(0, 2, N).astype(np.bool_),\n                    1: np.random.randint(0, N, N).astype(np.int16),\n                    2: np.random.randint(0, N, N).astype(np.int32),\n                    3: np.random.randint(0, N, N).astype(np.int64),\n                }[np.random.randint(0, 4)]\n                for c in range(N)\n            }\n        )", "min_run_count": 2, "name": "frame_methods.Reindex.time_reindex_axis1", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "4a93950c7bd7528bd910907cda4f0ff4d5194febad4f498b87cc400feff0d1a6", "warmup_time": -1}, "frame_methods.Reindex.time_reindex_axis1_missing": {"code": "class Reindex:\n    def time_reindex_axis1_missing(self):\n        self.df.reindex(columns=self.idx)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Reindex:\n    def setup(self):\n        N = 10**3\n        self.df = DataFrame(np.random.randn(N * 10, N))\n        self.idx = np.arange(4 * N, 7 * N)\n        self.idx_cols = np.random.randint(0, N, N)\n        self.df2 = DataFrame(\n            {\n                c: {\n                    0: np.random.randint(0, 2, N).astype(np.bool_),\n                    1: np.random.randint(0, N, N).astype(np.int16),\n                    2: np.random.randint(0, N, N).astype(np.int32),\n                    3: np.random.randint(0, N, N).astype(np.int64),\n                }[np.random.randint(0, 4)]\n                for c in range(N)\n            }\n        )", "min_run_count": 2, "name": "frame_methods.Reindex.time_reindex_axis1_missing", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "7749b0b3b38ff50cbd6509455c235277f2f3cc7ea7bb8642397cfe79fcd2025d", "warmup_time": -1}, "frame_methods.Reindex.time_reindex_both_axes": {"code": "class Reindex:\n    def time_reindex_both_axes(self):\n        self.df.reindex(index=self.idx, columns=self.idx_cols)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Reindex:\n    def setup(self):\n        N = 10**3\n        self.df = DataFrame(np.random.randn(N * 10, N))\n        self.idx = np.arange(4 * N, 7 * N)\n        self.idx_cols = np.random.randint(0, N, N)\n        self.df2 = DataFrame(\n            {\n                c: {\n                    0: np.random.randint(0, 2, N).astype(np.bool_),\n                    1: np.random.randint(0, N, N).astype(np.int16),\n                    2: np.random.randint(0, N, N).astype(np.int32),\n                    3: np.random.randint(0, N, N).astype(np.int64),\n                }[np.random.randint(0, 4)]\n                for c in range(N)\n            }\n        )", "min_run_count": 2, "name": "frame_methods.Reindex.time_reindex_both_axes", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "06ce9de462c065fcb31edc17bbaa87b044287b757a29abc717d85764e418e727", "warmup_time": -1}, "frame_methods.Reindex.time_reindex_upcast": {"code": "class Reindex:\n    def time_reindex_upcast(self):\n        self.df2.reindex(np.random.permutation(range(1200)))\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Reindex:\n    def setup(self):\n        N = 10**3\n        self.df = DataFrame(np.random.randn(N * 10, N))\n        self.idx = np.arange(4 * N, 7 * N)\n        self.idx_cols = np.random.randint(0, N, N)\n        self.df2 = DataFrame(\n            {\n                c: {\n                    0: np.random.randint(0, 2, N).astype(np.bool_),\n                    1: np.random.randint(0, N, N).astype(np.int16),\n                    2: np.random.randint(0, N, N).astype(np.int32),\n                    3: np.random.randint(0, N, N).astype(np.int64),\n                }[np.random.randint(0, 4)]\n                for c in range(N)\n            }\n        )", "min_run_count": 2, "name": "frame_methods.Reindex.time_reindex_upcast", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "8d05018638e09bdfc144121f846b4c2bef1cf019e84b76006bbdef08e268a466", "warmup_time": -1}, "frame_methods.Rename.time_dict_rename_both_axes": {"code": "class Rename:\n    def time_dict_rename_both_axes(self):\n        self.df.rename(index=self.dict_idx, columns=self.dict_idx)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Rename:\n    def setup(self):\n        N = 10**3\n        self.df = DataFrame(np.random.randn(N * 10, N))\n        self.idx = np.arange(4 * N, 7 * N)\n        self.dict_idx = {k: k for k in self.idx}\n        self.df2 = DataFrame(\n            {\n                c: {\n                    0: np.random.randint(0, 2, N).astype(np.bool_),\n                    1: np.random.randint(0, N, N).astype(np.int16),\n                    2: np.random.randint(0, N, N).astype(np.int32),\n                    3: np.random.randint(0, N, N).astype(np.int64),\n                }[np.random.randint(0, 4)]\n                for c in range(N)\n            }\n        )", "min_run_count": 2, "name": "frame_methods.Rename.time_dict_rename_both_axes", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "060b0d33988e4009693f1109e6274a165c7e1b54c2ce817d60a436c7b6f46325", "warmup_time": -1}, "frame_methods.Rename.time_rename_axis0": {"code": "class Rename:\n    def time_rename_axis0(self):\n        self.df.rename(self.dict_idx)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Rename:\n    def setup(self):\n        N = 10**3\n        self.df = DataFrame(np.random.randn(N * 10, N))\n        self.idx = np.arange(4 * N, 7 * N)\n        self.dict_idx = {k: k for k in self.idx}\n        self.df2 = DataFrame(\n            {\n                c: {\n                    0: np.random.randint(0, 2, N).astype(np.bool_),\n                    1: np.random.randint(0, N, N).astype(np.int16),\n                    2: np.random.randint(0, N, N).astype(np.int32),\n                    3: np.random.randint(0, N, N).astype(np.int64),\n                }[np.random.randint(0, 4)]\n                for c in range(N)\n            }\n        )", "min_run_count": 2, "name": "frame_methods.Rename.time_rename_axis0", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "7442ed7fc2e73ac7a280c1909b8a01ab6e5269f51652c483a3af6288beea66ea", "warmup_time": -1}, "frame_methods.Rename.time_rename_axis1": {"code": "class Rename:\n    def time_rename_axis1(self):\n        self.df.rename(columns=self.dict_idx)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Rename:\n    def setup(self):\n        N = 10**3\n        self.df = DataFrame(np.random.randn(N * 10, N))\n        self.idx = np.arange(4 * N, 7 * N)\n        self.dict_idx = {k: k for k in self.idx}\n        self.df2 = DataFrame(\n            {\n                c: {\n                    0: np.random.randint(0, 2, N).astype(np.bool_),\n                    1: np.random.randint(0, N, N).astype(np.int16),\n                    2: np.random.randint(0, N, N).astype(np.int32),\n                    3: np.random.randint(0, N, N).astype(np.int64),\n                }[np.random.randint(0, 4)]\n                for c in range(N)\n            }\n        )", "min_run_count": 2, "name": "frame_methods.Rename.time_rename_axis1", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "95e21d6ec76ff34607840fa82609ec8b610013d6bd877d0092453f968a5384f6", "warmup_time": -1}, "frame_methods.Rename.time_rename_both_axes": {"code": "class Rename:\n    def time_rename_both_axes(self):\n        self.df.rename(index=self.dict_idx, columns=self.dict_idx)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Rename:\n    def setup(self):\n        N = 10**3\n        self.df = DataFrame(np.random.randn(N * 10, N))\n        self.idx = np.arange(4 * N, 7 * N)\n        self.dict_idx = {k: k for k in self.idx}\n        self.df2 = DataFrame(\n            {\n                c: {\n                    0: np.random.randint(0, 2, N).astype(np.bool_),\n                    1: np.random.randint(0, N, N).astype(np.int16),\n                    2: np.random.randint(0, N, N).astype(np.int32),\n                    3: np.random.randint(0, N, N).astype(np.int64),\n                }[np.random.randint(0, 4)]\n                for c in range(N)\n            }\n        )", "min_run_count": 2, "name": "frame_methods.Rename.time_rename_both_axes", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "57060b21c7592bb4bd46070429134f61a772694a95ed1014c9c65df5e0f43873", "warmup_time": -1}, "frame_methods.Rename.time_rename_single": {"code": "class Rename:\n    def time_rename_single(self):\n        self.df.rename({0: 0})\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Rename:\n    def setup(self):\n        N = 10**3\n        self.df = DataFrame(np.random.randn(N * 10, N))\n        self.idx = np.arange(4 * N, 7 * N)\n        self.dict_idx = {k: k for k in self.idx}\n        self.df2 = DataFrame(\n            {\n                c: {\n                    0: np.random.randint(0, 2, N).astype(np.bool_),\n                    1: np.random.randint(0, N, N).astype(np.int16),\n                    2: np.random.randint(0, N, N).astype(np.int32),\n                    3: np.random.randint(0, N, N).astype(np.int64),\n                }[np.random.randint(0, 4)]\n                for c in range(N)\n            }\n        )", "min_run_count": 2, "name": "frame_methods.Rename.time_rename_single", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "ddc80d464ece8f0b4fabad5fcb4cbb0729ffdb09e225469ff23f5e49ed1ac8c4", "warmup_time": -1}, "frame_methods.Repr.time_frame_repr_wide": {"code": "class Repr:\n    def time_frame_repr_wide(self):\n        repr(self.df_wide)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Repr:\n    def setup(self):\n        nrows = 10000\n        data = np.random.randn(nrows, 10)\n        arrays = np.tile(np.random.randn(3, nrows // 100), 100)\n        idx = MultiIndex.from_arrays(arrays)\n        self.df3 = DataFrame(data, index=idx)\n        self.df4 = DataFrame(data, index=np.random.randn(nrows))\n        self.df_tall = DataFrame(np.random.randn(nrows, 10))\n        self.df_wide = DataFrame(np.random.randn(10, nrows))", "min_run_count": 2, "name": "frame_methods.Repr.time_frame_repr_wide", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "b7c902cd0a2f02eebcb938f83eb0bc567c8bf80146ce7c09a335b559e8715a33", "warmup_time": -1}, "frame_methods.Repr.time_html_repr_trunc_mi": {"code": "class Repr:\n    def time_html_repr_trunc_mi(self):\n        self.df3._repr_html_()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Repr:\n    def setup(self):\n        nrows = 10000\n        data = np.random.randn(nrows, 10)\n        arrays = np.tile(np.random.randn(3, nrows // 100), 100)\n        idx = MultiIndex.from_arrays(arrays)\n        self.df3 = DataFrame(data, index=idx)\n        self.df4 = DataFrame(data, index=np.random.randn(nrows))\n        self.df_tall = DataFrame(np.random.randn(nrows, 10))\n        self.df_wide = DataFrame(np.random.randn(10, nrows))", "min_run_count": 2, "name": "frame_methods.Repr.time_html_repr_trunc_mi", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "c5988920e0b3d00d1ec74379b4576a53ad6b17e4c9b71625316958d163ed4164", "warmup_time": -1}, "frame_methods.Repr.time_html_repr_trunc_si": {"code": "class Repr:\n    def time_html_repr_trunc_si(self):\n        self.df4._repr_html_()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Repr:\n    def setup(self):\n        nrows = 10000\n        data = np.random.randn(nrows, 10)\n        arrays = np.tile(np.random.randn(3, nrows // 100), 100)\n        idx = MultiIndex.from_arrays(arrays)\n        self.df3 = DataFrame(data, index=idx)\n        self.df4 = DataFrame(data, index=np.random.randn(nrows))\n        self.df_tall = DataFrame(np.random.randn(nrows, 10))\n        self.df_wide = DataFrame(np.random.randn(10, nrows))", "min_run_count": 2, "name": "frame_methods.Repr.time_html_repr_trunc_si", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "8fd8968223faa897090a27941e475b84b23f11c40bb5c7541e6f71c9fb9376a3", "warmup_time": -1}, "frame_methods.Repr.time_repr_tall": {"code": "class Repr:\n    def time_repr_tall(self):\n        repr(self.df_tall)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Repr:\n    def setup(self):\n        nrows = 10000\n        data = np.random.randn(nrows, 10)\n        arrays = np.tile(np.random.randn(3, nrows // 100), 100)\n        idx = MultiIndex.from_arrays(arrays)\n        self.df3 = DataFrame(data, index=idx)\n        self.df4 = DataFrame(data, index=np.random.randn(nrows))\n        self.df_tall = DataFrame(np.random.randn(nrows, 10))\n        self.df_wide = DataFrame(np.random.randn(10, nrows))", "min_run_count": 2, "name": "frame_methods.Repr.time_repr_tall", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "57c3fcd319895e084cdc6f5e24084880d4817e72dd3fe35856b00b69e7ea1742", "warmup_time": -1}, "frame_methods.Round.peakmem_round": {"code": "class Round:\n    def peakmem_round(self):\n        self.df.round()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Round:\n    def setup(self):\n        self.df = DataFrame(np.random.randn(10000, 10))\n        self.df_t = self.df.transpose(copy=True)", "name": "frame_methods.Round.peakmem_round", "param_names": [], "params": [], "timeout": 60.0, "type": "peakmemory", "unit": "bytes", "version": "6030b93289557c8c988898eb2865291b8bbb65999e8761c6dedd7d32eeae984c"}, "frame_methods.Round.peakmem_round_transposed": {"code": "class Round:\n    def peakmem_round_transposed(self):\n        self.df_t.round()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Round:\n    def setup(self):\n        self.df = DataFrame(np.random.randn(10000, 10))\n        self.df_t = self.df.transpose(copy=True)", "name": "frame_methods.Round.peakmem_round_transposed", "param_names": [], "params": [], "timeout": 60.0, "type": "peakmemory", "unit": "bytes", "version": "919cd08ae6984fe9193852f5e8b5432e1bc12537c5e39da7333f549a5e72ab37"}, "frame_methods.Round.time_round": {"code": "class Round:\n    def time_round(self):\n        self.df.round()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Round:\n    def setup(self):\n        self.df = DataFrame(np.random.randn(10000, 10))\n        self.df_t = self.df.transpose(copy=True)", "min_run_count": 2, "name": "frame_methods.Round.time_round", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "96ca48bf009b1f5637ae83a659df490757d37c26fee67d6a45104d6e0bf32219", "warmup_time": -1}, "frame_methods.Round.time_round_transposed": {"code": "class Round:\n    def time_round_transposed(self):\n        self.df_t.round()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Round:\n    def setup(self):\n        self.df = DataFrame(np.random.randn(10000, 10))\n        self.df_t = self.df.transpose(copy=True)", "min_run_count": 2, "name": "frame_methods.Round.time_round_transposed", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "19596a27ad277a08b79ca33e2b9773ebc43379e2443ff070f4b60f930bcef9d8", "warmup_time": -1}, "frame_methods.SeriesNuniqueWithNan.time_series_nunique_nan": {"code": "class SeriesNuniqueWithNan:\n    def time_series_nunique_nan(self):\n        self.ser.nunique()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass SeriesNuniqueWithNan:\n    def setup(self):\n        self.ser = Series(100000 * (100 * [np.nan] + list(range(100)))).astype(float)", "min_run_count": 2, "name": "frame_methods.SeriesNuniqueWithNan.time_series_nunique_nan", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "c540925505268ef2727fb50f58699d43a4df65305e01e31b05291f8568d4e742", "warmup_time": -1}, "frame_methods.Shift.time_shift": {"code": "class Shift:\n    def time_shift(self, axis):\n        self.df.shift(1, axis=axis)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Shift:\n    def setup(self, axis):\n        self.df = DataFrame(np.random.rand(10000, 500))", "min_run_count": 2, "name": "frame_methods.Shift.time_shift", "number": 0, "param_names": ["axis"], "params": [["0", "1"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "09d28e1e7b36fe4dfa6ed22317da40bcde0164c120b61d4efff8f61b02c768af", "warmup_time": -1}, "frame_methods.SortIndexByColumns.time_frame_sort_values_by_columns": {"code": "class SortIndexByColumns:\n    def time_frame_sort_values_by_columns(self):\n        self.df.sort_values(by=[\"key1\", \"key2\"])\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass SortIndexByColumns:\n    def setup(self):\n        N = 10000\n        K = 10\n        self.df = DataFrame(\n            {\n                \"key1\": tm.makeStringIndex(N).values.repeat(K),\n                \"key2\": tm.makeStringIndex(N).values.repeat(K),\n                \"value\": np.random.randn(N * K),\n            }\n        )", "min_run_count": 2, "name": "frame_methods.SortIndexByColumns.time_frame_sort_values_by_columns", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "318bad8e24c87625270a0510253512ec3ad9ae054ffad580e2d5bba6ce1ca19d", "warmup_time": -1}, "frame_methods.SortValues.time_frame_sort_values": {"code": "class SortValues:\n    def time_frame_sort_values(self, ascending):\n        self.df.sort_values(by=\"A\", ascending=ascending)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass SortValues:\n    def setup(self, ascending):\n        self.df = DataFrame(np.random.randn(1000000, 2), columns=list(\"AB\"))", "min_run_count": 2, "name": "frame_methods.SortValues.time_frame_sort_values", "number": 0, "param_names": ["ascending"], "params": [["True", "False"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "bf9c8ff877f2cd95431692cfe963e37b3de4634176be673d3de0b663177d7ad3", "warmup_time": -1}, "frame_methods.ToDict.time_to_dict_datetimelike": {"code": "class ToDict:\n    def time_to_dict_datetimelike(self, orient):\n        self.datetimelike_df.to_dict(orient=orient)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToDict:\n    def setup(self, orient):\n        data = np.random.randint(0, 1000, size=(10000, 4))\n        self.int_df = DataFrame(data)\n        self.datetimelike_df = self.int_df.astype(\"timedelta64[ns]\")", "min_run_count": 2, "name": "frame_methods.ToDict.time_to_dict_datetimelike", "number": 0, "param_names": ["orient"], "params": [["'dict'", "'list'", "'series'", "'split'", "'records'", "'index'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "939f612766529ae46a0b196a3dc13061331265310113f5a5c18d503fd623eb63", "warmup_time": -1}, "frame_methods.ToDict.time_to_dict_ints": {"code": "class ToDict:\n    def time_to_dict_ints(self, orient):\n        self.int_df.to_dict(orient=orient)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToDict:\n    def setup(self, orient):\n        data = np.random.randint(0, 1000, size=(10000, 4))\n        self.int_df = DataFrame(data)\n        self.datetimelike_df = self.int_df.astype(\"timedelta64[ns]\")", "min_run_count": 2, "name": "frame_methods.ToDict.time_to_dict_ints", "number": 0, "param_names": ["orient"], "params": [["'dict'", "'list'", "'series'", "'split'", "'records'", "'index'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "8ca05db38583b86c56e9781a0ba1f399533c5e196accee6737c23ade9750f5c9", "warmup_time": -1}, "frame_methods.ToHTML.time_to_html_mixed": {"code": "class ToHTML:\n    def time_to_html_mixed(self):\n        self.df2.to_html()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToHTML:\n    def setup(self):\n        nrows = 500\n        self.df2 = DataFrame(np.random.randn(nrows, 10))\n        self.df2[0] = period_range(\"2000\", periods=nrows)\n        self.df2[1] = range(nrows)", "min_run_count": 2, "name": "frame_methods.ToHTML.time_to_html_mixed", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "a63bfb2f9452ef12121452e5a13a47f1ddf16d3a2ecc961f1d143598ae48a31a", "warmup_time": -1}, "frame_methods.ToNumpy.time_to_numpy_mixed_tall": {"code": "class ToNumpy:\n    def time_to_numpy_mixed_tall(self):\n        self.df_mixed_tall.to_numpy()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToNumpy:\n    def setup(self):\n        N = 10000\n        M = 10\n        self.df_tall = DataFrame(np.random.randn(N, M))\n        self.df_wide = DataFrame(np.random.randn(M, N))\n        self.df_mixed_tall = self.df_tall.copy()\n        self.df_mixed_tall[\"foo\"] = \"bar\"\n        self.df_mixed_tall[0] = period_range(\"2000\", periods=N)\n        self.df_mixed_tall[1] = range(N)\n        self.df_mixed_wide = self.df_wide.copy()\n        self.df_mixed_wide[\"foo\"] = \"bar\"\n        self.df_mixed_wide[0] = period_range(\"2000\", periods=M)\n        self.df_mixed_wide[1] = range(M)", "min_run_count": 2, "name": "frame_methods.ToNumpy.time_to_numpy_mixed_tall", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "5609d5ea9c8d63719954d185af31995af502969500f52a283b95dee96b206b21", "warmup_time": -1}, "frame_methods.ToNumpy.time_to_numpy_mixed_wide": {"code": "class ToNumpy:\n    def time_to_numpy_mixed_wide(self):\n        self.df_mixed_wide.to_numpy()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToNumpy:\n    def setup(self):\n        N = 10000\n        M = 10\n        self.df_tall = DataFrame(np.random.randn(N, M))\n        self.df_wide = DataFrame(np.random.randn(M, N))\n        self.df_mixed_tall = self.df_tall.copy()\n        self.df_mixed_tall[\"foo\"] = \"bar\"\n        self.df_mixed_tall[0] = period_range(\"2000\", periods=N)\n        self.df_mixed_tall[1] = range(N)\n        self.df_mixed_wide = self.df_wide.copy()\n        self.df_mixed_wide[\"foo\"] = \"bar\"\n        self.df_mixed_wide[0] = period_range(\"2000\", periods=M)\n        self.df_mixed_wide[1] = range(M)", "min_run_count": 2, "name": "frame_methods.ToNumpy.time_to_numpy_mixed_wide", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "b8cf4cdbf480bfa101b1e9bbf6df8e6a9516540d5888f9acf40c29f0b39c4178", "warmup_time": -1}, "frame_methods.ToNumpy.time_to_numpy_tall": {"code": "class ToNumpy:\n    def time_to_numpy_tall(self):\n        self.df_tall.to_numpy()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToNumpy:\n    def setup(self):\n        N = 10000\n        M = 10\n        self.df_tall = DataFrame(np.random.randn(N, M))\n        self.df_wide = DataFrame(np.random.randn(M, N))\n        self.df_mixed_tall = self.df_tall.copy()\n        self.df_mixed_tall[\"foo\"] = \"bar\"\n        self.df_mixed_tall[0] = period_range(\"2000\", periods=N)\n        self.df_mixed_tall[1] = range(N)\n        self.df_mixed_wide = self.df_wide.copy()\n        self.df_mixed_wide[\"foo\"] = \"bar\"\n        self.df_mixed_wide[0] = period_range(\"2000\", periods=M)\n        self.df_mixed_wide[1] = range(M)", "min_run_count": 2, "name": "frame_methods.ToNumpy.time_to_numpy_tall", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "5569b6deed04489b4f459b07dc638df2d11771fc68bd230503521874fd8280e9", "warmup_time": -1}, "frame_methods.ToNumpy.time_to_numpy_wide": {"code": "class ToNumpy:\n    def time_to_numpy_wide(self):\n        self.df_wide.to_numpy()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToNumpy:\n    def setup(self):\n        N = 10000\n        M = 10\n        self.df_tall = DataFrame(np.random.randn(N, M))\n        self.df_wide = DataFrame(np.random.randn(M, N))\n        self.df_mixed_tall = self.df_tall.copy()\n        self.df_mixed_tall[\"foo\"] = \"bar\"\n        self.df_mixed_tall[0] = period_range(\"2000\", periods=N)\n        self.df_mixed_tall[1] = range(N)\n        self.df_mixed_wide = self.df_wide.copy()\n        self.df_mixed_wide[\"foo\"] = \"bar\"\n        self.df_mixed_wide[0] = period_range(\"2000\", periods=M)\n        self.df_mixed_wide[1] = range(M)", "min_run_count": 2, "name": "frame_methods.ToNumpy.time_to_numpy_wide", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "bf654b3ba6daa0281ee0f2802eb3d2aeda580273f37f51975c0a6949c7f80d88", "warmup_time": -1}, "frame_methods.ToNumpy.time_values_mixed_tall": {"code": "class ToNumpy:\n    def time_values_mixed_tall(self):\n        self.df_mixed_tall.values\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToNumpy:\n    def setup(self):\n        N = 10000\n        M = 10\n        self.df_tall = DataFrame(np.random.randn(N, M))\n        self.df_wide = DataFrame(np.random.randn(M, N))\n        self.df_mixed_tall = self.df_tall.copy()\n        self.df_mixed_tall[\"foo\"] = \"bar\"\n        self.df_mixed_tall[0] = period_range(\"2000\", periods=N)\n        self.df_mixed_tall[1] = range(N)\n        self.df_mixed_wide = self.df_wide.copy()\n        self.df_mixed_wide[\"foo\"] = \"bar\"\n        self.df_mixed_wide[0] = period_range(\"2000\", periods=M)\n        self.df_mixed_wide[1] = range(M)", "min_run_count": 2, "name": "frame_methods.ToNumpy.time_values_mixed_tall", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "63f9938602ca8bd629ccf01754db81ac30be79e67c04b0f0773bc5b0d042f33d", "warmup_time": -1}, "frame_methods.ToNumpy.time_values_mixed_wide": {"code": "class ToNumpy:\n    def time_values_mixed_wide(self):\n        self.df_mixed_wide.values\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToNumpy:\n    def setup(self):\n        N = 10000\n        M = 10\n        self.df_tall = DataFrame(np.random.randn(N, M))\n        self.df_wide = DataFrame(np.random.randn(M, N))\n        self.df_mixed_tall = self.df_tall.copy()\n        self.df_mixed_tall[\"foo\"] = \"bar\"\n        self.df_mixed_tall[0] = period_range(\"2000\", periods=N)\n        self.df_mixed_tall[1] = range(N)\n        self.df_mixed_wide = self.df_wide.copy()\n        self.df_mixed_wide[\"foo\"] = \"bar\"\n        self.df_mixed_wide[0] = period_range(\"2000\", periods=M)\n        self.df_mixed_wide[1] = range(M)", "min_run_count": 2, "name": "frame_methods.ToNumpy.time_values_mixed_wide", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "fafed5c463a9d832b1c45ce00e7755cf10235ae288cb4939713e9e25b2884d1e", "warmup_time": -1}, "frame_methods.ToNumpy.time_values_tall": {"code": "class ToNumpy:\n    def time_values_tall(self):\n        self.df_tall.values\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToNumpy:\n    def setup(self):\n        N = 10000\n        M = 10\n        self.df_tall = DataFrame(np.random.randn(N, M))\n        self.df_wide = DataFrame(np.random.randn(M, N))\n        self.df_mixed_tall = self.df_tall.copy()\n        self.df_mixed_tall[\"foo\"] = \"bar\"\n        self.df_mixed_tall[0] = period_range(\"2000\", periods=N)\n        self.df_mixed_tall[1] = range(N)\n        self.df_mixed_wide = self.df_wide.copy()\n        self.df_mixed_wide[\"foo\"] = \"bar\"\n        self.df_mixed_wide[0] = period_range(\"2000\", periods=M)\n        self.df_mixed_wide[1] = range(M)", "min_run_count": 2, "name": "frame_methods.ToNumpy.time_values_tall", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "d7415d8faba6d4a8ac5b59b9db979d88981de08547167f51ec5c31b322149dfb", "warmup_time": -1}, "frame_methods.ToNumpy.time_values_wide": {"code": "class ToNumpy:\n    def time_values_wide(self):\n        self.df_wide.values\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToNumpy:\n    def setup(self):\n        N = 10000\n        M = 10\n        self.df_tall = DataFrame(np.random.randn(N, M))\n        self.df_wide = DataFrame(np.random.randn(M, N))\n        self.df_mixed_tall = self.df_tall.copy()\n        self.df_mixed_tall[\"foo\"] = \"bar\"\n        self.df_mixed_tall[0] = period_range(\"2000\", periods=N)\n        self.df_mixed_tall[1] = range(N)\n        self.df_mixed_wide = self.df_wide.copy()\n        self.df_mixed_wide[\"foo\"] = \"bar\"\n        self.df_mixed_wide[0] = period_range(\"2000\", periods=M)\n        self.df_mixed_wide[1] = range(M)", "min_run_count": 2, "name": "frame_methods.ToNumpy.time_values_wide", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "5f1b62f28c9211bb22340a6af83d5b86811950ef975bfd00e0684048cb2de22f", "warmup_time": -1}, "frame_methods.ToRecords.time_to_records": {"code": "class ToRecords:\n    def time_to_records(self):\n        self.df.to_records(index=True)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToRecords:\n    def setup(self):\n        N = 100_000\n        data = np.random.randn(N, 2)\n        mi = MultiIndex.from_arrays(\n            [\n                np.arange(N),\n                date_range(\"1970-01-01\", periods=N, freq=\"ms\"),\n            ]\n        )\n        self.df = DataFrame(data)\n        self.df_mi = DataFrame(data, index=mi)", "min_run_count": 2, "name": "frame_methods.ToRecords.time_to_records", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "f42f25126b3a450ab55465c858ae504d2ded8b644488689fa856b421d41c0cba", "warmup_time": -1}, "frame_methods.ToRecords.time_to_records_multiindex": {"code": "class ToRecords:\n    def time_to_records_multiindex(self):\n        self.df_mi.to_records(index=True)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToRecords:\n    def setup(self):\n        N = 100_000\n        data = np.random.randn(N, 2)\n        mi = MultiIndex.from_arrays(\n            [\n                np.arange(N),\n                date_range(\"1970-01-01\", periods=N, freq=\"ms\"),\n            ]\n        )\n        self.df = DataFrame(data)\n        self.df_mi = DataFrame(data, index=mi)", "min_run_count": 2, "name": "frame_methods.ToRecords.time_to_records_multiindex", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "ba7c2132dec45f9679103e1739697a3c005f6921b9c766546d8535303d90777d", "warmup_time": -1}, "frame_methods.ToString.time_to_string_floats": {"code": "class ToString:\n    def time_to_string_floats(self):\n        self.df.to_string()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToString:\n    def setup(self):\n        self.df = DataFrame(np.random.randn(100, 10))", "min_run_count": 2, "name": "frame_methods.ToString.time_to_string_floats", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "e56ad6695cac3b92e88feb11d8c47fa92f10fb86e51634e87529d771f168cdbf", "warmup_time": -1}, "frame_methods.Where.time_where": {"code": "class Where:\n    def time_where(self, inplace, dtype):\n        self.df.where(self.mask, other=0.0, inplace=inplace)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Where:\n    def setup(self, inplace, dtype):\n        self.df = DataFrame(np.random.randn(100_000, 10), dtype=dtype)\n        self.mask = self.df < 0", "min_run_count": 2, "name": "frame_methods.Where.time_where", "number": 0, "param_names": ["dtype", "param2"], "params": [["True", "False"], ["'float64'", "'Float64'", "'float64[pyarrow]'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "d16b5044f854c91f698425fe60c4f71b7f819334706ddf4e2e6bb35a27c1a928", "warmup_time": -1}, "frame_methods.XS.time_frame_xs": {"code": "class XS:\n    def time_frame_xs(self, axis):\n        self.df.xs(self.N / 2, axis=axis)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass XS:\n    def setup(self, axis):\n        self.N = 10**4\n        self.df = DataFrame(np.random.randn(self.N, self.N))", "min_run_count": 2, "name": "frame_methods.XS.time_frame_xs", "number": 0, "param_names": ["axis"], "params": [["0", "1"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "4c10ba567aab8044d880b7e51f27220a7353cda967ee331f4bf88ebbc2406d4f", "warmup_time": -1}, "gil.ParallelDatetimeFields.time_datetime_field_day": {"code": "class ParallelDatetimeFields:\n    def time_datetime_field_day(self):\n        @test_parallel(num_threads=2)\n        def run(dti):\n            dti.day\n    \n        run(self.dti)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ParallelDatetimeFields:\n    def setup(self):\n        N = 10**6\n        self.dti = date_range(\"1900-01-01\", periods=N, freq=\"T\")\n        self.period = self.dti.to_period(\"D\")", "min_run_count": 2, "name": "gil.ParallelDatetimeFields.time_datetime_field_day", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "fc9a18c7e7662ce77c5e3ef46c68d71eea53f4bbc47beb1e08750e8af07fa519", "warmup_time": -1}, "gil.ParallelDatetimeFields.time_datetime_field_daysinmonth": {"code": "class ParallelDatetimeFields:\n    def time_datetime_field_daysinmonth(self):\n        @test_parallel(num_threads=2)\n        def run(dti):\n            dti.days_in_month\n    \n        run(self.dti)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ParallelDatetimeFields:\n    def setup(self):\n        N = 10**6\n        self.dti = date_range(\"1900-01-01\", periods=N, freq=\"T\")\n        self.period = self.dti.to_period(\"D\")", "min_run_count": 2, "name": "gil.ParallelDatetimeFields.time_datetime_field_daysinmonth", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "848cf67bf659403601778e1e5cd328527684283b6700751d69dab3d37c7dfb16", "warmup_time": -1}, "gil.ParallelDatetimeFields.time_datetime_field_normalize": {"code": "class ParallelDatetimeFields:\n    def time_datetime_field_normalize(self):\n        @test_parallel(num_threads=2)\n        def run(dti):\n            dti.normalize()\n    \n        run(self.dti)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ParallelDatetimeFields:\n    def setup(self):\n        N = 10**6\n        self.dti = date_range(\"1900-01-01\", periods=N, freq=\"T\")\n        self.period = self.dti.to_period(\"D\")", "min_run_count": 2, "name": "gil.ParallelDatetimeFields.time_datetime_field_normalize", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "334a3e8b853e35d1226aa6a69fb5c7a4874c30d3974d49c5acea90eae06d768a", "warmup_time": -1}, "gil.ParallelDatetimeFields.time_datetime_field_year": {"code": "class ParallelDatetimeFields:\n    def time_datetime_field_year(self):\n        @test_parallel(num_threads=2)\n        def run(dti):\n            dti.year\n    \n        run(self.dti)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ParallelDatetimeFields:\n    def setup(self):\n        N = 10**6\n        self.dti = date_range(\"1900-01-01\", periods=N, freq=\"T\")\n        self.period = self.dti.to_period(\"D\")", "min_run_count": 2, "name": "gil.ParallelDatetimeFields.time_datetime_field_year", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "ad662b91e3bb4a1ea604eb518b9de9d465d63878ea06843ef7039e702e60b39f", "warmup_time": -1}, "gil.ParallelDatetimeFields.time_datetime_to_period": {"code": "class ParallelDatetimeFields:\n    def time_datetime_to_period(self):\n        @test_parallel(num_threads=2)\n        def run(dti):\n            dti.to_period(\"S\")\n    \n        run(self.dti)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ParallelDatetimeFields:\n    def setup(self):\n        N = 10**6\n        self.dti = date_range(\"1900-01-01\", periods=N, freq=\"T\")\n        self.period = self.dti.to_period(\"D\")", "min_run_count": 2, "name": "gil.ParallelDatetimeFields.time_datetime_to_period", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "cde6d958573108e82e2590608e39d0383a40286ae5a58dece87d96ebe28bced7", "warmup_time": -1}, "gil.ParallelDatetimeFields.time_period_to_datetime": {"code": "class ParallelDatetimeFields:\n    def time_period_to_datetime(self):\n        @test_parallel(num_threads=2)\n        def run(period):\n            period.to_timestamp()\n    \n        run(self.period)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ParallelDatetimeFields:\n    def setup(self):\n        N = 10**6\n        self.dti = date_range(\"1900-01-01\", periods=N, freq=\"T\")\n        self.period = self.dti.to_period(\"D\")", "min_run_count": 2, "name": "gil.ParallelDatetimeFields.time_period_to_datetime", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "0d67772034c5533b1b4d23f6ecfb8b06509951f15b33fdeaa1fb6c41b6793b9b", "warmup_time": -1}, "gil.ParallelFactorize.time_loop": {"code": "class ParallelFactorize:\n    def time_loop(self, threads):\n        for i in range(threads):\n            self.loop()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ParallelFactorize:\n    def setup(self, threads):\n        strings = tm.makeStringIndex(100000)\n    \n        @test_parallel(num_threads=threads)\n        def parallel():\n            factorize(strings)\n    \n        self.parallel = parallel\n    \n        def loop():\n            factorize(strings)\n    \n        self.loop = loop", "min_run_count": 2, "name": "gil.ParallelFactorize.time_loop", "number": 1, "param_names": ["threads"], "params": [["2", "4", "8"]], "repeat": 5, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "9a50b5fe4568d0271835e433f8afde313aaf58bac912d6428afd8f7754c46965", "warmup_time": -1}, "gil.ParallelFactorize.time_parallel": {"code": "class ParallelFactorize:\n    def time_parallel(self, threads):\n        self.parallel()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ParallelFactorize:\n    def setup(self, threads):\n        strings = tm.makeStringIndex(100000)\n    \n        @test_parallel(num_threads=threads)\n        def parallel():\n            factorize(strings)\n    \n        self.parallel = parallel\n    \n        def loop():\n            factorize(strings)\n    \n        self.loop = loop", "min_run_count": 2, "name": "gil.ParallelFactorize.time_parallel", "number": 1, "param_names": ["threads"], "params": [["2", "4", "8"]], "repeat": 5, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "3b3a208cd8d8d225fd639961e867b2d3d885b46472caec0278deeb2643ca18c8", "warmup_time": -1}, "gil.ParallelGroupbyMethods.time_loop": {"code": "class ParallelGroupbyMethods:\n    def time_loop(self, threads, method):\n        for i in range(threads):\n            self.loop()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ParallelGroupbyMethods:\n    def setup(self, threads, method):\n        N = 10**6\n        ngroups = 10**3\n        df = DataFrame(\n            {\"key\": np.random.randint(0, ngroups, size=N), \"data\": np.random.randn(N)}\n        )\n    \n        @test_parallel(num_threads=threads)\n        def parallel():\n            getattr(df.groupby(\"key\")[\"data\"], method)()\n    \n        self.parallel = parallel\n    \n        def loop():\n            getattr(df.groupby(\"key\")[\"data\"], method)()\n    \n        self.loop = loop", "min_run_count": 2, "name": "gil.ParallelGroupbyMethods.time_loop", "number": 0, "param_names": ["threads", "method"], "params": [["2", "4", "8"], ["'count'", "'last'", "'max'", "'mean'", "'min'", "'prod'", "'sum'", "'var'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "eb7b8df45f4491f84224614922e1b5e9a4f93453147833890ec096562f96b248", "warmup_time": -1}, "gil.ParallelGroupbyMethods.time_parallel": {"code": "class ParallelGroupbyMethods:\n    def time_parallel(self, threads, method):\n        self.parallel()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ParallelGroupbyMethods:\n    def setup(self, threads, method):\n        N = 10**6\n        ngroups = 10**3\n        df = DataFrame(\n            {\"key\": np.random.randint(0, ngroups, size=N), \"data\": np.random.randn(N)}\n        )\n    \n        @test_parallel(num_threads=threads)\n        def parallel():\n            getattr(df.groupby(\"key\")[\"data\"], method)()\n    \n        self.parallel = parallel\n    \n        def loop():\n            getattr(df.groupby(\"key\")[\"data\"], method)()\n    \n        self.loop = loop", "min_run_count": 2, "name": "gil.ParallelGroupbyMethods.time_parallel", "number": 0, "param_names": ["threads", "method"], "params": [["2", "4", "8"], ["'count'", "'last'", "'max'", "'mean'", "'min'", "'prod'", "'sum'", "'var'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "ee3c7c1d8ffe98d3bbc8c64cb4af33754566e6351c3bb50458012a695887b895", "warmup_time": -1}, "gil.ParallelGroups.time_get_groups": {"code": "class ParallelGroups:\n    def time_get_groups(self, threads):\n        self.get_groups()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ParallelGroups:\n    def setup(self, threads):\n        size = 2**22\n        ngroups = 10**3\n        data = Series(np.random.randint(0, ngroups, size=size))\n    \n        @test_parallel(num_threads=threads)\n        def get_groups():\n            data.groupby(data).groups\n    \n        self.get_groups = get_groups", "min_run_count": 2, "name": "gil.ParallelGroups.time_get_groups", "number": 0, "param_names": ["threads"], "params": [["2", "4", "8"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "171c8e07e2d81baa3dde5f287fa352a1692571b4e8ab6bc86a6f308969c770f0", "warmup_time": -1}, "gil.ParallelKth.time_kth_smallest": {"code": "class ParallelKth:\n    def time_kth_smallest(self):\n        self.parallel_kth_smallest()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ParallelKth:\n    def setup(self):\n        N = 10**7\n        k = 5 * 10**5\n        kwargs_list = [{\"arr\": np.random.randn(N)}, {\"arr\": np.random.randn(N)}]\n    \n        @test_parallel(num_threads=2, kwargs_list=kwargs_list)\n        def parallel_kth_smallest(arr):\n            algos.kth_smallest(arr, k)\n    \n        self.parallel_kth_smallest = parallel_kth_smallest", "min_run_count": 2, "name": "gil.ParallelKth.time_kth_smallest", "number": 1, "param_names": [], "params": [], "repeat": 5, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "728baeaaeac8eda248c8708b2a4bc45d00a0df43c2103cac65cbfc9c8aff7dcd", "warmup_time": -1}, "gil.ParallelReadCSV.time_read_csv": {"code": "class ParallelReadCSV:\n    def time_read_csv(self, dtype):\n        self.parallel_read_csv()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ParallelReadCSV:\n    def setup(self, dtype):\n        rows = 10000\n        cols = 50\n        data = {\n            \"float\": DataFrame(np.random.randn(rows, cols)),\n            \"datetime\": DataFrame(\n                np.random.randn(rows, cols), index=date_range(\"1/1/2000\", periods=rows)\n            ),\n            \"object\": DataFrame(\n                \"foo\", index=range(rows), columns=[\"object%03d\" for _ in range(5)]\n            ),\n        }\n    \n        self.fname = f\"__test_{dtype}__.csv\"\n        df = data[dtype]\n        df.to_csv(self.fname)\n    \n        @test_parallel(num_threads=2)\n        def parallel_read_csv():\n            read_csv(self.fname)\n    \n        self.parallel_read_csv = parallel_read_csv", "min_run_count": 2, "name": "gil.ParallelReadCSV.time_read_csv", "number": 1, "param_names": ["dtype"], "params": [["'float'", "'object'", "'datetime'"]], "repeat": 5, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "34be8f4fa084810edc3c23771893b300e384a45e7f47b2a620cd65ac7569c6db", "warmup_time": -1}, "gil.ParallelRolling.time_rolling": {"code": "class ParallelRolling:\n    def time_rolling(self, method):\n        self.parallel_rolling()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ParallelRolling:\n    def setup(self, method):\n        win = 100\n        arr = np.random.rand(100000)\n        if hasattr(DataFrame, \"rolling\"):\n            df = DataFrame(arr).rolling(win)\n    \n            @test_parallel(num_threads=2)\n            def parallel_rolling():\n                getattr(df, method)()\n    \n            self.parallel_rolling = parallel_rolling\n        elif have_rolling_methods:\n            rolling = {\n                \"median\": rolling_median,\n                \"mean\": rolling_mean,\n                \"min\": rolling_min,\n                \"max\": rolling_max,\n                \"var\": rolling_var,\n                \"skew\": rolling_skew,\n                \"kurt\": rolling_kurt,\n                \"std\": rolling_std,\n            }\n    \n            @test_parallel(num_threads=2)\n            def parallel_rolling():\n                rolling[method](arr, win)\n    \n            self.parallel_rolling = parallel_rolling\n        else:\n            raise NotImplementedError", "min_run_count": 2, "name": "gil.ParallelRolling.time_rolling", "number": 0, "param_names": ["method"], "params": [["'median'", "'mean'", "'min'", "'max'", "'var'", "'skew'", "'kurt'", "'std'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "982eb24280f1da753438825641a9861564da7d7a000c415ab86a6bc7522c160b", "warmup_time": -1}, "gil.ParallelTake1D.time_take1d": {"code": "class ParallelTake1D:\n    def time_take1d(self, dtype):\n        self.parallel_take1d()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ParallelTake1D:\n    def setup(self, dtype):\n        N = 10**6\n        df = DataFrame({\"col\": np.arange(N, dtype=dtype)})\n        indexer = np.arange(100, len(df) - 100)\n    \n        @test_parallel(num_threads=2)\n        def parallel_take1d():\n            take_nd(df[\"col\"].values, indexer)\n    \n        self.parallel_take1d = parallel_take1d", "min_run_count": 2, "name": "gil.ParallelTake1D.time_take1d", "number": 0, "param_names": ["dtype"], "params": [["'int64'", "'float64'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "fd7379c21f5111cc9ec16f330e4ffc0e029ced1a7cd13e6b78511e7099f53926", "warmup_time": -1}, "groupby.AggEngine.time_dataframe_cython": {"code": "class AggEngine:\n    def time_dataframe_cython(self, parallel):\n        def function(values):\n            total = 0\n            for i, value in enumerate(values):\n                if i % 2:\n                    total += value + 5\n                else:\n                    total += value * 2\n            return total\n    \n        self.grouper.agg(function, engine=\"cython\")\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass AggEngine:\n    def setup(self, parallel):\n        N = 10**3\n        data = DataFrame(\n            {0: [str(i) for i in range(100)] * N, 1: list(range(100)) * N},\n            columns=[0, 1],\n        )\n        self.parallel = parallel\n        self.grouper = data.groupby(0)", "min_run_count": 2, "name": "groupby.AggEngine.time_dataframe_cython", "number": 0, "param_names": ["parallel"], "params": [["True", "False"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "b631e4aa17bbb96c2171d4d72e155061807325d0b39f89014e9ce5de10bfebd2", "warmup_time": -1}, "groupby.AggEngine.time_dataframe_numba": {"code": "class AggEngine:\n    def time_dataframe_numba(self, parallel):\n        def function(values, index):\n            total = 0\n            for i, value in enumerate(values):\n                if i % 2:\n                    total += value + 5\n                else:\n                    total += value * 2\n            return total\n    \n        self.grouper.agg(\n            function, engine=\"numba\", engine_kwargs={\"parallel\": self.parallel}\n        )\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass AggEngine:\n    def setup(self, parallel):\n        N = 10**3\n        data = DataFrame(\n            {0: [str(i) for i in range(100)] * N, 1: list(range(100)) * N},\n            columns=[0, 1],\n        )\n        self.parallel = parallel\n        self.grouper = data.groupby(0)", "min_run_count": 2, "name": "groupby.AggEngine.time_dataframe_numba", "number": 0, "param_names": ["parallel"], "params": [["True", "False"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "ac6601fa086e8c75d228fd781b72c5b02d2053fd155682b074b03fbd6562ccff", "warmup_time": -1}, "groupby.AggEngine.time_series_cython": {"code": "class AggEngine:\n    def time_series_cython(self, parallel):\n        def function(values):\n            total = 0\n            for i, value in enumerate(values):\n                if i % 2:\n                    total += value + 5\n                else:\n                    total += value * 2\n            return total\n    \n        self.grouper[1].agg(function, engine=\"cython\")\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass AggEngine:\n    def setup(self, parallel):\n        N = 10**3\n        data = DataFrame(\n            {0: [str(i) for i in range(100)] * N, 1: list(range(100)) * N},\n            columns=[0, 1],\n        )\n        self.parallel = parallel\n        self.grouper = data.groupby(0)", "min_run_count": 2, "name": "groupby.AggEngine.time_series_cython", "number": 0, "param_names": ["parallel"], "params": [["True", "False"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "e376d34069b9e05138d16b62f5314f36da3d7a957bb6f040793626df9edcb7ee", "warmup_time": -1}, "groupby.AggEngine.time_series_numba": {"code": "class AggEngine:\n    def time_series_numba(self, parallel):\n        def function(values, index):\n            total = 0\n            for i, value in enumerate(values):\n                if i % 2:\n                    total += value + 5\n                else:\n                    total += value * 2\n            return total\n    \n        self.grouper[1].agg(\n            function, engine=\"numba\", engine_kwargs={\"parallel\": self.parallel}\n        )\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass AggEngine:\n    def setup(self, parallel):\n        N = 10**3\n        data = DataFrame(\n            {0: [str(i) for i in range(100)] * N, 1: list(range(100)) * N},\n            columns=[0, 1],\n        )\n        self.parallel = parallel\n        self.grouper = data.groupby(0)", "min_run_count": 2, "name": "groupby.AggEngine.time_series_numba", "number": 0, "param_names": ["parallel"], "params": [["True", "False"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "c1e4164d5e903fe4335a07378a9a567a3e4f7c80cb9960c112d95f8919a292aa", "warmup_time": -1}, "groupby.AggFunctions.time_different_numpy_functions": {"code": "class AggFunctions:\n    def time_different_numpy_functions(self, df):\n        df.groupby([\"key1\", \"key2\"]).agg(\n            {\"value1\": np.mean, \"value2\": np.var, \"value3\": np.sum}\n        )\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass AggFunctions:\n    def setup_cache(self):\n        N = 10**5\n        fac1 = np.array([\"A\", \"B\", \"C\"], dtype=\"O\")\n        fac2 = np.array([\"one\", \"two\"], dtype=\"O\")\n        df = DataFrame(\n            {\n                \"key1\": fac1.take(np.random.randint(0, 3, size=N)),\n                \"key2\": fac2.take(np.random.randint(0, 2, size=N)),\n                \"value1\": np.random.randn(N),\n                \"value2\": np.random.randn(N),\n                \"value3\": np.random.randn(N),\n            }\n        )\n        return df", "min_run_count": 2, "name": "groupby.AggFunctions.time_different_numpy_functions", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "setup_cache_key": "groupby:280", "timeout": 60.0, "type": "time", "unit": "seconds", "version": "dff087faaa3823025f763076c86bd538c254ddd5e12bdc01594b34ccda327d81", "warmup_time": -1}, "groupby.AggFunctions.time_different_python_functions_multicol": {"code": "class AggFunctions:\n    def time_different_python_functions_multicol(self, df):\n        df.groupby([\"key1\", \"key2\"]).agg([sum, min, max])\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass AggFunctions:\n    def setup_cache(self):\n        N = 10**5\n        fac1 = np.array([\"A\", \"B\", \"C\"], dtype=\"O\")\n        fac2 = np.array([\"one\", \"two\"], dtype=\"O\")\n        df = DataFrame(\n            {\n                \"key1\": fac1.take(np.random.randint(0, 3, size=N)),\n                \"key2\": fac2.take(np.random.randint(0, 2, size=N)),\n                \"value1\": np.random.randn(N),\n                \"value2\": np.random.randn(N),\n                \"value3\": np.random.randn(N),\n            }\n        )\n        return df", "min_run_count": 2, "name": "groupby.AggFunctions.time_different_python_functions_multicol", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "setup_cache_key": "groupby:280", "timeout": 60.0, "type": "time", "unit": "seconds", "version": "622f9ad221007b8db26424ef36d5fcfdd6ab8589d535c04c2f26bd5cf16727fe", "warmup_time": -1}, "groupby.AggFunctions.time_different_python_functions_singlecol": {"code": "class AggFunctions:\n    def time_different_python_functions_singlecol(self, df):\n        df.groupby(\"key1\")[[\"value1\", \"value2\", \"value3\"]].agg([sum, min, max])\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass AggFunctions:\n    def setup_cache(self):\n        N = 10**5\n        fac1 = np.array([\"A\", \"B\", \"C\"], dtype=\"O\")\n        fac2 = np.array([\"one\", \"two\"], dtype=\"O\")\n        df = DataFrame(\n            {\n                \"key1\": fac1.take(np.random.randint(0, 3, size=N)),\n                \"key2\": fac2.take(np.random.randint(0, 2, size=N)),\n                \"value1\": np.random.randn(N),\n                \"value2\": np.random.randn(N),\n                \"value3\": np.random.randn(N),\n            }\n        )\n        return df", "min_run_count": 2, "name": "groupby.AggFunctions.time_different_python_functions_singlecol", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "setup_cache_key": "groupby:280", "timeout": 60.0, "type": "time", "unit": "seconds", "version": "ca2e0c306d210856d13b88fa4ac81ae2f1b2ad7b9d6248122c1f6f882d03931f", "warmup_time": -1}, "groupby.AggFunctions.time_different_str_functions": {"code": "class AggFunctions:\n    def time_different_str_functions(self, df):\n        df.groupby([\"key1\", \"key2\"]).agg(\n            {\"value1\": \"mean\", \"value2\": \"var\", \"value3\": \"sum\"}\n        )\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass AggFunctions:\n    def setup_cache(self):\n        N = 10**5\n        fac1 = np.array([\"A\", \"B\", \"C\"], dtype=\"O\")\n        fac2 = np.array([\"one\", \"two\"], dtype=\"O\")\n        df = DataFrame(\n            {\n                \"key1\": fac1.take(np.random.randint(0, 3, size=N)),\n                \"key2\": fac2.take(np.random.randint(0, 2, size=N)),\n                \"value1\": np.random.randn(N),\n                \"value2\": np.random.randn(N),\n                \"value3\": np.random.randn(N),\n            }\n        )\n        return df", "min_run_count": 2, "name": "groupby.AggFunctions.time_different_str_functions", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "setup_cache_key": "groupby:280", "timeout": 60.0, "type": "time", "unit": "seconds", "version": "176cde1b06cc31bb98fa33e5c2d0b5b504f18a26bc5160ce4eba434ee86f286c", "warmup_time": -1}, "groupby.Apply.time_copy_function_multi_col": {"code": "class Apply:\n    def time_copy_function_multi_col(self, factor):\n        self.df.groupby([\"key\", \"key2\"]).apply(self.df_copy_function)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Apply:\n    def setup(self, factor):\n        N = 10**factor\n        # two cases:\n        # - small groups: small data (N**4) + many labels (2000) -> average group\n        #   size of 5 (-> larger overhead of slicing method)\n        # - larger groups: larger data (N**5) + fewer labels (20) -> average group\n        #   size of 5000\n        labels = np.random.randint(0, 2000 if factor == 4 else 20, size=N)\n        labels2 = np.random.randint(0, 3, size=N)\n        df = DataFrame(\n            {\n                \"key\": labels,\n                \"key2\": labels2,\n                \"value1\": np.random.randn(N),\n                \"value2\": [\"foo\", \"bar\", \"baz\", \"qux\"] * (N // 4),\n            }\n        )\n        self.df = df", "min_run_count": 2, "name": "groupby.Apply.time_copy_function_multi_col", "number": 0, "param_names": ["factor"], "params": [["4", "5"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "508a1bf90ae09cc26585902afd9774deccb6c4fd643ff3f6e3cd66018ca60057", "warmup_time": -1}, "groupby.Apply.time_copy_overhead_single_col": {"code": "class Apply:\n    def time_copy_overhead_single_col(self, factor):\n        self.df.groupby(\"key\").apply(self.df_copy_function)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Apply:\n    def setup(self, factor):\n        N = 10**factor\n        # two cases:\n        # - small groups: small data (N**4) + many labels (2000) -> average group\n        #   size of 5 (-> larger overhead of slicing method)\n        # - larger groups: larger data (N**5) + fewer labels (20) -> average group\n        #   size of 5000\n        labels = np.random.randint(0, 2000 if factor == 4 else 20, size=N)\n        labels2 = np.random.randint(0, 3, size=N)\n        df = DataFrame(\n            {\n                \"key\": labels,\n                \"key2\": labels2,\n                \"value1\": np.random.randn(N),\n                \"value2\": [\"foo\", \"bar\", \"baz\", \"qux\"] * (N // 4),\n            }\n        )\n        self.df = df", "min_run_count": 2, "name": "groupby.Apply.time_copy_overhead_single_col", "number": 0, "param_names": ["factor"], "params": [["4", "5"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "004ee6e703ae1fbf983c0b4353be97cb81fcd0c0dde8175bbac3fe70f25e2eeb", "warmup_time": -1}, "groupby.Apply.time_scalar_function_multi_col": {"code": "class Apply:\n    def time_scalar_function_multi_col(self, factor):\n        self.df.groupby([\"key\", \"key2\"]).apply(lambda x: 1)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Apply:\n    def setup(self, factor):\n        N = 10**factor\n        # two cases:\n        # - small groups: small data (N**4) + many labels (2000) -> average group\n        #   size of 5 (-> larger overhead of slicing method)\n        # - larger groups: larger data (N**5) + fewer labels (20) -> average group\n        #   size of 5000\n        labels = np.random.randint(0, 2000 if factor == 4 else 20, size=N)\n        labels2 = np.random.randint(0, 3, size=N)\n        df = DataFrame(\n            {\n                \"key\": labels,\n                \"key2\": labels2,\n                \"value1\": np.random.randn(N),\n                \"value2\": [\"foo\", \"bar\", \"baz\", \"qux\"] * (N // 4),\n            }\n        )\n        self.df = df", "min_run_count": 2, "name": "groupby.Apply.time_scalar_function_multi_col", "number": 0, "param_names": ["factor"], "params": [["4", "5"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "c2684326af2c29dbc66ddff0ed5b88aa9ec425dbd70bb2874943b0ee3e8f916d", "warmup_time": -1}, "groupby.Apply.time_scalar_function_single_col": {"code": "class Apply:\n    def time_scalar_function_single_col(self, factor):\n        self.df.groupby(\"key\").apply(lambda x: 1)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Apply:\n    def setup(self, factor):\n        N = 10**factor\n        # two cases:\n        # - small groups: small data (N**4) + many labels (2000) -> average group\n        #   size of 5 (-> larger overhead of slicing method)\n        # - larger groups: larger data (N**5) + fewer labels (20) -> average group\n        #   size of 5000\n        labels = np.random.randint(0, 2000 if factor == 4 else 20, size=N)\n        labels2 = np.random.randint(0, 3, size=N)\n        df = DataFrame(\n            {\n                \"key\": labels,\n                \"key2\": labels2,\n                \"value1\": np.random.randn(N),\n                \"value2\": [\"foo\", \"bar\", \"baz\", \"qux\"] * (N // 4),\n            }\n        )\n        self.df = df", "min_run_count": 2, "name": "groupby.Apply.time_scalar_function_single_col", "number": 0, "param_names": ["factor"], "params": [["4", "5"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "69063f137e8f55d96073f5bed6cb8a4784eed89b8accd6d82bd386218d1d1e79", "warmup_time": -1}, "groupby.ApplyDictReturn.time_groupby_apply_dict_return": {"code": "class ApplyDictReturn:\n    def time_groupby_apply_dict_return(self):\n        self.data.groupby(self.labels).apply(\n            lambda x: {\"first\": x.values[0], \"last\": x.values[-1]}\n        )\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ApplyDictReturn:\n    def setup(self):\n        self.labels = np.arange(1000).repeat(10)\n        self.data = Series(np.random.randn(len(self.labels)))", "min_run_count": 2, "name": "groupby.ApplyDictReturn.time_groupby_apply_dict_return", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "5924f4088fcf382ce33f346ce7ddfd12e83ed70b71b93eaec422e9d9eebf6683", "warmup_time": -1}, "groupby.ApplyNonUniqueUnsortedIndex.time_groupby_apply_non_unique_unsorted_index": {"code": "class ApplyNonUniqueUnsortedIndex:\n    def time_groupby_apply_non_unique_unsorted_index(self):\n        self.df.groupby(\"key\", group_keys=False).apply(lambda x: x)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ApplyNonUniqueUnsortedIndex:\n    def setup(self):\n        # GH 46527\n        # unsorted and non-unique index\n        idx = np.arange(100)[::-1]\n        idx = Index(np.repeat(idx, 200), name=\"key\")\n        self.df = DataFrame(np.random.randn(len(idx), 10), index=idx)", "min_run_count": 2, "name": "groupby.ApplyNonUniqueUnsortedIndex.time_groupby_apply_non_unique_unsorted_index", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "f7c3bea0e579df6a33360dfc8c3303ce3a07b11bf0bd48d962a46d5522f4dcfd", "warmup_time": -1}, "groupby.Categories.time_groupby_extra_cat_nosort": {"code": "class Categories:\n    def time_groupby_extra_cat_nosort(self):\n        self.df_extra_cat.groupby(\"a\", sort=False)[\"b\"].count()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Categories:\n    def setup(self):\n        N = 10**5\n        arr = np.random.random(N)\n        data = {\"a\": Categorical(np.random.randint(10000, size=N)), \"b\": arr}\n        self.df = DataFrame(data)\n        data = {\n            \"a\": Categorical(np.random.randint(10000, size=N), ordered=True),\n            \"b\": arr,\n        }\n        self.df_ordered = DataFrame(data)\n        data = {\n            \"a\": Categorical(\n                np.random.randint(100, size=N), categories=np.arange(10000)\n            ),\n            \"b\": arr,\n        }\n        self.df_extra_cat = DataFrame(data)", "min_run_count": 2, "name": "groupby.Categories.time_groupby_extra_cat_nosort", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "0b8e16415a1ebec2878800ae589e059712bdaedb9518796686a64477dcbaa3ad", "warmup_time": -1}, "groupby.Categories.time_groupby_extra_cat_sort": {"code": "class Categories:\n    def time_groupby_extra_cat_sort(self):\n        self.df_extra_cat.groupby(\"a\")[\"b\"].count()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Categories:\n    def setup(self):\n        N = 10**5\n        arr = np.random.random(N)\n        data = {\"a\": Categorical(np.random.randint(10000, size=N)), \"b\": arr}\n        self.df = DataFrame(data)\n        data = {\n            \"a\": Categorical(np.random.randint(10000, size=N), ordered=True),\n            \"b\": arr,\n        }\n        self.df_ordered = DataFrame(data)\n        data = {\n            \"a\": Categorical(\n                np.random.randint(100, size=N), categories=np.arange(10000)\n            ),\n            \"b\": arr,\n        }\n        self.df_extra_cat = DataFrame(data)", "min_run_count": 2, "name": "groupby.Categories.time_groupby_extra_cat_sort", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "3983eec67cc893df848b2fbe97502ac200710afc7e85476de4b0d2e4bad0450a", "warmup_time": -1}, "groupby.Categories.time_groupby_nosort": {"code": "class Categories:\n    def time_groupby_nosort(self):\n        self.df.groupby(\"a\", sort=False)[\"b\"].count()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Categories:\n    def setup(self):\n        N = 10**5\n        arr = np.random.random(N)\n        data = {\"a\": Categorical(np.random.randint(10000, size=N)), \"b\": arr}\n        self.df = DataFrame(data)\n        data = {\n            \"a\": Categorical(np.random.randint(10000, size=N), ordered=True),\n            \"b\": arr,\n        }\n        self.df_ordered = DataFrame(data)\n        data = {\n            \"a\": Categorical(\n                np.random.randint(100, size=N), categories=np.arange(10000)\n            ),\n            \"b\": arr,\n        }\n        self.df_extra_cat = DataFrame(data)", "min_run_count": 2, "name": "groupby.Categories.time_groupby_nosort", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "01d4dd6ec6b18625e36f780db162f9ea2726903ef6b7317258d0574e44ea5126", "warmup_time": -1}, "groupby.Categories.time_groupby_ordered_nosort": {"code": "class Categories:\n    def time_groupby_ordered_nosort(self):\n        self.df_ordered.groupby(\"a\", sort=False)[\"b\"].count()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Categories:\n    def setup(self):\n        N = 10**5\n        arr = np.random.random(N)\n        data = {\"a\": Categorical(np.random.randint(10000, size=N)), \"b\": arr}\n        self.df = DataFrame(data)\n        data = {\n            \"a\": Categorical(np.random.randint(10000, size=N), ordered=True),\n            \"b\": arr,\n        }\n        self.df_ordered = DataFrame(data)\n        data = {\n            \"a\": Categorical(\n                np.random.randint(100, size=N), categories=np.arange(10000)\n            ),\n            \"b\": arr,\n        }\n        self.df_extra_cat = DataFrame(data)", "min_run_count": 2, "name": "groupby.Categories.time_groupby_ordered_nosort", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "9157e27722ba688448b780d0f3c3abf4d6106c97e6eae8a87cda4ed0e0b9cf3d", "warmup_time": -1}, "groupby.Categories.time_groupby_ordered_sort": {"code": "class Categories:\n    def time_groupby_ordered_sort(self):\n        self.df_ordered.groupby(\"a\")[\"b\"].count()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Categories:\n    def setup(self):\n        N = 10**5\n        arr = np.random.random(N)\n        data = {\"a\": Categorical(np.random.randint(10000, size=N)), \"b\": arr}\n        self.df = DataFrame(data)\n        data = {\n            \"a\": Categorical(np.random.randint(10000, size=N), ordered=True),\n            \"b\": arr,\n        }\n        self.df_ordered = DataFrame(data)\n        data = {\n            \"a\": Categorical(\n                np.random.randint(100, size=N), categories=np.arange(10000)\n            ),\n            \"b\": arr,\n        }\n        self.df_extra_cat = DataFrame(data)", "min_run_count": 2, "name": "groupby.Categories.time_groupby_ordered_sort", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "1d9c097671774fa9ce1cac817ce800b8806881da92e6da3d7a32285d9b9be8d6", "warmup_time": -1}, "groupby.Categories.time_groupby_sort": {"code": "class Categories:\n    def time_groupby_sort(self):\n        self.df.groupby(\"a\")[\"b\"].count()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Categories:\n    def setup(self):\n        N = 10**5\n        arr = np.random.random(N)\n        data = {\"a\": Categorical(np.random.randint(10000, size=N)), \"b\": arr}\n        self.df = DataFrame(data)\n        data = {\n            \"a\": Categorical(np.random.randint(10000, size=N), ordered=True),\n            \"b\": arr,\n        }\n        self.df_ordered = DataFrame(data)\n        data = {\n            \"a\": Categorical(\n                np.random.randint(100, size=N), categories=np.arange(10000)\n            ),\n            \"b\": arr,\n        }\n        self.df_extra_cat = DataFrame(data)", "min_run_count": 2, "name": "groupby.Categories.time_groupby_sort", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "0f17f3f42d0f5d91517c05cbee5f3b586b2a63b545091cdd1dd79201c87870e4", "warmup_time": -1}, "groupby.CountMultiDtype.time_multi_count": {"code": "class CountMultiDtype:\n    def time_multi_count(self, df):\n        df.groupby([\"key1\", \"key2\"]).count()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass CountMultiDtype:\n    def setup_cache(self):\n        n = 10000\n        offsets = np.random.randint(n, size=n).astype(\"timedelta64[ns]\")\n        dates = np.datetime64(\"now\") + offsets\n        dates[np.random.rand(n) > 0.5] = np.datetime64(\"nat\")\n        offsets[np.random.rand(n) > 0.5] = np.timedelta64(\"nat\")\n        value2 = np.random.randn(n)\n        value2[np.random.rand(n) > 0.5] = np.nan\n        obj = np.random.choice(list(\"ab\"), size=n).astype(object)\n        obj[np.random.randn(n) > 0.5] = np.nan\n        df = DataFrame(\n            {\n                \"key1\": np.random.randint(0, 500, size=n),\n                \"key2\": np.random.randint(0, 100, size=n),\n                \"dates\": dates,\n                \"value2\": value2,\n                \"value3\": np.random.randn(n),\n                \"ints\": np.random.randint(0, 1000, size=n),\n                \"obj\": obj,\n                \"offsets\": offsets,\n            }\n        )\n        return df", "min_run_count": 2, "name": "groupby.CountMultiDtype.time_multi_count", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "setup_cache_key": "groupby:231", "timeout": 60.0, "type": "time", "unit": "seconds", "version": "781eccf167f79b9db2b42e6637dca3e0917b3ee82948078ab34ec1fdd55a8ba7", "warmup_time": -1}, "groupby.CountMultiInt.time_multi_int_count": {"code": "class CountMultiInt:\n    def time_multi_int_count(self, df):\n        df.groupby([\"key1\", \"key2\"]).count()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass CountMultiInt:\n    def setup_cache(self):\n        n = 10000\n        df = DataFrame(\n            {\n                \"key1\": np.random.randint(0, 500, size=n),\n                \"key2\": np.random.randint(0, 100, size=n),\n                \"ints\": np.random.randint(0, 1000, size=n),\n                \"ints2\": np.random.randint(0, 1000, size=n),\n            }\n        )\n        return df", "min_run_count": 2, "name": "groupby.CountMultiInt.time_multi_int_count", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "setup_cache_key": "groupby:260", "timeout": 60.0, "type": "time", "unit": "seconds", "version": "c0c648960106b54be2a606e2093e04045e55e61c502f37ec87315025300cc688", "warmup_time": -1}, "groupby.CountMultiInt.time_multi_int_nunique": {"code": "class CountMultiInt:\n    def time_multi_int_nunique(self, df):\n        df.groupby([\"key1\", \"key2\"]).nunique()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass CountMultiInt:\n    def setup_cache(self):\n        n = 10000\n        df = DataFrame(\n            {\n                \"key1\": np.random.randint(0, 500, size=n),\n                \"key2\": np.random.randint(0, 100, size=n),\n                \"ints\": np.random.randint(0, 1000, size=n),\n                \"ints2\": np.random.randint(0, 1000, size=n),\n            }\n        )\n        return df", "min_run_count": 2, "name": "groupby.CountMultiInt.time_multi_int_nunique", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "setup_cache_key": "groupby:260", "timeout": 60.0, "type": "time", "unit": "seconds", "version": "02179b80a10ef56e163f7134b90b2b3a14e1e783c29bcd78e8c839cc49c2b89a", "warmup_time": -1}, "groupby.Cumulative.time_frame_transform": {"code": "class Cumulative:\n    def time_frame_transform(self, dtype, method, with_nans):\n        self.df.groupby(\"key\").transform(method)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Cumulative:\n    def setup(self, dtype, method, with_nans):\n        if with_nans and dtype == \"int64\":\n            raise NotImplementedError(\"Construction of df would raise\")\n    \n        N = 500_000\n        keys = np.random.randint(0, 100, size=N)\n        vals = np.random.randint(-10, 10, (N, 5))\n    \n        if with_nans:\n            null_vals = vals.astype(float, copy=True)\n            null_vals[::2, :] = np.nan\n            null_vals[::3, :] = np.nan\n            df = DataFrame(null_vals, columns=list(\"abcde\"), dtype=dtype)\n            df[\"key\"] = keys\n            self.df = df\n        else:\n            df = DataFrame(vals, columns=list(\"abcde\")).astype(dtype, copy=False)\n            df[\"key\"] = keys\n            self.df = df", "min_run_count": 2, "name": "groupby.Cumulative.time_frame_transform", "number": 0, "param_names": ["dtype", "method", "with_nans"], "params": [["'float64'", "'int64'", "'Float64'", "'Int64'"], ["'cummin'", "'cummax'", "'cumsum'"], ["True", "False"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "508bbc112e0877babc3aaf14b674b720e942cd27f59280bc4678e5cca617dd6d", "warmup_time": -1}, "groupby.DateAttributes.time_len_groupby_object": {"code": "class DateAttributes:\n    def time_len_groupby_object(self):\n        len(self.ts.groupby([self.year, self.month, self.day]))\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass DateAttributes:\n    def setup(self):\n        rng = date_range(\"1/1/2000\", \"12/31/2005\", freq=\"H\")\n        self.year, self.month, self.day = rng.year, rng.month, rng.day\n        self.ts = Series(np.random.randn(len(rng)), index=rng)", "min_run_count": 2, "name": "groupby.DateAttributes.time_len_groupby_object", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "d1f886f153117a642f7678e24ba28a35956c89d6e7660787a3a1f4b738ec73d7", "warmup_time": -1}, "groupby.Datelike.time_sum": {"code": "class Datelike:\n    def time_sum(self, grouper):\n        self.df.groupby(self.grouper).sum()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Datelike:\n    def setup(self, grouper):\n        N = 10**4\n        rng_map = {\n            \"period_range\": period_range,\n            \"date_range\": date_range,\n            \"date_range_tz\": partial(date_range, tz=\"US/Central\"),\n        }\n        self.grouper = rng_map[grouper](\"1900-01-01\", freq=\"D\", periods=N)\n        self.df = DataFrame(np.random.randn(10**4, 2))", "min_run_count": 2, "name": "groupby.Datelike.time_sum", "number": 0, "param_names": ["grouper"], "params": [["'period_range'", "'date_range'", "'date_range_tz'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "e8e6e1030bf91e85db8d838621c86faee1e19b8f21d49efe9d147e58d9b54307", "warmup_time": -1}, "groupby.FillNA.time_df_bfill": {"code": "class FillNA:\n    def time_df_bfill(self):\n        self.df.groupby(\"group\").fillna(method=\"bfill\")\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass FillNA:\n    def setup(self):\n        N = 100\n        self.df = DataFrame(\n            {\"group\": [1] * N + [2] * N, \"value\": [np.nan, 1.0] * N}\n        ).set_index(\"group\")", "min_run_count": 2, "name": "groupby.FillNA.time_df_bfill", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "24c3ea0c498314988ab2f7f514c7177a5d84c854090807e1b44f9dcd27a1b610", "warmup_time": -1}, "groupby.FillNA.time_df_ffill": {"code": "class FillNA:\n    def time_df_ffill(self):\n        self.df.groupby(\"group\").fillna(method=\"ffill\")\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass FillNA:\n    def setup(self):\n        N = 100\n        self.df = DataFrame(\n            {\"group\": [1] * N + [2] * N, \"value\": [np.nan, 1.0] * N}\n        ).set_index(\"group\")", "min_run_count": 2, "name": "groupby.FillNA.time_df_ffill", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "63c157de8d01fd0af22a1c9100ccb582c59bd816eea42ac7f1d13d388e3b1d61", "warmup_time": -1}, "groupby.FillNA.time_srs_bfill": {"code": "class FillNA:\n    def time_srs_bfill(self):\n        self.df.groupby(\"group\")[\"value\"].fillna(method=\"bfill\")\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass FillNA:\n    def setup(self):\n        N = 100\n        self.df = DataFrame(\n            {\"group\": [1] * N + [2] * N, \"value\": [np.nan, 1.0] * N}\n        ).set_index(\"group\")", "min_run_count": 2, "name": "groupby.FillNA.time_srs_bfill", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "ef22577198dc333646fb9f334ec1f742f270c7342a8c3cdaf7d93997487f81a2", "warmup_time": -1}, "groupby.FillNA.time_srs_ffill": {"code": "class FillNA:\n    def time_srs_ffill(self):\n        self.df.groupby(\"group\")[\"value\"].fillna(method=\"ffill\")\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass FillNA:\n    def setup(self):\n        N = 100\n        self.df = DataFrame(\n            {\"group\": [1] * N + [2] * N, \"value\": [np.nan, 1.0] * N}\n        ).set_index(\"group\")", "min_run_count": 2, "name": "groupby.FillNA.time_srs_ffill", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "b6490c508ad10feb8063c8f257b4fad1618c334fe7783676bbede929f0202dbb", "warmup_time": -1}, "groupby.Float32.time_sum": {"code": "class Float32:\n    def time_sum(self):\n        self.df.groupby([\"a\"])[\"b\"].sum()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Float32:\n    def setup(self):\n        tmp1 = (np.random.random(10000) * 0.1).astype(np.float32)\n        tmp2 = (np.random.random(10000) * 10.0).astype(np.float32)\n        tmp = np.concatenate((tmp1, tmp2))\n        arr = np.repeat(tmp, 10)\n        self.df = DataFrame({\"a\": arr, \"b\": arr})", "min_run_count": 2, "name": "groupby.Float32.time_sum", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "ffe9e34b1eb793ed006421668ab941faed0e6f0e51c5142f0940d4117f1aedb4", "warmup_time": -1}, "groupby.GroupByCythonAgg.time_frame_agg": {"code": "class GroupByCythonAgg:\n    def time_frame_agg(self, dtype, method):\n        self.df.groupby(\"key\").agg(method)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass GroupByCythonAgg:\n    def setup(self, dtype, method):\n        N = 1_000_000\n        df = DataFrame(np.random.randn(N, 10), columns=list(\"abcdefghij\"))\n        df[\"key\"] = np.random.randint(0, 100, size=N)\n        self.df = df", "min_run_count": 2, "name": "groupby.GroupByCythonAgg.time_frame_agg", "number": 0, "param_names": ["dtype", "method"], "params": [["'float64'"], ["'sum'", "'prod'", "'min'", "'max'", "'mean'", "'median'", "'var'", "'first'", "'last'", "'any'", "'all'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "08ae292d77e9806660d8e3c10232a024c7526f433635c0290aa62b6b313af20f", "warmup_time": -1}, "groupby.GroupByCythonAggEaDtypes.time_frame_agg": {"code": "class GroupByCythonAggEaDtypes:\n    def time_frame_agg(self, dtype, method):\n        self.df.groupby(\"key\").agg(method)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass GroupByCythonAggEaDtypes:\n    def setup(self, dtype, method):\n        N = 1_000_000\n        df = DataFrame(\n            np.random.randint(0, high=100, size=(N, 10)),\n            columns=list(\"abcdefghij\"),\n            dtype=dtype,\n        )\n        df.loc[list(range(1, N, 5)), list(\"abcdefghij\")] = NA\n        df[\"key\"] = np.random.randint(0, 100, size=N)\n        self.df = df", "min_run_count": 2, "name": "groupby.GroupByCythonAggEaDtypes.time_frame_agg", "number": 0, "param_names": ["dtype", "method"], "params": [["'Float64'", "'Int64'", "'Int32'"], ["'sum'", "'prod'", "'min'", "'max'", "'mean'", "'median'", "'var'", "'first'", "'last'", "'any'", "'all'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "9d0957d40f08e9fb265f5ca8f466358e6742a3b6b934d1714c6cfc2f9604ded1", "warmup_time": -1}, "groupby.GroupByMethods.time_dtype_as_field": {"code": "class GroupByMethods:\n    def time_dtype_as_field(self, dtype, method, application, ncols):\n        self.as_field_method()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass GroupByMethods:\n    def setup(self, dtype, method, application, ncols):\n        if method in method_blocklist.get(dtype, {}):\n            raise NotImplementedError  # skip benchmark\n    \n        if ncols != 1 and method in [\"value_counts\", \"unique\"]:\n            # DataFrameGroupBy doesn't have these methods\n            raise NotImplementedError\n    \n        if application == \"transformation\" and method in [\n            \"describe\",\n            \"head\",\n            \"tail\",\n            \"unique\",\n            \"value_counts\",\n            \"size\",\n        ]:\n            # DataFrameGroupBy doesn't have these methods\n            raise NotImplementedError\n    \n        if method == \"describe\":\n            ngroups = 20\n        elif method == \"skew\":\n            ngroups = 100\n        else:\n            ngroups = 1000\n        size = ngroups * 2\n        rng = np.arange(ngroups).reshape(-1, 1)\n        rng = np.broadcast_to(rng, (len(rng), ncols))\n        taker = np.random.randint(0, ngroups, size=size)\n        values = rng.take(taker, axis=0)\n        if dtype == \"int\":\n            key = np.random.randint(0, size, size=size)\n        elif dtype in (\"int16\", \"uint\"):\n            key = np.random.randint(0, size, size=size, dtype=dtype)\n        elif dtype == \"float\":\n            key = np.concatenate(\n                [np.random.random(ngroups) * 0.1, np.random.random(ngroups) * 10.0]\n            )\n        elif dtype == \"object\":\n            key = [\"foo\"] * size\n        elif dtype == \"datetime\":\n            key = date_range(\"1/1/2011\", periods=size, freq=\"s\")\n    \n        cols = [f\"values{n}\" for n in range(ncols)]\n        df = DataFrame(values, columns=cols)\n        df[\"key\"] = key\n    \n        if len(cols) == 1:\n            cols = cols[0]\n    \n        if application == \"transformation\":\n            self.as_group_method = lambda: df.groupby(\"key\")[cols].transform(method)\n            self.as_field_method = lambda: df.groupby(cols)[\"key\"].transform(method)\n        else:\n            self.as_group_method = getattr(df.groupby(\"key\")[cols], method)\n            self.as_field_method = getattr(df.groupby(cols)[\"key\"], method)", "min_run_count": 2, "name": "groupby.GroupByMethods.time_dtype_as_field", "number": 0, "param_names": ["dtype", "method", "application", "ncols"], "params": [["'int'", "'int16'", "'float'", "'object'", "'datetime'", "'uint'"], ["'all'", "'any'", "'bfill'", "'count'", "'cumcount'", "'cummax'", "'cummin'", "'cumprod'", "'cumsum'", "'describe'", "'diff'", "'ffill'", "'first'", "'head'", "'last'", "'max'", "'min'", "'median'", "'mean'", "'nunique'", "'pct_change'", "'prod'", "'quantile'", "'rank'", "'sem'", "'shift'", "'size'", "'skew'", "'std'", "'sum'", "'tail'", "'unique'", "'value_counts'", "'var'"], ["'direct'", "'transformation'"], ["1", "5"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "d73dbc311b34d5047efffbf45a293cf574cd7c010a078f148dbdac284f61b06d", "warmup_time": -1}, "groupby.GroupByMethods.time_dtype_as_group": {"code": "class GroupByMethods:\n    def time_dtype_as_group(self, dtype, method, application, ncols):\n        self.as_group_method()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass GroupByMethods:\n    def setup(self, dtype, method, application, ncols):\n        if method in method_blocklist.get(dtype, {}):\n            raise NotImplementedError  # skip benchmark\n    \n        if ncols != 1 and method in [\"value_counts\", \"unique\"]:\n            # DataFrameGroupBy doesn't have these methods\n            raise NotImplementedError\n    \n        if application == \"transformation\" and method in [\n            \"describe\",\n            \"head\",\n            \"tail\",\n            \"unique\",\n            \"value_counts\",\n            \"size\",\n        ]:\n            # DataFrameGroupBy doesn't have these methods\n            raise NotImplementedError\n    \n        if method == \"describe\":\n            ngroups = 20\n        elif method == \"skew\":\n            ngroups = 100\n        else:\n            ngroups = 1000\n        size = ngroups * 2\n        rng = np.arange(ngroups).reshape(-1, 1)\n        rng = np.broadcast_to(rng, (len(rng), ncols))\n        taker = np.random.randint(0, ngroups, size=size)\n        values = rng.take(taker, axis=0)\n        if dtype == \"int\":\n            key = np.random.randint(0, size, size=size)\n        elif dtype in (\"int16\", \"uint\"):\n            key = np.random.randint(0, size, size=size, dtype=dtype)\n        elif dtype == \"float\":\n            key = np.concatenate(\n                [np.random.random(ngroups) * 0.1, np.random.random(ngroups) * 10.0]\n            )\n        elif dtype == \"object\":\n            key = [\"foo\"] * size\n        elif dtype == \"datetime\":\n            key = date_range(\"1/1/2011\", periods=size, freq=\"s\")\n    \n        cols = [f\"values{n}\" for n in range(ncols)]\n        df = DataFrame(values, columns=cols)\n        df[\"key\"] = key\n    \n        if len(cols) == 1:\n            cols = cols[0]\n    \n        if application == \"transformation\":\n            self.as_group_method = lambda: df.groupby(\"key\")[cols].transform(method)\n            self.as_field_method = lambda: df.groupby(cols)[\"key\"].transform(method)\n        else:\n            self.as_group_method = getattr(df.groupby(\"key\")[cols], method)\n            self.as_field_method = getattr(df.groupby(cols)[\"key\"], method)", "min_run_count": 2, "name": "groupby.GroupByMethods.time_dtype_as_group", "number": 0, "param_names": ["dtype", "method", "application", "ncols"], "params": [["'int'", "'int16'", "'float'", "'object'", "'datetime'", "'uint'"], ["'all'", "'any'", "'bfill'", "'count'", "'cumcount'", "'cummax'", "'cummin'", "'cumprod'", "'cumsum'", "'describe'", "'diff'", "'ffill'", "'first'", "'head'", "'last'", "'max'", "'min'", "'median'", "'mean'", "'nunique'", "'pct_change'", "'prod'", "'quantile'", "'rank'", "'sem'", "'shift'", "'size'", "'skew'", "'std'", "'sum'", "'tail'", "'unique'", "'value_counts'", "'var'"], ["'direct'", "'transformation'"], ["1", "5"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "9d79ee16a5370f3ac2581307a89291b35e76a49cf96b3383c9b7430b009f77c2", "warmup_time": -1}, "groupby.GroupManyLabels.time_sum": {"code": "class GroupManyLabels:\n    def time_sum(self, ncols):\n        self.df.groupby(self.labels).sum()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass GroupManyLabels:\n    def setup(self, ncols):\n        N = 1000\n        data = np.random.randn(N, ncols)\n        self.labels = np.random.randint(0, 100, size=N)\n        self.df = DataFrame(data)", "min_run_count": 2, "name": "groupby.GroupManyLabels.time_sum", "number": 0, "param_names": ["ncols"], "params": [["1", "1000"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "66b2e0c8c016da785fe5cc599d0ce7892b1c5657f8af53ff854fed498e28878a", "warmup_time": -1}, "groupby.GroupStrings.time_multi_columns": {"code": "class GroupStrings:\n    def time_multi_columns(self):\n        self.df.groupby(list(\"abcd\")).max()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass GroupStrings:\n    def setup(self):\n        n = 2 * 10**5\n        alpha = list(map(\"\".join, product(ascii_letters, repeat=4)))\n        data = np.random.choice(alpha, (n // 5, 4), replace=False)\n        data = np.repeat(data, 5, axis=0)\n        self.df = DataFrame(data, columns=list(\"abcd\"))\n        self.df[\"joe\"] = (np.random.randn(len(self.df)) * 10).round(3)\n        self.df = self.df.sample(frac=1).reset_index(drop=True)", "min_run_count": 2, "name": "groupby.GroupStrings.time_multi_columns", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "e2cad1f849665339cebeef8f37279cd4824c4fa1e86e39fe618e4052a76b7dd6", "warmup_time": -1}, "groupby.Groups.time_series_groups": {"code": "class Groups:\n    def time_series_groups(self, data, key):\n        self.ser.groupby(self.ser).groups\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Groups:\n    def setup(self, data, key):\n        self.ser = data[key]\n\n    def setup_cache(self):\n        size = 10**6\n        data = {\n            \"int64_small\": Series(np.random.randint(0, 100, size=size)),\n            \"int64_large\": Series(np.random.randint(0, 10000, size=size)),\n            \"object_small\": Series(\n                tm.makeStringIndex(100).take(np.random.randint(0, 100, size=size))\n            ),\n            \"object_large\": Series(\n                tm.makeStringIndex(10000).take(np.random.randint(0, 10000, size=size))\n            ),\n        }\n        return data", "min_run_count": 2, "name": "groupby.Groups.time_series_groups", "number": 0, "param_names": ["key"], "params": [["'int64_small'", "'int64_large'", "'object_small'", "'object_large'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "setup_cache_key": "groupby:130", "timeout": 60.0, "type": "time", "unit": "seconds", "version": "b410b45d823c2e308772d7c7629314c55c3de2bb1cd6822642161eaa20104d40", "warmup_time": -1}, "groupby.Groups.time_series_indices": {"code": "class Groups:\n    def time_series_indices(self, data, key):\n        self.ser.groupby(self.ser).indices\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Groups:\n    def setup(self, data, key):\n        self.ser = data[key]\n\n    def setup_cache(self):\n        size = 10**6\n        data = {\n            \"int64_small\": Series(np.random.randint(0, 100, size=size)),\n            \"int64_large\": Series(np.random.randint(0, 10000, size=size)),\n            \"object_small\": Series(\n                tm.makeStringIndex(100).take(np.random.randint(0, 100, size=size))\n            ),\n            \"object_large\": Series(\n                tm.makeStringIndex(10000).take(np.random.randint(0, 10000, size=size))\n            ),\n        }\n        return data", "min_run_count": 2, "name": "groupby.Groups.time_series_indices", "number": 0, "param_names": ["key"], "params": [["'int64_small'", "'int64_large'", "'object_small'", "'object_large'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "setup_cache_key": "groupby:130", "timeout": 60.0, "type": "time", "unit": "seconds", "version": "f7146f0835fdc0c362c8220f23baf3e7fbc72f123c368b2a39555786fe50d6a4", "warmup_time": -1}, "groupby.Int64.time_overflow": {"code": "class Int64:\n    def time_overflow(self):\n        self.df.groupby(self.cols).max()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Int64:\n    def setup(self):\n        arr = np.random.randint(-1 << 12, 1 << 12, (1 << 17, 5))\n        i = np.random.choice(len(arr), len(arr) * 5)\n        arr = np.vstack((arr, arr[i]))\n        i = np.random.permutation(len(arr))\n        arr = arr[i]\n        self.cols = list(\"abcde\")\n        self.df = DataFrame(arr, columns=self.cols)\n        self.df[\"jim\"], self.df[\"joe\"] = np.random.randn(2, len(self.df)) * 10", "min_run_count": 2, "name": "groupby.Int64.time_overflow", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "c59f5b180f618f9de6657c8e0c5a373add1e863a6f3969b4097836f1f4e40929", "warmup_time": -1}, "groupby.MultiColumn.time_col_select_lambda_sum": {"code": "class MultiColumn:\n    def time_col_select_lambda_sum(self, df):\n        df.groupby([\"key1\", \"key2\"])[\"data1\"].agg(lambda x: x.values.sum())\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass MultiColumn:\n    def setup_cache(self):\n        N = 10**5\n        key1 = np.tile(np.arange(100, dtype=object), 1000)\n        key2 = key1.copy()\n        np.random.shuffle(key1)\n        np.random.shuffle(key2)\n        df = DataFrame(\n            {\n                \"key1\": key1,\n                \"key2\": key2,\n                \"data1\": np.random.randn(N),\n                \"data2\": np.random.randn(N),\n            }\n        )\n        return df", "min_run_count": 2, "name": "groupby.MultiColumn.time_col_select_lambda_sum", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "setup_cache_key": "groupby:327", "timeout": 60.0, "type": "time", "unit": "seconds", "version": "cada8d1efcf927c41db4c7b33b88a6816790e5d361e4cf10f3f03f390386a717", "warmup_time": -1}, "groupby.MultiColumn.time_col_select_numpy_sum": {"code": "class MultiColumn:\n    def time_col_select_numpy_sum(self, df):\n        df.groupby([\"key1\", \"key2\"])[\"data1\"].agg(np.sum)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass MultiColumn:\n    def setup_cache(self):\n        N = 10**5\n        key1 = np.tile(np.arange(100, dtype=object), 1000)\n        key2 = key1.copy()\n        np.random.shuffle(key1)\n        np.random.shuffle(key2)\n        df = DataFrame(\n            {\n                \"key1\": key1,\n                \"key2\": key2,\n                \"data1\": np.random.randn(N),\n                \"data2\": np.random.randn(N),\n            }\n        )\n        return df", "min_run_count": 2, "name": "groupby.MultiColumn.time_col_select_numpy_sum", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "setup_cache_key": "groupby:327", "timeout": 60.0, "type": "time", "unit": "seconds", "version": "46c07f45c8c5a8f81a94d4799e0ecb868685ebb501351c2a12ebede2d2c41c7c", "warmup_time": -1}, "groupby.MultiColumn.time_cython_sum": {"code": "class MultiColumn:\n    def time_cython_sum(self, df):\n        df.groupby([\"key1\", \"key2\"]).sum()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass MultiColumn:\n    def setup_cache(self):\n        N = 10**5\n        key1 = np.tile(np.arange(100, dtype=object), 1000)\n        key2 = key1.copy()\n        np.random.shuffle(key1)\n        np.random.shuffle(key2)\n        df = DataFrame(\n            {\n                \"key1\": key1,\n                \"key2\": key2,\n                \"data1\": np.random.randn(N),\n                \"data2\": np.random.randn(N),\n            }\n        )\n        return df", "min_run_count": 2, "name": "groupby.MultiColumn.time_cython_sum", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "setup_cache_key": "groupby:327", "timeout": 60.0, "type": "time", "unit": "seconds", "version": "9ba6f25ceb0666279babb6760f71ea64c8a52a817294261fed73699bc7b516f3", "warmup_time": -1}, "groupby.MultiColumn.time_lambda_sum": {"code": "class MultiColumn:\n    def time_lambda_sum(self, df):\n        df.groupby([\"key1\", \"key2\"]).agg(lambda x: x.values.sum())\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass MultiColumn:\n    def setup_cache(self):\n        N = 10**5\n        key1 = np.tile(np.arange(100, dtype=object), 1000)\n        key2 = key1.copy()\n        np.random.shuffle(key1)\n        np.random.shuffle(key2)\n        df = DataFrame(\n            {\n                \"key1\": key1,\n                \"key2\": key2,\n                \"data1\": np.random.randn(N),\n                \"data2\": np.random.randn(N),\n            }\n        )\n        return df", "min_run_count": 2, "name": "groupby.MultiColumn.time_lambda_sum", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "setup_cache_key": "groupby:327", "timeout": 60.0, "type": "time", "unit": "seconds", "version": "38b6452a313f2508f0dfd7fa593d129b13ec9c33f22753679877d5f06818a566", "warmup_time": -1}, "groupby.Nth.time_frame_nth": {"code": "class Nth:\n    def time_frame_nth(self, dtype):\n        self.df.groupby(\"key\").nth(0)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Nth:\n    def setup(self, dtype):\n        N = 10**5\n        # with datetimes (GH7555)\n        if dtype == \"datetime\":\n            values = date_range(\"1/1/2011\", periods=N, freq=\"s\")\n        elif dtype == \"object\":\n            values = [\"foo\"] * N\n        else:\n            values = np.arange(N).astype(dtype)\n    \n        key = np.arange(N)\n        self.df = DataFrame({\"key\": key, \"values\": values})\n        self.df.iloc[1, 1] = np.nan  # insert missing data", "min_run_count": 2, "name": "groupby.Nth.time_frame_nth", "number": 0, "param_names": ["dtype"], "params": [["'float32'", "'float64'", "'datetime'", "'object'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "e1d08a270138a89c0f1723213b6519ab3f5bf1373d8e8d2c2b54a43b065b76be", "warmup_time": -1}, "groupby.Nth.time_frame_nth_any": {"code": "class Nth:\n    def time_frame_nth_any(self, dtype):\n        self.df.groupby(\"key\").nth(0, dropna=\"any\")\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Nth:\n    def setup(self, dtype):\n        N = 10**5\n        # with datetimes (GH7555)\n        if dtype == \"datetime\":\n            values = date_range(\"1/1/2011\", periods=N, freq=\"s\")\n        elif dtype == \"object\":\n            values = [\"foo\"] * N\n        else:\n            values = np.arange(N).astype(dtype)\n    \n        key = np.arange(N)\n        self.df = DataFrame({\"key\": key, \"values\": values})\n        self.df.iloc[1, 1] = np.nan  # insert missing data", "min_run_count": 2, "name": "groupby.Nth.time_frame_nth_any", "number": 0, "param_names": ["dtype"], "params": [["'float32'", "'float64'", "'datetime'", "'object'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "a44829e68092f64486a6572a1a5465f5a0d577ee765ee5ad2e38c472e85346bd", "warmup_time": -1}, "groupby.Nth.time_groupby_nth_all": {"code": "class Nth:\n    def time_groupby_nth_all(self, dtype):\n        self.df.groupby(\"key\").nth(0, dropna=\"all\")\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Nth:\n    def setup(self, dtype):\n        N = 10**5\n        # with datetimes (GH7555)\n        if dtype == \"datetime\":\n            values = date_range(\"1/1/2011\", periods=N, freq=\"s\")\n        elif dtype == \"object\":\n            values = [\"foo\"] * N\n        else:\n            values = np.arange(N).astype(dtype)\n    \n        key = np.arange(N)\n        self.df = DataFrame({\"key\": key, \"values\": values})\n        self.df.iloc[1, 1] = np.nan  # insert missing data", "min_run_count": 2, "name": "groupby.Nth.time_groupby_nth_all", "number": 0, "param_names": ["dtype"], "params": [["'float32'", "'float64'", "'datetime'", "'object'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "866ef9a468514b755b4464d8fd09949132454a4161d7a99770caeec775a2bba6", "warmup_time": -1}, "groupby.Nth.time_series_nth": {"code": "class Nth:\n    def time_series_nth(self, dtype):\n        self.df[\"values\"].groupby(self.df[\"key\"]).nth(0)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Nth:\n    def setup(self, dtype):\n        N = 10**5\n        # with datetimes (GH7555)\n        if dtype == \"datetime\":\n            values = date_range(\"1/1/2011\", periods=N, freq=\"s\")\n        elif dtype == \"object\":\n            values = [\"foo\"] * N\n        else:\n            values = np.arange(N).astype(dtype)\n    \n        key = np.arange(N)\n        self.df = DataFrame({\"key\": key, \"values\": values})\n        self.df.iloc[1, 1] = np.nan  # insert missing data", "min_run_count": 2, "name": "groupby.Nth.time_series_nth", "number": 0, "param_names": ["dtype"], "params": [["'float32'", "'float64'", "'datetime'", "'object'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "c5b1e05da00cd08da75c885c95b13c18db12dc3332aafd79a79049e66f996c1e", "warmup_time": -1}, "groupby.Nth.time_series_nth_all": {"code": "class Nth:\n    def time_series_nth_all(self, dtype):\n        self.df[\"values\"].groupby(self.df[\"key\"]).nth(0, dropna=\"all\")\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Nth:\n    def setup(self, dtype):\n        N = 10**5\n        # with datetimes (GH7555)\n        if dtype == \"datetime\":\n            values = date_range(\"1/1/2011\", periods=N, freq=\"s\")\n        elif dtype == \"object\":\n            values = [\"foo\"] * N\n        else:\n            values = np.arange(N).astype(dtype)\n    \n        key = np.arange(N)\n        self.df = DataFrame({\"key\": key, \"values\": values})\n        self.df.iloc[1, 1] = np.nan  # insert missing data", "min_run_count": 2, "name": "groupby.Nth.time_series_nth_all", "number": 0, "param_names": ["dtype"], "params": [["'float32'", "'float64'", "'datetime'", "'object'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "42ed669cc8c03e7351add656e29a89d0fb07fc43ed2931e70701a559f09f12e1", "warmup_time": -1}, "groupby.Nth.time_series_nth_any": {"code": "class Nth:\n    def time_series_nth_any(self, dtype):\n        self.df[\"values\"].groupby(self.df[\"key\"]).nth(0, dropna=\"any\")\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Nth:\n    def setup(self, dtype):\n        N = 10**5\n        # with datetimes (GH7555)\n        if dtype == \"datetime\":\n            values = date_range(\"1/1/2011\", periods=N, freq=\"s\")\n        elif dtype == \"object\":\n            values = [\"foo\"] * N\n        else:\n            values = np.arange(N).astype(dtype)\n    \n        key = np.arange(N)\n        self.df = DataFrame({\"key\": key, \"values\": values})\n        self.df.iloc[1, 1] = np.nan  # insert missing data", "min_run_count": 2, "name": "groupby.Nth.time_series_nth_any", "number": 0, "param_names": ["dtype"], "params": [["'float32'", "'float64'", "'datetime'", "'object'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "011dc9ba29511d4b5f0b1bb7c6f5a991ef7a1590ce479e354646546de88cfea6", "warmup_time": -1}, "groupby.RankWithTies.time_rank_ties": {"code": "class RankWithTies:\n    def time_rank_ties(self, dtype, tie_method):\n        self.df.groupby(\"key\").rank(method=tie_method)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass RankWithTies:\n    def setup(self, dtype, tie_method):\n        N = 10**4\n        if dtype == \"datetime64\":\n            data = np.array([Timestamp(\"2011/01/01\")] * N, dtype=dtype)\n        else:\n            data = np.array([1] * N, dtype=dtype)\n        self.df = DataFrame({\"values\": data, \"key\": [\"foo\"] * N})", "min_run_count": 2, "name": "groupby.RankWithTies.time_rank_ties", "number": 0, "param_names": ["dtype", "tie_method"], "params": [["'float64'", "'float32'", "'int64'", "'datetime64'"], ["'first'", "'average'", "'dense'", "'min'", "'max'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "868d0c36a0189978a0bbd63db41c58f866d9966fa69ef49824b504d163f3b2b7", "warmup_time": -1}, "groupby.Resample.time_resample": {"code": "class Resample:\n    def time_resample(self):\n        self.df.groupby(level=\"groups\").resample(\"10s\", on=\"timedeltas\").mean()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Resample:\n    def setup(self):\n        num_timedeltas = 20_000\n        num_groups = 3\n    \n        index = MultiIndex.from_product(\n            [\n                np.arange(num_groups),\n                to_timedelta(np.arange(num_timedeltas), unit=\"s\"),\n            ],\n            names=[\"groups\", \"timedeltas\"],\n        )\n        data = np.random.randint(0, 1000, size=(len(index)))\n    \n        self.df = DataFrame(data, index=index).reset_index(\"timedeltas\")\n        self.df_multiindex = DataFrame(data, index=index)", "min_run_count": 2, "name": "groupby.Resample.time_resample", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "2f73c1abc5cfc408cd8604b1badf9ee4f00ceb2a76c77b5b5a78af2d74228f7b", "warmup_time": -1}, "groupby.Resample.time_resample_multiindex": {"code": "class Resample:\n    def time_resample_multiindex(self):\n        self.df_multiindex.groupby(level=\"groups\").resample(\n            \"10s\", level=\"timedeltas\"\n        ).mean()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Resample:\n    def setup(self):\n        num_timedeltas = 20_000\n        num_groups = 3\n    \n        index = MultiIndex.from_product(\n            [\n                np.arange(num_groups),\n                to_timedelta(np.arange(num_timedeltas), unit=\"s\"),\n            ],\n            names=[\"groups\", \"timedeltas\"],\n        )\n        data = np.random.randint(0, 1000, size=(len(index)))\n    \n        self.df = DataFrame(data, index=index).reset_index(\"timedeltas\")\n        self.df_multiindex = DataFrame(data, index=index)", "min_run_count": 2, "name": "groupby.Resample.time_resample_multiindex", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "07304b920f854bdb1422e0b993c60857e6e2d6ad9ce2664f92ee8e113c3df234", "warmup_time": -1}, "groupby.Sample.time_sample": {"code": "class Sample:\n    def time_sample(self):\n        self.df.groupby(self.groups).sample(n=1)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Sample:\n    def setup(self):\n        N = 10**3\n        self.df = DataFrame({\"a\": np.zeros(N)})\n        self.groups = np.arange(0, N)\n        self.weights = np.ones(N)", "min_run_count": 2, "name": "groupby.Sample.time_sample", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "d06fc92a35cfb5f7ef26863259f097f3aabbef9d90438fde13891e042fa2cff9", "warmup_time": -1}, "groupby.Sample.time_sample_weights": {"code": "class Sample:\n    def time_sample_weights(self):\n        self.df.groupby(self.groups).sample(n=1, weights=self.weights)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Sample:\n    def setup(self):\n        N = 10**3\n        self.df = DataFrame({\"a\": np.zeros(N)})\n        self.groups = np.arange(0, N)\n        self.weights = np.ones(N)", "min_run_count": 2, "name": "groupby.Sample.time_sample_weights", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "66bb261674cbd4d0e341aebd067908473e0734bca8091cd8bae8282d7706dd4d", "warmup_time": -1}, "groupby.Shift.time_defaults": {"code": "class Shift:\n    def time_defaults(self):\n        self.df.groupby(\"g\").shift()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Shift:\n    def setup(self):\n        N = 18\n        self.df = DataFrame({\"g\": [\"a\", \"b\"] * 9, \"v\": list(range(N))})", "min_run_count": 2, "name": "groupby.Shift.time_defaults", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "6a3a41956cf53e5cacf8be90a4432268657d065e708f3681cb0da232d8442b7b", "warmup_time": -1}, "groupby.Shift.time_fill_value": {"code": "class Shift:\n    def time_fill_value(self):\n        self.df.groupby(\"g\").shift(fill_value=99)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Shift:\n    def setup(self):\n        N = 18\n        self.df = DataFrame({\"g\": [\"a\", \"b\"] * 9, \"v\": list(range(N))})", "min_run_count": 2, "name": "groupby.Shift.time_fill_value", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "92e908ccaf513773d03d593373379bb94d333da277d2214a08ee1905d58e0c3b", "warmup_time": -1}, "groupby.Size.time_category_size": {"code": "class Size:\n    def time_category_size(self):\n        self.draws.groupby(self.cats).size()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Size:\n    def setup(self):\n        n = 10**5\n        offsets = np.random.randint(n, size=n).astype(\"timedelta64[ns]\")\n        dates = np.datetime64(\"now\") + offsets\n        self.df = DataFrame(\n            {\n                \"key1\": np.random.randint(0, 500, size=n),\n                \"key2\": np.random.randint(0, 100, size=n),\n                \"value1\": np.random.randn(n),\n                \"value2\": np.random.randn(n),\n                \"value3\": np.random.randn(n),\n                \"dates\": dates,\n            }\n        )\n        self.draws = Series(np.random.randn(n))\n        labels = Series([\"foo\", \"bar\", \"baz\", \"qux\"] * (n // 4))\n        self.cats = labels.astype(\"category\")", "min_run_count": 2, "name": "groupby.Size.time_category_size", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "f5fdd675d78197a990b08f998dc96dee12ef563d4a2647bbdd4470e3c89026bd", "warmup_time": -1}, "groupby.Size.time_multi_size": {"code": "class Size:\n    def time_multi_size(self):\n        self.df.groupby([\"key1\", \"key2\"]).size()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Size:\n    def setup(self):\n        n = 10**5\n        offsets = np.random.randint(n, size=n).astype(\"timedelta64[ns]\")\n        dates = np.datetime64(\"now\") + offsets\n        self.df = DataFrame(\n            {\n                \"key1\": np.random.randint(0, 500, size=n),\n                \"key2\": np.random.randint(0, 100, size=n),\n                \"value1\": np.random.randn(n),\n                \"value2\": np.random.randn(n),\n                \"value3\": np.random.randn(n),\n                \"dates\": dates,\n            }\n        )\n        self.draws = Series(np.random.randn(n))\n        labels = Series([\"foo\", \"bar\", \"baz\", \"qux\"] * (n // 4))\n        self.cats = labels.astype(\"category\")", "min_run_count": 2, "name": "groupby.Size.time_multi_size", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "34694723d47ec5028bd8d513e5986c685e58d7219113ca9a4be7e030a9a98aa1", "warmup_time": -1}, "groupby.String.time_str_func": {"code": "class String:\n    def time_str_func(self, dtype, method):\n        self.df.groupby(\"a\")[self.df.columns[1:]].agg(method)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass String:\n    def setup(self, dtype, method):\n        cols = list(\"abcdefghjkl\")\n        self.df = DataFrame(\n            np.random.randint(0, 100, size=(10_000, len(cols))),\n            columns=cols,\n            dtype=dtype,\n        )", "min_run_count": 2, "name": "groupby.String.time_str_func", "number": 0, "param_names": ["dtype", "method"], "params": [["'str'", "'string[python]'"], ["'sum'", "'min'", "'max'", "'first'", "'last'", "'any'", "'all'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "b49dcaf61606c8e3e1fd9bd0ca3f1d1b8833147e2b729e1e363d481f98270ec4", "warmup_time": -1}, "groupby.SumBools.time_groupby_sum_booleans": {"code": "class SumBools:\n    def time_groupby_sum_booleans(self):\n        self.df.groupby(\"ii\").sum()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass SumBools:\n    def setup(self):\n        N = 500\n        self.df = DataFrame({\"ii\": range(N), \"bb\": [True] * N})", "min_run_count": 2, "name": "groupby.SumBools.time_groupby_sum_booleans", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "c3539588ce95b04f6cfe6c310ff1d827826da14d25eafe09e1d58cf28f0f2020", "warmup_time": -1}, "groupby.SumMultiLevel.time_groupby_sum_multiindex": {"code": "class SumMultiLevel:\n    def time_groupby_sum_multiindex(self):\n        self.df.groupby(level=[0, 1]).sum()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass SumMultiLevel:\n    def setup(self):\n        N = 50\n        self.df = DataFrame(\n            {\"A\": list(range(N)) * 2, \"B\": range(N * 2), \"C\": 1}\n        ).set_index([\"A\", \"B\"])", "min_run_count": 2, "name": "groupby.SumMultiLevel.time_groupby_sum_multiindex", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 120.0, "type": "time", "unit": "seconds", "version": "b34947d529ea832ced0c45868dd46b91974ce4d6a23b4212210c255083673ef8", "warmup_time": -1}, "groupby.Transform.time_transform_lambda_max": {"code": "class Transform:\n    def time_transform_lambda_max(self):\n        self.df.groupby(level=\"lev1\").transform(lambda x: max(x))\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Transform:\n    def setup(self):\n        n1 = 400\n        n2 = 250\n        index = MultiIndex(\n            levels=[np.arange(n1), tm.makeStringIndex(n2)],\n            codes=[np.repeat(range(n1), n2).tolist(), list(range(n2)) * n1],\n            names=[\"lev1\", \"lev2\"],\n        )\n        arr = np.random.randn(n1 * n2, 3)\n        arr[::10000, 0] = np.nan\n        arr[1::10000, 1] = np.nan\n        arr[2::10000, 2] = np.nan\n        data = DataFrame(arr, index=index, columns=[\"col1\", \"col20\", \"col3\"])\n        self.df = data\n    \n        n = 1000\n        self.df_wide = DataFrame(\n            np.random.randn(n, n),\n            index=np.random.choice(range(10), n),\n        )\n    \n        n = 1_000_000\n        self.df_tall = DataFrame(\n            np.random.randn(n, 3),\n            index=np.random.randint(0, 5, n),\n        )\n    \n        n = 20000\n        self.df1 = DataFrame(\n            np.random.randint(1, n, (n, 3)), columns=[\"jim\", \"joe\", \"jolie\"]\n        )\n        self.df2 = self.df1.copy()\n        self.df2[\"jim\"] = self.df2[\"joe\"]\n    \n        self.df3 = DataFrame(\n            np.random.randint(1, (n / 10), (n, 3)), columns=[\"jim\", \"joe\", \"jolie\"]\n        )\n        self.df4 = self.df3.copy()\n        self.df4[\"jim\"] = self.df4[\"joe\"]", "min_run_count": 2, "name": "groupby.Transform.time_transform_lambda_max", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "8bc97da012357a07707263c0fb191e4fa6e05c3a26c089b3b601b59b0d14deb4", "warmup_time": -1}, "groupby.Transform.time_transform_lambda_max_tall": {"code": "class Transform:\n    def time_transform_lambda_max_tall(self):\n        self.df_tall.groupby(level=0).transform(lambda x: np.max(x, axis=0))\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Transform:\n    def setup(self):\n        n1 = 400\n        n2 = 250\n        index = MultiIndex(\n            levels=[np.arange(n1), tm.makeStringIndex(n2)],\n            codes=[np.repeat(range(n1), n2).tolist(), list(range(n2)) * n1],\n            names=[\"lev1\", \"lev2\"],\n        )\n        arr = np.random.randn(n1 * n2, 3)\n        arr[::10000, 0] = np.nan\n        arr[1::10000, 1] = np.nan\n        arr[2::10000, 2] = np.nan\n        data = DataFrame(arr, index=index, columns=[\"col1\", \"col20\", \"col3\"])\n        self.df = data\n    \n        n = 1000\n        self.df_wide = DataFrame(\n            np.random.randn(n, n),\n            index=np.random.choice(range(10), n),\n        )\n    \n        n = 1_000_000\n        self.df_tall = DataFrame(\n            np.random.randn(n, 3),\n            index=np.random.randint(0, 5, n),\n        )\n    \n        n = 20000\n        self.df1 = DataFrame(\n            np.random.randint(1, n, (n, 3)), columns=[\"jim\", \"joe\", \"jolie\"]\n        )\n        self.df2 = self.df1.copy()\n        self.df2[\"jim\"] = self.df2[\"joe\"]\n    \n        self.df3 = DataFrame(\n            np.random.randint(1, (n / 10), (n, 3)), columns=[\"jim\", \"joe\", \"jolie\"]\n        )\n        self.df4 = self.df3.copy()\n        self.df4[\"jim\"] = self.df4[\"joe\"]", "min_run_count": 2, "name": "groupby.Transform.time_transform_lambda_max_tall", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "de0891145fa5776389b95b12b1f0a33ed794e9f7badf2b5b77c9d0771566b3d8", "warmup_time": -1}, "groupby.Transform.time_transform_lambda_max_wide": {"code": "class Transform:\n    def time_transform_lambda_max_wide(self):\n        self.df_wide.groupby(level=0).transform(lambda x: np.max(x, axis=0))\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Transform:\n    def setup(self):\n        n1 = 400\n        n2 = 250\n        index = MultiIndex(\n            levels=[np.arange(n1), tm.makeStringIndex(n2)],\n            codes=[np.repeat(range(n1), n2).tolist(), list(range(n2)) * n1],\n            names=[\"lev1\", \"lev2\"],\n        )\n        arr = np.random.randn(n1 * n2, 3)\n        arr[::10000, 0] = np.nan\n        arr[1::10000, 1] = np.nan\n        arr[2::10000, 2] = np.nan\n        data = DataFrame(arr, index=index, columns=[\"col1\", \"col20\", \"col3\"])\n        self.df = data\n    \n        n = 1000\n        self.df_wide = DataFrame(\n            np.random.randn(n, n),\n            index=np.random.choice(range(10), n),\n        )\n    \n        n = 1_000_000\n        self.df_tall = DataFrame(\n            np.random.randn(n, 3),\n            index=np.random.randint(0, 5, n),\n        )\n    \n        n = 20000\n        self.df1 = DataFrame(\n            np.random.randint(1, n, (n, 3)), columns=[\"jim\", \"joe\", \"jolie\"]\n        )\n        self.df2 = self.df1.copy()\n        self.df2[\"jim\"] = self.df2[\"joe\"]\n    \n        self.df3 = DataFrame(\n            np.random.randint(1, (n / 10), (n, 3)), columns=[\"jim\", \"joe\", \"jolie\"]\n        )\n        self.df4 = self.df3.copy()\n        self.df4[\"jim\"] = self.df4[\"joe\"]", "min_run_count": 2, "name": "groupby.Transform.time_transform_lambda_max_wide", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "9b93ea2c0c33d78961ef1f293ff3956a46f712d7bee8c1a80c34622f3bcf5b14", "warmup_time": -1}, "groupby.Transform.time_transform_multi_key1": {"code": "class Transform:\n    def time_transform_multi_key1(self):\n        self.df1.groupby([\"jim\", \"joe\"])[\"jolie\"].transform(\"max\")\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Transform:\n    def setup(self):\n        n1 = 400\n        n2 = 250\n        index = MultiIndex(\n            levels=[np.arange(n1), tm.makeStringIndex(n2)],\n            codes=[np.repeat(range(n1), n2).tolist(), list(range(n2)) * n1],\n            names=[\"lev1\", \"lev2\"],\n        )\n        arr = np.random.randn(n1 * n2, 3)\n        arr[::10000, 0] = np.nan\n        arr[1::10000, 1] = np.nan\n        arr[2::10000, 2] = np.nan\n        data = DataFrame(arr, index=index, columns=[\"col1\", \"col20\", \"col3\"])\n        self.df = data\n    \n        n = 1000\n        self.df_wide = DataFrame(\n            np.random.randn(n, n),\n            index=np.random.choice(range(10), n),\n        )\n    \n        n = 1_000_000\n        self.df_tall = DataFrame(\n            np.random.randn(n, 3),\n            index=np.random.randint(0, 5, n),\n        )\n    \n        n = 20000\n        self.df1 = DataFrame(\n            np.random.randint(1, n, (n, 3)), columns=[\"jim\", \"joe\", \"jolie\"]\n        )\n        self.df2 = self.df1.copy()\n        self.df2[\"jim\"] = self.df2[\"joe\"]\n    \n        self.df3 = DataFrame(\n            np.random.randint(1, (n / 10), (n, 3)), columns=[\"jim\", \"joe\", \"jolie\"]\n        )\n        self.df4 = self.df3.copy()\n        self.df4[\"jim\"] = self.df4[\"joe\"]", "min_run_count": 2, "name": "groupby.Transform.time_transform_multi_key1", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "5f752f1cc0d959d6ca4e04105bccfecc902f3833e8fbe19e7d59cae1b5680564", "warmup_time": -1}, "groupby.Transform.time_transform_multi_key2": {"code": "class Transform:\n    def time_transform_multi_key2(self):\n        self.df2.groupby([\"jim\", \"joe\"])[\"jolie\"].transform(\"max\")\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Transform:\n    def setup(self):\n        n1 = 400\n        n2 = 250\n        index = MultiIndex(\n            levels=[np.arange(n1), tm.makeStringIndex(n2)],\n            codes=[np.repeat(range(n1), n2).tolist(), list(range(n2)) * n1],\n            names=[\"lev1\", \"lev2\"],\n        )\n        arr = np.random.randn(n1 * n2, 3)\n        arr[::10000, 0] = np.nan\n        arr[1::10000, 1] = np.nan\n        arr[2::10000, 2] = np.nan\n        data = DataFrame(arr, index=index, columns=[\"col1\", \"col20\", \"col3\"])\n        self.df = data\n    \n        n = 1000\n        self.df_wide = DataFrame(\n            np.random.randn(n, n),\n            index=np.random.choice(range(10), n),\n        )\n    \n        n = 1_000_000\n        self.df_tall = DataFrame(\n            np.random.randn(n, 3),\n            index=np.random.randint(0, 5, n),\n        )\n    \n        n = 20000\n        self.df1 = DataFrame(\n            np.random.randint(1, n, (n, 3)), columns=[\"jim\", \"joe\", \"jolie\"]\n        )\n        self.df2 = self.df1.copy()\n        self.df2[\"jim\"] = self.df2[\"joe\"]\n    \n        self.df3 = DataFrame(\n            np.random.randint(1, (n / 10), (n, 3)), columns=[\"jim\", \"joe\", \"jolie\"]\n        )\n        self.df4 = self.df3.copy()\n        self.df4[\"jim\"] = self.df4[\"joe\"]", "min_run_count": 2, "name": "groupby.Transform.time_transform_multi_key2", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "949a9dfa0dc5b5bc56ae5f5caf462f5ca9470a3984e05dd57f687c16a904cf61", "warmup_time": -1}, "groupby.Transform.time_transform_multi_key3": {"code": "class Transform:\n    def time_transform_multi_key3(self):\n        self.df3.groupby([\"jim\", \"joe\"])[\"jolie\"].transform(\"max\")\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Transform:\n    def setup(self):\n        n1 = 400\n        n2 = 250\n        index = MultiIndex(\n            levels=[np.arange(n1), tm.makeStringIndex(n2)],\n            codes=[np.repeat(range(n1), n2).tolist(), list(range(n2)) * n1],\n            names=[\"lev1\", \"lev2\"],\n        )\n        arr = np.random.randn(n1 * n2, 3)\n        arr[::10000, 0] = np.nan\n        arr[1::10000, 1] = np.nan\n        arr[2::10000, 2] = np.nan\n        data = DataFrame(arr, index=index, columns=[\"col1\", \"col20\", \"col3\"])\n        self.df = data\n    \n        n = 1000\n        self.df_wide = DataFrame(\n            np.random.randn(n, n),\n            index=np.random.choice(range(10), n),\n        )\n    \n        n = 1_000_000\n        self.df_tall = DataFrame(\n            np.random.randn(n, 3),\n            index=np.random.randint(0, 5, n),\n        )\n    \n        n = 20000\n        self.df1 = DataFrame(\n            np.random.randint(1, n, (n, 3)), columns=[\"jim\", \"joe\", \"jolie\"]\n        )\n        self.df2 = self.df1.copy()\n        self.df2[\"jim\"] = self.df2[\"joe\"]\n    \n        self.df3 = DataFrame(\n            np.random.randint(1, (n / 10), (n, 3)), columns=[\"jim\", \"joe\", \"jolie\"]\n        )\n        self.df4 = self.df3.copy()\n        self.df4[\"jim\"] = self.df4[\"joe\"]", "min_run_count": 2, "name": "groupby.Transform.time_transform_multi_key3", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "24597a3c42f988f274e3c9c5c629e475471ba89d49fd2140c653645cc39d4857", "warmup_time": -1}, "groupby.Transform.time_transform_multi_key4": {"code": "class Transform:\n    def time_transform_multi_key4(self):\n        self.df4.groupby([\"jim\", \"joe\"])[\"jolie\"].transform(\"max\")\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Transform:\n    def setup(self):\n        n1 = 400\n        n2 = 250\n        index = MultiIndex(\n            levels=[np.arange(n1), tm.makeStringIndex(n2)],\n            codes=[np.repeat(range(n1), n2).tolist(), list(range(n2)) * n1],\n            names=[\"lev1\", \"lev2\"],\n        )\n        arr = np.random.randn(n1 * n2, 3)\n        arr[::10000, 0] = np.nan\n        arr[1::10000, 1] = np.nan\n        arr[2::10000, 2] = np.nan\n        data = DataFrame(arr, index=index, columns=[\"col1\", \"col20\", \"col3\"])\n        self.df = data\n    \n        n = 1000\n        self.df_wide = DataFrame(\n            np.random.randn(n, n),\n            index=np.random.choice(range(10), n),\n        )\n    \n        n = 1_000_000\n        self.df_tall = DataFrame(\n            np.random.randn(n, 3),\n            index=np.random.randint(0, 5, n),\n        )\n    \n        n = 20000\n        self.df1 = DataFrame(\n            np.random.randint(1, n, (n, 3)), columns=[\"jim\", \"joe\", \"jolie\"]\n        )\n        self.df2 = self.df1.copy()\n        self.df2[\"jim\"] = self.df2[\"joe\"]\n    \n        self.df3 = DataFrame(\n            np.random.randint(1, (n / 10), (n, 3)), columns=[\"jim\", \"joe\", \"jolie\"]\n        )\n        self.df4 = self.df3.copy()\n        self.df4[\"jim\"] = self.df4[\"joe\"]", "min_run_count": 2, "name": "groupby.Transform.time_transform_multi_key4", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "e23cfc0a40f49c35aa953a3101fb7a3587b038567b00ac769bf036d494e5b4bf", "warmup_time": -1}, "groupby.Transform.time_transform_ufunc_max": {"code": "class Transform:\n    def time_transform_ufunc_max(self):\n        self.df.groupby(level=\"lev1\").transform(np.max)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Transform:\n    def setup(self):\n        n1 = 400\n        n2 = 250\n        index = MultiIndex(\n            levels=[np.arange(n1), tm.makeStringIndex(n2)],\n            codes=[np.repeat(range(n1), n2).tolist(), list(range(n2)) * n1],\n            names=[\"lev1\", \"lev2\"],\n        )\n        arr = np.random.randn(n1 * n2, 3)\n        arr[::10000, 0] = np.nan\n        arr[1::10000, 1] = np.nan\n        arr[2::10000, 2] = np.nan\n        data = DataFrame(arr, index=index, columns=[\"col1\", \"col20\", \"col3\"])\n        self.df = data\n    \n        n = 1000\n        self.df_wide = DataFrame(\n            np.random.randn(n, n),\n            index=np.random.choice(range(10), n),\n        )\n    \n        n = 1_000_000\n        self.df_tall = DataFrame(\n            np.random.randn(n, 3),\n            index=np.random.randint(0, 5, n),\n        )\n    \n        n = 20000\n        self.df1 = DataFrame(\n            np.random.randint(1, n, (n, 3)), columns=[\"jim\", \"joe\", \"jolie\"]\n        )\n        self.df2 = self.df1.copy()\n        self.df2[\"jim\"] = self.df2[\"joe\"]\n    \n        self.df3 = DataFrame(\n            np.random.randint(1, (n / 10), (n, 3)), columns=[\"jim\", \"joe\", \"jolie\"]\n        )\n        self.df4 = self.df3.copy()\n        self.df4[\"jim\"] = self.df4[\"joe\"]", "min_run_count": 2, "name": "groupby.Transform.time_transform_ufunc_max", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "a3fa331cd3522072d43aa125e0720524a3d3a01375c731eac9c8347e69c7c6de", "warmup_time": -1}, "groupby.TransformBools.time_transform_mean": {"code": "class TransformBools:\n    def time_transform_mean(self):\n        self.df[\"signal\"].groupby(self.g).transform(np.mean)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass TransformBools:\n    def setup(self):\n        N = 120000\n        transition_points = np.sort(np.random.choice(np.arange(N), 1400))\n        transitions = np.zeros(N, dtype=np.bool_)\n        transitions[transition_points] = True\n        self.g = transitions.cumsum()\n        self.df = DataFrame({\"signal\": np.random.rand(N)})", "min_run_count": 2, "name": "groupby.TransformBools.time_transform_mean", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "77ed5daec80a63b0a692cd76ae976065a154f1889d5c28313a19419a1b677a12", "warmup_time": -1}, "groupby.TransformEngine.time_dataframe_cython": {"code": "class TransformEngine:\n    def time_dataframe_cython(self, parallel):\n        def function(values):\n            return values * 5\n    \n        self.grouper.transform(function, engine=\"cython\")\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass TransformEngine:\n    def setup(self, parallel):\n        N = 10**3\n        data = DataFrame(\n            {0: [str(i) for i in range(100)] * N, 1: list(range(100)) * N},\n            columns=[0, 1],\n        )\n        self.parallel = parallel\n        self.grouper = data.groupby(0)", "min_run_count": 2, "name": "groupby.TransformEngine.time_dataframe_cython", "number": 0, "param_names": ["parallel"], "params": [["True", "False"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "d0c83497327280f78a5062c9717764f36483b50943b5eb9fe60025ca086edb53", "warmup_time": -1}, "groupby.TransformEngine.time_dataframe_numba": {"code": "class TransformEngine:\n    def time_dataframe_numba(self, parallel):\n        def function(values, index):\n            return values * 5\n    \n        self.grouper.transform(\n            function, engine=\"numba\", engine_kwargs={\"parallel\": self.parallel}\n        )\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass TransformEngine:\n    def setup(self, parallel):\n        N = 10**3\n        data = DataFrame(\n            {0: [str(i) for i in range(100)] * N, 1: list(range(100)) * N},\n            columns=[0, 1],\n        )\n        self.parallel = parallel\n        self.grouper = data.groupby(0)", "min_run_count": 2, "name": "groupby.TransformEngine.time_dataframe_numba", "number": 0, "param_names": ["parallel"], "params": [["True", "False"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "146b7844bad06cc92400f5337ad2abbbb2ef4e7262b9ecf7bf2f369e08df9e5c", "warmup_time": -1}, "groupby.TransformEngine.time_series_cython": {"code": "class TransformEngine:\n    def time_series_cython(self, parallel):\n        def function(values):\n            return values * 5\n    \n        self.grouper[1].transform(function, engine=\"cython\")\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass TransformEngine:\n    def setup(self, parallel):\n        N = 10**3\n        data = DataFrame(\n            {0: [str(i) for i in range(100)] * N, 1: list(range(100)) * N},\n            columns=[0, 1],\n        )\n        self.parallel = parallel\n        self.grouper = data.groupby(0)", "min_run_count": 2, "name": "groupby.TransformEngine.time_series_cython", "number": 0, "param_names": ["parallel"], "params": [["True", "False"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "2826562b07220b11d0e02a233f43f754b8f9b1b0dbed50ca3f2b3bf25b71995d", "warmup_time": -1}, "groupby.TransformEngine.time_series_numba": {"code": "class TransformEngine:\n    def time_series_numba(self, parallel):\n        def function(values, index):\n            return values * 5\n    \n        self.grouper[1].transform(\n            function, engine=\"numba\", engine_kwargs={\"parallel\": self.parallel}\n        )\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass TransformEngine:\n    def setup(self, parallel):\n        N = 10**3\n        data = DataFrame(\n            {0: [str(i) for i in range(100)] * N, 1: list(range(100)) * N},\n            columns=[0, 1],\n        )\n        self.parallel = parallel\n        self.grouper = data.groupby(0)", "min_run_count": 2, "name": "groupby.TransformEngine.time_series_numba", "number": 0, "param_names": ["parallel"], "params": [["True", "False"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "b20f5b20c80e1abd068634154b292c0cc05eaed4af84c3f95bdd4fb09e654937", "warmup_time": -1}, "groupby.TransformNaN.time_first": {"code": "class TransformNaN:\n    def time_first(self):\n        self.df_nans.groupby(\"key\").transform(\"first\")\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass TransformNaN:\n    def setup(self):\n        self.df_nans = DataFrame(\n            {\"key\": np.repeat(np.arange(1000), 10), \"B\": np.nan, \"C\": np.nan}\n        )\n        self.df_nans.loc[4::10, \"B\":\"C\"] = 5", "min_run_count": 2, "name": "groupby.TransformNaN.time_first", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "466258ae973db79b6c4ae80572d3424a11b6997e4ab98b9751eb9a5d30f468e8", "warmup_time": -1}, "hash_functions.Float64GroupIndex.time_groupby": {"code": "class Float64GroupIndex:\n    def time_groupby(self):\n        self.df.groupby(self.group_index).last()\n\n    def setup(self):\n        self.df = pd.date_range(\n            start=\"1/1/2018\", end=\"1/2/2018\", periods=10**6\n        ).to_frame()\n        self.group_index = np.round(self.df.index.astype(int) / 10**9)", "min_run_count": 2, "name": "hash_functions.Float64GroupIndex.time_groupby", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "16fa99f7d4871f73a649b4eb9085ebd39124ac1b6451a2321c9fb1e2792d9569", "warmup_time": -1}, "hash_functions.NumericSeriesIndexing.time_loc_slice": {"code": "class NumericSeriesIndexing:\n    def time_loc_slice(self, index, N):\n        # trigger building of mapping\n        self.data.loc[:800]\n\n    def setup(self, dtype, N):\n        vals = np.array(list(range(55)) + [54] + list(range(55, N - 1)), dtype=dtype)\n        indices = pd.Index(vals)\n        self.data = pd.Series(np.arange(N), index=indices)", "min_run_count": 2, "name": "hash_functions.NumericSeriesIndexing.time_loc_slice", "number": 0, "param_names": ["dtype", "N"], "params": [["<class 'numpy.int64'>", "<class 'numpy.uint64'>", "<class 'numpy.float64'>"], ["10000", "100000", "500000", "1000000", "5000000"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "bbd9b15d7f65d1d2a57335626da432a02c7db5e70cbd8098c13b4e3d4b391802", "warmup_time": -1}, "hash_functions.NumericSeriesIndexingShuffled.time_loc_slice": {"code": "class NumericSeriesIndexingShuffled:\n    def time_loc_slice(self, index, N):\n        # trigger building of mapping\n        self.data.loc[:800]\n\n    def setup(self, dtype, N):\n        vals = np.array(list(range(55)) + [54] + list(range(55, N - 1)), dtype=dtype)\n        np.random.shuffle(vals)\n        indices = pd.Index(vals)\n        self.data = pd.Series(np.arange(N), index=indices)", "min_run_count": 2, "name": "hash_functions.NumericSeriesIndexingShuffled.time_loc_slice", "number": 0, "param_names": ["dtype", "N"], "params": [["<class 'numpy.int64'>", "<class 'numpy.uint64'>", "<class 'numpy.float64'>"], ["10000", "100000", "500000", "1000000", "5000000"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "432c7f2c138c103e14be8ce799b1975974eeda009197320865b48b0310220376", "warmup_time": -1}, "hash_functions.Unique.time_unique": {"code": "class Unique:\n    def time_unique(self, exponent):\n        pd.unique(self.ser_unique)\n\n    def setup(self, dtype):\n        self.ser = pd.Series(([1, pd.NA, 2] + list(range(100_000))) * 3, dtype=dtype)\n        self.ser_unique = pd.Series(list(range(300_000)) + [pd.NA], dtype=dtype)", "min_run_count": 2, "name": "hash_functions.Unique.time_unique", "number": 0, "param_names": ["dtype"], "params": [["'Int64'", "'Float64'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "b4e9501a2d788652cf742d899e45ee6697865981d8caebbc02b5c662b0207edf", "warmup_time": -1}, "hash_functions.Unique.time_unique_with_duplicates": {"code": "class Unique:\n    def time_unique_with_duplicates(self, exponent):\n        pd.unique(self.ser)\n\n    def setup(self, dtype):\n        self.ser = pd.Series(([1, pd.NA, 2] + list(range(100_000))) * 3, dtype=dtype)\n        self.ser_unique = pd.Series(list(range(300_000)) + [pd.NA], dtype=dtype)", "min_run_count": 2, "name": "hash_functions.Unique.time_unique_with_duplicates", "number": 0, "param_names": ["dtype"], "params": [["'Int64'", "'Float64'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "167e56c7e4063b7bb8cad24ce741ad07d7714185a453ada8f9296eb9acf885af", "warmup_time": -1}, "hash_functions.UniqueAndFactorizeArange.time_factorize": {"code": "class UniqueAndFactorizeArange:\n    def time_factorize(self, exponent):\n        pd.factorize(self.a2)\n\n    def setup(self, exponent):\n        a = np.arange(10**4, dtype=\"float64\")\n        self.a2 = (a + 10**exponent).repeat(100)", "min_run_count": 2, "name": "hash_functions.UniqueAndFactorizeArange.time_factorize", "number": 0, "param_names": ["exponent"], "params": [["4", "5", "6", "7", "8", "9", "10", "11", "12", "13", "14", "15"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "0f26f4d8f2608aa8c5a85a0f06b3d3035de285c9a423a8f0f98688da07c40443", "warmup_time": -1}, "hash_functions.UniqueAndFactorizeArange.time_unique": {"code": "class UniqueAndFactorizeArange:\n    def time_unique(self, exponent):\n        pd.unique(self.a2)\n\n    def setup(self, exponent):\n        a = np.arange(10**4, dtype=\"float64\")\n        self.a2 = (a + 10**exponent).repeat(100)", "min_run_count": 2, "name": "hash_functions.UniqueAndFactorizeArange.time_unique", "number": 0, "param_names": ["exponent"], "params": [["4", "5", "6", "7", "8", "9", "10", "11", "12", "13", "14", "15"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "871707976cd021a306828a6723cac7ae71087078cf1b78c6d17c352b6b600d9c", "warmup_time": -1}, "hash_functions.UniqueForLargePyObjectInts.time_unique": {"code": "class UniqueForLargePyObjectInts:\n    def time_unique(self):\n        pd.unique(self.arr)\n\n    def setup(self):\n        lst = [x << 32 for x in range(5000)]\n        self.arr = np.array(lst, dtype=np.object_)", "min_run_count": 2, "name": "hash_functions.UniqueForLargePyObjectInts.time_unique", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "2b911217a8295551fd862ba4e9a94107678d903c84a5a197b90acce421e6f8c6", "warmup_time": -1}, "index_cached_properties.IndexCache.time_engine": {"code": "class IndexCache:\n    def time_engine(self, index_type):\n        self.idx._engine\n\n    def setup(self, index_type):\n        N = 10**5\n        if index_type == \"MultiIndex\":\n            self.idx = pd.MultiIndex.from_product(\n                [pd.date_range(\"1/1/2000\", freq=\"T\", periods=N // 2), [\"a\", \"b\"]]\n            )\n        elif index_type == \"DatetimeIndex\":\n            self.idx = pd.date_range(\"1/1/2000\", freq=\"T\", periods=N)\n        elif index_type == \"Int64Index\":\n            self.idx = pd.Index(range(N), dtype=\"int64\")\n        elif index_type == \"PeriodIndex\":\n            self.idx = pd.period_range(\"1/1/2000\", freq=\"T\", periods=N)\n        elif index_type == \"RangeIndex\":\n            self.idx = pd.RangeIndex(start=0, stop=N)\n        elif index_type == \"IntervalIndex\":\n            self.idx = pd.IntervalIndex.from_arrays(range(N), range(1, N + 1))\n        elif index_type == \"TimedeltaIndex\":\n            self.idx = pd.TimedeltaIndex(range(N))\n        elif index_type == \"Float64Index\":\n            self.idx = pd.Index(range(N), dtype=\"float64\")\n        elif index_type == \"UInt64Index\":\n            self.idx = pd.Index(range(N), dtype=\"uint64\")\n        elif index_type == \"CategoricalIndex\":\n            self.idx = pd.CategoricalIndex(range(N), range(N))\n        else:\n            raise ValueError\n        assert len(self.idx) == N\n        self.idx._cache = {}", "min_run_count": 2, "name": "index_cached_properties.IndexCache.time_engine", "number": 1, "param_names": ["index_type"], "params": [["'CategoricalIndex'", "'DatetimeIndex'", "'Float64Index'", "'IntervalIndex'", "'Int64Index'", "'MultiIndex'", "'PeriodIndex'", "'RangeIndex'", "'TimedeltaIndex'", "'UInt64Index'"]], "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "8e9dda3b39980f45b6eb50af9079bd7604382cee3a62dd2ef044c22e8d3a1f8b", "warmup_time": -1}, "index_cached_properties.IndexCache.time_inferred_type": {"code": "class IndexCache:\n    def time_inferred_type(self, index_type):\n        self.idx.inferred_type\n\n    def setup(self, index_type):\n        N = 10**5\n        if index_type == \"MultiIndex\":\n            self.idx = pd.MultiIndex.from_product(\n                [pd.date_range(\"1/1/2000\", freq=\"T\", periods=N // 2), [\"a\", \"b\"]]\n            )\n        elif index_type == \"DatetimeIndex\":\n            self.idx = pd.date_range(\"1/1/2000\", freq=\"T\", periods=N)\n        elif index_type == \"Int64Index\":\n            self.idx = pd.Index(range(N), dtype=\"int64\")\n        elif index_type == \"PeriodIndex\":\n            self.idx = pd.period_range(\"1/1/2000\", freq=\"T\", periods=N)\n        elif index_type == \"RangeIndex\":\n            self.idx = pd.RangeIndex(start=0, stop=N)\n        elif index_type == \"IntervalIndex\":\n            self.idx = pd.IntervalIndex.from_arrays(range(N), range(1, N + 1))\n        elif index_type == \"TimedeltaIndex\":\n            self.idx = pd.TimedeltaIndex(range(N))\n        elif index_type == \"Float64Index\":\n            self.idx = pd.Index(range(N), dtype=\"float64\")\n        elif index_type == \"UInt64Index\":\n            self.idx = pd.Index(range(N), dtype=\"uint64\")\n        elif index_type == \"CategoricalIndex\":\n            self.idx = pd.CategoricalIndex(range(N), range(N))\n        else:\n            raise ValueError\n        assert len(self.idx) == N\n        self.idx._cache = {}", "min_run_count": 2, "name": "index_cached_properties.IndexCache.time_inferred_type", "number": 1, "param_names": ["index_type"], "params": [["'CategoricalIndex'", "'DatetimeIndex'", "'Float64Index'", "'IntervalIndex'", "'Int64Index'", "'MultiIndex'", "'PeriodIndex'", "'RangeIndex'", "'TimedeltaIndex'", "'UInt64Index'"]], "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "62c60e95ab89be9c87e36aeccadca732a6d9d26e1027c77230ee19e549abdd37", "warmup_time": -1}, "index_cached_properties.IndexCache.time_is_monotonic_decreasing": {"code": "class IndexCache:\n    def time_is_monotonic_decreasing(self, index_type):\n        self.idx.is_monotonic_decreasing\n\n    def setup(self, index_type):\n        N = 10**5\n        if index_type == \"MultiIndex\":\n            self.idx = pd.MultiIndex.from_product(\n                [pd.date_range(\"1/1/2000\", freq=\"T\", periods=N // 2), [\"a\", \"b\"]]\n            )\n        elif index_type == \"DatetimeIndex\":\n            self.idx = pd.date_range(\"1/1/2000\", freq=\"T\", periods=N)\n        elif index_type == \"Int64Index\":\n            self.idx = pd.Index(range(N), dtype=\"int64\")\n        elif index_type == \"PeriodIndex\":\n            self.idx = pd.period_range(\"1/1/2000\", freq=\"T\", periods=N)\n        elif index_type == \"RangeIndex\":\n            self.idx = pd.RangeIndex(start=0, stop=N)\n        elif index_type == \"IntervalIndex\":\n            self.idx = pd.IntervalIndex.from_arrays(range(N), range(1, N + 1))\n        elif index_type == \"TimedeltaIndex\":\n            self.idx = pd.TimedeltaIndex(range(N))\n        elif index_type == \"Float64Index\":\n            self.idx = pd.Index(range(N), dtype=\"float64\")\n        elif index_type == \"UInt64Index\":\n            self.idx = pd.Index(range(N), dtype=\"uint64\")\n        elif index_type == \"CategoricalIndex\":\n            self.idx = pd.CategoricalIndex(range(N), range(N))\n        else:\n            raise ValueError\n        assert len(self.idx) == N\n        self.idx._cache = {}", "min_run_count": 2, "name": "index_cached_properties.IndexCache.time_is_monotonic_decreasing", "number": 1, "param_names": ["index_type"], "params": [["'CategoricalIndex'", "'DatetimeIndex'", "'Float64Index'", "'IntervalIndex'", "'Int64Index'", "'MultiIndex'", "'PeriodIndex'", "'RangeIndex'", "'TimedeltaIndex'", "'UInt64Index'"]], "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "17bf01354a3cd0aaa62a112f467102a03d6ef09a961544ab37f640910ea12f7d", "warmup_time": -1}, "index_cached_properties.IndexCache.time_is_monotonic_increasing": {"code": "class IndexCache:\n    def time_is_monotonic_increasing(self, index_type):\n        self.idx.is_monotonic_increasing\n\n    def setup(self, index_type):\n        N = 10**5\n        if index_type == \"MultiIndex\":\n            self.idx = pd.MultiIndex.from_product(\n                [pd.date_range(\"1/1/2000\", freq=\"T\", periods=N // 2), [\"a\", \"b\"]]\n            )\n        elif index_type == \"DatetimeIndex\":\n            self.idx = pd.date_range(\"1/1/2000\", freq=\"T\", periods=N)\n        elif index_type == \"Int64Index\":\n            self.idx = pd.Index(range(N), dtype=\"int64\")\n        elif index_type == \"PeriodIndex\":\n            self.idx = pd.period_range(\"1/1/2000\", freq=\"T\", periods=N)\n        elif index_type == \"RangeIndex\":\n            self.idx = pd.RangeIndex(start=0, stop=N)\n        elif index_type == \"IntervalIndex\":\n            self.idx = pd.IntervalIndex.from_arrays(range(N), range(1, N + 1))\n        elif index_type == \"TimedeltaIndex\":\n            self.idx = pd.TimedeltaIndex(range(N))\n        elif index_type == \"Float64Index\":\n            self.idx = pd.Index(range(N), dtype=\"float64\")\n        elif index_type == \"UInt64Index\":\n            self.idx = pd.Index(range(N), dtype=\"uint64\")\n        elif index_type == \"CategoricalIndex\":\n            self.idx = pd.CategoricalIndex(range(N), range(N))\n        else:\n            raise ValueError\n        assert len(self.idx) == N\n        self.idx._cache = {}", "min_run_count": 2, "name": "index_cached_properties.IndexCache.time_is_monotonic_increasing", "number": 1, "param_names": ["index_type"], "params": [["'CategoricalIndex'", "'DatetimeIndex'", "'Float64Index'", "'IntervalIndex'", "'Int64Index'", "'MultiIndex'", "'PeriodIndex'", "'RangeIndex'", "'TimedeltaIndex'", "'UInt64Index'"]], "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "94690e2445820b49533e86ed15dc733215d86c80fefec5be7ae535f1550e4001", "warmup_time": -1}, "index_cached_properties.IndexCache.time_is_unique": {"code": "class IndexCache:\n    def time_is_unique(self, index_type):\n        self.idx.is_unique\n\n    def setup(self, index_type):\n        N = 10**5\n        if index_type == \"MultiIndex\":\n            self.idx = pd.MultiIndex.from_product(\n                [pd.date_range(\"1/1/2000\", freq=\"T\", periods=N // 2), [\"a\", \"b\"]]\n            )\n        elif index_type == \"DatetimeIndex\":\n            self.idx = pd.date_range(\"1/1/2000\", freq=\"T\", periods=N)\n        elif index_type == \"Int64Index\":\n            self.idx = pd.Index(range(N), dtype=\"int64\")\n        elif index_type == \"PeriodIndex\":\n            self.idx = pd.period_range(\"1/1/2000\", freq=\"T\", periods=N)\n        elif index_type == \"RangeIndex\":\n            self.idx = pd.RangeIndex(start=0, stop=N)\n        elif index_type == \"IntervalIndex\":\n            self.idx = pd.IntervalIndex.from_arrays(range(N), range(1, N + 1))\n        elif index_type == \"TimedeltaIndex\":\n            self.idx = pd.TimedeltaIndex(range(N))\n        elif index_type == \"Float64Index\":\n            self.idx = pd.Index(range(N), dtype=\"float64\")\n        elif index_type == \"UInt64Index\":\n            self.idx = pd.Index(range(N), dtype=\"uint64\")\n        elif index_type == \"CategoricalIndex\":\n            self.idx = pd.CategoricalIndex(range(N), range(N))\n        else:\n            raise ValueError\n        assert len(self.idx) == N\n        self.idx._cache = {}", "min_run_count": 2, "name": "index_cached_properties.IndexCache.time_is_unique", "number": 1, "param_names": ["index_type"], "params": [["'CategoricalIndex'", "'DatetimeIndex'", "'Float64Index'", "'IntervalIndex'", "'Int64Index'", "'MultiIndex'", "'PeriodIndex'", "'RangeIndex'", "'TimedeltaIndex'", "'UInt64Index'"]], "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "3148700ed858c0dc6a21fd4ca60e6108fccb63e0d22a91dfb5dcefac0f11b727", "warmup_time": -1}, "index_cached_properties.IndexCache.time_shape": {"code": "class IndexCache:\n    def time_shape(self, index_type):\n        self.idx.shape\n\n    def setup(self, index_type):\n        N = 10**5\n        if index_type == \"MultiIndex\":\n            self.idx = pd.MultiIndex.from_product(\n                [pd.date_range(\"1/1/2000\", freq=\"T\", periods=N // 2), [\"a\", \"b\"]]\n            )\n        elif index_type == \"DatetimeIndex\":\n            self.idx = pd.date_range(\"1/1/2000\", freq=\"T\", periods=N)\n        elif index_type == \"Int64Index\":\n            self.idx = pd.Index(range(N), dtype=\"int64\")\n        elif index_type == \"PeriodIndex\":\n            self.idx = pd.period_range(\"1/1/2000\", freq=\"T\", periods=N)\n        elif index_type == \"RangeIndex\":\n            self.idx = pd.RangeIndex(start=0, stop=N)\n        elif index_type == \"IntervalIndex\":\n            self.idx = pd.IntervalIndex.from_arrays(range(N), range(1, N + 1))\n        elif index_type == \"TimedeltaIndex\":\n            self.idx = pd.TimedeltaIndex(range(N))\n        elif index_type == \"Float64Index\":\n            self.idx = pd.Index(range(N), dtype=\"float64\")\n        elif index_type == \"UInt64Index\":\n            self.idx = pd.Index(range(N), dtype=\"uint64\")\n        elif index_type == \"CategoricalIndex\":\n            self.idx = pd.CategoricalIndex(range(N), range(N))\n        else:\n            raise ValueError\n        assert len(self.idx) == N\n        self.idx._cache = {}", "min_run_count": 2, "name": "index_cached_properties.IndexCache.time_shape", "number": 1, "param_names": ["index_type"], "params": [["'CategoricalIndex'", "'DatetimeIndex'", "'Float64Index'", "'IntervalIndex'", "'Int64Index'", "'MultiIndex'", "'PeriodIndex'", "'RangeIndex'", "'TimedeltaIndex'", "'UInt64Index'"]], "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "a7518e70ad92adc4511c1a591e51e29935c63f68584fd4a712ceabf1e6441815", "warmup_time": -1}, "index_cached_properties.IndexCache.time_values": {"code": "class IndexCache:\n    def time_values(self, index_type):\n        self.idx._values\n\n    def setup(self, index_type):\n        N = 10**5\n        if index_type == \"MultiIndex\":\n            self.idx = pd.MultiIndex.from_product(\n                [pd.date_range(\"1/1/2000\", freq=\"T\", periods=N // 2), [\"a\", \"b\"]]\n            )\n        elif index_type == \"DatetimeIndex\":\n            self.idx = pd.date_range(\"1/1/2000\", freq=\"T\", periods=N)\n        elif index_type == \"Int64Index\":\n            self.idx = pd.Index(range(N), dtype=\"int64\")\n        elif index_type == \"PeriodIndex\":\n            self.idx = pd.period_range(\"1/1/2000\", freq=\"T\", periods=N)\n        elif index_type == \"RangeIndex\":\n            self.idx = pd.RangeIndex(start=0, stop=N)\n        elif index_type == \"IntervalIndex\":\n            self.idx = pd.IntervalIndex.from_arrays(range(N), range(1, N + 1))\n        elif index_type == \"TimedeltaIndex\":\n            self.idx = pd.TimedeltaIndex(range(N))\n        elif index_type == \"Float64Index\":\n            self.idx = pd.Index(range(N), dtype=\"float64\")\n        elif index_type == \"UInt64Index\":\n            self.idx = pd.Index(range(N), dtype=\"uint64\")\n        elif index_type == \"CategoricalIndex\":\n            self.idx = pd.CategoricalIndex(range(N), range(N))\n        else:\n            raise ValueError\n        assert len(self.idx) == N\n        self.idx._cache = {}", "min_run_count": 2, "name": "index_cached_properties.IndexCache.time_values", "number": 1, "param_names": ["index_type"], "params": [["'CategoricalIndex'", "'DatetimeIndex'", "'Float64Index'", "'IntervalIndex'", "'Int64Index'", "'MultiIndex'", "'PeriodIndex'", "'RangeIndex'", "'TimedeltaIndex'", "'UInt64Index'"]], "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "6b6630ecbc8e3b3db98ee87bd7310c8c8587c6342d3cbd14f305f0cb6145338d", "warmup_time": -1}, "index_object.Float64IndexMethod.time_get_loc": {"code": "class Float64IndexMethod:\n    def time_get_loc(self):\n        self.ind.get_loc(0)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Float64IndexMethod:\n    def setup(self):\n        N = 100_000\n        a = np.arange(N, dtype=np.float64)\n        self.ind = Index(a * 4.8000000418824129e-08)", "min_run_count": 2, "name": "index_object.Float64IndexMethod.time_get_loc", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "95061ed30b62c0b9d9cf95faffe63e95be78a617811548ad955f451532cb0fba", "warmup_time": -1}, "index_object.GC.peakmem_gc_instances": {"code": "class GC:\n    def peakmem_gc_instances(self, N):\n        try:\n            gc.disable()\n    \n            for _ in range(N):\n                self.create_use_drop()\n        finally:\n            gc.enable()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)", "name": "index_object.GC.peakmem_gc_instances", "param_names": ["param1"], "params": [["1", "2", "5"]], "timeout": 60.0, "type": "peakmemory", "unit": "bytes", "version": "7b1c36ff9e60323ef8e4df7fa94a4764bdb5c6dce62bfea0095812ca55841ff9"}, "index_object.IndexAppend.time_append_int_list": {"code": "class IndexAppend:\n    def time_append_int_list(self):\n        self.int_idx.append(self.int_idxs)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass IndexAppend:\n    def setup(self):\n        N = 10_000\n        self.range_idx = RangeIndex(0, 100)\n        self.int_idx = self.range_idx.astype(int)\n        self.obj_idx = self.int_idx.astype(str)\n        self.range_idxs = []\n        self.int_idxs = []\n        self.object_idxs = []\n        for i in range(1, N):\n            r_idx = RangeIndex(i * 100, (i + 1) * 100)\n            self.range_idxs.append(r_idx)\n            i_idx = r_idx.astype(int)\n            self.int_idxs.append(i_idx)\n            o_idx = i_idx.astype(str)\n            self.object_idxs.append(o_idx)", "min_run_count": 2, "name": "index_object.IndexAppend.time_append_int_list", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "05fbabe6fe601e117cf15506b123c19243307543aaa4062209fd2b93e36972e4", "warmup_time": -1}, "index_object.IndexAppend.time_append_obj_list": {"code": "class IndexAppend:\n    def time_append_obj_list(self):\n        self.obj_idx.append(self.object_idxs)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass IndexAppend:\n    def setup(self):\n        N = 10_000\n        self.range_idx = RangeIndex(0, 100)\n        self.int_idx = self.range_idx.astype(int)\n        self.obj_idx = self.int_idx.astype(str)\n        self.range_idxs = []\n        self.int_idxs = []\n        self.object_idxs = []\n        for i in range(1, N):\n            r_idx = RangeIndex(i * 100, (i + 1) * 100)\n            self.range_idxs.append(r_idx)\n            i_idx = r_idx.astype(int)\n            self.int_idxs.append(i_idx)\n            o_idx = i_idx.astype(str)\n            self.object_idxs.append(o_idx)", "min_run_count": 2, "name": "index_object.IndexAppend.time_append_obj_list", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "e802d94288d6fa85899782962dad0555c60caee495dcba93d82528d11d820caf", "warmup_time": -1}, "index_object.IndexAppend.time_append_range_list": {"code": "class IndexAppend:\n    def time_append_range_list(self):\n        self.range_idx.append(self.range_idxs)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass IndexAppend:\n    def setup(self):\n        N = 10_000\n        self.range_idx = RangeIndex(0, 100)\n        self.int_idx = self.range_idx.astype(int)\n        self.obj_idx = self.int_idx.astype(str)\n        self.range_idxs = []\n        self.int_idxs = []\n        self.object_idxs = []\n        for i in range(1, N):\n            r_idx = RangeIndex(i * 100, (i + 1) * 100)\n            self.range_idxs.append(r_idx)\n            i_idx = r_idx.astype(int)\n            self.int_idxs.append(i_idx)\n            o_idx = i_idx.astype(str)\n            self.object_idxs.append(o_idx)", "min_run_count": 2, "name": "index_object.IndexAppend.time_append_range_list", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "ce33d2de0a76a2454729de45db0e290dc82287e0866a615650e848ff37e4ba88", "warmup_time": -1}, "index_object.IndexEquals.time_non_object_equals_multiindex": {"code": "class IndexEquals:\n    def time_non_object_equals_multiindex(self):\n        self.idx_non_object.equals(self.mi_large_slow)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass IndexEquals:\n    def setup(self):\n        idx_large_fast = RangeIndex(100_000)\n        idx_small_slow = date_range(start=\"1/1/2012\", periods=1)\n        self.mi_large_slow = MultiIndex.from_product([idx_large_fast, idx_small_slow])\n    \n        self.idx_non_object = RangeIndex(1)", "min_run_count": 2, "name": "index_object.IndexEquals.time_non_object_equals_multiindex", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "bc0a852a1647f5faba1ff3d27b24d6f703432910d3e11571a9d33ab853b195fe", "warmup_time": -1}, "index_object.Indexing.time_boolean_array": {"code": "class Indexing:\n    def time_boolean_array(self, dtype):\n        self.idx[self.array_mask]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Indexing:\n    def setup(self, dtype):\n        N = 10**6\n        self.idx = getattr(tm, f\"make{dtype}Index\")(N)\n        self.array_mask = (np.arange(N) % 3) == 0\n        self.series_mask = Series(self.array_mask)\n        self.sorted = self.idx.sort_values()\n        half = N // 2\n        self.non_unique = self.idx[:half].append(self.idx[:half])\n        self.non_unique_sorted = (\n            self.sorted[:half].append(self.sorted[:half]).sort_values()\n        )\n        self.key = self.sorted[N // 4]", "min_run_count": 2, "name": "index_object.Indexing.time_boolean_array", "number": 0, "param_names": ["dtype"], "params": [["'String'", "'Float'", "'Int'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "4a2a40296b05687450fe7a058558d81618ba0ca324787be472021133435b41a8", "warmup_time": -1}, "index_object.Indexing.time_boolean_series": {"code": "class Indexing:\n    def time_boolean_series(self, dtype):\n        self.idx[self.series_mask]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Indexing:\n    def setup(self, dtype):\n        N = 10**6\n        self.idx = getattr(tm, f\"make{dtype}Index\")(N)\n        self.array_mask = (np.arange(N) % 3) == 0\n        self.series_mask = Series(self.array_mask)\n        self.sorted = self.idx.sort_values()\n        half = N // 2\n        self.non_unique = self.idx[:half].append(self.idx[:half])\n        self.non_unique_sorted = (\n            self.sorted[:half].append(self.sorted[:half]).sort_values()\n        )\n        self.key = self.sorted[N // 4]", "min_run_count": 2, "name": "index_object.Indexing.time_boolean_series", "number": 0, "param_names": ["dtype"], "params": [["'String'", "'Float'", "'Int'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "bd26ce26f520d7416befa7fda9bb4de6ca3330ce0063e4054dd12aaf2187fb84", "warmup_time": -1}, "index_object.Indexing.time_get": {"code": "class Indexing:\n    def time_get(self, dtype):\n        self.idx[1]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Indexing:\n    def setup(self, dtype):\n        N = 10**6\n        self.idx = getattr(tm, f\"make{dtype}Index\")(N)\n        self.array_mask = (np.arange(N) % 3) == 0\n        self.series_mask = Series(self.array_mask)\n        self.sorted = self.idx.sort_values()\n        half = N // 2\n        self.non_unique = self.idx[:half].append(self.idx[:half])\n        self.non_unique_sorted = (\n            self.sorted[:half].append(self.sorted[:half]).sort_values()\n        )\n        self.key = self.sorted[N // 4]", "min_run_count": 2, "name": "index_object.Indexing.time_get", "number": 0, "param_names": ["dtype"], "params": [["'String'", "'Float'", "'Int'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "78d9c06e1f05c755a8e47a94d43beac1c7421ac472c7bdc912ae34f62f4ea6d1", "warmup_time": -1}, "index_object.Indexing.time_get_loc": {"code": "class Indexing:\n    def time_get_loc(self, dtype):\n        self.idx.get_loc(self.key)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Indexing:\n    def setup(self, dtype):\n        N = 10**6\n        self.idx = getattr(tm, f\"make{dtype}Index\")(N)\n        self.array_mask = (np.arange(N) % 3) == 0\n        self.series_mask = Series(self.array_mask)\n        self.sorted = self.idx.sort_values()\n        half = N // 2\n        self.non_unique = self.idx[:half].append(self.idx[:half])\n        self.non_unique_sorted = (\n            self.sorted[:half].append(self.sorted[:half]).sort_values()\n        )\n        self.key = self.sorted[N // 4]", "min_run_count": 2, "name": "index_object.Indexing.time_get_loc", "number": 0, "param_names": ["dtype"], "params": [["'String'", "'Float'", "'Int'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "9e0895288a7a9db29afd54fc5a71db2ced992db50939440ba2dffb3799250309", "warmup_time": -1}, "index_object.Indexing.time_get_loc_non_unique": {"code": "class Indexing:\n    def time_get_loc_non_unique(self, dtype):\n        self.non_unique.get_loc(self.key)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Indexing:\n    def setup(self, dtype):\n        N = 10**6\n        self.idx = getattr(tm, f\"make{dtype}Index\")(N)\n        self.array_mask = (np.arange(N) % 3) == 0\n        self.series_mask = Series(self.array_mask)\n        self.sorted = self.idx.sort_values()\n        half = N // 2\n        self.non_unique = self.idx[:half].append(self.idx[:half])\n        self.non_unique_sorted = (\n            self.sorted[:half].append(self.sorted[:half]).sort_values()\n        )\n        self.key = self.sorted[N // 4]", "min_run_count": 2, "name": "index_object.Indexing.time_get_loc_non_unique", "number": 0, "param_names": ["dtype"], "params": [["'String'", "'Float'", "'Int'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "7bda4a3210d429592167c485fd10d0628a5025eb43839ef0c934c86454e6ae50", "warmup_time": -1}, "index_object.Indexing.time_get_loc_non_unique_sorted": {"code": "class Indexing:\n    def time_get_loc_non_unique_sorted(self, dtype):\n        self.non_unique_sorted.get_loc(self.key)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Indexing:\n    def setup(self, dtype):\n        N = 10**6\n        self.idx = getattr(tm, f\"make{dtype}Index\")(N)\n        self.array_mask = (np.arange(N) % 3) == 0\n        self.series_mask = Series(self.array_mask)\n        self.sorted = self.idx.sort_values()\n        half = N // 2\n        self.non_unique = self.idx[:half].append(self.idx[:half])\n        self.non_unique_sorted = (\n            self.sorted[:half].append(self.sorted[:half]).sort_values()\n        )\n        self.key = self.sorted[N // 4]", "min_run_count": 2, "name": "index_object.Indexing.time_get_loc_non_unique_sorted", "number": 0, "param_names": ["dtype"], "params": [["'String'", "'Float'", "'Int'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "f2740cd11bbd6869f5ad91ab7a52b9024a51feb3cff2696dec7692830ea32a39", "warmup_time": -1}, "index_object.Indexing.time_get_loc_sorted": {"code": "class Indexing:\n    def time_get_loc_sorted(self, dtype):\n        self.sorted.get_loc(self.key)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Indexing:\n    def setup(self, dtype):\n        N = 10**6\n        self.idx = getattr(tm, f\"make{dtype}Index\")(N)\n        self.array_mask = (np.arange(N) % 3) == 0\n        self.series_mask = Series(self.array_mask)\n        self.sorted = self.idx.sort_values()\n        half = N // 2\n        self.non_unique = self.idx[:half].append(self.idx[:half])\n        self.non_unique_sorted = (\n            self.sorted[:half].append(self.sorted[:half]).sort_values()\n        )\n        self.key = self.sorted[N // 4]", "min_run_count": 2, "name": "index_object.Indexing.time_get_loc_sorted", "number": 0, "param_names": ["dtype"], "params": [["'String'", "'Float'", "'Int'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "55ad49fff96e1250cec4719a0c5f8c56191695beb79649a8ac4aa5af798c2c2e", "warmup_time": -1}, "index_object.Indexing.time_slice": {"code": "class Indexing:\n    def time_slice(self, dtype):\n        self.idx[:-1]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Indexing:\n    def setup(self, dtype):\n        N = 10**6\n        self.idx = getattr(tm, f\"make{dtype}Index\")(N)\n        self.array_mask = (np.arange(N) % 3) == 0\n        self.series_mask = Series(self.array_mask)\n        self.sorted = self.idx.sort_values()\n        half = N // 2\n        self.non_unique = self.idx[:half].append(self.idx[:half])\n        self.non_unique_sorted = (\n            self.sorted[:half].append(self.sorted[:half]).sort_values()\n        )\n        self.key = self.sorted[N // 4]", "min_run_count": 2, "name": "index_object.Indexing.time_slice", "number": 0, "param_names": ["dtype"], "params": [["'String'", "'Float'", "'Int'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "efa3a38ca2330e01288e336717bb3dfecca823b71849236bb21fb74b23e48bfd", "warmup_time": -1}, "index_object.Indexing.time_slice_step": {"code": "class Indexing:\n    def time_slice_step(self, dtype):\n        self.idx[::2]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Indexing:\n    def setup(self, dtype):\n        N = 10**6\n        self.idx = getattr(tm, f\"make{dtype}Index\")(N)\n        self.array_mask = (np.arange(N) % 3) == 0\n        self.series_mask = Series(self.array_mask)\n        self.sorted = self.idx.sort_values()\n        half = N // 2\n        self.non_unique = self.idx[:half].append(self.idx[:half])\n        self.non_unique_sorted = (\n            self.sorted[:half].append(self.sorted[:half]).sort_values()\n        )\n        self.key = self.sorted[N // 4]", "min_run_count": 2, "name": "index_object.Indexing.time_slice_step", "number": 0, "param_names": ["dtype"], "params": [["'String'", "'Float'", "'Int'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "4699d30b971025d741693c863310dd33d83182db3461044cf71c4655221007ac", "warmup_time": -1}, "index_object.IntervalIndexMethod.time_intersection": {"code": "class IntervalIndexMethod:\n    def time_intersection(self, N):\n        self.left.intersection(self.right)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass IntervalIndexMethod:\n    def setup(self, N):\n        left = np.append(np.arange(N), np.array(0))\n        right = np.append(np.arange(1, N + 1), np.array(1))\n        self.intv = IntervalIndex.from_arrays(left, right)\n        self.intv._engine\n    \n        self.intv2 = IntervalIndex.from_arrays(left + 1, right + 1)\n        self.intv2._engine\n    \n        self.left = IntervalIndex.from_breaks(np.arange(N))\n        self.right = IntervalIndex.from_breaks(np.arange(N - 3, 2 * N - 3))", "min_run_count": 2, "name": "index_object.IntervalIndexMethod.time_intersection", "number": 0, "param_names": ["param1"], "params": [["1000", "100000"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "4211da5ac938e20dc8e3ebad85e3fd809e9b9485898f7bc9fa4b78bf51836ba1", "warmup_time": -1}, "index_object.IntervalIndexMethod.time_intersection_both_duplicate": {"code": "class IntervalIndexMethod:\n    def time_intersection_both_duplicate(self, N):\n        self.intv.intersection(self.intv2)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass IntervalIndexMethod:\n    def setup(self, N):\n        left = np.append(np.arange(N), np.array(0))\n        right = np.append(np.arange(1, N + 1), np.array(1))\n        self.intv = IntervalIndex.from_arrays(left, right)\n        self.intv._engine\n    \n        self.intv2 = IntervalIndex.from_arrays(left + 1, right + 1)\n        self.intv2._engine\n    \n        self.left = IntervalIndex.from_breaks(np.arange(N))\n        self.right = IntervalIndex.from_breaks(np.arange(N - 3, 2 * N - 3))", "min_run_count": 2, "name": "index_object.IntervalIndexMethod.time_intersection_both_duplicate", "number": 0, "param_names": ["param1"], "params": [["1000", "100000"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "51c27b25f860d486d8b165a9a8fff37e4de68c2b0a193957783434e9151daaaa", "warmup_time": -1}, "index_object.IntervalIndexMethod.time_intersection_one_duplicate": {"code": "class IntervalIndexMethod:\n    def time_intersection_one_duplicate(self, N):\n        self.intv.intersection(self.right)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass IntervalIndexMethod:\n    def setup(self, N):\n        left = np.append(np.arange(N), np.array(0))\n        right = np.append(np.arange(1, N + 1), np.array(1))\n        self.intv = IntervalIndex.from_arrays(left, right)\n        self.intv._engine\n    \n        self.intv2 = IntervalIndex.from_arrays(left + 1, right + 1)\n        self.intv2._engine\n    \n        self.left = IntervalIndex.from_breaks(np.arange(N))\n        self.right = IntervalIndex.from_breaks(np.arange(N - 3, 2 * N - 3))", "min_run_count": 2, "name": "index_object.IntervalIndexMethod.time_intersection_one_duplicate", "number": 0, "param_names": ["param1"], "params": [["1000", "100000"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "d690ff28419653e49b71207cafa08bd0c7e2901de3773c422f3c20c5659c70da", "warmup_time": -1}, "index_object.IntervalIndexMethod.time_is_unique": {"code": "class IntervalIndexMethod:\n    def time_is_unique(self, N):\n        self.intv.is_unique\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass IntervalIndexMethod:\n    def setup(self, N):\n        left = np.append(np.arange(N), np.array(0))\n        right = np.append(np.arange(1, N + 1), np.array(1))\n        self.intv = IntervalIndex.from_arrays(left, right)\n        self.intv._engine\n    \n        self.intv2 = IntervalIndex.from_arrays(left + 1, right + 1)\n        self.intv2._engine\n    \n        self.left = IntervalIndex.from_breaks(np.arange(N))\n        self.right = IntervalIndex.from_breaks(np.arange(N - 3, 2 * N - 3))", "min_run_count": 2, "name": "index_object.IntervalIndexMethod.time_is_unique", "number": 0, "param_names": ["param1"], "params": [["1000", "100000"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "b17a38c55c09eaaebc6e2a4010627e28285f0f0b8e734cf754a82d09ba25a090", "warmup_time": -1}, "index_object.IntervalIndexMethod.time_monotonic_inc": {"code": "class IntervalIndexMethod:\n    def time_monotonic_inc(self, N):\n        self.intv.is_monotonic_increasing\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass IntervalIndexMethod:\n    def setup(self, N):\n        left = np.append(np.arange(N), np.array(0))\n        right = np.append(np.arange(1, N + 1), np.array(1))\n        self.intv = IntervalIndex.from_arrays(left, right)\n        self.intv._engine\n    \n        self.intv2 = IntervalIndex.from_arrays(left + 1, right + 1)\n        self.intv2._engine\n    \n        self.left = IntervalIndex.from_breaks(np.arange(N))\n        self.right = IntervalIndex.from_breaks(np.arange(N - 3, 2 * N - 3))", "min_run_count": 2, "name": "index_object.IntervalIndexMethod.time_monotonic_inc", "number": 0, "param_names": ["param1"], "params": [["1000", "100000"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "2f556c42b4ba4b668eb1eb25dfddbcc31dc3735f52e12303ef99ae8a4b9243e0", "warmup_time": -1}, "index_object.Range.time_get_loc_dec": {"code": "class Range:\n    def time_get_loc_dec(self):\n        self.idx_dec.get_loc(100_000)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Range:\n    def setup(self):\n        self.idx_inc = RangeIndex(start=0, stop=10**6, step=3)\n        self.idx_dec = RangeIndex(start=10**6, stop=-1, step=-3)", "min_run_count": 2, "name": "index_object.Range.time_get_loc_dec", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "cf79b8ebe5bba662336f38ac055b59d39696daca21fa516ec6f3d586ef77fbeb", "warmup_time": -1}, "index_object.Range.time_get_loc_inc": {"code": "class Range:\n    def time_get_loc_inc(self):\n        self.idx_inc.get_loc(900_000)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Range:\n    def setup(self):\n        self.idx_inc = RangeIndex(start=0, stop=10**6, step=3)\n        self.idx_dec = RangeIndex(start=10**6, stop=-1, step=-3)", "min_run_count": 2, "name": "index_object.Range.time_get_loc_inc", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "e65b3c2e45ffd07fe90c70762651887bf917e0004b33efeabc1a1513961834af", "warmup_time": -1}, "index_object.Range.time_iter_dec": {"code": "class Range:\n    def time_iter_dec(self):\n        for _ in self.idx_dec:\n            pass\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Range:\n    def setup(self):\n        self.idx_inc = RangeIndex(start=0, stop=10**6, step=3)\n        self.idx_dec = RangeIndex(start=10**6, stop=-1, step=-3)", "min_run_count": 2, "name": "index_object.Range.time_iter_dec", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "0a8939329588ad2b3dccc5769b034e1cc2e6af1940fac168fcfa5dc2b425573c", "warmup_time": -1}, "index_object.Range.time_iter_inc": {"code": "class Range:\n    def time_iter_inc(self):\n        for _ in self.idx_inc:\n            pass\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Range:\n    def setup(self):\n        self.idx_inc = RangeIndex(start=0, stop=10**6, step=3)\n        self.idx_dec = RangeIndex(start=10**6, stop=-1, step=-3)", "min_run_count": 2, "name": "index_object.Range.time_iter_inc", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "83fc9b98da37845cad00c4fbdc28fc193a5ba6fe4036f48c28387979e66deb80", "warmup_time": -1}, "index_object.Range.time_max": {"code": "class Range:\n    def time_max(self):\n        self.idx_inc.max()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Range:\n    def setup(self):\n        self.idx_inc = RangeIndex(start=0, stop=10**6, step=3)\n        self.idx_dec = RangeIndex(start=10**6, stop=-1, step=-3)", "min_run_count": 2, "name": "index_object.Range.time_max", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "3fe3d3e0faeaa6aca9e99b56ed9428c2909cf685bc2777ad15b8b139f7f9b6fc", "warmup_time": -1}, "index_object.Range.time_max_trivial": {"code": "class Range:\n    def time_max_trivial(self):\n        self.idx_dec.max()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Range:\n    def setup(self):\n        self.idx_inc = RangeIndex(start=0, stop=10**6, step=3)\n        self.idx_dec = RangeIndex(start=10**6, stop=-1, step=-3)", "min_run_count": 2, "name": "index_object.Range.time_max_trivial", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "4e25e4137da187681125aee125ed76c646d75254e914e5a610454f0dab1bdbf2", "warmup_time": -1}, "index_object.Range.time_min": {"code": "class Range:\n    def time_min(self):\n        self.idx_dec.min()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Range:\n    def setup(self):\n        self.idx_inc = RangeIndex(start=0, stop=10**6, step=3)\n        self.idx_dec = RangeIndex(start=10**6, stop=-1, step=-3)", "min_run_count": 2, "name": "index_object.Range.time_min", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "5d8be4d1e9900d49eb6d2838b94ceaf7b5b6044f15d46b44772fd09d2ed706ed", "warmup_time": -1}, "index_object.Range.time_min_trivial": {"code": "class Range:\n    def time_min_trivial(self):\n        self.idx_inc.min()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Range:\n    def setup(self):\n        self.idx_inc = RangeIndex(start=0, stop=10**6, step=3)\n        self.idx_dec = RangeIndex(start=10**6, stop=-1, step=-3)", "min_run_count": 2, "name": "index_object.Range.time_min_trivial", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "9406fe8e0431d861ebb9af746fdd854868498b66f1a43f0b7184b8a5955f901b", "warmup_time": -1}, "index_object.Range.time_sort_values_asc": {"code": "class Range:\n    def time_sort_values_asc(self):\n        self.idx_inc.sort_values()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Range:\n    def setup(self):\n        self.idx_inc = RangeIndex(start=0, stop=10**6, step=3)\n        self.idx_dec = RangeIndex(start=10**6, stop=-1, step=-3)", "min_run_count": 2, "name": "index_object.Range.time_sort_values_asc", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "ad0ef7f510dcd8d00149b95616b19281a15359db8f2989bf9b4db306fdf0153f", "warmup_time": -1}, "index_object.Range.time_sort_values_des": {"code": "class Range:\n    def time_sort_values_des(self):\n        self.idx_inc.sort_values(ascending=False)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Range:\n    def setup(self):\n        self.idx_inc = RangeIndex(start=0, stop=10**6, step=3)\n        self.idx_dec = RangeIndex(start=10**6, stop=-1, step=-3)", "min_run_count": 2, "name": "index_object.Range.time_sort_values_des", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "c7ce6ea7bb8b8649240594fbbc1a612d9d42aa3b0e41c90f92cfb40283cbbd45", "warmup_time": -1}, "index_object.SetDisjoint.time_datetime_difference_disjoint": {"code": "class SetDisjoint:\n    def time_datetime_difference_disjoint(self):\n        self.datetime_left.difference(self.datetime_right)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass SetDisjoint:\n    def setup(self):\n        N = 10**5\n        B = N + 20000\n        self.datetime_left = DatetimeIndex(range(N))\n        self.datetime_right = DatetimeIndex(range(N, B))", "min_run_count": 2, "name": "index_object.SetDisjoint.time_datetime_difference_disjoint", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "5f314bb98034f50776d52507597278df13b4f23a7942559fc0dedf93d1c11c62", "warmup_time": -1}, "index_object.SetOperations.time_operation": {"code": "class SetOperations:\n    def time_operation(self, index_structure, dtype, method):\n        getattr(self.left, method)(self.right)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass SetOperations:\n    def setup(self, index_structure, dtype, method):\n        N = 10**5\n        dates_left = date_range(\"1/1/2000\", periods=N, freq=\"T\")\n        fmt = \"%Y-%m-%d %H:%M:%S\"\n        date_str_left = Index(dates_left.strftime(fmt))\n        int_left = Index(np.arange(N))\n        ea_int_left = Index(np.arange(N), dtype=\"Int64\")\n        str_left = tm.makeStringIndex(N)\n    \n        data = {\n            \"datetime\": dates_left,\n            \"date_string\": date_str_left,\n            \"int\": int_left,\n            \"strings\": str_left,\n            \"ea_int\": ea_int_left,\n        }\n    \n        if index_structure == \"non_monotonic\":\n            data = {k: mi[::-1] for k, mi in data.items()}\n    \n        data = {k: {\"left\": idx, \"right\": idx[:-1]} for k, idx in data.items()}\n    \n        self.left = data[dtype][\"left\"]\n        self.right = data[dtype][\"right\"]", "min_run_count": 2, "name": "index_object.SetOperations.time_operation", "number": 0, "param_names": ["index_structure", "dtype", "method"], "params": [["'monotonic'", "'non_monotonic'"], ["'datetime'", "'date_string'", "'int'", "'strings'", "'ea_int'"], ["'intersection'", "'union'", "'symmetric_difference'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "a389c61561b5063cab295803798975711f7118e4904b247b2eb99c132cdfb9c6", "warmup_time": -1}, "index_object.UnionWithDuplicates.time_union_with_duplicates": {"code": "class UnionWithDuplicates:\n    def time_union_with_duplicates(self):\n        self.left.union(self.right)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass UnionWithDuplicates:\n    def setup(self):\n        self.left = Index(np.repeat(np.arange(1000), 100))\n        self.right = Index(np.tile(np.arange(500, 1500), 50))", "min_run_count": 2, "name": "index_object.UnionWithDuplicates.time_union_with_duplicates", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "0420e720a40b09b5a83ef4ace67c704a238d521a86a8cb00c673aae12cfa2f25", "warmup_time": -1}, "indexing.AssignTimeseriesIndex.time_frame_assign_timeseries_index": {"code": "class AssignTimeseriesIndex:\n    def time_frame_assign_timeseries_index(self):\n        self.df[\"date\"] = self.df.index\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass AssignTimeseriesIndex:\n    def setup(self):\n        N = 100000\n        idx = date_range(\"1/1/2000\", periods=N, freq=\"H\")\n        self.df = DataFrame(np.random.randn(N, 1), columns=[\"A\"], index=idx)", "min_run_count": 2, "name": "indexing.AssignTimeseriesIndex.time_frame_assign_timeseries_index", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "e551ce8d4df98da3d5a232e80a7837bf3adae5c13ecd3d477cc36e1442a5983e", "warmup_time": -1}, "indexing.CategoricalIndexIndexing.time_get_indexer_list": {"code": "class CategoricalIndexIndexing:\n    def time_get_indexer_list(self, index):\n        self.data_unique.get_indexer(self.cat_list)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass CategoricalIndexIndexing:\n    def setup(self, index):\n        N = 10**5\n        values = list(\"a\" * N + \"b\" * N + \"c\" * N)\n        indices = {\n            \"monotonic_incr\": CategoricalIndex(values),\n            \"monotonic_decr\": CategoricalIndex(reversed(values)),\n            \"non_monotonic\": CategoricalIndex(list(\"abc\" * N)),\n        }\n        self.data = indices[index]\n        self.data_unique = CategoricalIndex([str(i) for i in range(N * 3)])\n    \n        self.int_scalar = 10000\n        self.int_list = list(range(10000))\n    \n        self.cat_scalar = \"b\"\n        self.cat_list = [\"1\", \"3\"]", "min_run_count": 2, "name": "indexing.CategoricalIndexIndexing.time_get_indexer_list", "number": 0, "param_names": ["index"], "params": [["'monotonic_incr'", "'monotonic_decr'", "'non_monotonic'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "62150e3781f883d8f6823c45067fcac0fefeb8ec685a47ce8057bed4cbaf3de7", "warmup_time": -1}, "indexing.CategoricalIndexIndexing.time_get_loc_scalar": {"code": "class CategoricalIndexIndexing:\n    def time_get_loc_scalar(self, index):\n        self.data.get_loc(self.cat_scalar)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass CategoricalIndexIndexing:\n    def setup(self, index):\n        N = 10**5\n        values = list(\"a\" * N + \"b\" * N + \"c\" * N)\n        indices = {\n            \"monotonic_incr\": CategoricalIndex(values),\n            \"monotonic_decr\": CategoricalIndex(reversed(values)),\n            \"non_monotonic\": CategoricalIndex(list(\"abc\" * N)),\n        }\n        self.data = indices[index]\n        self.data_unique = CategoricalIndex([str(i) for i in range(N * 3)])\n    \n        self.int_scalar = 10000\n        self.int_list = list(range(10000))\n    \n        self.cat_scalar = \"b\"\n        self.cat_list = [\"1\", \"3\"]", "min_run_count": 2, "name": "indexing.CategoricalIndexIndexing.time_get_loc_scalar", "number": 0, "param_names": ["index"], "params": [["'monotonic_incr'", "'monotonic_decr'", "'non_monotonic'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "f37f9a77340871ef67cae5bac921473a106ea7e1c707babd9a5d708a28df0d9a", "warmup_time": -1}, "indexing.CategoricalIndexIndexing.time_getitem_bool_array": {"code": "class CategoricalIndexIndexing:\n    def time_getitem_bool_array(self, index):\n        self.data[self.data == self.cat_scalar]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass CategoricalIndexIndexing:\n    def setup(self, index):\n        N = 10**5\n        values = list(\"a\" * N + \"b\" * N + \"c\" * N)\n        indices = {\n            \"monotonic_incr\": CategoricalIndex(values),\n            \"monotonic_decr\": CategoricalIndex(reversed(values)),\n            \"non_monotonic\": CategoricalIndex(list(\"abc\" * N)),\n        }\n        self.data = indices[index]\n        self.data_unique = CategoricalIndex([str(i) for i in range(N * 3)])\n    \n        self.int_scalar = 10000\n        self.int_list = list(range(10000))\n    \n        self.cat_scalar = \"b\"\n        self.cat_list = [\"1\", \"3\"]", "min_run_count": 2, "name": "indexing.CategoricalIndexIndexing.time_getitem_bool_array", "number": 0, "param_names": ["index"], "params": [["'monotonic_incr'", "'monotonic_decr'", "'non_monotonic'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "b4c1625b9c78f360819094fa2e243d9c3671eccf5396bd00cc7d4298824b370d", "warmup_time": -1}, "indexing.CategoricalIndexIndexing.time_getitem_list": {"code": "class CategoricalIndexIndexing:\n    def time_getitem_list(self, index):\n        self.data[self.int_list]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass CategoricalIndexIndexing:\n    def setup(self, index):\n        N = 10**5\n        values = list(\"a\" * N + \"b\" * N + \"c\" * N)\n        indices = {\n            \"monotonic_incr\": CategoricalIndex(values),\n            \"monotonic_decr\": CategoricalIndex(reversed(values)),\n            \"non_monotonic\": CategoricalIndex(list(\"abc\" * N)),\n        }\n        self.data = indices[index]\n        self.data_unique = CategoricalIndex([str(i) for i in range(N * 3)])\n    \n        self.int_scalar = 10000\n        self.int_list = list(range(10000))\n    \n        self.cat_scalar = \"b\"\n        self.cat_list = [\"1\", \"3\"]", "min_run_count": 2, "name": "indexing.CategoricalIndexIndexing.time_getitem_list", "number": 0, "param_names": ["index"], "params": [["'monotonic_incr'", "'monotonic_decr'", "'non_monotonic'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "25f5a440360e857bbf13b393292f058291a0fe0e335aa56339d4690c25ac147c", "warmup_time": -1}, "indexing.CategoricalIndexIndexing.time_getitem_list_like": {"code": "class CategoricalIndexIndexing:\n    def time_getitem_list_like(self, index):\n        self.data[[self.int_scalar]]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass CategoricalIndexIndexing:\n    def setup(self, index):\n        N = 10**5\n        values = list(\"a\" * N + \"b\" * N + \"c\" * N)\n        indices = {\n            \"monotonic_incr\": CategoricalIndex(values),\n            \"monotonic_decr\": CategoricalIndex(reversed(values)),\n            \"non_monotonic\": CategoricalIndex(list(\"abc\" * N)),\n        }\n        self.data = indices[index]\n        self.data_unique = CategoricalIndex([str(i) for i in range(N * 3)])\n    \n        self.int_scalar = 10000\n        self.int_list = list(range(10000))\n    \n        self.cat_scalar = \"b\"\n        self.cat_list = [\"1\", \"3\"]", "min_run_count": 2, "name": "indexing.CategoricalIndexIndexing.time_getitem_list_like", "number": 0, "param_names": ["index"], "params": [["'monotonic_incr'", "'monotonic_decr'", "'non_monotonic'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "d616c85b999476b17108e8f7e22f95a195640eb4a2d59226df18c1f7eb5fbc26", "warmup_time": -1}, "indexing.CategoricalIndexIndexing.time_getitem_scalar": {"code": "class CategoricalIndexIndexing:\n    def time_getitem_scalar(self, index):\n        self.data[self.int_scalar]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass CategoricalIndexIndexing:\n    def setup(self, index):\n        N = 10**5\n        values = list(\"a\" * N + \"b\" * N + \"c\" * N)\n        indices = {\n            \"monotonic_incr\": CategoricalIndex(values),\n            \"monotonic_decr\": CategoricalIndex(reversed(values)),\n            \"non_monotonic\": CategoricalIndex(list(\"abc\" * N)),\n        }\n        self.data = indices[index]\n        self.data_unique = CategoricalIndex([str(i) for i in range(N * 3)])\n    \n        self.int_scalar = 10000\n        self.int_list = list(range(10000))\n    \n        self.cat_scalar = \"b\"\n        self.cat_list = [\"1\", \"3\"]", "min_run_count": 2, "name": "indexing.CategoricalIndexIndexing.time_getitem_scalar", "number": 0, "param_names": ["index"], "params": [["'monotonic_incr'", "'monotonic_decr'", "'non_monotonic'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "a18201ebf2cfad696d0e413b9cbc8eb4884b1f5b7447ca8f974fe3f765766278", "warmup_time": -1}, "indexing.CategoricalIndexIndexing.time_getitem_slice": {"code": "class CategoricalIndexIndexing:\n    def time_getitem_slice(self, index):\n        self.data[: self.int_scalar]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass CategoricalIndexIndexing:\n    def setup(self, index):\n        N = 10**5\n        values = list(\"a\" * N + \"b\" * N + \"c\" * N)\n        indices = {\n            \"monotonic_incr\": CategoricalIndex(values),\n            \"monotonic_decr\": CategoricalIndex(reversed(values)),\n            \"non_monotonic\": CategoricalIndex(list(\"abc\" * N)),\n        }\n        self.data = indices[index]\n        self.data_unique = CategoricalIndex([str(i) for i in range(N * 3)])\n    \n        self.int_scalar = 10000\n        self.int_list = list(range(10000))\n    \n        self.cat_scalar = \"b\"\n        self.cat_list = [\"1\", \"3\"]", "min_run_count": 2, "name": "indexing.CategoricalIndexIndexing.time_getitem_slice", "number": 0, "param_names": ["index"], "params": [["'monotonic_incr'", "'monotonic_decr'", "'non_monotonic'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "4c7a1c61821c96671e21fd7ce147081487558bee846c82a1db1d2a696acb4761", "warmup_time": -1}, "indexing.ChainIndexing.time_chained_indexing": {"code": "class ChainIndexing:\n    def time_chained_indexing(self, mode):\n        df = self.df\n        N = self.N\n        with warnings.catch_warnings(record=True):\n            with option_context(\"mode.chained_assignment\", mode):\n                df2 = df[df.A > N // 2]\n                df2[\"C\"] = 1.0\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ChainIndexing:\n    def setup(self, mode):\n        self.N = 1000000\n        self.df = DataFrame({\"A\": np.arange(self.N), \"B\": \"foo\"})", "min_run_count": 2, "name": "indexing.ChainIndexing.time_chained_indexing", "number": 0, "param_names": ["mode"], "params": [["None", "'warn'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "16258f12b7c725f7ffc21ffed9c69bd9751f02f6a459f86e81c20750c1fc1bba", "warmup_time": -1}, "indexing.DataFrameNumericIndexing.time_bool_indexer": {"code": "class DataFrameNumericIndexing:\n    def time_bool_indexer(self, index, index_structure):\n        self.df[self.bool_indexer]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass DataFrameNumericIndexing:\n    def setup(self, dtype, index_structure):\n        N = 10**5\n        indices = {\n            \"unique_monotonic_inc\": Index(range(N), dtype=dtype),\n            \"nonunique_monotonic_inc\": Index(\n                list(range(55)) + [54] + list(range(55, N - 1)), dtype=dtype\n            ),\n        }\n        self.idx_dupe = np.array(range(30)) * 99\n        self.df = DataFrame(np.random.randn(N, 5), index=indices[index_structure])\n        self.df_dup = concat([self.df, 2 * self.df, 3 * self.df])\n        self.bool_indexer = [True] * (N // 2) + [False] * (N - N // 2)", "min_run_count": 2, "name": "indexing.DataFrameNumericIndexing.time_bool_indexer", "number": 0, "param_names": ["dtype", "index_structure"], "params": [["<class 'numpy.int64'>", "<class 'numpy.uint64'>", "<class 'numpy.float64'>"], ["'unique_monotonic_inc'", "'nonunique_monotonic_inc'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "5b49ac8c1fc01d2dc2c19c3edcf588116fa02ee673f47dde99584eb435361fed", "warmup_time": -1}, "indexing.DataFrameNumericIndexing.time_iloc": {"code": "class DataFrameNumericIndexing:\n    def time_iloc(self, index, index_structure):\n        self.df.iloc[:100, 0]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass DataFrameNumericIndexing:\n    def setup(self, dtype, index_structure):\n        N = 10**5\n        indices = {\n            \"unique_monotonic_inc\": Index(range(N), dtype=dtype),\n            \"nonunique_monotonic_inc\": Index(\n                list(range(55)) + [54] + list(range(55, N - 1)), dtype=dtype\n            ),\n        }\n        self.idx_dupe = np.array(range(30)) * 99\n        self.df = DataFrame(np.random.randn(N, 5), index=indices[index_structure])\n        self.df_dup = concat([self.df, 2 * self.df, 3 * self.df])\n        self.bool_indexer = [True] * (N // 2) + [False] * (N - N // 2)", "min_run_count": 2, "name": "indexing.DataFrameNumericIndexing.time_iloc", "number": 0, "param_names": ["dtype", "index_structure"], "params": [["<class 'numpy.int64'>", "<class 'numpy.uint64'>", "<class 'numpy.float64'>"], ["'unique_monotonic_inc'", "'nonunique_monotonic_inc'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "d4f1ee902bd3f0617b7fe7bfbca605d0c34d424476e2ea162e220ee701e530eb", "warmup_time": -1}, "indexing.DataFrameNumericIndexing.time_iloc_dups": {"code": "class DataFrameNumericIndexing:\n    def time_iloc_dups(self, index, index_structure):\n        self.df_dup.iloc[self.idx_dupe]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass DataFrameNumericIndexing:\n    def setup(self, dtype, index_structure):\n        N = 10**5\n        indices = {\n            \"unique_monotonic_inc\": Index(range(N), dtype=dtype),\n            \"nonunique_monotonic_inc\": Index(\n                list(range(55)) + [54] + list(range(55, N - 1)), dtype=dtype\n            ),\n        }\n        self.idx_dupe = np.array(range(30)) * 99\n        self.df = DataFrame(np.random.randn(N, 5), index=indices[index_structure])\n        self.df_dup = concat([self.df, 2 * self.df, 3 * self.df])\n        self.bool_indexer = [True] * (N // 2) + [False] * (N - N // 2)", "min_run_count": 2, "name": "indexing.DataFrameNumericIndexing.time_iloc_dups", "number": 0, "param_names": ["dtype", "index_structure"], "params": [["<class 'numpy.int64'>", "<class 'numpy.uint64'>", "<class 'numpy.float64'>"], ["'unique_monotonic_inc'", "'nonunique_monotonic_inc'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "4390803cba45b26841ac1b3f27cffcaed921e6083822e3d13e9eff994ee542e5", "warmup_time": -1}, "indexing.DataFrameNumericIndexing.time_loc": {"code": "class DataFrameNumericIndexing:\n    def time_loc(self, index, index_structure):\n        self.df.loc[:100, 0]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass DataFrameNumericIndexing:\n    def setup(self, dtype, index_structure):\n        N = 10**5\n        indices = {\n            \"unique_monotonic_inc\": Index(range(N), dtype=dtype),\n            \"nonunique_monotonic_inc\": Index(\n                list(range(55)) + [54] + list(range(55, N - 1)), dtype=dtype\n            ),\n        }\n        self.idx_dupe = np.array(range(30)) * 99\n        self.df = DataFrame(np.random.randn(N, 5), index=indices[index_structure])\n        self.df_dup = concat([self.df, 2 * self.df, 3 * self.df])\n        self.bool_indexer = [True] * (N // 2) + [False] * (N - N // 2)", "min_run_count": 2, "name": "indexing.DataFrameNumericIndexing.time_loc", "number": 0, "param_names": ["dtype", "index_structure"], "params": [["<class 'numpy.int64'>", "<class 'numpy.uint64'>", "<class 'numpy.float64'>"], ["'unique_monotonic_inc'", "'nonunique_monotonic_inc'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "a85621866c240f052375710c72ffe0cc190d797923084092e4984bff4240dfdf", "warmup_time": -1}, "indexing.DataFrameNumericIndexing.time_loc_dups": {"code": "class DataFrameNumericIndexing:\n    def time_loc_dups(self, index, index_structure):\n        self.df_dup.loc[self.idx_dupe]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass DataFrameNumericIndexing:\n    def setup(self, dtype, index_structure):\n        N = 10**5\n        indices = {\n            \"unique_monotonic_inc\": Index(range(N), dtype=dtype),\n            \"nonunique_monotonic_inc\": Index(\n                list(range(55)) + [54] + list(range(55, N - 1)), dtype=dtype\n            ),\n        }\n        self.idx_dupe = np.array(range(30)) * 99\n        self.df = DataFrame(np.random.randn(N, 5), index=indices[index_structure])\n        self.df_dup = concat([self.df, 2 * self.df, 3 * self.df])\n        self.bool_indexer = [True] * (N // 2) + [False] * (N - N // 2)", "min_run_count": 2, "name": "indexing.DataFrameNumericIndexing.time_loc_dups", "number": 0, "param_names": ["dtype", "index_structure"], "params": [["<class 'numpy.int64'>", "<class 'numpy.uint64'>", "<class 'numpy.float64'>"], ["'unique_monotonic_inc'", "'nonunique_monotonic_inc'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "9789412267c4eba4099218c01b54dc8d5055978255c8cae7cd1d3f96cf362b7e", "warmup_time": -1}, "indexing.DataFrameStringIndexing.time_at": {"code": "class DataFrameStringIndexing:\n    def time_at(self):\n        self.df.at[self.idx_scalar, self.col_scalar]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass DataFrameStringIndexing:\n    def setup(self):\n        index = tm.makeStringIndex(1000)\n        columns = tm.makeStringIndex(30)\n        with warnings.catch_warnings(record=True):\n            self.df = DataFrame(np.random.randn(1000, 30), index=index, columns=columns)\n        self.idx_scalar = index[100]\n        self.col_scalar = columns[10]\n        self.bool_indexer = self.df[self.col_scalar] > 0\n        self.bool_obj_indexer = self.bool_indexer.astype(object)\n        self.boolean_indexer = (self.df[self.col_scalar] > 0).astype(\"boolean\")", "min_run_count": 2, "name": "indexing.DataFrameStringIndexing.time_at", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "4c1489cc64e61bb8b9ddcd730591fe20457e32fe5cea29c365f5b67a42cf97f9", "warmup_time": -1}, "indexing.DataFrameStringIndexing.time_at_setitem": {"code": "class DataFrameStringIndexing:\n    def time_at_setitem(self):\n        self.df.at[self.idx_scalar, self.col_scalar] = 0.0\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass DataFrameStringIndexing:\n    def setup(self):\n        index = tm.makeStringIndex(1000)\n        columns = tm.makeStringIndex(30)\n        with warnings.catch_warnings(record=True):\n            self.df = DataFrame(np.random.randn(1000, 30), index=index, columns=columns)\n        self.idx_scalar = index[100]\n        self.col_scalar = columns[10]\n        self.bool_indexer = self.df[self.col_scalar] > 0\n        self.bool_obj_indexer = self.bool_indexer.astype(object)\n        self.boolean_indexer = (self.df[self.col_scalar] > 0).astype(\"boolean\")", "min_run_count": 2, "name": "indexing.DataFrameStringIndexing.time_at_setitem", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "f78bdb6a0e8865f031756c3639046da76706ff9666e28d5f231b70ac921be1d6", "warmup_time": -1}, "indexing.DataFrameStringIndexing.time_boolean_rows": {"code": "class DataFrameStringIndexing:\n    def time_boolean_rows(self):\n        self.df[self.bool_indexer]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass DataFrameStringIndexing:\n    def setup(self):\n        index = tm.makeStringIndex(1000)\n        columns = tm.makeStringIndex(30)\n        with warnings.catch_warnings(record=True):\n            self.df = DataFrame(np.random.randn(1000, 30), index=index, columns=columns)\n        self.idx_scalar = index[100]\n        self.col_scalar = columns[10]\n        self.bool_indexer = self.df[self.col_scalar] > 0\n        self.bool_obj_indexer = self.bool_indexer.astype(object)\n        self.boolean_indexer = (self.df[self.col_scalar] > 0).astype(\"boolean\")", "min_run_count": 2, "name": "indexing.DataFrameStringIndexing.time_boolean_rows", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "337e03057fef98383104445edb6c4267328a55fe53fb638926d965f5cf58d62c", "warmup_time": -1}, "indexing.DataFrameStringIndexing.time_boolean_rows_boolean": {"code": "class DataFrameStringIndexing:\n    def time_boolean_rows_boolean(self):\n        self.df[self.boolean_indexer]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass DataFrameStringIndexing:\n    def setup(self):\n        index = tm.makeStringIndex(1000)\n        columns = tm.makeStringIndex(30)\n        with warnings.catch_warnings(record=True):\n            self.df = DataFrame(np.random.randn(1000, 30), index=index, columns=columns)\n        self.idx_scalar = index[100]\n        self.col_scalar = columns[10]\n        self.bool_indexer = self.df[self.col_scalar] > 0\n        self.bool_obj_indexer = self.bool_indexer.astype(object)\n        self.boolean_indexer = (self.df[self.col_scalar] > 0).astype(\"boolean\")", "min_run_count": 2, "name": "indexing.DataFrameStringIndexing.time_boolean_rows_boolean", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "c9f3b2e000c947b4479e318626a31b98afabbd649cb0fcf7107bbdbb0ab57055", "warmup_time": -1}, "indexing.DataFrameStringIndexing.time_boolean_rows_object": {"code": "class DataFrameStringIndexing:\n    def time_boolean_rows_object(self):\n        self.df[self.bool_obj_indexer]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass DataFrameStringIndexing:\n    def setup(self):\n        index = tm.makeStringIndex(1000)\n        columns = tm.makeStringIndex(30)\n        with warnings.catch_warnings(record=True):\n            self.df = DataFrame(np.random.randn(1000, 30), index=index, columns=columns)\n        self.idx_scalar = index[100]\n        self.col_scalar = columns[10]\n        self.bool_indexer = self.df[self.col_scalar] > 0\n        self.bool_obj_indexer = self.bool_indexer.astype(object)\n        self.boolean_indexer = (self.df[self.col_scalar] > 0).astype(\"boolean\")", "min_run_count": 2, "name": "indexing.DataFrameStringIndexing.time_boolean_rows_object", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "362bb6b6048c65b4c6ac3c8336721e4497f0e44e0b12ec89aeba7906cc7ac826", "warmup_time": -1}, "indexing.DataFrameStringIndexing.time_getitem_scalar": {"code": "class DataFrameStringIndexing:\n    def time_getitem_scalar(self):\n        self.df[self.col_scalar][self.idx_scalar]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass DataFrameStringIndexing:\n    def setup(self):\n        index = tm.makeStringIndex(1000)\n        columns = tm.makeStringIndex(30)\n        with warnings.catch_warnings(record=True):\n            self.df = DataFrame(np.random.randn(1000, 30), index=index, columns=columns)\n        self.idx_scalar = index[100]\n        self.col_scalar = columns[10]\n        self.bool_indexer = self.df[self.col_scalar] > 0\n        self.bool_obj_indexer = self.bool_indexer.astype(object)\n        self.boolean_indexer = (self.df[self.col_scalar] > 0).astype(\"boolean\")", "min_run_count": 2, "name": "indexing.DataFrameStringIndexing.time_getitem_scalar", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "6cb8e8daea5819b952bfed19651ac1724a5968bb35c37a752425587dfd49452d", "warmup_time": -1}, "indexing.DataFrameStringIndexing.time_loc": {"code": "class DataFrameStringIndexing:\n    def time_loc(self):\n        self.df.loc[self.idx_scalar, self.col_scalar]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass DataFrameStringIndexing:\n    def setup(self):\n        index = tm.makeStringIndex(1000)\n        columns = tm.makeStringIndex(30)\n        with warnings.catch_warnings(record=True):\n            self.df = DataFrame(np.random.randn(1000, 30), index=index, columns=columns)\n        self.idx_scalar = index[100]\n        self.col_scalar = columns[10]\n        self.bool_indexer = self.df[self.col_scalar] > 0\n        self.bool_obj_indexer = self.bool_indexer.astype(object)\n        self.boolean_indexer = (self.df[self.col_scalar] > 0).astype(\"boolean\")", "min_run_count": 2, "name": "indexing.DataFrameStringIndexing.time_loc", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "265aab9816591b0620d3f729f705598419ec9b26e32927a7fa1a5c4c87630b97", "warmup_time": -1}, "indexing.DatetimeIndexIndexing.time_get_indexer_mismatched_tz": {"code": "class DatetimeIndexIndexing:\n    def time_get_indexer_mismatched_tz(self):\n        # reached via e.g.\n        #  ser = Series(range(len(dti)), index=dti)\n        #  ser[dti2]\n        self.dti.get_indexer(self.dti2)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass DatetimeIndexIndexing:\n    def setup(self):\n        dti = date_range(\"2016-01-01\", periods=10000, tz=\"US/Pacific\")\n        dti2 = dti.tz_convert(\"UTC\")\n        self.dti = dti\n        self.dti2 = dti2", "min_run_count": 2, "name": "indexing.DatetimeIndexIndexing.time_get_indexer_mismatched_tz", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "c9cf20755eb4a51e544f3173086738738b06c2840acdc00a8c905a951594ce03", "warmup_time": -1}, "indexing.GetItemSingleColumn.time_frame_getitem_single_column_int": {"code": "class GetItemSingleColumn:\n    def time_frame_getitem_single_column_int(self):\n        self.df_int_col[0]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass GetItemSingleColumn:\n    def setup(self):\n        self.df_string_col = DataFrame(np.random.randn(3000, 1), columns=[\"A\"])\n        self.df_int_col = DataFrame(np.random.randn(3000, 1))", "min_run_count": 2, "name": "indexing.GetItemSingleColumn.time_frame_getitem_single_column_int", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "8516566e6a549f1f7c5a48623aa1378d299f882af8c200a8ab04eb7d321f0a23", "warmup_time": -1}, "indexing.GetItemSingleColumn.time_frame_getitem_single_column_label": {"code": "class GetItemSingleColumn:\n    def time_frame_getitem_single_column_label(self):\n        self.df_string_col[\"A\"]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass GetItemSingleColumn:\n    def setup(self):\n        self.df_string_col = DataFrame(np.random.randn(3000, 1), columns=[\"A\"])\n        self.df_int_col = DataFrame(np.random.randn(3000, 1))", "min_run_count": 2, "name": "indexing.GetItemSingleColumn.time_frame_getitem_single_column_label", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "a03a82b5117e7c2d6cccfe8ac22ef652a2ac9b039e27f15814a7bfab97c94f00", "warmup_time": -1}, "indexing.IndexSingleRow.time_iloc_row": {"code": "class IndexSingleRow:\n    def time_iloc_row(self, unique_cols):\n        self.df.iloc[10000]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass IndexSingleRow:\n    def setup(self, unique_cols):\n        arr = np.arange(10**7).reshape(-1, 10)\n        df = DataFrame(arr)\n        dtypes = [\"u1\", \"u2\", \"u4\", \"u8\", \"i1\", \"i2\", \"i4\", \"i8\", \"f8\", \"f4\"]\n        for i, d in enumerate(dtypes):\n            df[i] = df[i].astype(d)\n    \n        if not unique_cols:\n            # GH#33032 single-row lookups with non-unique columns were\n            #  15x slower than with unique columns\n            df.columns = [\"A\", \"A\"] + list(df.columns[2:])\n    \n        self.df = df", "min_run_count": 2, "name": "indexing.IndexSingleRow.time_iloc_row", "number": 0, "param_names": ["unique_cols"], "params": [["True", "False"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "4e20d2ce44a18740b78a7eae0eab3b3352a211486335db125fa22f685c9c5c68", "warmup_time": -1}, "indexing.IndexSingleRow.time_loc_row": {"code": "class IndexSingleRow:\n    def time_loc_row(self, unique_cols):\n        self.df.loc[10000]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass IndexSingleRow:\n    def setup(self, unique_cols):\n        arr = np.arange(10**7).reshape(-1, 10)\n        df = DataFrame(arr)\n        dtypes = [\"u1\", \"u2\", \"u4\", \"u8\", \"i1\", \"i2\", \"i4\", \"i8\", \"f8\", \"f4\"]\n        for i, d in enumerate(dtypes):\n            df[i] = df[i].astype(d)\n    \n        if not unique_cols:\n            # GH#33032 single-row lookups with non-unique columns were\n            #  15x slower than with unique columns\n            df.columns = [\"A\", \"A\"] + list(df.columns[2:])\n    \n        self.df = df", "min_run_count": 2, "name": "indexing.IndexSingleRow.time_loc_row", "number": 0, "param_names": ["unique_cols"], "params": [["True", "False"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "b1ae71b2de36f0424ee21d6b377c7e4370496ce8ed29f92ce82786280ff4c9db", "warmup_time": -1}, "indexing.InsertColumns.time_assign_list_like_with_setitem": {"code": "class InsertColumns:\n    def time_assign_list_like_with_setitem(self):\n        self.df[list(range(100))] = np.random.randn(self.N, 100)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass InsertColumns:\n    def setup(self):\n        self.N = 10**3\n        self.df = DataFrame(index=range(self.N))\n        self.df2 = DataFrame(np.random.randn(self.N, 2))", "min_run_count": 2, "name": "indexing.InsertColumns.time_assign_list_like_with_setitem", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "3bb24f36b40d94be98724ac3ffea9a7afbc390d394fa5fa9475cc77a13ffdf7b", "warmup_time": -1}, "indexing.InsertColumns.time_assign_list_of_columns_concat": {"code": "class InsertColumns:\n    def time_assign_list_of_columns_concat(self):\n        df = DataFrame(np.random.randn(self.N, 100))\n        concat([self.df, df], axis=1)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass InsertColumns:\n    def setup(self):\n        self.N = 10**3\n        self.df = DataFrame(index=range(self.N))\n        self.df2 = DataFrame(np.random.randn(self.N, 2))", "min_run_count": 2, "name": "indexing.InsertColumns.time_assign_list_of_columns_concat", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "41cef472b41bd56488365882e9724052692d13ec0abf67f3fa395e44af3a045d", "warmup_time": -1}, "indexing.InsertColumns.time_assign_with_setitem": {"code": "class InsertColumns:\n    def time_assign_with_setitem(self):\n        for i in range(100):\n            self.df[i] = np.random.randn(self.N)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass InsertColumns:\n    def setup(self):\n        self.N = 10**3\n        self.df = DataFrame(index=range(self.N))\n        self.df2 = DataFrame(np.random.randn(self.N, 2))", "min_run_count": 2, "name": "indexing.InsertColumns.time_assign_with_setitem", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "594d490a7116f20753d8366d82e417220b8035ce74080b41de66a9f64d7b2abd", "warmup_time": -1}, "indexing.InsertColumns.time_insert": {"code": "class InsertColumns:\n    def time_insert(self):\n        for i in range(100):\n            self.df.insert(0, i, np.random.randn(self.N), allow_duplicates=True)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass InsertColumns:\n    def setup(self):\n        self.N = 10**3\n        self.df = DataFrame(index=range(self.N))\n        self.df2 = DataFrame(np.random.randn(self.N, 2))", "min_run_count": 2, "name": "indexing.InsertColumns.time_insert", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "0021e91e2211b243fded9954bae458921f73a3e5ded206d0817555b44c945c0d", "warmup_time": -1}, "indexing.InsertColumns.time_insert_middle": {"code": "class InsertColumns:\n    def time_insert_middle(self):\n        # same as time_insert but inserting to a middle column rather than\n        #  front or back (which have fast-paths)\n        for i in range(100):\n            self.df2.insert(\n                1, \"colname\", np.random.randn(self.N), allow_duplicates=True\n            )\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass InsertColumns:\n    def setup(self):\n        self.N = 10**3\n        self.df = DataFrame(index=range(self.N))\n        self.df2 = DataFrame(np.random.randn(self.N, 2))", "min_run_count": 2, "name": "indexing.InsertColumns.time_insert_middle", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "c08ac878c8c7f19edcae9cddb8525e726ef5328f5fb06d9932ca3e83158e4a7d", "warmup_time": -1}, "indexing.IntervalIndexing.time_getitem_list": {"code": "class IntervalIndexing:\n    def time_getitem_list(self, monotonic):\n        monotonic[80000:]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass IntervalIndexing:\n    def setup_cache(self):\n        idx = IntervalIndex.from_breaks(np.arange(1000001))\n        monotonic = Series(np.arange(1000000), index=idx)\n        return monotonic", "min_run_count": 2, "name": "indexing.IntervalIndexing.time_getitem_list", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "setup_cache_key": "indexing:322", "timeout": 60.0, "type": "time", "unit": "seconds", "version": "ae80a330a1a4becae8c369fe9bcb0c8f430beb2d8ac3986f5e2f82490c50e071", "warmup_time": -1}, "indexing.IntervalIndexing.time_getitem_scalar": {"code": "class IntervalIndexing:\n    def time_getitem_scalar(self, monotonic):\n        monotonic[80000]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass IntervalIndexing:\n    def setup_cache(self):\n        idx = IntervalIndex.from_breaks(np.arange(1000001))\n        monotonic = Series(np.arange(1000000), index=idx)\n        return monotonic", "min_run_count": 2, "name": "indexing.IntervalIndexing.time_getitem_scalar", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "setup_cache_key": "indexing:322", "timeout": 60.0, "type": "time", "unit": "seconds", "version": "f160eaae3bf3bcbcc3fd20357b12c28670839282da6644be0e8024f97b21204b", "warmup_time": -1}, "indexing.IntervalIndexing.time_loc_list": {"code": "class IntervalIndexing:\n    def time_loc_list(self, monotonic):\n        monotonic.loc[80000:]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass IntervalIndexing:\n    def setup_cache(self):\n        idx = IntervalIndex.from_breaks(np.arange(1000001))\n        monotonic = Series(np.arange(1000000), index=idx)\n        return monotonic", "min_run_count": 2, "name": "indexing.IntervalIndexing.time_loc_list", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "setup_cache_key": "indexing:322", "timeout": 60.0, "type": "time", "unit": "seconds", "version": "634735f3995a5c9be2542706652ca9d8a024f91ded9a8e3ec8653b176bb9c556", "warmup_time": -1}, "indexing.IntervalIndexing.time_loc_scalar": {"code": "class IntervalIndexing:\n    def time_loc_scalar(self, monotonic):\n        monotonic.loc[80000]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass IntervalIndexing:\n    def setup_cache(self):\n        idx = IntervalIndex.from_breaks(np.arange(1000001))\n        monotonic = Series(np.arange(1000000), index=idx)\n        return monotonic", "min_run_count": 2, "name": "indexing.IntervalIndexing.time_loc_scalar", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "setup_cache_key": "indexing:322", "timeout": 60.0, "type": "time", "unit": "seconds", "version": "9682c17d993a421023a33cdfbf1ae6a67d4f2b1a8a9eb98fb60445f56f4d892e", "warmup_time": -1}, "indexing.MethodLookup.time_lookup_iloc": {"code": "class MethodLookup:\n    def time_lookup_iloc(self, s):\n        s.iloc\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass MethodLookup:\n    def setup_cache(self):\n        s = Series()\n        return s", "min_run_count": 2, "name": "indexing.MethodLookup.time_lookup_iloc", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "setup_cache_key": "indexing:416", "timeout": 60.0, "type": "time", "unit": "seconds", "version": "de130c1315ebaff60daa5132a0ffba11a1513d688c4d7465c4f0b75fa3b40d4d", "warmup_time": -1}, "indexing.MethodLookup.time_lookup_loc": {"code": "class MethodLookup:\n    def time_lookup_loc(self, s):\n        s.loc\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass MethodLookup:\n    def setup_cache(self):\n        s = Series()\n        return s", "min_run_count": 2, "name": "indexing.MethodLookup.time_lookup_loc", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "setup_cache_key": "indexing:416", "timeout": 60.0, "type": "time", "unit": "seconds", "version": "8f3e9ba1fa6ae32795b77d4fb0a2cb3a36108a494ac5a33197076f41a75cee6c", "warmup_time": -1}, "indexing.MultiIndexing.time_loc_all_bool_indexers": {"code": "class MultiIndexing:\n    def time_loc_all_bool_indexers(self, unique_levels):\n        target = tuple([self.tgt_bool_indexer] * self.nlevels)\n        self.df.loc[target, :]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass MultiIndexing:\n    def setup(self, unique_levels):\n        self.nlevels = 2\n        if unique_levels:\n            mi = MultiIndex.from_arrays([range(1000000)] * self.nlevels)\n        else:\n            mi = MultiIndex.from_product([range(1000)] * self.nlevels)\n        self.df = DataFrame(np.random.randn(len(mi)), index=mi)\n    \n        self.tgt_slice = slice(200, 800)\n        self.tgt_null_slice = slice(None)\n        self.tgt_list = list(range(0, 1000, 10))\n        self.tgt_scalar = 500\n    \n        bool_indexer = np.zeros(len(mi), dtype=np.bool_)\n        bool_indexer[slice(0, len(mi), 100)] = True\n        self.tgt_bool_indexer = bool_indexer", "min_run_count": 2, "name": "indexing.MultiIndexing.time_loc_all_bool_indexers", "number": 0, "param_names": ["unique_levels"], "params": [["True", "False"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "1771918b3fe0b5cbe067324593f312813f66ac1576a3387207feb5abfb7ca806", "warmup_time": -1}, "indexing.MultiIndexing.time_loc_all_lists": {"code": "class MultiIndexing:\n    def time_loc_all_lists(self, unique_levels):\n        target = tuple([self.tgt_list] * self.nlevels)\n        self.df.loc[target, :]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass MultiIndexing:\n    def setup(self, unique_levels):\n        self.nlevels = 2\n        if unique_levels:\n            mi = MultiIndex.from_arrays([range(1000000)] * self.nlevels)\n        else:\n            mi = MultiIndex.from_product([range(1000)] * self.nlevels)\n        self.df = DataFrame(np.random.randn(len(mi)), index=mi)\n    \n        self.tgt_slice = slice(200, 800)\n        self.tgt_null_slice = slice(None)\n        self.tgt_list = list(range(0, 1000, 10))\n        self.tgt_scalar = 500\n    \n        bool_indexer = np.zeros(len(mi), dtype=np.bool_)\n        bool_indexer[slice(0, len(mi), 100)] = True\n        self.tgt_bool_indexer = bool_indexer", "min_run_count": 2, "name": "indexing.MultiIndexing.time_loc_all_lists", "number": 0, "param_names": ["unique_levels"], "params": [["True", "False"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "472ab8a43bc8d905a0c7bfecd2190e954a7da13e4e29ddbaf54d1ffa9c50a846", "warmup_time": -1}, "indexing.MultiIndexing.time_loc_all_null_slices": {"code": "class MultiIndexing:\n    def time_loc_all_null_slices(self, unique_levels):\n        target = tuple([self.tgt_null_slice] * self.nlevels)\n        self.df.loc[target, :]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass MultiIndexing:\n    def setup(self, unique_levels):\n        self.nlevels = 2\n        if unique_levels:\n            mi = MultiIndex.from_arrays([range(1000000)] * self.nlevels)\n        else:\n            mi = MultiIndex.from_product([range(1000)] * self.nlevels)\n        self.df = DataFrame(np.random.randn(len(mi)), index=mi)\n    \n        self.tgt_slice = slice(200, 800)\n        self.tgt_null_slice = slice(None)\n        self.tgt_list = list(range(0, 1000, 10))\n        self.tgt_scalar = 500\n    \n        bool_indexer = np.zeros(len(mi), dtype=np.bool_)\n        bool_indexer[slice(0, len(mi), 100)] = True\n        self.tgt_bool_indexer = bool_indexer", "min_run_count": 2, "name": "indexing.MultiIndexing.time_loc_all_null_slices", "number": 0, "param_names": ["unique_levels"], "params": [["True", "False"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "ee13de44701c0630572b0428b6d08740c41bc7278df47aae6f015bed57f20896", "warmup_time": -1}, "indexing.MultiIndexing.time_loc_all_scalars": {"code": "class MultiIndexing:\n    def time_loc_all_scalars(self, unique_levels):\n        target = tuple([self.tgt_scalar] * self.nlevels)\n        self.df.loc[target, :]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass MultiIndexing:\n    def setup(self, unique_levels):\n        self.nlevels = 2\n        if unique_levels:\n            mi = MultiIndex.from_arrays([range(1000000)] * self.nlevels)\n        else:\n            mi = MultiIndex.from_product([range(1000)] * self.nlevels)\n        self.df = DataFrame(np.random.randn(len(mi)), index=mi)\n    \n        self.tgt_slice = slice(200, 800)\n        self.tgt_null_slice = slice(None)\n        self.tgt_list = list(range(0, 1000, 10))\n        self.tgt_scalar = 500\n    \n        bool_indexer = np.zeros(len(mi), dtype=np.bool_)\n        bool_indexer[slice(0, len(mi), 100)] = True\n        self.tgt_bool_indexer = bool_indexer", "min_run_count": 2, "name": "indexing.MultiIndexing.time_loc_all_scalars", "number": 0, "param_names": ["unique_levels"], "params": [["True", "False"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "52fba5b8883c06b2ad277a711b4ac49603c38321be1afb8a2daf975deff153af", "warmup_time": -1}, "indexing.MultiIndexing.time_loc_all_slices": {"code": "class MultiIndexing:\n    def time_loc_all_slices(self, unique_levels):\n        target = tuple([self.tgt_slice] * self.nlevels)\n        self.df.loc[target, :]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass MultiIndexing:\n    def setup(self, unique_levels):\n        self.nlevels = 2\n        if unique_levels:\n            mi = MultiIndex.from_arrays([range(1000000)] * self.nlevels)\n        else:\n            mi = MultiIndex.from_product([range(1000)] * self.nlevels)\n        self.df = DataFrame(np.random.randn(len(mi)), index=mi)\n    \n        self.tgt_slice = slice(200, 800)\n        self.tgt_null_slice = slice(None)\n        self.tgt_list = list(range(0, 1000, 10))\n        self.tgt_scalar = 500\n    \n        bool_indexer = np.zeros(len(mi), dtype=np.bool_)\n        bool_indexer[slice(0, len(mi), 100)] = True\n        self.tgt_bool_indexer = bool_indexer", "min_run_count": 2, "name": "indexing.MultiIndexing.time_loc_all_slices", "number": 0, "param_names": ["unique_levels"], "params": [["True", "False"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "7ee6845e7a946179e2f28eb51291bf1e8dc5aa663346c5e70b7db58cf6a415d4", "warmup_time": -1}, "indexing.MultiIndexing.time_loc_null_slice_plus_slice": {"code": "class MultiIndexing:\n    def time_loc_null_slice_plus_slice(self, unique_levels):\n        target = (self.tgt_null_slice, self.tgt_slice)\n        self.df.loc[target, :]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass MultiIndexing:\n    def setup(self, unique_levels):\n        self.nlevels = 2\n        if unique_levels:\n            mi = MultiIndex.from_arrays([range(1000000)] * self.nlevels)\n        else:\n            mi = MultiIndex.from_product([range(1000)] * self.nlevels)\n        self.df = DataFrame(np.random.randn(len(mi)), index=mi)\n    \n        self.tgt_slice = slice(200, 800)\n        self.tgt_null_slice = slice(None)\n        self.tgt_list = list(range(0, 1000, 10))\n        self.tgt_scalar = 500\n    \n        bool_indexer = np.zeros(len(mi), dtype=np.bool_)\n        bool_indexer[slice(0, len(mi), 100)] = True\n        self.tgt_bool_indexer = bool_indexer", "min_run_count": 2, "name": "indexing.MultiIndexing.time_loc_null_slice_plus_slice", "number": 0, "param_names": ["unique_levels"], "params": [["True", "False"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "f8a8667e507761ed75e543d5d59a9b99abf35fbbd88506af79bba513db537b1d", "warmup_time": -1}, "indexing.MultiIndexing.time_loc_partial_key_bool_indexer": {"code": "class MultiIndexing:\n    def time_loc_partial_key_bool_indexer(self, unique_levels):\n        self.df.loc[self.tgt_bool_indexer, :]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass MultiIndexing:\n    def setup(self, unique_levels):\n        self.nlevels = 2\n        if unique_levels:\n            mi = MultiIndex.from_arrays([range(1000000)] * self.nlevels)\n        else:\n            mi = MultiIndex.from_product([range(1000)] * self.nlevels)\n        self.df = DataFrame(np.random.randn(len(mi)), index=mi)\n    \n        self.tgt_slice = slice(200, 800)\n        self.tgt_null_slice = slice(None)\n        self.tgt_list = list(range(0, 1000, 10))\n        self.tgt_scalar = 500\n    \n        bool_indexer = np.zeros(len(mi), dtype=np.bool_)\n        bool_indexer[slice(0, len(mi), 100)] = True\n        self.tgt_bool_indexer = bool_indexer", "min_run_count": 2, "name": "indexing.MultiIndexing.time_loc_partial_key_bool_indexer", "number": 0, "param_names": ["unique_levels"], "params": [["True", "False"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "f4163b15e26adc988dcb7d895e5ced6f1fa85495a29d44c6f1df7010fff0d379", "warmup_time": -1}, "indexing.MultiIndexing.time_loc_partial_key_list": {"code": "class MultiIndexing:\n    def time_loc_partial_key_list(self, unique_levels):\n        self.df.loc[self.tgt_list, :]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass MultiIndexing:\n    def setup(self, unique_levels):\n        self.nlevels = 2\n        if unique_levels:\n            mi = MultiIndex.from_arrays([range(1000000)] * self.nlevels)\n        else:\n            mi = MultiIndex.from_product([range(1000)] * self.nlevels)\n        self.df = DataFrame(np.random.randn(len(mi)), index=mi)\n    \n        self.tgt_slice = slice(200, 800)\n        self.tgt_null_slice = slice(None)\n        self.tgt_list = list(range(0, 1000, 10))\n        self.tgt_scalar = 500\n    \n        bool_indexer = np.zeros(len(mi), dtype=np.bool_)\n        bool_indexer[slice(0, len(mi), 100)] = True\n        self.tgt_bool_indexer = bool_indexer", "min_run_count": 2, "name": "indexing.MultiIndexing.time_loc_partial_key_list", "number": 0, "param_names": ["unique_levels"], "params": [["True", "False"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "3d998427658ce79d9730202287dfc27f39d7b70b94481fc82cc28c58bb10fc2c", "warmup_time": -1}, "indexing.MultiIndexing.time_loc_partial_key_null_slice": {"code": "class MultiIndexing:\n    def time_loc_partial_key_null_slice(self, unique_levels):\n        self.df.loc[self.tgt_null_slice, :]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass MultiIndexing:\n    def setup(self, unique_levels):\n        self.nlevels = 2\n        if unique_levels:\n            mi = MultiIndex.from_arrays([range(1000000)] * self.nlevels)\n        else:\n            mi = MultiIndex.from_product([range(1000)] * self.nlevels)\n        self.df = DataFrame(np.random.randn(len(mi)), index=mi)\n    \n        self.tgt_slice = slice(200, 800)\n        self.tgt_null_slice = slice(None)\n        self.tgt_list = list(range(0, 1000, 10))\n        self.tgt_scalar = 500\n    \n        bool_indexer = np.zeros(len(mi), dtype=np.bool_)\n        bool_indexer[slice(0, len(mi), 100)] = True\n        self.tgt_bool_indexer = bool_indexer", "min_run_count": 2, "name": "indexing.MultiIndexing.time_loc_partial_key_null_slice", "number": 0, "param_names": ["unique_levels"], "params": [["True", "False"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "777e2da95dafebe327dcbfc63277290e5760e3bb51661ddfe6a5fd3c7e0702bc", "warmup_time": -1}, "indexing.MultiIndexing.time_loc_partial_key_scalar": {"code": "class MultiIndexing:\n    def time_loc_partial_key_scalar(self, unique_levels):\n        self.df.loc[self.tgt_scalar, :]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass MultiIndexing:\n    def setup(self, unique_levels):\n        self.nlevels = 2\n        if unique_levels:\n            mi = MultiIndex.from_arrays([range(1000000)] * self.nlevels)\n        else:\n            mi = MultiIndex.from_product([range(1000)] * self.nlevels)\n        self.df = DataFrame(np.random.randn(len(mi)), index=mi)\n    \n        self.tgt_slice = slice(200, 800)\n        self.tgt_null_slice = slice(None)\n        self.tgt_list = list(range(0, 1000, 10))\n        self.tgt_scalar = 500\n    \n        bool_indexer = np.zeros(len(mi), dtype=np.bool_)\n        bool_indexer[slice(0, len(mi), 100)] = True\n        self.tgt_bool_indexer = bool_indexer", "min_run_count": 2, "name": "indexing.MultiIndexing.time_loc_partial_key_scalar", "number": 0, "param_names": ["unique_levels"], "params": [["True", "False"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "7fff81ab0ee84cd8d0d1cbb857a086f21277e9956a9dd836bbe17b4070bf4188", "warmup_time": -1}, "indexing.MultiIndexing.time_loc_partial_key_slice": {"code": "class MultiIndexing:\n    def time_loc_partial_key_slice(self, unique_levels):\n        self.df.loc[self.tgt_slice, :]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass MultiIndexing:\n    def setup(self, unique_levels):\n        self.nlevels = 2\n        if unique_levels:\n            mi = MultiIndex.from_arrays([range(1000000)] * self.nlevels)\n        else:\n            mi = MultiIndex.from_product([range(1000)] * self.nlevels)\n        self.df = DataFrame(np.random.randn(len(mi)), index=mi)\n    \n        self.tgt_slice = slice(200, 800)\n        self.tgt_null_slice = slice(None)\n        self.tgt_list = list(range(0, 1000, 10))\n        self.tgt_scalar = 500\n    \n        bool_indexer = np.zeros(len(mi), dtype=np.bool_)\n        bool_indexer[slice(0, len(mi), 100)] = True\n        self.tgt_bool_indexer = bool_indexer", "min_run_count": 2, "name": "indexing.MultiIndexing.time_loc_partial_key_slice", "number": 0, "param_names": ["unique_levels"], "params": [["True", "False"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "7e493377f1a856eeb73c21aae1208537b26a4a29edb1afaa8ac89e4ffa29ef49", "warmup_time": -1}, "indexing.MultiIndexing.time_loc_slice_plus_null_slice": {"code": "class MultiIndexing:\n    def time_loc_slice_plus_null_slice(self, unique_levels):\n        target = (self.tgt_slice, self.tgt_null_slice)\n        self.df.loc[target, :]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass MultiIndexing:\n    def setup(self, unique_levels):\n        self.nlevels = 2\n        if unique_levels:\n            mi = MultiIndex.from_arrays([range(1000000)] * self.nlevels)\n        else:\n            mi = MultiIndex.from_product([range(1000)] * self.nlevels)\n        self.df = DataFrame(np.random.randn(len(mi)), index=mi)\n    \n        self.tgt_slice = slice(200, 800)\n        self.tgt_null_slice = slice(None)\n        self.tgt_list = list(range(0, 1000, 10))\n        self.tgt_scalar = 500\n    \n        bool_indexer = np.zeros(len(mi), dtype=np.bool_)\n        bool_indexer[slice(0, len(mi), 100)] = True\n        self.tgt_bool_indexer = bool_indexer", "min_run_count": 2, "name": "indexing.MultiIndexing.time_loc_slice_plus_null_slice", "number": 0, "param_names": ["unique_levels"], "params": [["True", "False"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "e35e95d2686e9edb9c298e881d73f80b937d8cc77b9c363ce78a9e6f079157f9", "warmup_time": -1}, "indexing.MultiIndexing.time_xs_full_key": {"code": "class MultiIndexing:\n    def time_xs_full_key(self, unique_levels):\n        target = tuple([self.tgt_scalar] * self.nlevels)\n        self.df.xs(target)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass MultiIndexing:\n    def setup(self, unique_levels):\n        self.nlevels = 2\n        if unique_levels:\n            mi = MultiIndex.from_arrays([range(1000000)] * self.nlevels)\n        else:\n            mi = MultiIndex.from_product([range(1000)] * self.nlevels)\n        self.df = DataFrame(np.random.randn(len(mi)), index=mi)\n    \n        self.tgt_slice = slice(200, 800)\n        self.tgt_null_slice = slice(None)\n        self.tgt_list = list(range(0, 1000, 10))\n        self.tgt_scalar = 500\n    \n        bool_indexer = np.zeros(len(mi), dtype=np.bool_)\n        bool_indexer[slice(0, len(mi), 100)] = True\n        self.tgt_bool_indexer = bool_indexer", "min_run_count": 2, "name": "indexing.MultiIndexing.time_xs_full_key", "number": 0, "param_names": ["unique_levels"], "params": [["True", "False"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "d9bbac09a6803b7e0d554f99cfbfa0517a1d7320e6a6af606bce52ec78fe89d5", "warmup_time": -1}, "indexing.MultiIndexing.time_xs_level_0": {"code": "class MultiIndexing:\n    def time_xs_level_0(self, unique_levels):\n        target = self.tgt_scalar\n        self.df.xs(target, level=0)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass MultiIndexing:\n    def setup(self, unique_levels):\n        self.nlevels = 2\n        if unique_levels:\n            mi = MultiIndex.from_arrays([range(1000000)] * self.nlevels)\n        else:\n            mi = MultiIndex.from_product([range(1000)] * self.nlevels)\n        self.df = DataFrame(np.random.randn(len(mi)), index=mi)\n    \n        self.tgt_slice = slice(200, 800)\n        self.tgt_null_slice = slice(None)\n        self.tgt_list = list(range(0, 1000, 10))\n        self.tgt_scalar = 500\n    \n        bool_indexer = np.zeros(len(mi), dtype=np.bool_)\n        bool_indexer[slice(0, len(mi), 100)] = True\n        self.tgt_bool_indexer = bool_indexer", "min_run_count": 2, "name": "indexing.MultiIndexing.time_xs_level_0", "number": 0, "param_names": ["unique_levels"], "params": [["True", "False"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "daaf4beb33874670dbba4df791aff72a906678fd1058938bc990e56cd7b733e3", "warmup_time": -1}, "indexing.MultiIndexing.time_xs_level_1": {"code": "class MultiIndexing:\n    def time_xs_level_1(self, unique_levels):\n        target = self.tgt_scalar\n        self.df.xs(target, level=1)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass MultiIndexing:\n    def setup(self, unique_levels):\n        self.nlevels = 2\n        if unique_levels:\n            mi = MultiIndex.from_arrays([range(1000000)] * self.nlevels)\n        else:\n            mi = MultiIndex.from_product([range(1000)] * self.nlevels)\n        self.df = DataFrame(np.random.randn(len(mi)), index=mi)\n    \n        self.tgt_slice = slice(200, 800)\n        self.tgt_null_slice = slice(None)\n        self.tgt_list = list(range(0, 1000, 10))\n        self.tgt_scalar = 500\n    \n        bool_indexer = np.zeros(len(mi), dtype=np.bool_)\n        bool_indexer[slice(0, len(mi), 100)] = True\n        self.tgt_bool_indexer = bool_indexer", "min_run_count": 2, "name": "indexing.MultiIndexing.time_xs_level_1", "number": 0, "param_names": ["unique_levels"], "params": [["True", "False"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "464f6f9822548adbb0a5afc6fd74b0fa4a5077d6215ac2a85daf48a6454b74b8", "warmup_time": -1}, "indexing.NonNumericSeriesIndexing.time_getitem_label_slice": {"code": "class NonNumericSeriesIndexing:\n    def time_getitem_label_slice(self, index, index_structure):\n        self.s[: self.lbl]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass NonNumericSeriesIndexing:\n    def setup(self, index, index_structure):\n        N = 10**6\n        if index == \"string\":\n            index = tm.makeStringIndex(N)\n        elif index == \"datetime\":\n            index = date_range(\"1900\", periods=N, freq=\"s\")\n        elif index == \"period\":\n            index = period_range(\"1900\", periods=N, freq=\"s\")\n        index = index.sort_values()\n        assert index.is_unique and index.is_monotonic_increasing\n        if index_structure == \"nonunique_monotonic_inc\":\n            index = index.insert(item=index[2], loc=2)[:-1]\n        elif index_structure == \"non_monotonic\":\n            index = index[::2].append(index[1::2])\n            assert len(index) == N\n        self.s = Series(np.random.rand(N), index=index)\n        self.lbl = index[80000]\n        # warm up index mapping\n        self.s[self.lbl]", "min_run_count": 2, "name": "indexing.NonNumericSeriesIndexing.time_getitem_label_slice", "number": 0, "param_names": ["index_dtype", "index_structure"], "params": [["'string'", "'datetime'", "'period'"], ["'unique_monotonic_inc'", "'nonunique_monotonic_inc'", "'non_monotonic'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "811d3861520f2001011b87ad03ffb62c1fb5a8e906d1b0f69d20a7e252042941", "warmup_time": -1}, "indexing.NonNumericSeriesIndexing.time_getitem_list_like": {"code": "class NonNumericSeriesIndexing:\n    def time_getitem_list_like(self, index, index_structure):\n        self.s[[self.lbl]]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass NonNumericSeriesIndexing:\n    def setup(self, index, index_structure):\n        N = 10**6\n        if index == \"string\":\n            index = tm.makeStringIndex(N)\n        elif index == \"datetime\":\n            index = date_range(\"1900\", periods=N, freq=\"s\")\n        elif index == \"period\":\n            index = period_range(\"1900\", periods=N, freq=\"s\")\n        index = index.sort_values()\n        assert index.is_unique and index.is_monotonic_increasing\n        if index_structure == \"nonunique_monotonic_inc\":\n            index = index.insert(item=index[2], loc=2)[:-1]\n        elif index_structure == \"non_monotonic\":\n            index = index[::2].append(index[1::2])\n            assert len(index) == N\n        self.s = Series(np.random.rand(N), index=index)\n        self.lbl = index[80000]\n        # warm up index mapping\n        self.s[self.lbl]", "min_run_count": 2, "name": "indexing.NonNumericSeriesIndexing.time_getitem_list_like", "number": 0, "param_names": ["index_dtype", "index_structure"], "params": [["'string'", "'datetime'", "'period'"], ["'unique_monotonic_inc'", "'nonunique_monotonic_inc'", "'non_monotonic'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "d5f03b2722c50f59fef5c5897b636d0fafb2ba9882dc1f1f422230c56dcc9f19", "warmup_time": -1}, "indexing.NonNumericSeriesIndexing.time_getitem_pos_slice": {"code": "class NonNumericSeriesIndexing:\n    def time_getitem_pos_slice(self, index, index_structure):\n        self.s[:80000]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass NonNumericSeriesIndexing:\n    def setup(self, index, index_structure):\n        N = 10**6\n        if index == \"string\":\n            index = tm.makeStringIndex(N)\n        elif index == \"datetime\":\n            index = date_range(\"1900\", periods=N, freq=\"s\")\n        elif index == \"period\":\n            index = period_range(\"1900\", periods=N, freq=\"s\")\n        index = index.sort_values()\n        assert index.is_unique and index.is_monotonic_increasing\n        if index_structure == \"nonunique_monotonic_inc\":\n            index = index.insert(item=index[2], loc=2)[:-1]\n        elif index_structure == \"non_monotonic\":\n            index = index[::2].append(index[1::2])\n            assert len(index) == N\n        self.s = Series(np.random.rand(N), index=index)\n        self.lbl = index[80000]\n        # warm up index mapping\n        self.s[self.lbl]", "min_run_count": 2, "name": "indexing.NonNumericSeriesIndexing.time_getitem_pos_slice", "number": 0, "param_names": ["index_dtype", "index_structure"], "params": [["'string'", "'datetime'", "'period'"], ["'unique_monotonic_inc'", "'nonunique_monotonic_inc'", "'non_monotonic'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "68495b4c6566712a89e5ffc20d1d5220bce941d1bb4fe6db5280f5940be5876d", "warmup_time": -1}, "indexing.NonNumericSeriesIndexing.time_getitem_scalar": {"code": "class NonNumericSeriesIndexing:\n    def time_getitem_scalar(self, index, index_structure):\n        self.s[self.lbl]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass NonNumericSeriesIndexing:\n    def setup(self, index, index_structure):\n        N = 10**6\n        if index == \"string\":\n            index = tm.makeStringIndex(N)\n        elif index == \"datetime\":\n            index = date_range(\"1900\", periods=N, freq=\"s\")\n        elif index == \"period\":\n            index = period_range(\"1900\", periods=N, freq=\"s\")\n        index = index.sort_values()\n        assert index.is_unique and index.is_monotonic_increasing\n        if index_structure == \"nonunique_monotonic_inc\":\n            index = index.insert(item=index[2], loc=2)[:-1]\n        elif index_structure == \"non_monotonic\":\n            index = index[::2].append(index[1::2])\n            assert len(index) == N\n        self.s = Series(np.random.rand(N), index=index)\n        self.lbl = index[80000]\n        # warm up index mapping\n        self.s[self.lbl]", "min_run_count": 2, "name": "indexing.NonNumericSeriesIndexing.time_getitem_scalar", "number": 0, "param_names": ["index_dtype", "index_structure"], "params": [["'string'", "'datetime'", "'period'"], ["'unique_monotonic_inc'", "'nonunique_monotonic_inc'", "'non_monotonic'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "0fef91dd57992a25df2e27f55a134359db1807fe73078f4a7f9d84aa7565abe6", "warmup_time": -1}, "indexing.NumericMaskedIndexing.time_get_indexer": {"code": "class NumericMaskedIndexing:\n    def time_get_indexer(self, dtype, monotonic):\n        self.data.get_indexer(self.indexer)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass NumericMaskedIndexing:\n    def setup(self, dtype, monotonic):\n        indices = {\n            True: Index(self.monotonic_list, dtype=dtype),\n            False: Index(self.non_monotonic_list, dtype=dtype).append(\n                Index([NA], dtype=dtype)\n            ),\n        }\n        self.data = indices[monotonic]\n        self.indexer = np.arange(300, 1_000)\n        self.data_dups = self.data.append(self.data)", "min_run_count": 2, "name": "indexing.NumericMaskedIndexing.time_get_indexer", "number": 0, "param_names": ["dtype", "monotonic"], "params": [["'Int64'", "'UInt64'", "'Float64'"], ["True", "False"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "c9f9a8ac9f8595fa973302687b629db6bf6b9924be4c3431f56d1b61c68570d2", "warmup_time": -1}, "indexing.NumericMaskedIndexing.time_get_indexer_dups": {"code": "class NumericMaskedIndexing:\n    def time_get_indexer_dups(self, dtype, monotonic):\n        self.data.get_indexer_for(self.indexer)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass NumericMaskedIndexing:\n    def setup(self, dtype, monotonic):\n        indices = {\n            True: Index(self.monotonic_list, dtype=dtype),\n            False: Index(self.non_monotonic_list, dtype=dtype).append(\n                Index([NA], dtype=dtype)\n            ),\n        }\n        self.data = indices[monotonic]\n        self.indexer = np.arange(300, 1_000)\n        self.data_dups = self.data.append(self.data)", "min_run_count": 2, "name": "indexing.NumericMaskedIndexing.time_get_indexer_dups", "number": 0, "param_names": ["dtype", "monotonic"], "params": [["'Int64'", "'UInt64'", "'Float64'"], ["True", "False"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "650c0af5a8f5231315bb45ae613c0b6e4fe1a990510b7c6ef5cb41e20818e616", "warmup_time": -1}, "indexing.NumericSeriesIndexing.time_getitem_array": {"code": "class NumericSeriesIndexing:\n    def time_getitem_array(self, index, index_structure):\n        self.data[self.array]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass NumericSeriesIndexing:\n    def setup(self, dtype, index_structure):\n        N = 10**6\n        indices = {\n            \"unique_monotonic_inc\": Index(range(N), dtype=dtype),\n            \"nonunique_monotonic_inc\": Index(\n                list(range(55)) + [54] + list(range(55, N - 1)), dtype=dtype\n            ),\n        }\n        self.data = Series(np.random.rand(N), index=indices[index_structure])\n        self.array = np.arange(10000)\n        self.array_list = self.array.tolist()", "min_run_count": 2, "name": "indexing.NumericSeriesIndexing.time_getitem_array", "number": 0, "param_names": ["dtype", "index_structure"], "params": [["<class 'numpy.int64'>", "<class 'numpy.uint64'>", "<class 'numpy.float64'>"], ["'unique_monotonic_inc'", "'nonunique_monotonic_inc'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "f8dbc1486bd95bff70285ace102a5d9ae45c39e61501c81985e19c24fef1d788", "warmup_time": -1}, "indexing.NumericSeriesIndexing.time_getitem_list_like": {"code": "class NumericSeriesIndexing:\n    def time_getitem_list_like(self, index, index_structure):\n        self.data[[800000]]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass NumericSeriesIndexing:\n    def setup(self, dtype, index_structure):\n        N = 10**6\n        indices = {\n            \"unique_monotonic_inc\": Index(range(N), dtype=dtype),\n            \"nonunique_monotonic_inc\": Index(\n                list(range(55)) + [54] + list(range(55, N - 1)), dtype=dtype\n            ),\n        }\n        self.data = Series(np.random.rand(N), index=indices[index_structure])\n        self.array = np.arange(10000)\n        self.array_list = self.array.tolist()", "min_run_count": 2, "name": "indexing.NumericSeriesIndexing.time_getitem_list_like", "number": 0, "param_names": ["dtype", "index_structure"], "params": [["<class 'numpy.int64'>", "<class 'numpy.uint64'>", "<class 'numpy.float64'>"], ["'unique_monotonic_inc'", "'nonunique_monotonic_inc'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "767f017c9055f888f75b6eed2e15a080b0b64319d1095620556c015c88fa110d", "warmup_time": -1}, "indexing.NumericSeriesIndexing.time_getitem_lists": {"code": "class NumericSeriesIndexing:\n    def time_getitem_lists(self, index, index_structure):\n        self.data[self.array_list]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass NumericSeriesIndexing:\n    def setup(self, dtype, index_structure):\n        N = 10**6\n        indices = {\n            \"unique_monotonic_inc\": Index(range(N), dtype=dtype),\n            \"nonunique_monotonic_inc\": Index(\n                list(range(55)) + [54] + list(range(55, N - 1)), dtype=dtype\n            ),\n        }\n        self.data = Series(np.random.rand(N), index=indices[index_structure])\n        self.array = np.arange(10000)\n        self.array_list = self.array.tolist()", "min_run_count": 2, "name": "indexing.NumericSeriesIndexing.time_getitem_lists", "number": 0, "param_names": ["dtype", "index_structure"], "params": [["<class 'numpy.int64'>", "<class 'numpy.uint64'>", "<class 'numpy.float64'>"], ["'unique_monotonic_inc'", "'nonunique_monotonic_inc'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "443e55142dfd34591a735feb3d4d744e6958acb9018b753424bb95601e47a666", "warmup_time": -1}, "indexing.NumericSeriesIndexing.time_getitem_scalar": {"code": "class NumericSeriesIndexing:\n    def time_getitem_scalar(self, index, index_structure):\n        self.data[800000]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass NumericSeriesIndexing:\n    def setup(self, dtype, index_structure):\n        N = 10**6\n        indices = {\n            \"unique_monotonic_inc\": Index(range(N), dtype=dtype),\n            \"nonunique_monotonic_inc\": Index(\n                list(range(55)) + [54] + list(range(55, N - 1)), dtype=dtype\n            ),\n        }\n        self.data = Series(np.random.rand(N), index=indices[index_structure])\n        self.array = np.arange(10000)\n        self.array_list = self.array.tolist()", "min_run_count": 2, "name": "indexing.NumericSeriesIndexing.time_getitem_scalar", "number": 0, "param_names": ["dtype", "index_structure"], "params": [["<class 'numpy.int64'>", "<class 'numpy.uint64'>", "<class 'numpy.float64'>"], ["'unique_monotonic_inc'", "'nonunique_monotonic_inc'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "73c063a362862485753efeb9a6fbc07336e18a6c35add26bec792086df47b674", "warmup_time": -1}, "indexing.NumericSeriesIndexing.time_getitem_slice": {"code": "class NumericSeriesIndexing:\n    def time_getitem_slice(self, index, index_structure):\n        self.data[:800000]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass NumericSeriesIndexing:\n    def setup(self, dtype, index_structure):\n        N = 10**6\n        indices = {\n            \"unique_monotonic_inc\": Index(range(N), dtype=dtype),\n            \"nonunique_monotonic_inc\": Index(\n                list(range(55)) + [54] + list(range(55, N - 1)), dtype=dtype\n            ),\n        }\n        self.data = Series(np.random.rand(N), index=indices[index_structure])\n        self.array = np.arange(10000)\n        self.array_list = self.array.tolist()", "min_run_count": 2, "name": "indexing.NumericSeriesIndexing.time_getitem_slice", "number": 0, "param_names": ["dtype", "index_structure"], "params": [["<class 'numpy.int64'>", "<class 'numpy.uint64'>", "<class 'numpy.float64'>"], ["'unique_monotonic_inc'", "'nonunique_monotonic_inc'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "53dd251b95b13c6d4735cc1d1ad7f926e4ec0328748779a56fa1c63f4fa359a0", "warmup_time": -1}, "indexing.NumericSeriesIndexing.time_iloc_array": {"code": "class NumericSeriesIndexing:\n    def time_iloc_array(self, index, index_structure):\n        self.data.iloc[self.array]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass NumericSeriesIndexing:\n    def setup(self, dtype, index_structure):\n        N = 10**6\n        indices = {\n            \"unique_monotonic_inc\": Index(range(N), dtype=dtype),\n            \"nonunique_monotonic_inc\": Index(\n                list(range(55)) + [54] + list(range(55, N - 1)), dtype=dtype\n            ),\n        }\n        self.data = Series(np.random.rand(N), index=indices[index_structure])\n        self.array = np.arange(10000)\n        self.array_list = self.array.tolist()", "min_run_count": 2, "name": "indexing.NumericSeriesIndexing.time_iloc_array", "number": 0, "param_names": ["dtype", "index_structure"], "params": [["<class 'numpy.int64'>", "<class 'numpy.uint64'>", "<class 'numpy.float64'>"], ["'unique_monotonic_inc'", "'nonunique_monotonic_inc'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "7ca4d36d48a371195da509750de2d5dbb5fe15f466c419bd88a3d832c7339921", "warmup_time": -1}, "indexing.NumericSeriesIndexing.time_iloc_list_like": {"code": "class NumericSeriesIndexing:\n    def time_iloc_list_like(self, index, index_structure):\n        self.data.iloc[[800000]]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass NumericSeriesIndexing:\n    def setup(self, dtype, index_structure):\n        N = 10**6\n        indices = {\n            \"unique_monotonic_inc\": Index(range(N), dtype=dtype),\n            \"nonunique_monotonic_inc\": Index(\n                list(range(55)) + [54] + list(range(55, N - 1)), dtype=dtype\n            ),\n        }\n        self.data = Series(np.random.rand(N), index=indices[index_structure])\n        self.array = np.arange(10000)\n        self.array_list = self.array.tolist()", "min_run_count": 2, "name": "indexing.NumericSeriesIndexing.time_iloc_list_like", "number": 0, "param_names": ["dtype", "index_structure"], "params": [["<class 'numpy.int64'>", "<class 'numpy.uint64'>", "<class 'numpy.float64'>"], ["'unique_monotonic_inc'", "'nonunique_monotonic_inc'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "e6eb0977e121dbf9c0f8fed57bba4cbd0712e219c303813a323edfbeb879ca5f", "warmup_time": -1}, "indexing.NumericSeriesIndexing.time_iloc_scalar": {"code": "class NumericSeriesIndexing:\n    def time_iloc_scalar(self, index, index_structure):\n        self.data.iloc[800000]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass NumericSeriesIndexing:\n    def setup(self, dtype, index_structure):\n        N = 10**6\n        indices = {\n            \"unique_monotonic_inc\": Index(range(N), dtype=dtype),\n            \"nonunique_monotonic_inc\": Index(\n                list(range(55)) + [54] + list(range(55, N - 1)), dtype=dtype\n            ),\n        }\n        self.data = Series(np.random.rand(N), index=indices[index_structure])\n        self.array = np.arange(10000)\n        self.array_list = self.array.tolist()", "min_run_count": 2, "name": "indexing.NumericSeriesIndexing.time_iloc_scalar", "number": 0, "param_names": ["dtype", "index_structure"], "params": [["<class 'numpy.int64'>", "<class 'numpy.uint64'>", "<class 'numpy.float64'>"], ["'unique_monotonic_inc'", "'nonunique_monotonic_inc'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "d5a3df9b91de4f27357390975b96e77f6fe4ed9eced3a16044211134bc38617b", "warmup_time": -1}, "indexing.NumericSeriesIndexing.time_iloc_slice": {"code": "class NumericSeriesIndexing:\n    def time_iloc_slice(self, index, index_structure):\n        self.data.iloc[:800000]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass NumericSeriesIndexing:\n    def setup(self, dtype, index_structure):\n        N = 10**6\n        indices = {\n            \"unique_monotonic_inc\": Index(range(N), dtype=dtype),\n            \"nonunique_monotonic_inc\": Index(\n                list(range(55)) + [54] + list(range(55, N - 1)), dtype=dtype\n            ),\n        }\n        self.data = Series(np.random.rand(N), index=indices[index_structure])\n        self.array = np.arange(10000)\n        self.array_list = self.array.tolist()", "min_run_count": 2, "name": "indexing.NumericSeriesIndexing.time_iloc_slice", "number": 0, "param_names": ["dtype", "index_structure"], "params": [["<class 'numpy.int64'>", "<class 'numpy.uint64'>", "<class 'numpy.float64'>"], ["'unique_monotonic_inc'", "'nonunique_monotonic_inc'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "6dd75593c3e3cf6040fc6b6152cae16559fec377ae607105dc5867d7257d6e6b", "warmup_time": -1}, "indexing.NumericSeriesIndexing.time_loc_array": {"code": "class NumericSeriesIndexing:\n    def time_loc_array(self, index, index_structure):\n        self.data.loc[self.array]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass NumericSeriesIndexing:\n    def setup(self, dtype, index_structure):\n        N = 10**6\n        indices = {\n            \"unique_monotonic_inc\": Index(range(N), dtype=dtype),\n            \"nonunique_monotonic_inc\": Index(\n                list(range(55)) + [54] + list(range(55, N - 1)), dtype=dtype\n            ),\n        }\n        self.data = Series(np.random.rand(N), index=indices[index_structure])\n        self.array = np.arange(10000)\n        self.array_list = self.array.tolist()", "min_run_count": 2, "name": "indexing.NumericSeriesIndexing.time_loc_array", "number": 0, "param_names": ["dtype", "index_structure"], "params": [["<class 'numpy.int64'>", "<class 'numpy.uint64'>", "<class 'numpy.float64'>"], ["'unique_monotonic_inc'", "'nonunique_monotonic_inc'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "3165bdce66ae50b67ee74bf5b720ddc68ab182ec7445bc812e1c0a6282bdf773", "warmup_time": -1}, "indexing.NumericSeriesIndexing.time_loc_list_like": {"code": "class NumericSeriesIndexing:\n    def time_loc_list_like(self, index, index_structure):\n        self.data.loc[[800000]]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass NumericSeriesIndexing:\n    def setup(self, dtype, index_structure):\n        N = 10**6\n        indices = {\n            \"unique_monotonic_inc\": Index(range(N), dtype=dtype),\n            \"nonunique_monotonic_inc\": Index(\n                list(range(55)) + [54] + list(range(55, N - 1)), dtype=dtype\n            ),\n        }\n        self.data = Series(np.random.rand(N), index=indices[index_structure])\n        self.array = np.arange(10000)\n        self.array_list = self.array.tolist()", "min_run_count": 2, "name": "indexing.NumericSeriesIndexing.time_loc_list_like", "number": 0, "param_names": ["dtype", "index_structure"], "params": [["<class 'numpy.int64'>", "<class 'numpy.uint64'>", "<class 'numpy.float64'>"], ["'unique_monotonic_inc'", "'nonunique_monotonic_inc'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "9bd41a8e0e77f49c1815e6441bfed382f1642a7ffd8d470af8ae822095871ce7", "warmup_time": -1}, "indexing.NumericSeriesIndexing.time_loc_scalar": {"code": "class NumericSeriesIndexing:\n    def time_loc_scalar(self, index, index_structure):\n        self.data.loc[800000]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass NumericSeriesIndexing:\n    def setup(self, dtype, index_structure):\n        N = 10**6\n        indices = {\n            \"unique_monotonic_inc\": Index(range(N), dtype=dtype),\n            \"nonunique_monotonic_inc\": Index(\n                list(range(55)) + [54] + list(range(55, N - 1)), dtype=dtype\n            ),\n        }\n        self.data = Series(np.random.rand(N), index=indices[index_structure])\n        self.array = np.arange(10000)\n        self.array_list = self.array.tolist()", "min_run_count": 2, "name": "indexing.NumericSeriesIndexing.time_loc_scalar", "number": 0, "param_names": ["dtype", "index_structure"], "params": [["<class 'numpy.int64'>", "<class 'numpy.uint64'>", "<class 'numpy.float64'>"], ["'unique_monotonic_inc'", "'nonunique_monotonic_inc'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "ca036299851e1902e2e167658690aabd8b3c4a23c4565717eaed87565bac7725", "warmup_time": -1}, "indexing.NumericSeriesIndexing.time_loc_slice": {"code": "class NumericSeriesIndexing:\n    def time_loc_slice(self, index, index_structure):\n        self.data.loc[:800000]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass NumericSeriesIndexing:\n    def setup(self, dtype, index_structure):\n        N = 10**6\n        indices = {\n            \"unique_monotonic_inc\": Index(range(N), dtype=dtype),\n            \"nonunique_monotonic_inc\": Index(\n                list(range(55)) + [54] + list(range(55, N - 1)), dtype=dtype\n            ),\n        }\n        self.data = Series(np.random.rand(N), index=indices[index_structure])\n        self.array = np.arange(10000)\n        self.array_list = self.array.tolist()", "min_run_count": 2, "name": "indexing.NumericSeriesIndexing.time_loc_slice", "number": 0, "param_names": ["dtype", "index_structure"], "params": [["<class 'numpy.int64'>", "<class 'numpy.uint64'>", "<class 'numpy.float64'>"], ["'unique_monotonic_inc'", "'nonunique_monotonic_inc'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "7ec9524466f40bb446af6342c1220299a782e5c6c08e8a074782d963360ff732", "warmup_time": -1}, "indexing.Setitem.time_setitem": {"code": "class Setitem:\n    def time_setitem(self):\n        self.df[100] = 100\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Setitem:\n    def setup(self):\n        N = 500_000\n        cols = 500\n        self.df = DataFrame(np.random.rand(N, cols))", "min_run_count": 2, "name": "indexing.Setitem.time_setitem", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "05f726f7641992ec4777d8bd735c1ae3ec9b5046bec013ae0c155fe1b3e37560", "warmup_time": -1}, "indexing.Setitem.time_setitem_list": {"code": "class Setitem:\n    def time_setitem_list(self):\n        self.df[[100, 200, 300]] = 100\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Setitem:\n    def setup(self):\n        N = 500_000\n        cols = 500\n        self.df = DataFrame(np.random.rand(N, cols))", "min_run_count": 2, "name": "indexing.Setitem.time_setitem_list", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "6ae63a2e6c513edbdfdf8c6e2acfeca129311e22230ada6b94c26bda50916b2b", "warmup_time": -1}, "indexing.SortedAndUnsortedDatetimeIndexLoc.time_loc_sorted": {"code": "class SortedAndUnsortedDatetimeIndexLoc:\n    def time_loc_sorted(self):\n        self.df_sort.loc[\"2016-6-11\"]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass SortedAndUnsortedDatetimeIndexLoc:\n    def setup(self):\n        dti = date_range(\"2016-01-01\", periods=10000, tz=\"US/Pacific\")\n        index = np.array(dti)\n    \n        unsorted_index = index.copy()\n        unsorted_index[10] = unsorted_index[20]\n    \n        self.df_unsorted = DataFrame(index=unsorted_index, data={\"a\": 1})\n        self.df_sort = DataFrame(index=index, data={\"a\": 1})", "min_run_count": 2, "name": "indexing.SortedAndUnsortedDatetimeIndexLoc.time_loc_sorted", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "0f65be8fdfcef229110b3366c9eeec8b227559f9db6dbbae3de7e915928496c4", "warmup_time": -1}, "indexing.SortedAndUnsortedDatetimeIndexLoc.time_loc_unsorted": {"code": "class SortedAndUnsortedDatetimeIndexLoc:\n    def time_loc_unsorted(self):\n        self.df_unsorted.loc[\"2016-6-11\"]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass SortedAndUnsortedDatetimeIndexLoc:\n    def setup(self):\n        dti = date_range(\"2016-01-01\", periods=10000, tz=\"US/Pacific\")\n        index = np.array(dti)\n    \n        unsorted_index = index.copy()\n        unsorted_index[10] = unsorted_index[20]\n    \n        self.df_unsorted = DataFrame(index=unsorted_index, data={\"a\": 1})\n        self.df_sort = DataFrame(index=index, data={\"a\": 1})", "min_run_count": 2, "name": "indexing.SortedAndUnsortedDatetimeIndexLoc.time_loc_unsorted", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "7f7406b54217c050b92bb548cd77d9e99371a9102aed4a513cc83b2677d7dd3d", "warmup_time": -1}, "indexing.Take.time_take": {"code": "class Take:\n    def time_take(self, index):\n        self.s.take(self.indexer)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Take:\n    def setup(self, index):\n        N = 100000\n        indexes = {\n            \"int\": Index(np.arange(N), dtype=np.int64),\n            \"datetime\": date_range(\"2011-01-01\", freq=\"S\", periods=N),\n        }\n        index = indexes[index]\n        self.s = Series(np.random.rand(N), index=index)\n        self.indexer = np.random.randint(0, N, size=N)", "min_run_count": 2, "name": "indexing.Take.time_take", "number": 0, "param_names": ["index"], "params": [["'int'", "'datetime'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "e634816b6d36759558a7852e07fa8fd6f8177e6f501d75f64e9477d82c2a8bbf", "warmup_time": -1}, "indexing_engines.MaskedNumericEngineIndexing.time_get_loc": {"code": "class MaskedNumericEngineIndexing:\n    def time_get_loc(self, engine_and_dtype, index_type, unique, N):\n        self.data.get_loc(self.key_early)\n\n    def setup(self, engine_and_dtype, index_type, unique, N):\n        engine, dtype = engine_and_dtype\n    \n        if index_type == \"monotonic_incr\":\n            if unique:\n                arr = np.arange(N * 3, dtype=dtype.lower())\n            else:\n                values = list([1] * N + [2] * N + [3] * N)\n                arr = np.array(values, dtype=dtype.lower())\n            mask = np.zeros(N * 3, dtype=np.bool_)\n        elif index_type == \"monotonic_decr\":\n            if unique:\n                arr = np.arange(N * 3, dtype=dtype.lower())[::-1]\n            else:\n                values = list([1] * N + [2] * N + [3] * N)\n                arr = np.array(values, dtype=dtype.lower())[::-1]\n            mask = np.zeros(N * 3, dtype=np.bool_)\n        else:\n            assert index_type == \"non_monotonic\"\n            if unique:\n                arr = np.zeros(N * 3, dtype=dtype.lower())\n                arr[:N] = np.arange(N * 2, N * 3, dtype=dtype.lower())\n                arr[N:] = np.arange(N * 2, dtype=dtype.lower())\n    \n            else:\n                arr = np.array([1, 2, 3] * N, dtype=dtype.lower())\n            mask = np.zeros(N * 3, dtype=np.bool_)\n            mask[-1] = True\n    \n        self.data = engine(BaseMaskedArray(arr, mask))\n        # code belows avoids populating the mapping etc. while timing.\n        self.data.get_loc(2)\n    \n        self.key_middle = arr[len(arr) // 2]\n        self.key_early = arr[2]", "min_run_count": 2, "name": "indexing_engines.MaskedNumericEngineIndexing.time_get_loc", "number": 0, "param_names": ["engine_and_dtype", "index_type", "unique", "N"], "params": [["(<class 'pandas._libs.index.MaskedInt64Engine'>, 'Int64')", "(<class 'pandas._libs.index.MaskedInt32Engine'>, 'Int32')", "(<class 'pandas._libs.index.MaskedInt16Engine'>, 'Int16')", "(<class 'pandas._libs.index.MaskedInt8Engine'>, 'Int8')", "(<class 'pandas._libs.index.MaskedUInt64Engine'>, 'UInt64')", "(<class 'pandas._libs.index.MaskedUInt32Engine'>, 'UInt32')", "(<class 'pandas._libs.index.MaskedUInt8Engine'>, 'UInt8')", "(<class 'pandas._libs.index.MaskedFloat64Engine'>, 'Float64')", "(<class 'pandas._libs.index.MaskedFloat32Engine'>, 'Float32')"], ["'monotonic_incr'", "'monotonic_decr'", "'non_monotonic'"], ["True", "False"], ["100000", "2000000"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "c2abd141c4c8b60de92e678f5208de412a56708552c710232867817234bc2587", "warmup_time": -1}, "indexing_engines.MaskedNumericEngineIndexing.time_get_loc_near_middle": {"code": "class MaskedNumericEngineIndexing:\n    def time_get_loc_near_middle(self, engine_and_dtype, index_type, unique, N):\n        # searchsorted performance may be different near the middle of a range\n        #  vs near an endpoint\n        self.data.get_loc(self.key_middle)\n\n    def setup(self, engine_and_dtype, index_type, unique, N):\n        engine, dtype = engine_and_dtype\n    \n        if index_type == \"monotonic_incr\":\n            if unique:\n                arr = np.arange(N * 3, dtype=dtype.lower())\n            else:\n                values = list([1] * N + [2] * N + [3] * N)\n                arr = np.array(values, dtype=dtype.lower())\n            mask = np.zeros(N * 3, dtype=np.bool_)\n        elif index_type == \"monotonic_decr\":\n            if unique:\n                arr = np.arange(N * 3, dtype=dtype.lower())[::-1]\n            else:\n                values = list([1] * N + [2] * N + [3] * N)\n                arr = np.array(values, dtype=dtype.lower())[::-1]\n            mask = np.zeros(N * 3, dtype=np.bool_)\n        else:\n            assert index_type == \"non_monotonic\"\n            if unique:\n                arr = np.zeros(N * 3, dtype=dtype.lower())\n                arr[:N] = np.arange(N * 2, N * 3, dtype=dtype.lower())\n                arr[N:] = np.arange(N * 2, dtype=dtype.lower())\n    \n            else:\n                arr = np.array([1, 2, 3] * N, dtype=dtype.lower())\n            mask = np.zeros(N * 3, dtype=np.bool_)\n            mask[-1] = True\n    \n        self.data = engine(BaseMaskedArray(arr, mask))\n        # code belows avoids populating the mapping etc. while timing.\n        self.data.get_loc(2)\n    \n        self.key_middle = arr[len(arr) // 2]\n        self.key_early = arr[2]", "min_run_count": 2, "name": "indexing_engines.MaskedNumericEngineIndexing.time_get_loc_near_middle", "number": 0, "param_names": ["engine_and_dtype", "index_type", "unique", "N"], "params": [["(<class 'pandas._libs.index.MaskedInt64Engine'>, 'Int64')", "(<class 'pandas._libs.index.MaskedInt32Engine'>, 'Int32')", "(<class 'pandas._libs.index.MaskedInt16Engine'>, 'Int16')", "(<class 'pandas._libs.index.MaskedInt8Engine'>, 'Int8')", "(<class 'pandas._libs.index.MaskedUInt64Engine'>, 'UInt64')", "(<class 'pandas._libs.index.MaskedUInt32Engine'>, 'UInt32')", "(<class 'pandas._libs.index.MaskedUInt8Engine'>, 'UInt8')", "(<class 'pandas._libs.index.MaskedFloat64Engine'>, 'Float64')", "(<class 'pandas._libs.index.MaskedFloat32Engine'>, 'Float32')"], ["'monotonic_incr'", "'monotonic_decr'", "'non_monotonic'"], ["True", "False"], ["100000", "2000000"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "65e78843079af76edd9c166009ab4cff5750f1a985e970f585b637944cabc0a3", "warmup_time": -1}, "indexing_engines.NumericEngineIndexing.time_get_loc": {"code": "class NumericEngineIndexing:\n    def time_get_loc(self, engine_and_dtype, index_type, unique, N):\n        self.data.get_loc(self.key_early)\n\n    def setup(self, engine_and_dtype, index_type, unique, N):\n        engine, dtype = engine_and_dtype\n    \n        if index_type == \"monotonic_incr\":\n            if unique:\n                arr = np.arange(N * 3, dtype=dtype)\n            else:\n                values = list([1] * N + [2] * N + [3] * N)\n                arr = np.array(values, dtype=dtype)\n        elif index_type == \"monotonic_decr\":\n            if unique:\n                arr = np.arange(N * 3, dtype=dtype)[::-1]\n            else:\n                values = list([1] * N + [2] * N + [3] * N)\n                arr = np.array(values, dtype=dtype)[::-1]\n        else:\n            assert index_type == \"non_monotonic\"\n            if unique:\n                arr = np.empty(N * 3, dtype=dtype)\n                arr[:N] = np.arange(N * 2, N * 3, dtype=dtype)\n                arr[N:] = np.arange(N * 2, dtype=dtype)\n            else:\n                arr = np.array([1, 2, 3] * N, dtype=dtype)\n    \n        self.data = engine(arr)\n        # code belows avoids populating the mapping etc. while timing.\n        self.data.get_loc(2)\n    \n        self.key_middle = arr[len(arr) // 2]\n        self.key_early = arr[2]", "min_run_count": 2, "name": "indexing_engines.NumericEngineIndexing.time_get_loc", "number": 0, "param_names": ["engine_and_dtype", "index_type", "unique", "N"], "params": [["(<class 'pandas._libs.index.Int64Engine'>, <class 'numpy.int64'>)", "(<class 'pandas._libs.index.Int32Engine'>, <class 'numpy.int32'>)", "(<class 'pandas._libs.index.Int16Engine'>, <class 'numpy.int16'>)", "(<class 'pandas._libs.index.Int8Engine'>, <class 'numpy.int8'>)", "(<class 'pandas._libs.index.UInt64Engine'>, <class 'numpy.uint64'>)", "(<class 'pandas._libs.index.UInt32Engine'>, <class 'numpy.uint32'>)", "(<class 'pandas._libs.index.UInt8Engine'>, <class 'numpy.uint8'>)", "(<class 'pandas._libs.index.Float64Engine'>, <class 'numpy.float64'>)", "(<class 'pandas._libs.index.Float32Engine'>, <class 'numpy.float32'>)"], ["'monotonic_incr'", "'monotonic_decr'", "'non_monotonic'"], ["True", "False"], ["100000", "2000000"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "eb49cbbf223b552f13727c50a1e3742ad38791c4b24c9d9b3c7dff9d456b637b", "warmup_time": -1}, "indexing_engines.NumericEngineIndexing.time_get_loc_near_middle": {"code": "class NumericEngineIndexing:\n    def time_get_loc_near_middle(self, engine_and_dtype, index_type, unique, N):\n        # searchsorted performance may be different near the middle of a range\n        #  vs near an endpoint\n        self.data.get_loc(self.key_middle)\n\n    def setup(self, engine_and_dtype, index_type, unique, N):\n        engine, dtype = engine_and_dtype\n    \n        if index_type == \"monotonic_incr\":\n            if unique:\n                arr = np.arange(N * 3, dtype=dtype)\n            else:\n                values = list([1] * N + [2] * N + [3] * N)\n                arr = np.array(values, dtype=dtype)\n        elif index_type == \"monotonic_decr\":\n            if unique:\n                arr = np.arange(N * 3, dtype=dtype)[::-1]\n            else:\n                values = list([1] * N + [2] * N + [3] * N)\n                arr = np.array(values, dtype=dtype)[::-1]\n        else:\n            assert index_type == \"non_monotonic\"\n            if unique:\n                arr = np.empty(N * 3, dtype=dtype)\n                arr[:N] = np.arange(N * 2, N * 3, dtype=dtype)\n                arr[N:] = np.arange(N * 2, dtype=dtype)\n            else:\n                arr = np.array([1, 2, 3] * N, dtype=dtype)\n    \n        self.data = engine(arr)\n        # code belows avoids populating the mapping etc. while timing.\n        self.data.get_loc(2)\n    \n        self.key_middle = arr[len(arr) // 2]\n        self.key_early = arr[2]", "min_run_count": 2, "name": "indexing_engines.NumericEngineIndexing.time_get_loc_near_middle", "number": 0, "param_names": ["engine_and_dtype", "index_type", "unique", "N"], "params": [["(<class 'pandas._libs.index.Int64Engine'>, <class 'numpy.int64'>)", "(<class 'pandas._libs.index.Int32Engine'>, <class 'numpy.int32'>)", "(<class 'pandas._libs.index.Int16Engine'>, <class 'numpy.int16'>)", "(<class 'pandas._libs.index.Int8Engine'>, <class 'numpy.int8'>)", "(<class 'pandas._libs.index.UInt64Engine'>, <class 'numpy.uint64'>)", "(<class 'pandas._libs.index.UInt32Engine'>, <class 'numpy.uint32'>)", "(<class 'pandas._libs.index.UInt8Engine'>, <class 'numpy.uint8'>)", "(<class 'pandas._libs.index.Float64Engine'>, <class 'numpy.float64'>)", "(<class 'pandas._libs.index.Float32Engine'>, <class 'numpy.float32'>)"], ["'monotonic_incr'", "'monotonic_decr'", "'non_monotonic'"], ["True", "False"], ["100000", "2000000"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "6bd3ade508d6db6ef376f66c545a8ca5531e1ed703ece1938476702134c89ccb", "warmup_time": -1}, "indexing_engines.ObjectEngineIndexing.time_get_loc": {"code": "class ObjectEngineIndexing:\n    def time_get_loc(self, index_type):\n        self.data.get_loc(\"b\")\n\n    def setup(self, index_type):\n        N = 10**5\n        values = list(\"a\" * N + \"b\" * N + \"c\" * N)\n        arr = {\n            \"monotonic_incr\": np.array(values, dtype=object),\n            \"monotonic_decr\": np.array(list(reversed(values)), dtype=object),\n            \"non_monotonic\": np.array(list(\"abc\") * N, dtype=object),\n        }[index_type]\n    \n        self.data = libindex.ObjectEngine(arr)\n        # code belows avoids populating the mapping etc. while timing.\n        self.data.get_loc(\"b\")", "min_run_count": 2, "name": "indexing_engines.ObjectEngineIndexing.time_get_loc", "number": 0, "param_names": ["index_type"], "params": [["'monotonic_incr'", "'monotonic_decr'", "'non_monotonic'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "147e59ebd8ed373d14dbc9abdbd3d300ac731c931df74b2c8286bb2495bf8f7f", "warmup_time": -1}, "inference.MaybeConvertNumeric.time_convert": {"code": "class MaybeConvertNumeric:\n    def time_convert(self, data):\n        lib.maybe_convert_numeric(data, set(), coerce_numeric=False)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass MaybeConvertNumeric:\n    def setup_cache(self):\n        N = 10**6\n        arr = np.repeat([2**63], N) + np.arange(N).astype(\"uint64\")\n        data = arr.astype(object)\n        data[1::2] = arr[1::2].astype(str)\n        data[-1] = -1\n        return data", "min_run_count": 2, "name": "inference.MaybeConvertNumeric.time_convert", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "setup_cache_key": "inference:85", "timeout": 60.0, "type": "time", "unit": "seconds", "version": "cf27dbc37431d8df629b71882573a765fb8244c558a5874dc6c8d279f80c581e", "warmup_time": -1}, "inference.MaybeConvertObjects.time_maybe_convert_objects": {"code": "class MaybeConvertObjects:\n    def time_maybe_convert_objects(self):\n        lib.maybe_convert_objects(self.data)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass MaybeConvertObjects:\n    def setup(self):\n        N = 10**5\n    \n        data = list(range(N))\n        data[0] = NaT\n        data = np.array(data)\n        self.data = data", "min_run_count": 2, "name": "inference.MaybeConvertObjects.time_maybe_convert_objects", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "5e7742ec3e74701df6d7944b29f2a86f87a571e7c29cdd82373fbc1264620fcf", "warmup_time": -1}, "inference.ToDatetimeCache.time_dup_seconds_and_unit": {"code": "class ToDatetimeCache:\n    def time_dup_seconds_and_unit(self, cache):\n        to_datetime(self.dup_numeric_seconds, unit=\"s\", cache=cache)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToDatetimeCache:\n    def setup(self, cache):\n        N = 10000\n        self.unique_numeric_seconds = list(range(N))\n        self.dup_numeric_seconds = [1000] * N\n        self.dup_string_dates = [\"2000-02-11\"] * N\n        self.dup_string_with_tz = [\"2000-02-11 15:00:00-0800\"] * N", "min_run_count": 2, "name": "inference.ToDatetimeCache.time_dup_seconds_and_unit", "number": 0, "param_names": ["cache"], "params": [["True", "False"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "115495d011e90c1e84334a047f0989bfb9edee09d9a3180f0c98d9d55a4f5d9e", "warmup_time": -1}, "inference.ToDatetimeCache.time_dup_string_dates": {"code": "class ToDatetimeCache:\n    def time_dup_string_dates(self, cache):\n        to_datetime(self.dup_string_dates, cache=cache)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToDatetimeCache:\n    def setup(self, cache):\n        N = 10000\n        self.unique_numeric_seconds = list(range(N))\n        self.dup_numeric_seconds = [1000] * N\n        self.dup_string_dates = [\"2000-02-11\"] * N\n        self.dup_string_with_tz = [\"2000-02-11 15:00:00-0800\"] * N", "min_run_count": 2, "name": "inference.ToDatetimeCache.time_dup_string_dates", "number": 0, "param_names": ["cache"], "params": [["True", "False"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "98daac9ccb43e22cad7edf108a8f9ef3f7dfbf2eb8deb23ea7df594845b8af4c", "warmup_time": -1}, "inference.ToDatetimeCache.time_dup_string_dates_and_format": {"code": "class ToDatetimeCache:\n    def time_dup_string_dates_and_format(self, cache):\n        to_datetime(self.dup_string_dates, format=\"%Y-%m-%d\", cache=cache)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToDatetimeCache:\n    def setup(self, cache):\n        N = 10000\n        self.unique_numeric_seconds = list(range(N))\n        self.dup_numeric_seconds = [1000] * N\n        self.dup_string_dates = [\"2000-02-11\"] * N\n        self.dup_string_with_tz = [\"2000-02-11 15:00:00-0800\"] * N", "min_run_count": 2, "name": "inference.ToDatetimeCache.time_dup_string_dates_and_format", "number": 0, "param_names": ["cache"], "params": [["True", "False"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "ee70077e5420259875c0f2299f011187d7baaef6f1cdeb4826b8ef8b1552dbce", "warmup_time": -1}, "inference.ToDatetimeCache.time_dup_string_tzoffset_dates": {"code": "class ToDatetimeCache:\n    def time_dup_string_tzoffset_dates(self, cache):\n        to_datetime(self.dup_string_with_tz, cache=cache)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToDatetimeCache:\n    def setup(self, cache):\n        N = 10000\n        self.unique_numeric_seconds = list(range(N))\n        self.dup_numeric_seconds = [1000] * N\n        self.dup_string_dates = [\"2000-02-11\"] * N\n        self.dup_string_with_tz = [\"2000-02-11 15:00:00-0800\"] * N", "min_run_count": 2, "name": "inference.ToDatetimeCache.time_dup_string_tzoffset_dates", "number": 0, "param_names": ["cache"], "params": [["True", "False"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "9e31f01ac2515ecaf953530ced77a145692dd110a116641738e36e284fe36dd6", "warmup_time": -1}, "inference.ToDatetimeCache.time_unique_seconds_and_unit": {"code": "class ToDatetimeCache:\n    def time_unique_seconds_and_unit(self, cache):\n        to_datetime(self.unique_numeric_seconds, unit=\"s\", cache=cache)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToDatetimeCache:\n    def setup(self, cache):\n        N = 10000\n        self.unique_numeric_seconds = list(range(N))\n        self.dup_numeric_seconds = [1000] * N\n        self.dup_string_dates = [\"2000-02-11\"] * N\n        self.dup_string_with_tz = [\"2000-02-11 15:00:00-0800\"] * N", "min_run_count": 2, "name": "inference.ToDatetimeCache.time_unique_seconds_and_unit", "number": 0, "param_names": ["cache"], "params": [["True", "False"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "0cd72e287b8884f32a7696a5bae419aa06c002232f3f3e5644000bec0a231d7c", "warmup_time": -1}, "inference.ToDatetimeCacheSmallCount.time_unique_date_strings": {"code": "class ToDatetimeCacheSmallCount:\n    def time_unique_date_strings(self, cache, count):\n        to_datetime(self.unique_date_strings, cache=cache)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToDatetimeCacheSmallCount:\n    def setup(self, cache, count):\n        rng = date_range(start=\"1/1/1971\", periods=count)\n        self.unique_date_strings = rng.strftime(\"%Y-%m-%d\").tolist()", "min_run_count": 2, "name": "inference.ToDatetimeCacheSmallCount.time_unique_date_strings", "number": 0, "param_names": ["cache", "count"], "params": [["True", "False"], ["50", "500", "5000", "100000"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "a56323da170a0fe1ab82a8aa298f38bf720a11efd9c5e53816e754fbfa0d2c10", "warmup_time": -1}, "inference.ToDatetimeFormat.time_different_offset": {"code": "class ToDatetimeFormat:\n    def time_different_offset(self):\n        to_datetime(self.diff_offset, format=\"%m/%d/%Y %H:%M:%S.%f%z\")\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToDatetimeFormat:\n    def setup(self):\n        N = 100000\n        self.s = Series([\"19MAY11\", \"19MAY11:00:00:00\"] * N)\n        self.s2 = self.s.str.replace(\":\\\\S+$\", \"\", regex=True)\n    \n        self.same_offset = [\"10/11/2018 00:00:00.045-07:00\"] * N\n        self.diff_offset = [\n            f\"10/11/2018 00:00:00.045-0{offset}:00\" for offset in range(10)\n        ] * (N // 10)", "min_run_count": 2, "name": "inference.ToDatetimeFormat.time_different_offset", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "7635604221c85fc5fcf2ef9c49c0e010d35795728991a4871bc9395a87e64568", "warmup_time": -1}, "inference.ToDatetimeFormat.time_different_offset_to_utc": {"code": "class ToDatetimeFormat:\n    def time_different_offset_to_utc(self):\n        to_datetime(self.diff_offset, format=\"%m/%d/%Y %H:%M:%S.%f%z\", utc=True)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToDatetimeFormat:\n    def setup(self):\n        N = 100000\n        self.s = Series([\"19MAY11\", \"19MAY11:00:00:00\"] * N)\n        self.s2 = self.s.str.replace(\":\\\\S+$\", \"\", regex=True)\n    \n        self.same_offset = [\"10/11/2018 00:00:00.045-07:00\"] * N\n        self.diff_offset = [\n            f\"10/11/2018 00:00:00.045-0{offset}:00\" for offset in range(10)\n        ] * (N // 10)", "min_run_count": 2, "name": "inference.ToDatetimeFormat.time_different_offset_to_utc", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "1134fb9d2267ce314aafafd3994e3faf459b0ffb6f88a729c01ab4ea6bb44302", "warmup_time": -1}, "inference.ToDatetimeFormat.time_exact": {"code": "class ToDatetimeFormat:\n    def time_exact(self):\n        to_datetime(self.s2, format=\"%d%b%y\")\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToDatetimeFormat:\n    def setup(self):\n        N = 100000\n        self.s = Series([\"19MAY11\", \"19MAY11:00:00:00\"] * N)\n        self.s2 = self.s.str.replace(\":\\\\S+$\", \"\", regex=True)\n    \n        self.same_offset = [\"10/11/2018 00:00:00.045-07:00\"] * N\n        self.diff_offset = [\n            f\"10/11/2018 00:00:00.045-0{offset}:00\" for offset in range(10)\n        ] * (N // 10)", "min_run_count": 2, "name": "inference.ToDatetimeFormat.time_exact", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "76d9d38bf86802c26b9548453bc209c70d50d02a2d30f7ae0469155f0576cb0a", "warmup_time": -1}, "inference.ToDatetimeFormat.time_no_exact": {"code": "class ToDatetimeFormat:\n    def time_no_exact(self):\n        to_datetime(self.s, format=\"%d%b%y\", exact=False)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToDatetimeFormat:\n    def setup(self):\n        N = 100000\n        self.s = Series([\"19MAY11\", \"19MAY11:00:00:00\"] * N)\n        self.s2 = self.s.str.replace(\":\\\\S+$\", \"\", regex=True)\n    \n        self.same_offset = [\"10/11/2018 00:00:00.045-07:00\"] * N\n        self.diff_offset = [\n            f\"10/11/2018 00:00:00.045-0{offset}:00\" for offset in range(10)\n        ] * (N // 10)", "min_run_count": 2, "name": "inference.ToDatetimeFormat.time_no_exact", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "1cbd72079d4edb0010f0b4016b0fd8ef613e37fb9f6c47a4de28327121902b19", "warmup_time": -1}, "inference.ToDatetimeFormat.time_same_offset": {"code": "class ToDatetimeFormat:\n    def time_same_offset(self):\n        to_datetime(self.same_offset, format=\"%m/%d/%Y %H:%M:%S.%f%z\")\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToDatetimeFormat:\n    def setup(self):\n        N = 100000\n        self.s = Series([\"19MAY11\", \"19MAY11:00:00:00\"] * N)\n        self.s2 = self.s.str.replace(\":\\\\S+$\", \"\", regex=True)\n    \n        self.same_offset = [\"10/11/2018 00:00:00.045-07:00\"] * N\n        self.diff_offset = [\n            f\"10/11/2018 00:00:00.045-0{offset}:00\" for offset in range(10)\n        ] * (N // 10)", "min_run_count": 2, "name": "inference.ToDatetimeFormat.time_same_offset", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "081651f9c7ef04560ccff0b7e01f00e729a8f50007024b8be6ae5df6d8252682", "warmup_time": -1}, "inference.ToDatetimeFormat.time_same_offset_to_utc": {"code": "class ToDatetimeFormat:\n    def time_same_offset_to_utc(self):\n        to_datetime(self.same_offset, format=\"%m/%d/%Y %H:%M:%S.%f%z\", utc=True)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToDatetimeFormat:\n    def setup(self):\n        N = 100000\n        self.s = Series([\"19MAY11\", \"19MAY11:00:00:00\"] * N)\n        self.s2 = self.s.str.replace(\":\\\\S+$\", \"\", regex=True)\n    \n        self.same_offset = [\"10/11/2018 00:00:00.045-07:00\"] * N\n        self.diff_offset = [\n            f\"10/11/2018 00:00:00.045-0{offset}:00\" for offset in range(10)\n        ] * (N // 10)", "min_run_count": 2, "name": "inference.ToDatetimeFormat.time_same_offset_to_utc", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "19b041862541f6a61d1616096316f0f2de3452b56a3bf5c720c671b4f0bad85f", "warmup_time": -1}, "inference.ToDatetimeFormatQuarters.time_infer_quarter": {"code": "class ToDatetimeFormatQuarters:\n    def time_infer_quarter(self):\n        to_datetime(self.s)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToDatetimeFormatQuarters:\n    def setup(self):\n        self.s = Series([\"2Q2005\", \"2Q05\", \"2005Q1\", \"05Q1\"] * 10000)", "min_run_count": 2, "name": "inference.ToDatetimeFormatQuarters.time_infer_quarter", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "87bb6a74eb91c588ca3c6a25551ece61b8b7585eb61f04410973d650e0964120", "warmup_time": -1}, "inference.ToDatetimeFromIntsFloats.time_nanosec_float64": {"code": "class ToDatetimeFromIntsFloats:\n    def time_nanosec_float64(self):\n        to_datetime(self.ts_nanosec_float, unit=\"ns\")\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToDatetimeFromIntsFloats:\n    def setup(self):\n        self.ts_sec = Series(range(1521080307, 1521685107), dtype=\"int64\")\n        self.ts_sec_uint = Series(range(1521080307, 1521685107), dtype=\"uint64\")\n        self.ts_sec_float = self.ts_sec.astype(\"float64\")\n    \n        self.ts_nanosec = 1_000_000 * self.ts_sec\n        self.ts_nanosec_uint = 1_000_000 * self.ts_sec_uint\n        self.ts_nanosec_float = self.ts_nanosec.astype(\"float64\")", "min_run_count": 2, "name": "inference.ToDatetimeFromIntsFloats.time_nanosec_float64", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "2a6fbb3b51b828848e8d7f73b076d8fae1161c6e4d53f48a8c4524fb4bd1820e", "warmup_time": -1}, "inference.ToDatetimeFromIntsFloats.time_nanosec_int64": {"code": "class ToDatetimeFromIntsFloats:\n    def time_nanosec_int64(self):\n        to_datetime(self.ts_nanosec, unit=\"ns\")\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToDatetimeFromIntsFloats:\n    def setup(self):\n        self.ts_sec = Series(range(1521080307, 1521685107), dtype=\"int64\")\n        self.ts_sec_uint = Series(range(1521080307, 1521685107), dtype=\"uint64\")\n        self.ts_sec_float = self.ts_sec.astype(\"float64\")\n    \n        self.ts_nanosec = 1_000_000 * self.ts_sec\n        self.ts_nanosec_uint = 1_000_000 * self.ts_sec_uint\n        self.ts_nanosec_float = self.ts_nanosec.astype(\"float64\")", "min_run_count": 2, "name": "inference.ToDatetimeFromIntsFloats.time_nanosec_int64", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "8970f8a6a15aef3813dcea5bb9bf3a7c39853f92d88c59907ac2830fd16daef2", "warmup_time": -1}, "inference.ToDatetimeFromIntsFloats.time_nanosec_uint64": {"code": "class ToDatetimeFromIntsFloats:\n    def time_nanosec_uint64(self):\n        to_datetime(self.ts_nanosec_uint, unit=\"ns\")\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToDatetimeFromIntsFloats:\n    def setup(self):\n        self.ts_sec = Series(range(1521080307, 1521685107), dtype=\"int64\")\n        self.ts_sec_uint = Series(range(1521080307, 1521685107), dtype=\"uint64\")\n        self.ts_sec_float = self.ts_sec.astype(\"float64\")\n    \n        self.ts_nanosec = 1_000_000 * self.ts_sec\n        self.ts_nanosec_uint = 1_000_000 * self.ts_sec_uint\n        self.ts_nanosec_float = self.ts_nanosec.astype(\"float64\")", "min_run_count": 2, "name": "inference.ToDatetimeFromIntsFloats.time_nanosec_uint64", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "55b37560ce70ea683ab6134ede09ee43de470162b68416ec0ef8b0f469e90e97", "warmup_time": -1}, "inference.ToDatetimeFromIntsFloats.time_sec_float64": {"code": "class ToDatetimeFromIntsFloats:\n    def time_sec_float64(self):\n        to_datetime(self.ts_sec_float, unit=\"s\")\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToDatetimeFromIntsFloats:\n    def setup(self):\n        self.ts_sec = Series(range(1521080307, 1521685107), dtype=\"int64\")\n        self.ts_sec_uint = Series(range(1521080307, 1521685107), dtype=\"uint64\")\n        self.ts_sec_float = self.ts_sec.astype(\"float64\")\n    \n        self.ts_nanosec = 1_000_000 * self.ts_sec\n        self.ts_nanosec_uint = 1_000_000 * self.ts_sec_uint\n        self.ts_nanosec_float = self.ts_nanosec.astype(\"float64\")", "min_run_count": 2, "name": "inference.ToDatetimeFromIntsFloats.time_sec_float64", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "412960192629b47bdb51536bd1acc465c6644d94331ec0b060809f15f2270d21", "warmup_time": -1}, "inference.ToDatetimeFromIntsFloats.time_sec_int64": {"code": "class ToDatetimeFromIntsFloats:\n    def time_sec_int64(self):\n        to_datetime(self.ts_sec, unit=\"s\")\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToDatetimeFromIntsFloats:\n    def setup(self):\n        self.ts_sec = Series(range(1521080307, 1521685107), dtype=\"int64\")\n        self.ts_sec_uint = Series(range(1521080307, 1521685107), dtype=\"uint64\")\n        self.ts_sec_float = self.ts_sec.astype(\"float64\")\n    \n        self.ts_nanosec = 1_000_000 * self.ts_sec\n        self.ts_nanosec_uint = 1_000_000 * self.ts_sec_uint\n        self.ts_nanosec_float = self.ts_nanosec.astype(\"float64\")", "min_run_count": 2, "name": "inference.ToDatetimeFromIntsFloats.time_sec_int64", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "723bef42790ad2535ae6772086a189690bbc81c0dc720a9ae78f79b14541e1ed", "warmup_time": -1}, "inference.ToDatetimeFromIntsFloats.time_sec_uint64": {"code": "class ToDatetimeFromIntsFloats:\n    def time_sec_uint64(self):\n        to_datetime(self.ts_sec_uint, unit=\"s\")\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToDatetimeFromIntsFloats:\n    def setup(self):\n        self.ts_sec = Series(range(1521080307, 1521685107), dtype=\"int64\")\n        self.ts_sec_uint = Series(range(1521080307, 1521685107), dtype=\"uint64\")\n        self.ts_sec_float = self.ts_sec.astype(\"float64\")\n    \n        self.ts_nanosec = 1_000_000 * self.ts_sec\n        self.ts_nanosec_uint = 1_000_000 * self.ts_sec_uint\n        self.ts_nanosec_float = self.ts_nanosec.astype(\"float64\")", "min_run_count": 2, "name": "inference.ToDatetimeFromIntsFloats.time_sec_uint64", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "ca17f492874efa6d87297d7a5eb649d9b0235ba934649a093f70ea48bc399454", "warmup_time": -1}, "inference.ToDatetimeISO8601.time_iso8601": {"code": "class ToDatetimeISO8601:\n    def time_iso8601(self):\n        to_datetime(self.strings)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToDatetimeISO8601:\n    def setup(self):\n        rng = date_range(start=\"1/1/2000\", periods=20000, freq=\"H\")\n        self.strings = rng.strftime(\"%Y-%m-%d %H:%M:%S\").tolist()\n        self.strings_nosep = rng.strftime(\"%Y%m%d %H:%M:%S\").tolist()\n        self.strings_tz_space = [\n            x.strftime(\"%Y-%m-%d %H:%M:%S\") + \" -0800\" for x in rng\n        ]\n        self.strings_zero_tz = [x.strftime(\"%Y-%m-%d %H:%M:%S\") + \"Z\" for x in rng]", "min_run_count": 2, "name": "inference.ToDatetimeISO8601.time_iso8601", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "8a9f5fa8618dda5ec7d3fcacc7ea1b91b2f812dea4716f11e58bc0a3e893b194", "warmup_time": -1}, "inference.ToDatetimeISO8601.time_iso8601_format": {"code": "class ToDatetimeISO8601:\n    def time_iso8601_format(self):\n        to_datetime(self.strings, format=\"%Y-%m-%d %H:%M:%S\")\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToDatetimeISO8601:\n    def setup(self):\n        rng = date_range(start=\"1/1/2000\", periods=20000, freq=\"H\")\n        self.strings = rng.strftime(\"%Y-%m-%d %H:%M:%S\").tolist()\n        self.strings_nosep = rng.strftime(\"%Y%m%d %H:%M:%S\").tolist()\n        self.strings_tz_space = [\n            x.strftime(\"%Y-%m-%d %H:%M:%S\") + \" -0800\" for x in rng\n        ]\n        self.strings_zero_tz = [x.strftime(\"%Y-%m-%d %H:%M:%S\") + \"Z\" for x in rng]", "min_run_count": 2, "name": "inference.ToDatetimeISO8601.time_iso8601_format", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "d9b6d05dcef0bd9a57b30f88e40cba877d5d3a456d585869ad724c9cd7778691", "warmup_time": -1}, "inference.ToDatetimeISO8601.time_iso8601_format_no_sep": {"code": "class ToDatetimeISO8601:\n    def time_iso8601_format_no_sep(self):\n        to_datetime(self.strings_nosep, format=\"%Y%m%d %H:%M:%S\")\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToDatetimeISO8601:\n    def setup(self):\n        rng = date_range(start=\"1/1/2000\", periods=20000, freq=\"H\")\n        self.strings = rng.strftime(\"%Y-%m-%d %H:%M:%S\").tolist()\n        self.strings_nosep = rng.strftime(\"%Y%m%d %H:%M:%S\").tolist()\n        self.strings_tz_space = [\n            x.strftime(\"%Y-%m-%d %H:%M:%S\") + \" -0800\" for x in rng\n        ]\n        self.strings_zero_tz = [x.strftime(\"%Y-%m-%d %H:%M:%S\") + \"Z\" for x in rng]", "min_run_count": 2, "name": "inference.ToDatetimeISO8601.time_iso8601_format_no_sep", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "90328a5ba99082bbb0b5759492dd90d4b20174a908bf8eb53038490d589931ff", "warmup_time": -1}, "inference.ToDatetimeISO8601.time_iso8601_infer_zero_tz_fromat": {"code": "class ToDatetimeISO8601:\n    def time_iso8601_infer_zero_tz_fromat(self):\n        # GH 41047\n        to_datetime(self.strings_zero_tz, infer_datetime_format=True)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToDatetimeISO8601:\n    def setup(self):\n        rng = date_range(start=\"1/1/2000\", periods=20000, freq=\"H\")\n        self.strings = rng.strftime(\"%Y-%m-%d %H:%M:%S\").tolist()\n        self.strings_nosep = rng.strftime(\"%Y%m%d %H:%M:%S\").tolist()\n        self.strings_tz_space = [\n            x.strftime(\"%Y-%m-%d %H:%M:%S\") + \" -0800\" for x in rng\n        ]\n        self.strings_zero_tz = [x.strftime(\"%Y-%m-%d %H:%M:%S\") + \"Z\" for x in rng]", "min_run_count": 2, "name": "inference.ToDatetimeISO8601.time_iso8601_infer_zero_tz_fromat", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "18d1b84037f1590dcd9949420496153dbb1ff9b74e8baaa7190b5db5b69e47cb", "warmup_time": -1}, "inference.ToDatetimeISO8601.time_iso8601_nosep": {"code": "class ToDatetimeISO8601:\n    def time_iso8601_nosep(self):\n        to_datetime(self.strings_nosep)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToDatetimeISO8601:\n    def setup(self):\n        rng = date_range(start=\"1/1/2000\", periods=20000, freq=\"H\")\n        self.strings = rng.strftime(\"%Y-%m-%d %H:%M:%S\").tolist()\n        self.strings_nosep = rng.strftime(\"%Y%m%d %H:%M:%S\").tolist()\n        self.strings_tz_space = [\n            x.strftime(\"%Y-%m-%d %H:%M:%S\") + \" -0800\" for x in rng\n        ]\n        self.strings_zero_tz = [x.strftime(\"%Y-%m-%d %H:%M:%S\") + \"Z\" for x in rng]", "min_run_count": 2, "name": "inference.ToDatetimeISO8601.time_iso8601_nosep", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "75bb85aabdd375a3bca428f0e741a086e63ddeedd898c59144432029585d0bf2", "warmup_time": -1}, "inference.ToDatetimeISO8601.time_iso8601_tz_spaceformat": {"code": "class ToDatetimeISO8601:\n    def time_iso8601_tz_spaceformat(self):\n        to_datetime(self.strings_tz_space)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToDatetimeISO8601:\n    def setup(self):\n        rng = date_range(start=\"1/1/2000\", periods=20000, freq=\"H\")\n        self.strings = rng.strftime(\"%Y-%m-%d %H:%M:%S\").tolist()\n        self.strings_nosep = rng.strftime(\"%Y%m%d %H:%M:%S\").tolist()\n        self.strings_tz_space = [\n            x.strftime(\"%Y-%m-%d %H:%M:%S\") + \" -0800\" for x in rng\n        ]\n        self.strings_zero_tz = [x.strftime(\"%Y-%m-%d %H:%M:%S\") + \"Z\" for x in rng]", "min_run_count": 2, "name": "inference.ToDatetimeISO8601.time_iso8601_tz_spaceformat", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "ffda3795a72b4023991d1daa18e3b0a3cabffd330b369a59c89a7d6c8d190102", "warmup_time": -1}, "inference.ToDatetimeInferDatetimeFormat.time_infer_datetime_format": {"code": "class ToDatetimeInferDatetimeFormat:\n    def time_infer_datetime_format(self):\n        to_datetime(self.strings, infer_datetime_format=True)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToDatetimeInferDatetimeFormat:\n    def setup(self):\n        rng = date_range(start=\"1/1/2000\", periods=100000, freq=\"H\")\n        self.strings = rng.strftime(\"%Y-%m-%d %H:%M:%S\").tolist()", "min_run_count": 2, "name": "inference.ToDatetimeInferDatetimeFormat.time_infer_datetime_format", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "1c3c74ed99381261b9280915b0699af46b2fa2fd04caecf83328d1bc6eabf06e", "warmup_time": -1}, "inference.ToDatetimeNONISO8601.time_different_offset": {"code": "class ToDatetimeNONISO8601:\n    def time_different_offset(self):\n        to_datetime(self.diff_offset)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToDatetimeNONISO8601:\n    def setup(self):\n        N = 10000\n        half = N // 2\n        ts_string_1 = \"March 1, 2018 12:00:00+0400\"\n        ts_string_2 = \"March 1, 2018 12:00:00+0500\"\n        self.same_offset = [ts_string_1] * N\n        self.diff_offset = [ts_string_1] * half + [ts_string_2] * half", "min_run_count": 2, "name": "inference.ToDatetimeNONISO8601.time_different_offset", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "2e0c92a1d5e9a354637aa8cc2832b3bc010f1197d796dc79ef3f026a0281060f", "warmup_time": -1}, "inference.ToDatetimeNONISO8601.time_same_offset": {"code": "class ToDatetimeNONISO8601:\n    def time_same_offset(self):\n        to_datetime(self.same_offset)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToDatetimeNONISO8601:\n    def setup(self):\n        N = 10000\n        half = N // 2\n        ts_string_1 = \"March 1, 2018 12:00:00+0400\"\n        ts_string_2 = \"March 1, 2018 12:00:00+0500\"\n        self.same_offset = [ts_string_1] * N\n        self.diff_offset = [ts_string_1] * half + [ts_string_2] * half", "min_run_count": 2, "name": "inference.ToDatetimeNONISO8601.time_same_offset", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "f4cfe5cc89ed121e911be978f375ccb3976e7f6b8bc0e40ffd649e75abf676dc", "warmup_time": -1}, "inference.ToDatetimeYYYYMMDD.time_format_YYYYMMDD": {"code": "class ToDatetimeYYYYMMDD:\n    def time_format_YYYYMMDD(self):\n        to_datetime(self.stringsD, format=\"%Y%m%d\")\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToDatetimeYYYYMMDD:\n    def setup(self):\n        rng = date_range(start=\"1/1/2000\", periods=10000, freq=\"D\")\n        self.stringsD = Series(rng.strftime(\"%Y%m%d\"))", "min_run_count": 2, "name": "inference.ToDatetimeYYYYMMDD.time_format_YYYYMMDD", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "1231af2c8acd673f7622a4a5cda34d3f69371a14c6d712e970653093e409349a", "warmup_time": -1}, "inference.ToNumeric.time_from_float": {"code": "class ToNumeric:\n    def time_from_float(self, errors):\n        to_numeric(self.float, errors=errors)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToNumeric:\n    def setup(self, errors):\n        N = 10000\n        self.float = Series(np.random.randn(N))\n        self.numstr = self.float.astype(\"str\")\n        self.str = Series(tm.makeStringIndex(N))", "min_run_count": 2, "name": "inference.ToNumeric.time_from_float", "number": 0, "param_names": ["errors"], "params": [["'ignore'", "'coerce'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "142e0697d61aecf684621de53345634c6889754a1fe765627387e7212dbfb7e6", "warmup_time": -1}, "inference.ToNumeric.time_from_numeric_str": {"code": "class ToNumeric:\n    def time_from_numeric_str(self, errors):\n        to_numeric(self.numstr, errors=errors)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToNumeric:\n    def setup(self, errors):\n        N = 10000\n        self.float = Series(np.random.randn(N))\n        self.numstr = self.float.astype(\"str\")\n        self.str = Series(tm.makeStringIndex(N))", "min_run_count": 2, "name": "inference.ToNumeric.time_from_numeric_str", "number": 0, "param_names": ["errors"], "params": [["'ignore'", "'coerce'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "2827b0fccbdea4148c6ddc140ffd204887ec86edcf4b006884d3250ade25e619", "warmup_time": -1}, "inference.ToNumeric.time_from_str": {"code": "class ToNumeric:\n    def time_from_str(self, errors):\n        to_numeric(self.str, errors=errors)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToNumeric:\n    def setup(self, errors):\n        N = 10000\n        self.float = Series(np.random.randn(N))\n        self.numstr = self.float.astype(\"str\")\n        self.str = Series(tm.makeStringIndex(N))", "min_run_count": 2, "name": "inference.ToNumeric.time_from_str", "number": 0, "param_names": ["errors"], "params": [["'ignore'", "'coerce'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "898a2f79d432c9bd2b285b7d3c97441d282b380c9aa9105bd7f057afa3f10267", "warmup_time": -1}, "inference.ToNumericDowncast.time_downcast": {"code": "class ToNumericDowncast:\n    def time_downcast(self, dtype, downcast):\n        to_numeric(self.data, downcast=downcast)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToNumericDowncast:\n    def setup(self, dtype, downcast):\n        self.data = self.data_dict[dtype]", "min_run_count": 2, "name": "inference.ToNumericDowncast.time_downcast", "number": 0, "param_names": ["dtype", "downcast"], "params": [["'string-float'", "'string-int'", "'string-nint'", "'datetime64'", "'int-list'", "'int32'"], ["None", "'integer'", "'signed'", "'unsigned'", "'float'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "0c056f48d7870e4188d6e5d83b2fae5d416f447632d4ee4e9e8c1ccec4b933bc", "warmup_time": -1}, "inference.ToTimedelta.time_convert_int": {"code": "class ToTimedelta:\n    def time_convert_int(self):\n        to_timedelta(self.ints, unit=\"s\")\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToTimedelta:\n    def setup(self):\n        self.ints = np.random.randint(0, 60, size=10000)\n        self.str_days = []\n        self.str_seconds = []\n        for i in self.ints:\n            self.str_days.append(f\"{i} days\")\n            self.str_seconds.append(f\"00:00:{i:02d}\")", "min_run_count": 2, "name": "inference.ToTimedelta.time_convert_int", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "e3d32b170c7865f14153be4d1dfe4cedbbfa407716af9b931a20cbf2be09aa76", "warmup_time": -1}, "inference.ToTimedelta.time_convert_string_days": {"code": "class ToTimedelta:\n    def time_convert_string_days(self):\n        to_timedelta(self.str_days)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToTimedelta:\n    def setup(self):\n        self.ints = np.random.randint(0, 60, size=10000)\n        self.str_days = []\n        self.str_seconds = []\n        for i in self.ints:\n            self.str_days.append(f\"{i} days\")\n            self.str_seconds.append(f\"00:00:{i:02d}\")", "min_run_count": 2, "name": "inference.ToTimedelta.time_convert_string_days", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "b10b9c32557f6894a8d5cdad6099b33d92453d78580ed6ac9bce54eeda6ac731", "warmup_time": -1}, "inference.ToTimedelta.time_convert_string_seconds": {"code": "class ToTimedelta:\n    def time_convert_string_seconds(self):\n        to_timedelta(self.str_seconds)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToTimedelta:\n    def setup(self):\n        self.ints = np.random.randint(0, 60, size=10000)\n        self.str_days = []\n        self.str_seconds = []\n        for i in self.ints:\n            self.str_days.append(f\"{i} days\")\n            self.str_seconds.append(f\"00:00:{i:02d}\")", "min_run_count": 2, "name": "inference.ToTimedelta.time_convert_string_seconds", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "ab0555d598557f0386f6743a49658aed686a61742a1a10086b99506a9dc533ba", "warmup_time": -1}, "inference.ToTimedeltaErrors.time_convert": {"code": "class ToTimedeltaErrors:\n    def time_convert(self, errors):\n        to_timedelta(self.arr, errors=errors)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToTimedeltaErrors:\n    def setup(self, errors):\n        ints = np.random.randint(0, 60, size=10000)\n        self.arr = [f\"{i} days\" for i in ints]\n        self.arr[-1] = \"apple\"", "min_run_count": 2, "name": "inference.ToTimedeltaErrors.time_convert", "number": 0, "param_names": ["errors"], "params": [["'coerce'", "'ignore'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "8a1b83205aea85d9e2d96e4303cdb083f3815f1959f3dee5f921a8668cb54c13", "warmup_time": -1}, "io.csv.ParseDateComparison.time_read_csv_dayfirst": {"code": "class ParseDateComparison:\n    def time_read_csv_dayfirst(self, cache_dates):\n        try:\n            read_csv(\n                self.data(self.StringIO_input),\n                sep=\",\",\n                header=None,\n                names=[\"Date\"],\n                parse_dates=[\"Date\"],\n                cache_dates=cache_dates,\n                dayfirst=True,\n            )\n        except TypeError:\n            # cache_dates is a new keyword in 0.25\n            pass\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ParseDateComparison:\n    def setup(self, cache_dates):\n        count_elem = 10000\n        data = \"12-02-2010\\n\" * count_elem\n        self.StringIO_input = StringIO(data)", "min_run_count": 2, "name": "io.csv.ParseDateComparison.time_read_csv_dayfirst", "number": 0, "param_names": ["cache_dates"], "params": [["False", "True"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "b531fbcabfa9f50a40159c707fc3c7f6e7b08d581c7b1d7a345041defb16e66f", "warmup_time": -1}, "io.csv.ParseDateComparison.time_to_datetime_dayfirst": {"code": "class ParseDateComparison:\n    def time_to_datetime_dayfirst(self, cache_dates):\n        df = read_csv(\n            self.data(self.StringIO_input), dtype={\"date\": str}, names=[\"date\"]\n        )\n        to_datetime(df[\"date\"], cache=cache_dates, dayfirst=True)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ParseDateComparison:\n    def setup(self, cache_dates):\n        count_elem = 10000\n        data = \"12-02-2010\\n\" * count_elem\n        self.StringIO_input = StringIO(data)", "min_run_count": 2, "name": "io.csv.ParseDateComparison.time_to_datetime_dayfirst", "number": 0, "param_names": ["cache_dates"], "params": [["False", "True"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "50d96a36fe567c997d3c1a6fbd696fe9705f2ea698a08554aa84d41cd77fcd4d", "warmup_time": -1}, "io.csv.ParseDateComparison.time_to_datetime_format_DD_MM_YYYY": {"code": "class ParseDateComparison:\n    def time_to_datetime_format_DD_MM_YYYY(self, cache_dates):\n        df = read_csv(\n            self.data(self.StringIO_input), dtype={\"date\": str}, names=[\"date\"]\n        )\n        to_datetime(df[\"date\"], cache=cache_dates, format=\"%d-%m-%Y\")\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ParseDateComparison:\n    def setup(self, cache_dates):\n        count_elem = 10000\n        data = \"12-02-2010\\n\" * count_elem\n        self.StringIO_input = StringIO(data)", "min_run_count": 2, "name": "io.csv.ParseDateComparison.time_to_datetime_format_DD_MM_YYYY", "number": 0, "param_names": ["cache_dates"], "params": [["False", "True"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "22583c40b98481bf789be587a51186ee7ff145dc4fb7e8e302872d06333449c9", "warmup_time": -1}, "io.csv.ReadCSVCachedParseDates.time_read_csv_cached": {"code": "class ReadCSVCachedParseDates:\n    def time_read_csv_cached(self, do_cache, engine):\n        try:\n            read_csv(\n                self.data(self.StringIO_input),\n                engine=engine,\n                header=None,\n                parse_dates=[0],\n                cache_dates=do_cache,\n            )\n        except TypeError:\n            # cache_dates is a new keyword in 0.25\n            pass\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ReadCSVCachedParseDates:\n    def setup(self, do_cache, engine):\n        data = (\"\\n\".join([f\"10/{year}\" for year in range(2000, 2100)]) + \"\\n\") * 10\n        self.StringIO_input = StringIO(data)", "min_run_count": 2, "name": "io.csv.ReadCSVCachedParseDates.time_read_csv_cached", "number": 0, "param_names": ["do_cache", "engine"], "params": [["True", "False"], ["'c'", "'python'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "bd18017d7e35c75b5b8e7641eba13970add0683431db08d765c8d0c218e4a37d", "warmup_time": -1}, "io.csv.ReadCSVCategorical.time_convert_direct": {"code": "class ReadCSVCategorical:\n    def time_convert_direct(self, engine):\n        read_csv(self.fname, engine=engine, dtype=\"category\")\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ReadCSVCategorical:\n    def setup(self, engine):\n        N = 100000\n        group1 = [\"aaaaaaaa\", \"bbbbbbb\", \"cccccccc\", \"dddddddd\", \"eeeeeeee\"]\n        df = DataFrame(np.random.choice(group1, (N, 3)), columns=list(\"abc\"))\n        df.to_csv(self.fname, index=False)", "min_run_count": 2, "name": "io.csv.ReadCSVCategorical.time_convert_direct", "number": 0, "param_names": ["engine"], "params": [["'c'", "'python'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "b2e9577b100c6272d45c9326e6ae5cc423be2a61cded554dcded5c3f443ab3d3", "warmup_time": -1}, "io.csv.ReadCSVCategorical.time_convert_post": {"code": "class ReadCSVCategorical:\n    def time_convert_post(self, engine):\n        read_csv(self.fname, engine=engine).apply(Categorical)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ReadCSVCategorical:\n    def setup(self, engine):\n        N = 100000\n        group1 = [\"aaaaaaaa\", \"bbbbbbb\", \"cccccccc\", \"dddddddd\", \"eeeeeeee\"]\n        df = DataFrame(np.random.choice(group1, (N, 3)), columns=list(\"abc\"))\n        df.to_csv(self.fname, index=False)", "min_run_count": 2, "name": "io.csv.ReadCSVCategorical.time_convert_post", "number": 0, "param_names": ["engine"], "params": [["'c'", "'python'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "b7f42a0fff0e3f819147a800861b2f3c3bfe6ed2893ab8f978bbc88396a2df45", "warmup_time": -1}, "io.csv.ReadCSVComment.time_comment": {"code": "class ReadCSVComment:\n    def time_comment(self, engine):\n        read_csv(\n            self.data(self.StringIO_input), comment=\"#\", header=None, names=list(\"abc\")\n        )\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ReadCSVComment:\n    def setup(self, engine):\n        data = [\"A,B,C\"] + ([\"1,2,3 # comment\"] * 100000)\n        self.StringIO_input = StringIO(\"\\n\".join(data))", "min_run_count": 2, "name": "io.csv.ReadCSVComment.time_comment", "number": 0, "param_names": ["engine"], "params": [["'c'", "'python'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "a90bbb38eb91ba9eeed032776bd52d7fd80b20ac0f6bc97853a821d08e98cf4b", "warmup_time": -1}, "io.csv.ReadCSVConcatDatetime.time_read_csv": {"code": "class ReadCSVConcatDatetime:\n    def time_read_csv(self):\n        read_csv(\n            self.data(self.StringIO_input),\n            header=None,\n            names=[\"foo\"],\n            parse_dates=[\"foo\"],\n            infer_datetime_format=False,\n        )\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ReadCSVConcatDatetime:\n    def setup(self):\n        rng = date_range(\"1/1/2000\", periods=50000, freq=\"S\")\n        self.StringIO_input = StringIO(\"\\n\".join(rng.strftime(self.iso8601).tolist()))", "min_run_count": 2, "name": "io.csv.ReadCSVConcatDatetime.time_read_csv", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "04f965ce10ce6bb060584a73051bd6b6062404a406007706d3a43f7f967b672f", "warmup_time": -1}, "io.csv.ReadCSVConcatDatetimeBadDateValue.time_read_csv": {"code": "class ReadCSVConcatDatetimeBadDateValue:\n    def time_read_csv(self, bad_date_value):\n        read_csv(\n            self.data(self.StringIO_input),\n            header=None,\n            names=[\"foo\", \"bar\"],\n            parse_dates=[\"foo\"],\n            infer_datetime_format=False,\n        )\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ReadCSVConcatDatetimeBadDateValue:\n    def setup(self, bad_date_value):\n        self.StringIO_input = StringIO((f\"{bad_date_value},\\n\") * 50000)", "min_run_count": 2, "name": "io.csv.ReadCSVConcatDatetimeBadDateValue.time_read_csv", "number": 0, "param_names": ["bad_date_value"], "params": [["'nan'", "'0'", "''"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "d1a989645a6825f45d9917dc9594da101d94ea1ee2f584f6453e42462e20cc2c", "warmup_time": -1}, "io.csv.ReadCSVDInferDatetimeFormat.time_read_csv": {"code": "class ReadCSVDInferDatetimeFormat:\n    def time_read_csv(self, infer_datetime_format, format):\n        read_csv(\n            self.data(self.StringIO_input),\n            header=None,\n            names=[\"foo\"],\n            parse_dates=[\"foo\"],\n            infer_datetime_format=infer_datetime_format,\n        )\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ReadCSVDInferDatetimeFormat:\n    def setup(self, infer_datetime_format, format):\n        rng = date_range(\"1/1/2000\", periods=1000)\n        formats = {\n            \"custom\": \"%m/%d/%Y %H:%M:%S.%f\",\n            \"iso8601\": \"%Y-%m-%d %H:%M:%S\",\n            \"ymd\": \"%Y%m%d\",\n        }\n        dt_format = formats[format]\n        self.StringIO_input = StringIO(\"\\n\".join(rng.strftime(dt_format).tolist()))", "min_run_count": 2, "name": "io.csv.ReadCSVDInferDatetimeFormat.time_read_csv", "number": 0, "param_names": ["infer_datetime_format", "format"], "params": [["True", "False"], ["'custom'", "'iso8601'", "'ymd'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "1d766c56889753f724932473cc56dfbb33553878406369271322e8a6d1a04d74", "warmup_time": -1}, "io.csv.ReadCSVEngine.time_read_bytescsv": {"code": "class ReadCSVEngine:\n    def time_read_bytescsv(self, engine):\n        read_csv(self.data(self.BytesIO_input), engine=engine)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ReadCSVEngine:\n    def setup(self, engine):\n        data = [\"A,B,C,D,E\"] + ([\"1,2,3,4,5\"] * 100000)\n        self.StringIO_input = StringIO(\"\\n\".join(data))\n        # simulate reading from file\n        self.BytesIO_input = BytesIO(self.StringIO_input.read().encode(\"utf-8\"))", "min_run_count": 2, "name": "io.csv.ReadCSVEngine.time_read_bytescsv", "number": 0, "param_names": ["engine"], "params": [["'c'", "'python'", "'pyarrow'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "c55db1629ca6d2b9c2cc35edb1684bf28f0a642354365378b739990b2beb3b36", "warmup_time": -1}, "io.csv.ReadCSVEngine.time_read_stringcsv": {"code": "class ReadCSVEngine:\n    def time_read_stringcsv(self, engine):\n        read_csv(self.data(self.StringIO_input), engine=engine)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ReadCSVEngine:\n    def setup(self, engine):\n        data = [\"A,B,C,D,E\"] + ([\"1,2,3,4,5\"] * 100000)\n        self.StringIO_input = StringIO(\"\\n\".join(data))\n        # simulate reading from file\n        self.BytesIO_input = BytesIO(self.StringIO_input.read().encode(\"utf-8\"))", "min_run_count": 2, "name": "io.csv.ReadCSVEngine.time_read_stringcsv", "number": 0, "param_names": ["engine"], "params": [["'c'", "'python'", "'pyarrow'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "bcd2541e7d01564732b9ee7d1a6eb25bc0640eba5345d2109c242f2887344d0b", "warmup_time": -1}, "io.csv.ReadCSVFloatPrecision.time_read_csv": {"code": "class ReadCSVFloatPrecision:\n    def time_read_csv(self, sep, decimal, float_precision):\n        read_csv(\n            self.data(self.StringIO_input),\n            sep=sep,\n            header=None,\n            names=list(\"abc\"),\n            float_precision=float_precision,\n        )\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ReadCSVFloatPrecision:\n    def setup(self, sep, decimal, float_precision):\n        floats = [\n            \"\".join([random.choice(string.digits) for _ in range(28)])\n            for _ in range(15)\n        ]\n        rows = sep.join([f\"0{decimal}{{}}\"] * 3) + \"\\n\"\n        data = rows * 5\n        data = data.format(*floats) * 200  # 1000 x 3 strings csv\n        self.StringIO_input = StringIO(data)", "min_run_count": 2, "name": "io.csv.ReadCSVFloatPrecision.time_read_csv", "number": 0, "param_names": ["sep", "decimal", "float_precision"], "params": [["','", "';'"], ["'.'", "'_'"], ["None", "'high'", "'round_trip'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "663280822afc0347b49d14d5e3295794e4e85cd460cf06e6afe197b7a034a74d", "warmup_time": -1}, "io.csv.ReadCSVFloatPrecision.time_read_csv_python_engine": {"code": "class ReadCSVFloatPrecision:\n    def time_read_csv_python_engine(self, sep, decimal, float_precision):\n        read_csv(\n            self.data(self.StringIO_input),\n            sep=sep,\n            header=None,\n            engine=\"python\",\n            float_precision=None,\n            names=list(\"abc\"),\n        )\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ReadCSVFloatPrecision:\n    def setup(self, sep, decimal, float_precision):\n        floats = [\n            \"\".join([random.choice(string.digits) for _ in range(28)])\n            for _ in range(15)\n        ]\n        rows = sep.join([f\"0{decimal}{{}}\"] * 3) + \"\\n\"\n        data = rows * 5\n        data = data.format(*floats) * 200  # 1000 x 3 strings csv\n        self.StringIO_input = StringIO(data)", "min_run_count": 2, "name": "io.csv.ReadCSVFloatPrecision.time_read_csv_python_engine", "number": 0, "param_names": ["sep", "decimal", "float_precision"], "params": [["','", "';'"], ["'.'", "'_'"], ["None", "'high'", "'round_trip'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "8904e1f9bcabd952d3ac2b41f754258e2e24205b0106b3bde4ba9fe99d668d64", "warmup_time": -1}, "io.csv.ReadCSVIndexCol.time_read_csv_index_col": {"code": "class ReadCSVIndexCol:\n    def time_read_csv_index_col(self):\n        read_csv(self.StringIO_input, index_col=\"a\")\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ReadCSVIndexCol:\n    def setup(self):\n        count_elem = 100_000\n        data = \"a,b\\n\" + \"1,2\\n\" * count_elem\n        self.StringIO_input = StringIO(data)", "min_run_count": 2, "name": "io.csv.ReadCSVIndexCol.time_read_csv_index_col", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "f6b24f24cf759e64c0087a252f48f6776c5e68abea602439336c61fb7db08a91", "warmup_time": -1}, "io.csv.ReadCSVMemMapUTF8.time_read_memmapped_utf8": {"code": "class ReadCSVMemMapUTF8:\n    def time_read_memmapped_utf8(self):\n        read_csv(self.fname, header=None, memory_map=True, encoding=\"utf-8\", engine=\"c\")\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ReadCSVMemMapUTF8:\n    def setup(self):\n        lines = []\n        line_length = 128\n        start_char = \" \"\n        end_char = \"\\U00010080\"\n        # This for loop creates a list of 128-char strings\n        # consisting of consecutive Unicode chars\n        for lnum in range(ord(start_char), ord(end_char), line_length):\n            line = \"\".join([chr(c) for c in range(lnum, lnum + 0x80)]) + \"\\n\"\n            try:\n                line.encode(\"utf-8\")\n            except UnicodeEncodeError:\n                # Some 16-bit words are not valid Unicode chars and must be skipped\n                continue\n            lines.append(line)\n        df = DataFrame(lines)\n        df = concat([df for n in range(100)], ignore_index=True)\n        df.to_csv(self.fname, index=False, header=False, encoding=\"utf-8\")", "min_run_count": 2, "name": "io.csv.ReadCSVMemMapUTF8.time_read_memmapped_utf8", "number": 5, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "28f7fd520f718e3d43c75304bfe758d8db2e0e48f9ecbcc93c96af3d09bb34c5", "warmup_time": -1}, "io.csv.ReadCSVMemoryGrowth.mem_parser_chunks": {"code": "class ReadCSVMemoryGrowth:\n    def mem_parser_chunks(self, engine):\n        # see gh-24805.\n        result = read_csv(self.fname, chunksize=self.chunksize, engine=engine)\n    \n        for _ in result:\n            pass\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ReadCSVMemoryGrowth:\n    def setup(self, engine):\n        with open(self.fname, \"w\") as f:\n            for i in range(self.num_rows):\n                f.write(f\"{i}\\n\")", "name": "io.csv.ReadCSVMemoryGrowth.mem_parser_chunks", "param_names": ["engine"], "params": [["'c'", "'python'"]], "timeout": 60.0, "type": "memory", "unit": "bytes", "version": "5b8828ad6997b8f5dd29b23caf71b20bc6f89ff1813e5ed7dd7eec0aed97be9c"}, "io.csv.ReadCSVParseDates.time_baseline": {"code": "class ReadCSVParseDates:\n    def time_baseline(self, engine):\n        read_csv(\n            self.data(self.StringIO_input),\n            engine=engine,\n            sep=\",\",\n            header=None,\n            parse_dates=[1],\n            names=list(string.digits[:9]),\n        )\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ReadCSVParseDates:\n    def setup(self, engine):\n        data = \"\"\"{},19:00:00,18:56:00,0.8100,2.8100,7.2000,0.0000,280.0000\\n\n                  {},20:00:00,19:56:00,0.0100,2.2100,7.2000,0.0000,260.0000\\n\n                  {},21:00:00,20:56:00,-0.5900,2.2100,5.7000,0.0000,280.0000\\n\n                  {},21:00:00,21:18:00,-0.9900,2.0100,3.6000,0.0000,270.0000\\n\n                  {},22:00:00,21:56:00,-0.5900,1.7100,5.1000,0.0000,290.0000\\n\n               \"\"\"\n        two_cols = [\"KORD,19990127\"] * 5\n        data = data.format(*two_cols)\n        self.StringIO_input = StringIO(data)", "min_run_count": 2, "name": "io.csv.ReadCSVParseDates.time_baseline", "number": 0, "param_names": ["engine"], "params": [["'c'", "'python'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "221a4700fd1f02faac09f891ec2ff4bf841f4f8838d4912b40bd070ce1747d0d", "warmup_time": -1}, "io.csv.ReadCSVParseDates.time_multiple_date": {"code": "class ReadCSVParseDates:\n    def time_multiple_date(self, engine):\n        read_csv(\n            self.data(self.StringIO_input),\n            engine=engine,\n            sep=\",\",\n            header=None,\n            names=list(string.digits[:9]),\n            parse_dates=[[1, 2], [1, 3]],\n        )\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ReadCSVParseDates:\n    def setup(self, engine):\n        data = \"\"\"{},19:00:00,18:56:00,0.8100,2.8100,7.2000,0.0000,280.0000\\n\n                  {},20:00:00,19:56:00,0.0100,2.2100,7.2000,0.0000,260.0000\\n\n                  {},21:00:00,20:56:00,-0.5900,2.2100,5.7000,0.0000,280.0000\\n\n                  {},21:00:00,21:18:00,-0.9900,2.0100,3.6000,0.0000,270.0000\\n\n                  {},22:00:00,21:56:00,-0.5900,1.7100,5.1000,0.0000,290.0000\\n\n               \"\"\"\n        two_cols = [\"KORD,19990127\"] * 5\n        data = data.format(*two_cols)\n        self.StringIO_input = StringIO(data)", "min_run_count": 2, "name": "io.csv.ReadCSVParseDates.time_multiple_date", "number": 0, "param_names": ["engine"], "params": [["'c'", "'python'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "ddee417fe3a4e78483aae8d5f9fdc3e5fc75fd2257354f3445f110295eca8b93", "warmup_time": -1}, "io.csv.ReadCSVParseSpecialDate.time_read_special_date": {"code": "class ReadCSVParseSpecialDate:\n    def time_read_special_date(self, value, engine):\n        read_csv(\n            self.data(self.StringIO_input),\n            engine=engine,\n            sep=\",\",\n            header=None,\n            names=[\"Date\"],\n            parse_dates=[\"Date\"],\n        )\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ReadCSVParseSpecialDate:\n    def setup(self, value, engine):\n        count_elem = 10000\n        data = self.objects[value] * count_elem\n        self.StringIO_input = StringIO(data)", "min_run_count": 2, "name": "io.csv.ReadCSVParseSpecialDate.time_read_special_date", "number": 0, "param_names": ["value", "engine"], "params": [["'mY'", "'mdY'", "'hm'"], ["'c'", "'python'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "4adfa495cb5b837ceef161540601f8b0378f4433acbcd79ec36d1936f32b0276", "warmup_time": -1}, "io.csv.ReadCSVSkipRows.time_skipprows": {"code": "class ReadCSVSkipRows:\n    def time_skipprows(self, skiprows, engine):\n        read_csv(self.fname, skiprows=skiprows, engine=engine)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ReadCSVSkipRows:\n    def setup(self, skiprows, engine):\n        N = 20000\n        index = tm.makeStringIndex(N)\n        df = DataFrame(\n            {\n                \"float1\": np.random.randn(N),\n                \"float2\": np.random.randn(N),\n                \"string1\": [\"foo\"] * N,\n                \"bool1\": [True] * N,\n                \"int1\": np.random.randint(0, N, size=N),\n            },\n            index=index,\n        )\n        df.to_csv(self.fname)", "min_run_count": 2, "name": "io.csv.ReadCSVSkipRows.time_skipprows", "number": 0, "param_names": ["skiprows", "engine"], "params": [["None", "10000"], ["'c'", "'python'", "'pyarrow'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "0dc6d0e8c8764ff0b22a12464e38e2e562d4aae0a4bd527e7a3f5a13303a37e6", "warmup_time": -1}, "io.csv.ReadCSVThousands.time_thousands": {"code": "class ReadCSVThousands:\n    def time_thousands(self, sep, thousands, engine):\n        read_csv(self.fname, sep=sep, thousands=thousands, engine=engine)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ReadCSVThousands:\n    def setup(self, sep, thousands, engine):\n        N = 10000\n        K = 8\n        data = np.random.randn(N, K) * np.random.randint(100, 10000, (N, K))\n        df = DataFrame(data)\n        if thousands is not None:\n            fmt = f\":{thousands}\"\n            fmt = \"{\" + fmt + \"}\"\n            df = df.applymap(lambda x: fmt.format(x))\n        df.to_csv(self.fname, sep=sep)", "min_run_count": 2, "name": "io.csv.ReadCSVThousands.time_thousands", "number": 0, "param_names": ["sep", "thousands", "engine"], "params": [["','", "'|'"], ["None", "','"], ["'c'", "'python'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "30e186d86b00baebda491c2da633cb23873955f9b445b05c0eca0e91d7e724e5", "warmup_time": -1}, "io.csv.ReadUint64Integers.time_read_uint64": {"code": "class ReadUint64Integers:\n    def time_read_uint64(self):\n        read_csv(self.data(self.data1), header=None, names=[\"foo\"])\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ReadUint64Integers:\n    def setup(self):\n        self.na_values = [2**63 + 500]\n        arr = np.arange(10000).astype(\"uint64\") + 2**63\n        self.data1 = StringIO(\"\\n\".join(arr.astype(str).tolist()))\n        arr = arr.astype(object)\n        arr[500] = -1\n        self.data2 = StringIO(\"\\n\".join(arr.astype(str).tolist()))", "min_run_count": 2, "name": "io.csv.ReadUint64Integers.time_read_uint64", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "d4d93b300cdd080ede9b4b6103d9f29b7d9a87955c39dab1b41661f3b1836158", "warmup_time": -1}, "io.csv.ReadUint64Integers.time_read_uint64_na_values": {"code": "class ReadUint64Integers:\n    def time_read_uint64_na_values(self):\n        read_csv(\n            self.data(self.data1), header=None, names=[\"foo\"], na_values=self.na_values\n        )\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ReadUint64Integers:\n    def setup(self):\n        self.na_values = [2**63 + 500]\n        arr = np.arange(10000).astype(\"uint64\") + 2**63\n        self.data1 = StringIO(\"\\n\".join(arr.astype(str).tolist()))\n        arr = arr.astype(object)\n        arr[500] = -1\n        self.data2 = StringIO(\"\\n\".join(arr.astype(str).tolist()))", "min_run_count": 2, "name": "io.csv.ReadUint64Integers.time_read_uint64_na_values", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "36be6bf3e25ad59106e12794881da1b2cb92dfed243163b4c6802ee873fff567", "warmup_time": -1}, "io.csv.ReadUint64Integers.time_read_uint64_neg_values": {"code": "class ReadUint64Integers:\n    def time_read_uint64_neg_values(self):\n        read_csv(self.data(self.data2), header=None, names=[\"foo\"])\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ReadUint64Integers:\n    def setup(self):\n        self.na_values = [2**63 + 500]\n        arr = np.arange(10000).astype(\"uint64\") + 2**63\n        self.data1 = StringIO(\"\\n\".join(arr.astype(str).tolist()))\n        arr = arr.astype(object)\n        arr[500] = -1\n        self.data2 = StringIO(\"\\n\".join(arr.astype(str).tolist()))", "min_run_count": 2, "name": "io.csv.ReadUint64Integers.time_read_uint64_neg_values", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "2ff84e494ccdcd98ac1f99314c9865a5af568a2a806ace6dd69261d3ff23bd17", "warmup_time": -1}, "io.csv.ToCSV.time_frame": {"code": "class ToCSV:\n    def time_frame(self, kind):\n        self.df.to_csv(self.fname)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToCSV:\n    def setup(self, kind):\n        wide_frame = DataFrame(np.random.randn(3000, 30))\n        long_frame = DataFrame(\n            {\n                \"A\": np.arange(50000),\n                \"B\": np.arange(50000) + 1.0,\n                \"C\": np.arange(50000) + 2.0,\n                \"D\": np.arange(50000) + 3.0,\n            }\n        )\n        mixed_frame = DataFrame(\n            {\n                \"float\": np.random.randn(5000),\n                \"int\": np.random.randn(5000).astype(int),\n                \"bool\": (np.arange(5000) % 2) == 0,\n                \"datetime\": date_range(\"2001\", freq=\"s\", periods=5000),\n                \"object\": [\"foo\"] * 5000,\n            }\n        )\n        mixed_frame.loc[30:500, \"float\"] = np.nan\n        data = {\"wide\": wide_frame, \"long\": long_frame, \"mixed\": mixed_frame}\n        self.df = data[kind]", "min_run_count": 2, "name": "io.csv.ToCSV.time_frame", "number": 0, "param_names": ["kind"], "params": [["'wide'", "'long'", "'mixed'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "b207acadf1f9b5992775d04050e8e1c95f5b672a69adc5ea1bb47fac8c558b49", "warmup_time": -1}, "io.csv.ToCSVDatetime.time_frame_date_formatting": {"code": "class ToCSVDatetime:\n    def time_frame_date_formatting(self):\n        self.data.to_csv(self.fname, date_format=\"%Y%m%d\")\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToCSVDatetime:\n    def setup(self):\n        rng = date_range(\"1/1/2000\", periods=1000)\n        self.data = DataFrame(rng, index=rng)", "min_run_count": 2, "name": "io.csv.ToCSVDatetime.time_frame_date_formatting", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "48aec9f413466587de05eec973105aa3ca66fba9830fc6165228f306cfa384d0", "warmup_time": -1}, "io.csv.ToCSVDatetimeBig.time_frame": {"code": "class ToCSVDatetimeBig:\n    def time_frame(self, obs):\n        self.data.to_csv(self.fname)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToCSVDatetimeBig:\n    def setup(self, obs):\n        d = \"2018-11-29\"\n        dt = \"2018-11-26 11:18:27.0\"\n        self.data = DataFrame(\n            {\n                \"dt\": [np.datetime64(dt)] * obs,\n                \"d\": [np.datetime64(d)] * obs,\n                \"r\": [np.random.uniform()] * obs,\n            }\n        )", "min_run_count": 2, "name": "io.csv.ToCSVDatetimeBig.time_frame", "number": 0, "param_names": ["obs"], "params": [["1000", "10000", "100000"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 1500, "type": "time", "unit": "seconds", "version": "0af424429330b78d982d95d3db7345e25c98dd6bf7bb45459cc961052ef01e3d", "warmup_time": -1}, "io.csv.ToCSVDatetimeIndex.time_frame_date_formatting_index": {"code": "class ToCSVDatetimeIndex:\n    def time_frame_date_formatting_index(self):\n        self.data.to_csv(self.fname, date_format=\"%Y-%m-%d %H:%M:%S\")\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToCSVDatetimeIndex:\n    def setup(self):\n        rng = date_range(\"2000\", periods=100_000, freq=\"S\")\n        self.data = DataFrame({\"a\": 1}, index=rng)", "min_run_count": 2, "name": "io.csv.ToCSVDatetimeIndex.time_frame_date_formatting_index", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "e5534930a97e1ea48e9bfbaa9b35fc796aea813ab81fd86e6a6105e455efba16", "warmup_time": -1}, "io.csv.ToCSVDatetimeIndex.time_frame_date_no_format_index": {"code": "class ToCSVDatetimeIndex:\n    def time_frame_date_no_format_index(self):\n        self.data.to_csv(self.fname)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToCSVDatetimeIndex:\n    def setup(self):\n        rng = date_range(\"2000\", periods=100_000, freq=\"S\")\n        self.data = DataFrame({\"a\": 1}, index=rng)", "min_run_count": 2, "name": "io.csv.ToCSVDatetimeIndex.time_frame_date_no_format_index", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "2a535dd9f47419b3d657ee9fab09396cc0e878e6999a21f94fe01ec453689068", "warmup_time": -1}, "io.csv.ToCSVIndexes.time_head_of_multiindex": {"code": "class ToCSVIndexes:\n    def time_head_of_multiindex(self):\n        self.df_custom_index_then_head.to_csv(self.fname)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToCSVIndexes:\n    def setup(self):\n        ROWS = 100000\n        COLS = 5\n        # For tests using .head(), create an initial dataframe with this many times\n        # more rows\n        HEAD_ROW_MULTIPLIER = 10\n    \n        self.df_standard_index = self._create_df(ROWS, COLS)\n    \n        self.df_custom_index_then_head = (\n            self._create_df(ROWS * HEAD_ROW_MULTIPLIER, COLS)\n            .set_index([\"index1\", \"index2\", \"index3\"])\n            .head(ROWS)\n        )\n    \n        self.df_head_then_custom_index = (\n            self._create_df(ROWS * HEAD_ROW_MULTIPLIER, COLS)\n            .head(ROWS)\n            .set_index([\"index1\", \"index2\", \"index3\"])\n        )", "min_run_count": 2, "name": "io.csv.ToCSVIndexes.time_head_of_multiindex", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "b19bd98ca4e016f0e4a61cb075ab765fe428f49a7a406dd786bf37617833558c", "warmup_time": -1}, "io.csv.ToCSVIndexes.time_multiindex": {"code": "class ToCSVIndexes:\n    def time_multiindex(self):\n        self.df_head_then_custom_index.to_csv(self.fname)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToCSVIndexes:\n    def setup(self):\n        ROWS = 100000\n        COLS = 5\n        # For tests using .head(), create an initial dataframe with this many times\n        # more rows\n        HEAD_ROW_MULTIPLIER = 10\n    \n        self.df_standard_index = self._create_df(ROWS, COLS)\n    \n        self.df_custom_index_then_head = (\n            self._create_df(ROWS * HEAD_ROW_MULTIPLIER, COLS)\n            .set_index([\"index1\", \"index2\", \"index3\"])\n            .head(ROWS)\n        )\n    \n        self.df_head_then_custom_index = (\n            self._create_df(ROWS * HEAD_ROW_MULTIPLIER, COLS)\n            .head(ROWS)\n            .set_index([\"index1\", \"index2\", \"index3\"])\n        )", "min_run_count": 2, "name": "io.csv.ToCSVIndexes.time_multiindex", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "e6c356ab53559b97134b83598c7406d7849f7d72f0cd33999f3ed3a1388ae70b", "warmup_time": -1}, "io.csv.ToCSVIndexes.time_standard_index": {"code": "class ToCSVIndexes:\n    def time_standard_index(self):\n        self.df_standard_index.to_csv(self.fname)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToCSVIndexes:\n    def setup(self):\n        ROWS = 100000\n        COLS = 5\n        # For tests using .head(), create an initial dataframe with this many times\n        # more rows\n        HEAD_ROW_MULTIPLIER = 10\n    \n        self.df_standard_index = self._create_df(ROWS, COLS)\n    \n        self.df_custom_index_then_head = (\n            self._create_df(ROWS * HEAD_ROW_MULTIPLIER, COLS)\n            .set_index([\"index1\", \"index2\", \"index3\"])\n            .head(ROWS)\n        )\n    \n        self.df_head_then_custom_index = (\n            self._create_df(ROWS * HEAD_ROW_MULTIPLIER, COLS)\n            .head(ROWS)\n            .set_index([\"index1\", \"index2\", \"index3\"])\n        )", "min_run_count": 2, "name": "io.csv.ToCSVIndexes.time_standard_index", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "4d8e112a392acdd1a4bdd4008abb8a96e5e23ac65da30366feda0363459f118b", "warmup_time": -1}, "io.csv.ToCSVMultiIndexUnusedLevels.time_full_frame": {"code": "class ToCSVMultiIndexUnusedLevels:\n    def time_full_frame(self):\n        self.df.to_csv(self.fname)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToCSVMultiIndexUnusedLevels:\n    def setup(self):\n        df = DataFrame({\"a\": np.random.randn(100_000), \"b\": 1, \"c\": 1})\n        self.df = df.set_index([\"a\", \"b\"])\n        self.df_unused_levels = self.df.iloc[:10_000]\n        self.df_single_index = df.set_index([\"a\"]).iloc[:10_000]", "min_run_count": 2, "name": "io.csv.ToCSVMultiIndexUnusedLevels.time_full_frame", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "724d348ca5334e593a849378524d8ed762f78bff3cdf32b12389521b5d4296d6", "warmup_time": -1}, "io.csv.ToCSVMultiIndexUnusedLevels.time_single_index_frame": {"code": "class ToCSVMultiIndexUnusedLevels:\n    def time_single_index_frame(self):\n        self.df_single_index.to_csv(self.fname)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToCSVMultiIndexUnusedLevels:\n    def setup(self):\n        df = DataFrame({\"a\": np.random.randn(100_000), \"b\": 1, \"c\": 1})\n        self.df = df.set_index([\"a\", \"b\"])\n        self.df_unused_levels = self.df.iloc[:10_000]\n        self.df_single_index = df.set_index([\"a\"]).iloc[:10_000]", "min_run_count": 2, "name": "io.csv.ToCSVMultiIndexUnusedLevels.time_single_index_frame", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "fddcb69899294d5fe6894ce1add6d4d9dd6b6c889218886482b796f7df3f0718", "warmup_time": -1}, "io.csv.ToCSVMultiIndexUnusedLevels.time_sliced_frame": {"code": "class ToCSVMultiIndexUnusedLevels:\n    def time_sliced_frame(self):\n        self.df_unused_levels.to_csv(self.fname)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToCSVMultiIndexUnusedLevels:\n    def setup(self):\n        df = DataFrame({\"a\": np.random.randn(100_000), \"b\": 1, \"c\": 1})\n        self.df = df.set_index([\"a\", \"b\"])\n        self.df_unused_levels = self.df.iloc[:10_000]\n        self.df_single_index = df.set_index([\"a\"]).iloc[:10_000]", "min_run_count": 2, "name": "io.csv.ToCSVMultiIndexUnusedLevels.time_sliced_frame", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "c52b3c8ffc9d375d7d7fe89c76149484b884cdab2db3b786aa976b2a571dc669", "warmup_time": -1}, "io.excel.ReadExcel.time_read_excel": {"code": "class ReadExcel:\n    def time_read_excel(self, engine):\n        if engine == \"odf\":\n            fname = self.fname_odf\n        else:\n            fname = self.fname_excel\n        read_excel(fname, engine=engine)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ReadExcel:\n    def setup_cache(self):\n        self.df = _generate_dataframe()\n    \n        self.df.to_excel(self.fname_excel, sheet_name=\"Sheet1\")\n        self._create_odf()", "min_run_count": 2, "name": "io.excel.ReadExcel.time_read_excel", "number": 0, "param_names": ["engine"], "params": [["'openpyxl'", "'odf'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "setup_cache_key": "io.excel:86", "timeout": 60.0, "type": "time", "unit": "seconds", "version": "5b4c727b29b6c7a2c1a6679ecdebdf57f4082a33d80b1b263e51a694d738c7f8", "warmup_time": -1}, "io.excel.ReadExcelNRows.time_read_excel": {"code": "class ReadExcelNRows:\n    def time_read_excel(self, engine):\n        if engine == \"odf\":\n            fname = self.fname_odf\n        else:\n            fname = self.fname_excel\n        read_excel(fname, engine=engine, nrows=10)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ReadExcel:\n    def setup_cache(self):\n        self.df = _generate_dataframe()\n    \n        self.df.to_excel(self.fname_excel, sheet_name=\"Sheet1\")\n        self._create_odf()", "min_run_count": 2, "name": "io.excel.ReadExcelNRows.time_read_excel", "number": 0, "param_names": ["engine"], "params": [["'openpyxl'", "'odf'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "setup_cache_key": "io.excel:86", "timeout": 60.0, "type": "time", "unit": "seconds", "version": "3e5f8dfb13ec7132e6defe6d8e37342d4d227165982cfc87986a70725225b237", "warmup_time": -1}, "io.excel.WriteExcel.time_write_excel": {"code": "class WriteExcel:\n    def time_write_excel(self, engine):\n        bio = BytesIO()\n        bio.seek(0)\n        with ExcelWriter(bio, engine=engine) as writer:\n            self.df.to_excel(writer, sheet_name=\"Sheet1\")\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass WriteExcel:\n    def setup(self, engine):\n        self.df = _generate_dataframe()", "min_run_count": 2, "name": "io.excel.WriteExcel.time_write_excel", "number": 0, "param_names": ["engine"], "params": [["'openpyxl'", "'xlsxwriter'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "7578b2403493bd3778db1aadd2c8d24328372b68145f847a4e479265ddccd155", "warmup_time": -1}, "io.excel.WriteExcelStyled.time_write_excel_style": {"code": "class WriteExcelStyled:\n    def time_write_excel_style(self, engine):\n        bio = BytesIO()\n        bio.seek(0)\n        with ExcelWriter(bio, engine=engine) as writer:\n            df_style = self.df.style\n            df_style.applymap(lambda x: \"border: red 1px solid;\")\n            df_style.applymap(lambda x: \"color: blue\")\n            df_style.applymap(lambda x: \"border-color: green black\", subset=[\"float1\"])\n            df_style.to_excel(writer, sheet_name=\"Sheet1\")\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass WriteExcelStyled:\n    def setup(self, engine):\n        self.df = _generate_dataframe()", "min_run_count": 2, "name": "io.excel.WriteExcelStyled.time_write_excel_style", "number": 0, "param_names": ["engine"], "params": [["'openpyxl'", "'xlsxwriter'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "81127c008e8eb39c76d2fc89bf5e0d70369e0cd306a682e2e4ad559d9f8a2d6f", "warmup_time": -1}, "io.hdf.HDF.peakmem_read_hdf": {"code": "class HDF:\n    def peakmem_read_hdf(self, format):\n        read_hdf(self.fname, \"df\")\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass HDF:\n    def setup(self, format):\n        self.fname = \"__test__.h5\"\n        N = 100000\n        C = 5\n        self.df = DataFrame(\n            np.random.randn(N, C),\n            columns=[f\"float{i}\" for i in range(C)],\n            index=date_range(\"20000101\", periods=N, freq=\"H\"),\n        )\n        self.df[\"object\"] = tm.makeStringIndex(N)\n        self.df.to_hdf(self.fname, \"df\", format=format)\n    \n        # Numeric df\n        self.df1 = self.df.copy()\n        self.df1 = self.df1.reset_index()\n        self.df1.to_hdf(self.fname, \"df1\", format=format)", "name": "io.hdf.HDF.peakmem_read_hdf", "param_names": ["format"], "params": [["'table'", "'fixed'"]], "timeout": 60.0, "type": "peakmemory", "unit": "bytes", "version": "1af285e1ce308c7b514cfac5ab80835e8b3866b0a29f47e2da144b73e9c4d4ab"}, "io.hdf.HDF.time_read_hdf": {"code": "class HDF:\n    def time_read_hdf(self, format):\n        read_hdf(self.fname, \"df\")\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass HDF:\n    def setup(self, format):\n        self.fname = \"__test__.h5\"\n        N = 100000\n        C = 5\n        self.df = DataFrame(\n            np.random.randn(N, C),\n            columns=[f\"float{i}\" for i in range(C)],\n            index=date_range(\"20000101\", periods=N, freq=\"H\"),\n        )\n        self.df[\"object\"] = tm.makeStringIndex(N)\n        self.df.to_hdf(self.fname, \"df\", format=format)\n    \n        # Numeric df\n        self.df1 = self.df.copy()\n        self.df1 = self.df1.reset_index()\n        self.df1.to_hdf(self.fname, \"df1\", format=format)", "min_run_count": 2, "name": "io.hdf.HDF.time_read_hdf", "number": 0, "param_names": ["format"], "params": [["'table'", "'fixed'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "6a98684ed6e7a77669a0c87be42baf556583e3d151a6fb04cca29d40105ee7ef", "warmup_time": -1}, "io.hdf.HDF.time_write_hdf": {"code": "class HDF:\n    def time_write_hdf(self, format):\n        self.df.to_hdf(self.fname, \"df\", format=format)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass HDF:\n    def setup(self, format):\n        self.fname = \"__test__.h5\"\n        N = 100000\n        C = 5\n        self.df = DataFrame(\n            np.random.randn(N, C),\n            columns=[f\"float{i}\" for i in range(C)],\n            index=date_range(\"20000101\", periods=N, freq=\"H\"),\n        )\n        self.df[\"object\"] = tm.makeStringIndex(N)\n        self.df.to_hdf(self.fname, \"df\", format=format)\n    \n        # Numeric df\n        self.df1 = self.df.copy()\n        self.df1 = self.df1.reset_index()\n        self.df1.to_hdf(self.fname, \"df1\", format=format)", "min_run_count": 2, "name": "io.hdf.HDF.time_write_hdf", "number": 0, "param_names": ["format"], "params": [["'table'", "'fixed'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "a33013cefd3ffb99a62d58385191f1040c561d1a0b7ecead5ef4983b55a16b2e", "warmup_time": -1}, "io.hdf.HDFStoreDataFrame.time_query_store_table": {"code": "class HDFStoreDataFrame:\n    def time_query_store_table(self):\n        self.store.select(\"table\", where=\"index > self.start and index < self.stop\")\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass HDFStoreDataFrame:\n    def setup(self):\n        N = 25000\n        index = tm.makeStringIndex(N)\n        self.df = DataFrame(\n            {\"float1\": np.random.randn(N), \"float2\": np.random.randn(N)}, index=index\n        )\n        self.df_mixed = DataFrame(\n            {\n                \"float1\": np.random.randn(N),\n                \"float2\": np.random.randn(N),\n                \"string1\": [\"foo\"] * N,\n                \"bool1\": [True] * N,\n                \"int1\": np.random.randint(0, N, size=N),\n            },\n            index=index,\n        )\n        self.df_wide = DataFrame(np.random.randn(N, 100))\n        self.start_wide = self.df_wide.index[10000]\n        self.stop_wide = self.df_wide.index[15000]\n        self.df2 = DataFrame(\n            {\"float1\": np.random.randn(N), \"float2\": np.random.randn(N)},\n            index=date_range(\"1/1/2000\", periods=N),\n        )\n        self.start = self.df2.index[10000]\n        self.stop = self.df2.index[15000]\n        self.df_wide2 = DataFrame(\n            np.random.randn(N, 100), index=date_range(\"1/1/2000\", periods=N)\n        )\n        self.df_dc = DataFrame(\n            np.random.randn(N, 10), columns=[f\"C{i:03d}\" for i in range(10)]\n        )\n    \n        self.fname = \"__test__.h5\"\n    \n        self.store = HDFStore(self.fname)\n        self.store.put(\"fixed\", self.df)\n        self.store.put(\"fixed_mixed\", self.df_mixed)\n        self.store.append(\"table\", self.df2)\n        self.store.append(\"table_mixed\", self.df_mixed)\n        self.store.append(\"table_wide\", self.df_wide)\n        self.store.append(\"table_wide2\", self.df_wide2)", "min_run_count": 2, "name": "io.hdf.HDFStoreDataFrame.time_query_store_table", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "4374d204feb3550b0b465a790d6458f12e592db320bf25e581fef56103654559", "warmup_time": -1}, "io.hdf.HDFStoreDataFrame.time_query_store_table_wide": {"code": "class HDFStoreDataFrame:\n    def time_query_store_table_wide(self):\n        self.store.select(\n            \"table_wide\", where=\"index > self.start_wide and index < self.stop_wide\"\n        )\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass HDFStoreDataFrame:\n    def setup(self):\n        N = 25000\n        index = tm.makeStringIndex(N)\n        self.df = DataFrame(\n            {\"float1\": np.random.randn(N), \"float2\": np.random.randn(N)}, index=index\n        )\n        self.df_mixed = DataFrame(\n            {\n                \"float1\": np.random.randn(N),\n                \"float2\": np.random.randn(N),\n                \"string1\": [\"foo\"] * N,\n                \"bool1\": [True] * N,\n                \"int1\": np.random.randint(0, N, size=N),\n            },\n            index=index,\n        )\n        self.df_wide = DataFrame(np.random.randn(N, 100))\n        self.start_wide = self.df_wide.index[10000]\n        self.stop_wide = self.df_wide.index[15000]\n        self.df2 = DataFrame(\n            {\"float1\": np.random.randn(N), \"float2\": np.random.randn(N)},\n            index=date_range(\"1/1/2000\", periods=N),\n        )\n        self.start = self.df2.index[10000]\n        self.stop = self.df2.index[15000]\n        self.df_wide2 = DataFrame(\n            np.random.randn(N, 100), index=date_range(\"1/1/2000\", periods=N)\n        )\n        self.df_dc = DataFrame(\n            np.random.randn(N, 10), columns=[f\"C{i:03d}\" for i in range(10)]\n        )\n    \n        self.fname = \"__test__.h5\"\n    \n        self.store = HDFStore(self.fname)\n        self.store.put(\"fixed\", self.df)\n        self.store.put(\"fixed_mixed\", self.df_mixed)\n        self.store.append(\"table\", self.df2)\n        self.store.append(\"table_mixed\", self.df_mixed)\n        self.store.append(\"table_wide\", self.df_wide)\n        self.store.append(\"table_wide2\", self.df_wide2)", "min_run_count": 2, "name": "io.hdf.HDFStoreDataFrame.time_query_store_table_wide", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "7e575b7ae6da405ec2003c3cdafcdb38d185972f1cef021b6f3fe2bfb93243e5", "warmup_time": -1}, "io.hdf.HDFStoreDataFrame.time_read_store": {"code": "class HDFStoreDataFrame:\n    def time_read_store(self):\n        self.store.get(\"fixed\")\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass HDFStoreDataFrame:\n    def setup(self):\n        N = 25000\n        index = tm.makeStringIndex(N)\n        self.df = DataFrame(\n            {\"float1\": np.random.randn(N), \"float2\": np.random.randn(N)}, index=index\n        )\n        self.df_mixed = DataFrame(\n            {\n                \"float1\": np.random.randn(N),\n                \"float2\": np.random.randn(N),\n                \"string1\": [\"foo\"] * N,\n                \"bool1\": [True] * N,\n                \"int1\": np.random.randint(0, N, size=N),\n            },\n            index=index,\n        )\n        self.df_wide = DataFrame(np.random.randn(N, 100))\n        self.start_wide = self.df_wide.index[10000]\n        self.stop_wide = self.df_wide.index[15000]\n        self.df2 = DataFrame(\n            {\"float1\": np.random.randn(N), \"float2\": np.random.randn(N)},\n            index=date_range(\"1/1/2000\", periods=N),\n        )\n        self.start = self.df2.index[10000]\n        self.stop = self.df2.index[15000]\n        self.df_wide2 = DataFrame(\n            np.random.randn(N, 100), index=date_range(\"1/1/2000\", periods=N)\n        )\n        self.df_dc = DataFrame(\n            np.random.randn(N, 10), columns=[f\"C{i:03d}\" for i in range(10)]\n        )\n    \n        self.fname = \"__test__.h5\"\n    \n        self.store = HDFStore(self.fname)\n        self.store.put(\"fixed\", self.df)\n        self.store.put(\"fixed_mixed\", self.df_mixed)\n        self.store.append(\"table\", self.df2)\n        self.store.append(\"table_mixed\", self.df_mixed)\n        self.store.append(\"table_wide\", self.df_wide)\n        self.store.append(\"table_wide2\", self.df_wide2)", "min_run_count": 2, "name": "io.hdf.HDFStoreDataFrame.time_read_store", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "5324166bfb9df4ab70f4c3fd566076f09d590a27e1c3e02b2ac51fac63962ef2", "warmup_time": -1}, "io.hdf.HDFStoreDataFrame.time_read_store_mixed": {"code": "class HDFStoreDataFrame:\n    def time_read_store_mixed(self):\n        self.store.get(\"fixed_mixed\")\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass HDFStoreDataFrame:\n    def setup(self):\n        N = 25000\n        index = tm.makeStringIndex(N)\n        self.df = DataFrame(\n            {\"float1\": np.random.randn(N), \"float2\": np.random.randn(N)}, index=index\n        )\n        self.df_mixed = DataFrame(\n            {\n                \"float1\": np.random.randn(N),\n                \"float2\": np.random.randn(N),\n                \"string1\": [\"foo\"] * N,\n                \"bool1\": [True] * N,\n                \"int1\": np.random.randint(0, N, size=N),\n            },\n            index=index,\n        )\n        self.df_wide = DataFrame(np.random.randn(N, 100))\n        self.start_wide = self.df_wide.index[10000]\n        self.stop_wide = self.df_wide.index[15000]\n        self.df2 = DataFrame(\n            {\"float1\": np.random.randn(N), \"float2\": np.random.randn(N)},\n            index=date_range(\"1/1/2000\", periods=N),\n        )\n        self.start = self.df2.index[10000]\n        self.stop = self.df2.index[15000]\n        self.df_wide2 = DataFrame(\n            np.random.randn(N, 100), index=date_range(\"1/1/2000\", periods=N)\n        )\n        self.df_dc = DataFrame(\n            np.random.randn(N, 10), columns=[f\"C{i:03d}\" for i in range(10)]\n        )\n    \n        self.fname = \"__test__.h5\"\n    \n        self.store = HDFStore(self.fname)\n        self.store.put(\"fixed\", self.df)\n        self.store.put(\"fixed_mixed\", self.df_mixed)\n        self.store.append(\"table\", self.df2)\n        self.store.append(\"table_mixed\", self.df_mixed)\n        self.store.append(\"table_wide\", self.df_wide)\n        self.store.append(\"table_wide2\", self.df_wide2)", "min_run_count": 2, "name": "io.hdf.HDFStoreDataFrame.time_read_store_mixed", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "1f25dd137ce1a70bd53fb09cf254c134bb5f89114daf5e14b5cebb48b11dc834", "warmup_time": -1}, "io.hdf.HDFStoreDataFrame.time_read_store_table": {"code": "class HDFStoreDataFrame:\n    def time_read_store_table(self):\n        self.store.select(\"table\")\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass HDFStoreDataFrame:\n    def setup(self):\n        N = 25000\n        index = tm.makeStringIndex(N)\n        self.df = DataFrame(\n            {\"float1\": np.random.randn(N), \"float2\": np.random.randn(N)}, index=index\n        )\n        self.df_mixed = DataFrame(\n            {\n                \"float1\": np.random.randn(N),\n                \"float2\": np.random.randn(N),\n                \"string1\": [\"foo\"] * N,\n                \"bool1\": [True] * N,\n                \"int1\": np.random.randint(0, N, size=N),\n            },\n            index=index,\n        )\n        self.df_wide = DataFrame(np.random.randn(N, 100))\n        self.start_wide = self.df_wide.index[10000]\n        self.stop_wide = self.df_wide.index[15000]\n        self.df2 = DataFrame(\n            {\"float1\": np.random.randn(N), \"float2\": np.random.randn(N)},\n            index=date_range(\"1/1/2000\", periods=N),\n        )\n        self.start = self.df2.index[10000]\n        self.stop = self.df2.index[15000]\n        self.df_wide2 = DataFrame(\n            np.random.randn(N, 100), index=date_range(\"1/1/2000\", periods=N)\n        )\n        self.df_dc = DataFrame(\n            np.random.randn(N, 10), columns=[f\"C{i:03d}\" for i in range(10)]\n        )\n    \n        self.fname = \"__test__.h5\"\n    \n        self.store = HDFStore(self.fname)\n        self.store.put(\"fixed\", self.df)\n        self.store.put(\"fixed_mixed\", self.df_mixed)\n        self.store.append(\"table\", self.df2)\n        self.store.append(\"table_mixed\", self.df_mixed)\n        self.store.append(\"table_wide\", self.df_wide)\n        self.store.append(\"table_wide2\", self.df_wide2)", "min_run_count": 2, "name": "io.hdf.HDFStoreDataFrame.time_read_store_table", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "faead3241e31971c7e274c8ba9671f758f7ecdeeda35f0f3095d66bce9a33e12", "warmup_time": -1}, "io.hdf.HDFStoreDataFrame.time_read_store_table_mixed": {"code": "class HDFStoreDataFrame:\n    def time_read_store_table_mixed(self):\n        self.store.select(\"table_mixed\")\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass HDFStoreDataFrame:\n    def setup(self):\n        N = 25000\n        index = tm.makeStringIndex(N)\n        self.df = DataFrame(\n            {\"float1\": np.random.randn(N), \"float2\": np.random.randn(N)}, index=index\n        )\n        self.df_mixed = DataFrame(\n            {\n                \"float1\": np.random.randn(N),\n                \"float2\": np.random.randn(N),\n                \"string1\": [\"foo\"] * N,\n                \"bool1\": [True] * N,\n                \"int1\": np.random.randint(0, N, size=N),\n            },\n            index=index,\n        )\n        self.df_wide = DataFrame(np.random.randn(N, 100))\n        self.start_wide = self.df_wide.index[10000]\n        self.stop_wide = self.df_wide.index[15000]\n        self.df2 = DataFrame(\n            {\"float1\": np.random.randn(N), \"float2\": np.random.randn(N)},\n            index=date_range(\"1/1/2000\", periods=N),\n        )\n        self.start = self.df2.index[10000]\n        self.stop = self.df2.index[15000]\n        self.df_wide2 = DataFrame(\n            np.random.randn(N, 100), index=date_range(\"1/1/2000\", periods=N)\n        )\n        self.df_dc = DataFrame(\n            np.random.randn(N, 10), columns=[f\"C{i:03d}\" for i in range(10)]\n        )\n    \n        self.fname = \"__test__.h5\"\n    \n        self.store = HDFStore(self.fname)\n        self.store.put(\"fixed\", self.df)\n        self.store.put(\"fixed_mixed\", self.df_mixed)\n        self.store.append(\"table\", self.df2)\n        self.store.append(\"table_mixed\", self.df_mixed)\n        self.store.append(\"table_wide\", self.df_wide)\n        self.store.append(\"table_wide2\", self.df_wide2)", "min_run_count": 2, "name": "io.hdf.HDFStoreDataFrame.time_read_store_table_mixed", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "e75633f6721195b43ead2477aef9983d6c55e8062626a7529021e1f6ee133760", "warmup_time": -1}, "io.hdf.HDFStoreDataFrame.time_read_store_table_wide": {"code": "class HDFStoreDataFrame:\n    def time_read_store_table_wide(self):\n        self.store.select(\"table_wide\")\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass HDFStoreDataFrame:\n    def setup(self):\n        N = 25000\n        index = tm.makeStringIndex(N)\n        self.df = DataFrame(\n            {\"float1\": np.random.randn(N), \"float2\": np.random.randn(N)}, index=index\n        )\n        self.df_mixed = DataFrame(\n            {\n                \"float1\": np.random.randn(N),\n                \"float2\": np.random.randn(N),\n                \"string1\": [\"foo\"] * N,\n                \"bool1\": [True] * N,\n                \"int1\": np.random.randint(0, N, size=N),\n            },\n            index=index,\n        )\n        self.df_wide = DataFrame(np.random.randn(N, 100))\n        self.start_wide = self.df_wide.index[10000]\n        self.stop_wide = self.df_wide.index[15000]\n        self.df2 = DataFrame(\n            {\"float1\": np.random.randn(N), \"float2\": np.random.randn(N)},\n            index=date_range(\"1/1/2000\", periods=N),\n        )\n        self.start = self.df2.index[10000]\n        self.stop = self.df2.index[15000]\n        self.df_wide2 = DataFrame(\n            np.random.randn(N, 100), index=date_range(\"1/1/2000\", periods=N)\n        )\n        self.df_dc = DataFrame(\n            np.random.randn(N, 10), columns=[f\"C{i:03d}\" for i in range(10)]\n        )\n    \n        self.fname = \"__test__.h5\"\n    \n        self.store = HDFStore(self.fname)\n        self.store.put(\"fixed\", self.df)\n        self.store.put(\"fixed_mixed\", self.df_mixed)\n        self.store.append(\"table\", self.df2)\n        self.store.append(\"table_mixed\", self.df_mixed)\n        self.store.append(\"table_wide\", self.df_wide)\n        self.store.append(\"table_wide2\", self.df_wide2)", "min_run_count": 2, "name": "io.hdf.HDFStoreDataFrame.time_read_store_table_wide", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "e1241b3b3a28c13f998ae523442a1d104c6dc146050f3b20702e709ae0d527b9", "warmup_time": -1}, "io.hdf.HDFStoreDataFrame.time_store_info": {"code": "class HDFStoreDataFrame:\n    def time_store_info(self):\n        self.store.info()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass HDFStoreDataFrame:\n    def setup(self):\n        N = 25000\n        index = tm.makeStringIndex(N)\n        self.df = DataFrame(\n            {\"float1\": np.random.randn(N), \"float2\": np.random.randn(N)}, index=index\n        )\n        self.df_mixed = DataFrame(\n            {\n                \"float1\": np.random.randn(N),\n                \"float2\": np.random.randn(N),\n                \"string1\": [\"foo\"] * N,\n                \"bool1\": [True] * N,\n                \"int1\": np.random.randint(0, N, size=N),\n            },\n            index=index,\n        )\n        self.df_wide = DataFrame(np.random.randn(N, 100))\n        self.start_wide = self.df_wide.index[10000]\n        self.stop_wide = self.df_wide.index[15000]\n        self.df2 = DataFrame(\n            {\"float1\": np.random.randn(N), \"float2\": np.random.randn(N)},\n            index=date_range(\"1/1/2000\", periods=N),\n        )\n        self.start = self.df2.index[10000]\n        self.stop = self.df2.index[15000]\n        self.df_wide2 = DataFrame(\n            np.random.randn(N, 100), index=date_range(\"1/1/2000\", periods=N)\n        )\n        self.df_dc = DataFrame(\n            np.random.randn(N, 10), columns=[f\"C{i:03d}\" for i in range(10)]\n        )\n    \n        self.fname = \"__test__.h5\"\n    \n        self.store = HDFStore(self.fname)\n        self.store.put(\"fixed\", self.df)\n        self.store.put(\"fixed_mixed\", self.df_mixed)\n        self.store.append(\"table\", self.df2)\n        self.store.append(\"table_mixed\", self.df_mixed)\n        self.store.append(\"table_wide\", self.df_wide)\n        self.store.append(\"table_wide2\", self.df_wide2)", "min_run_count": 2, "name": "io.hdf.HDFStoreDataFrame.time_store_info", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "f48b16639e26226231d2997cc50d3ca441d27196fc9b3887e9654063c63e5d41", "warmup_time": -1}, "io.hdf.HDFStoreDataFrame.time_store_repr": {"code": "class HDFStoreDataFrame:\n    def time_store_repr(self):\n        repr(self.store)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass HDFStoreDataFrame:\n    def setup(self):\n        N = 25000\n        index = tm.makeStringIndex(N)\n        self.df = DataFrame(\n            {\"float1\": np.random.randn(N), \"float2\": np.random.randn(N)}, index=index\n        )\n        self.df_mixed = DataFrame(\n            {\n                \"float1\": np.random.randn(N),\n                \"float2\": np.random.randn(N),\n                \"string1\": [\"foo\"] * N,\n                \"bool1\": [True] * N,\n                \"int1\": np.random.randint(0, N, size=N),\n            },\n            index=index,\n        )\n        self.df_wide = DataFrame(np.random.randn(N, 100))\n        self.start_wide = self.df_wide.index[10000]\n        self.stop_wide = self.df_wide.index[15000]\n        self.df2 = DataFrame(\n            {\"float1\": np.random.randn(N), \"float2\": np.random.randn(N)},\n            index=date_range(\"1/1/2000\", periods=N),\n        )\n        self.start = self.df2.index[10000]\n        self.stop = self.df2.index[15000]\n        self.df_wide2 = DataFrame(\n            np.random.randn(N, 100), index=date_range(\"1/1/2000\", periods=N)\n        )\n        self.df_dc = DataFrame(\n            np.random.randn(N, 10), columns=[f\"C{i:03d}\" for i in range(10)]\n        )\n    \n        self.fname = \"__test__.h5\"\n    \n        self.store = HDFStore(self.fname)\n        self.store.put(\"fixed\", self.df)\n        self.store.put(\"fixed_mixed\", self.df_mixed)\n        self.store.append(\"table\", self.df2)\n        self.store.append(\"table_mixed\", self.df_mixed)\n        self.store.append(\"table_wide\", self.df_wide)\n        self.store.append(\"table_wide2\", self.df_wide2)", "min_run_count": 2, "name": "io.hdf.HDFStoreDataFrame.time_store_repr", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "88091066e0600a1b56f0fa4accf983881db955f723131e3a67aaa225107acec2", "warmup_time": -1}, "io.hdf.HDFStoreDataFrame.time_store_str": {"code": "class HDFStoreDataFrame:\n    def time_store_str(self):\n        str(self.store)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass HDFStoreDataFrame:\n    def setup(self):\n        N = 25000\n        index = tm.makeStringIndex(N)\n        self.df = DataFrame(\n            {\"float1\": np.random.randn(N), \"float2\": np.random.randn(N)}, index=index\n        )\n        self.df_mixed = DataFrame(\n            {\n                \"float1\": np.random.randn(N),\n                \"float2\": np.random.randn(N),\n                \"string1\": [\"foo\"] * N,\n                \"bool1\": [True] * N,\n                \"int1\": np.random.randint(0, N, size=N),\n            },\n            index=index,\n        )\n        self.df_wide = DataFrame(np.random.randn(N, 100))\n        self.start_wide = self.df_wide.index[10000]\n        self.stop_wide = self.df_wide.index[15000]\n        self.df2 = DataFrame(\n            {\"float1\": np.random.randn(N), \"float2\": np.random.randn(N)},\n            index=date_range(\"1/1/2000\", periods=N),\n        )\n        self.start = self.df2.index[10000]\n        self.stop = self.df2.index[15000]\n        self.df_wide2 = DataFrame(\n            np.random.randn(N, 100), index=date_range(\"1/1/2000\", periods=N)\n        )\n        self.df_dc = DataFrame(\n            np.random.randn(N, 10), columns=[f\"C{i:03d}\" for i in range(10)]\n        )\n    \n        self.fname = \"__test__.h5\"\n    \n        self.store = HDFStore(self.fname)\n        self.store.put(\"fixed\", self.df)\n        self.store.put(\"fixed_mixed\", self.df_mixed)\n        self.store.append(\"table\", self.df2)\n        self.store.append(\"table_mixed\", self.df_mixed)\n        self.store.append(\"table_wide\", self.df_wide)\n        self.store.append(\"table_wide2\", self.df_wide2)", "min_run_count": 2, "name": "io.hdf.HDFStoreDataFrame.time_store_str", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "793364f2afd9a5c73d69fa73035488eefd16b2ea50090deadb8b1ea611ffa4be", "warmup_time": -1}, "io.hdf.HDFStoreDataFrame.time_write_store": {"code": "class HDFStoreDataFrame:\n    def time_write_store(self):\n        self.store.put(\"fixed_write\", self.df)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass HDFStoreDataFrame:\n    def setup(self):\n        N = 25000\n        index = tm.makeStringIndex(N)\n        self.df = DataFrame(\n            {\"float1\": np.random.randn(N), \"float2\": np.random.randn(N)}, index=index\n        )\n        self.df_mixed = DataFrame(\n            {\n                \"float1\": np.random.randn(N),\n                \"float2\": np.random.randn(N),\n                \"string1\": [\"foo\"] * N,\n                \"bool1\": [True] * N,\n                \"int1\": np.random.randint(0, N, size=N),\n            },\n            index=index,\n        )\n        self.df_wide = DataFrame(np.random.randn(N, 100))\n        self.start_wide = self.df_wide.index[10000]\n        self.stop_wide = self.df_wide.index[15000]\n        self.df2 = DataFrame(\n            {\"float1\": np.random.randn(N), \"float2\": np.random.randn(N)},\n            index=date_range(\"1/1/2000\", periods=N),\n        )\n        self.start = self.df2.index[10000]\n        self.stop = self.df2.index[15000]\n        self.df_wide2 = DataFrame(\n            np.random.randn(N, 100), index=date_range(\"1/1/2000\", periods=N)\n        )\n        self.df_dc = DataFrame(\n            np.random.randn(N, 10), columns=[f\"C{i:03d}\" for i in range(10)]\n        )\n    \n        self.fname = \"__test__.h5\"\n    \n        self.store = HDFStore(self.fname)\n        self.store.put(\"fixed\", self.df)\n        self.store.put(\"fixed_mixed\", self.df_mixed)\n        self.store.append(\"table\", self.df2)\n        self.store.append(\"table_mixed\", self.df_mixed)\n        self.store.append(\"table_wide\", self.df_wide)\n        self.store.append(\"table_wide2\", self.df_wide2)", "min_run_count": 2, "name": "io.hdf.HDFStoreDataFrame.time_write_store", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "6d2ade6c0454ef142f558914924a018a721fa3a94f800e7596b7dfdd93c0d709", "warmup_time": -1}, "io.hdf.HDFStoreDataFrame.time_write_store_mixed": {"code": "class HDFStoreDataFrame:\n    def time_write_store_mixed(self):\n        self.store.put(\"fixed_mixed_write\", self.df_mixed)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass HDFStoreDataFrame:\n    def setup(self):\n        N = 25000\n        index = tm.makeStringIndex(N)\n        self.df = DataFrame(\n            {\"float1\": np.random.randn(N), \"float2\": np.random.randn(N)}, index=index\n        )\n        self.df_mixed = DataFrame(\n            {\n                \"float1\": np.random.randn(N),\n                \"float2\": np.random.randn(N),\n                \"string1\": [\"foo\"] * N,\n                \"bool1\": [True] * N,\n                \"int1\": np.random.randint(0, N, size=N),\n            },\n            index=index,\n        )\n        self.df_wide = DataFrame(np.random.randn(N, 100))\n        self.start_wide = self.df_wide.index[10000]\n        self.stop_wide = self.df_wide.index[15000]\n        self.df2 = DataFrame(\n            {\"float1\": np.random.randn(N), \"float2\": np.random.randn(N)},\n            index=date_range(\"1/1/2000\", periods=N),\n        )\n        self.start = self.df2.index[10000]\n        self.stop = self.df2.index[15000]\n        self.df_wide2 = DataFrame(\n            np.random.randn(N, 100), index=date_range(\"1/1/2000\", periods=N)\n        )\n        self.df_dc = DataFrame(\n            np.random.randn(N, 10), columns=[f\"C{i:03d}\" for i in range(10)]\n        )\n    \n        self.fname = \"__test__.h5\"\n    \n        self.store = HDFStore(self.fname)\n        self.store.put(\"fixed\", self.df)\n        self.store.put(\"fixed_mixed\", self.df_mixed)\n        self.store.append(\"table\", self.df2)\n        self.store.append(\"table_mixed\", self.df_mixed)\n        self.store.append(\"table_wide\", self.df_wide)\n        self.store.append(\"table_wide2\", self.df_wide2)", "min_run_count": 2, "name": "io.hdf.HDFStoreDataFrame.time_write_store_mixed", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "d4909be72fd94e5c57c8c996a84ebd5a304e63f79eb034b16f6dc6556b8e5462", "warmup_time": -1}, "io.hdf.HDFStoreDataFrame.time_write_store_table": {"code": "class HDFStoreDataFrame:\n    def time_write_store_table(self):\n        self.store.append(\"table_write\", self.df)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass HDFStoreDataFrame:\n    def setup(self):\n        N = 25000\n        index = tm.makeStringIndex(N)\n        self.df = DataFrame(\n            {\"float1\": np.random.randn(N), \"float2\": np.random.randn(N)}, index=index\n        )\n        self.df_mixed = DataFrame(\n            {\n                \"float1\": np.random.randn(N),\n                \"float2\": np.random.randn(N),\n                \"string1\": [\"foo\"] * N,\n                \"bool1\": [True] * N,\n                \"int1\": np.random.randint(0, N, size=N),\n            },\n            index=index,\n        )\n        self.df_wide = DataFrame(np.random.randn(N, 100))\n        self.start_wide = self.df_wide.index[10000]\n        self.stop_wide = self.df_wide.index[15000]\n        self.df2 = DataFrame(\n            {\"float1\": np.random.randn(N), \"float2\": np.random.randn(N)},\n            index=date_range(\"1/1/2000\", periods=N),\n        )\n        self.start = self.df2.index[10000]\n        self.stop = self.df2.index[15000]\n        self.df_wide2 = DataFrame(\n            np.random.randn(N, 100), index=date_range(\"1/1/2000\", periods=N)\n        )\n        self.df_dc = DataFrame(\n            np.random.randn(N, 10), columns=[f\"C{i:03d}\" for i in range(10)]\n        )\n    \n        self.fname = \"__test__.h5\"\n    \n        self.store = HDFStore(self.fname)\n        self.store.put(\"fixed\", self.df)\n        self.store.put(\"fixed_mixed\", self.df_mixed)\n        self.store.append(\"table\", self.df2)\n        self.store.append(\"table_mixed\", self.df_mixed)\n        self.store.append(\"table_wide\", self.df_wide)\n        self.store.append(\"table_wide2\", self.df_wide2)", "min_run_count": 2, "name": "io.hdf.HDFStoreDataFrame.time_write_store_table", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "a7d66d112f213af33beca7f53facf379d253b6096ee54f697a59ccf669b48813", "warmup_time": -1}, "io.hdf.HDFStoreDataFrame.time_write_store_table_dc": {"code": "class HDFStoreDataFrame:\n    def time_write_store_table_dc(self):\n        self.store.append(\"table_dc_write\", self.df_dc, data_columns=True)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass HDFStoreDataFrame:\n    def setup(self):\n        N = 25000\n        index = tm.makeStringIndex(N)\n        self.df = DataFrame(\n            {\"float1\": np.random.randn(N), \"float2\": np.random.randn(N)}, index=index\n        )\n        self.df_mixed = DataFrame(\n            {\n                \"float1\": np.random.randn(N),\n                \"float2\": np.random.randn(N),\n                \"string1\": [\"foo\"] * N,\n                \"bool1\": [True] * N,\n                \"int1\": np.random.randint(0, N, size=N),\n            },\n            index=index,\n        )\n        self.df_wide = DataFrame(np.random.randn(N, 100))\n        self.start_wide = self.df_wide.index[10000]\n        self.stop_wide = self.df_wide.index[15000]\n        self.df2 = DataFrame(\n            {\"float1\": np.random.randn(N), \"float2\": np.random.randn(N)},\n            index=date_range(\"1/1/2000\", periods=N),\n        )\n        self.start = self.df2.index[10000]\n        self.stop = self.df2.index[15000]\n        self.df_wide2 = DataFrame(\n            np.random.randn(N, 100), index=date_range(\"1/1/2000\", periods=N)\n        )\n        self.df_dc = DataFrame(\n            np.random.randn(N, 10), columns=[f\"C{i:03d}\" for i in range(10)]\n        )\n    \n        self.fname = \"__test__.h5\"\n    \n        self.store = HDFStore(self.fname)\n        self.store.put(\"fixed\", self.df)\n        self.store.put(\"fixed_mixed\", self.df_mixed)\n        self.store.append(\"table\", self.df2)\n        self.store.append(\"table_mixed\", self.df_mixed)\n        self.store.append(\"table_wide\", self.df_wide)\n        self.store.append(\"table_wide2\", self.df_wide2)", "min_run_count": 2, "name": "io.hdf.HDFStoreDataFrame.time_write_store_table_dc", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "5b5863cedda7b3988dd90b82f3a121d3e04549b36b7af6bccc8cbc5b9e8c768d", "warmup_time": -1}, "io.hdf.HDFStoreDataFrame.time_write_store_table_mixed": {"code": "class HDFStoreDataFrame:\n    def time_write_store_table_mixed(self):\n        self.store.append(\"table_mixed_write\", self.df_mixed)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass HDFStoreDataFrame:\n    def setup(self):\n        N = 25000\n        index = tm.makeStringIndex(N)\n        self.df = DataFrame(\n            {\"float1\": np.random.randn(N), \"float2\": np.random.randn(N)}, index=index\n        )\n        self.df_mixed = DataFrame(\n            {\n                \"float1\": np.random.randn(N),\n                \"float2\": np.random.randn(N),\n                \"string1\": [\"foo\"] * N,\n                \"bool1\": [True] * N,\n                \"int1\": np.random.randint(0, N, size=N),\n            },\n            index=index,\n        )\n        self.df_wide = DataFrame(np.random.randn(N, 100))\n        self.start_wide = self.df_wide.index[10000]\n        self.stop_wide = self.df_wide.index[15000]\n        self.df2 = DataFrame(\n            {\"float1\": np.random.randn(N), \"float2\": np.random.randn(N)},\n            index=date_range(\"1/1/2000\", periods=N),\n        )\n        self.start = self.df2.index[10000]\n        self.stop = self.df2.index[15000]\n        self.df_wide2 = DataFrame(\n            np.random.randn(N, 100), index=date_range(\"1/1/2000\", periods=N)\n        )\n        self.df_dc = DataFrame(\n            np.random.randn(N, 10), columns=[f\"C{i:03d}\" for i in range(10)]\n        )\n    \n        self.fname = \"__test__.h5\"\n    \n        self.store = HDFStore(self.fname)\n        self.store.put(\"fixed\", self.df)\n        self.store.put(\"fixed_mixed\", self.df_mixed)\n        self.store.append(\"table\", self.df2)\n        self.store.append(\"table_mixed\", self.df_mixed)\n        self.store.append(\"table_wide\", self.df_wide)\n        self.store.append(\"table_wide2\", self.df_wide2)", "min_run_count": 2, "name": "io.hdf.HDFStoreDataFrame.time_write_store_table_mixed", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "3244392e18aae5d4ff2924348f7cedd7e182d9f89067b92e5ce5c545de1e64db", "warmup_time": -1}, "io.hdf.HDFStoreDataFrame.time_write_store_table_wide": {"code": "class HDFStoreDataFrame:\n    def time_write_store_table_wide(self):\n        self.store.append(\"table_wide_write\", self.df_wide)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass HDFStoreDataFrame:\n    def setup(self):\n        N = 25000\n        index = tm.makeStringIndex(N)\n        self.df = DataFrame(\n            {\"float1\": np.random.randn(N), \"float2\": np.random.randn(N)}, index=index\n        )\n        self.df_mixed = DataFrame(\n            {\n                \"float1\": np.random.randn(N),\n                \"float2\": np.random.randn(N),\n                \"string1\": [\"foo\"] * N,\n                \"bool1\": [True] * N,\n                \"int1\": np.random.randint(0, N, size=N),\n            },\n            index=index,\n        )\n        self.df_wide = DataFrame(np.random.randn(N, 100))\n        self.start_wide = self.df_wide.index[10000]\n        self.stop_wide = self.df_wide.index[15000]\n        self.df2 = DataFrame(\n            {\"float1\": np.random.randn(N), \"float2\": np.random.randn(N)},\n            index=date_range(\"1/1/2000\", periods=N),\n        )\n        self.start = self.df2.index[10000]\n        self.stop = self.df2.index[15000]\n        self.df_wide2 = DataFrame(\n            np.random.randn(N, 100), index=date_range(\"1/1/2000\", periods=N)\n        )\n        self.df_dc = DataFrame(\n            np.random.randn(N, 10), columns=[f\"C{i:03d}\" for i in range(10)]\n        )\n    \n        self.fname = \"__test__.h5\"\n    \n        self.store = HDFStore(self.fname)\n        self.store.put(\"fixed\", self.df)\n        self.store.put(\"fixed_mixed\", self.df_mixed)\n        self.store.append(\"table\", self.df2)\n        self.store.append(\"table_mixed\", self.df_mixed)\n        self.store.append(\"table_wide\", self.df_wide)\n        self.store.append(\"table_wide2\", self.df_wide2)", "min_run_count": 2, "name": "io.hdf.HDFStoreDataFrame.time_write_store_table_wide", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "13e0c7f007dfa3d1ea1ab08df0d14121775a62379b59efb68b18e70f4c5f4f7a", "warmup_time": -1}, "io.json.NormalizeJSON.time_normalize_json": {"code": "class NormalizeJSON:\n    def time_normalize_json(self, orient, frame):\n        json_normalize(self.data)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass NormalizeJSON:\n    def setup(self, orient, frame):\n        data = {\n            \"hello\": [\"thisisatest\", 999898, \"mixed types\"],\n            \"nest1\": {\"nest2\": {\"nest3\": \"nest3_value\", \"nest3_int\": 3445}},\n            \"nest1_list\": {\"nest2\": [\"blah\", 32423, 546456.876, 92030234]},\n            \"hello2\": \"string\",\n        }\n        self.data = [data for i in range(10000)]", "min_run_count": 2, "name": "io.json.NormalizeJSON.time_normalize_json", "number": 0, "param_names": ["orient", "frame"], "params": [["'split'", "'columns'", "'index'", "'values'", "'records'"], ["'df'", "'df_date_idx'", "'df_td_int_ts'", "'df_int_floats'", "'df_int_float_str'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "318fc7d7f7bff26fc7a49a190be4dc0e2690469149e9fda19e3a8074d89cde6c", "warmup_time": -1}, "io.json.ReadJSON.time_read_json": {"code": "class ReadJSON:\n    def time_read_json(self, orient, index):\n        read_json(self.fname, orient=orient)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ReadJSON:\n    def setup(self, orient, index):\n        N = 100000\n        indexes = {\n            \"int\": np.arange(N),\n            \"datetime\": date_range(\"20000101\", periods=N, freq=\"H\"),\n        }\n        df = DataFrame(\n            np.random.randn(N, 5),\n            columns=[f\"float_{i}\" for i in range(5)],\n            index=indexes[index],\n        )\n        df.to_json(self.fname, orient=orient)", "min_run_count": 2, "name": "io.json.ReadJSON.time_read_json", "number": 0, "param_names": ["orient", "index"], "params": [["'split'", "'index'", "'records'"], ["'int'", "'datetime'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "3f6c14bc9e55f7a8db1ac1ac3e51554a8b8c13a584d65d6378577af9886c2dc3", "warmup_time": -1}, "io.json.ReadJSONLines.peakmem_read_json_lines": {"code": "class ReadJSONLines:\n    def peakmem_read_json_lines(self, index):\n        read_json(self.fname, orient=\"records\", lines=True)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ReadJSONLines:\n    def setup(self, index):\n        N = 100000\n        indexes = {\n            \"int\": np.arange(N),\n            \"datetime\": date_range(\"20000101\", periods=N, freq=\"H\"),\n        }\n        df = DataFrame(\n            np.random.randn(N, 5),\n            columns=[f\"float_{i}\" for i in range(5)],\n            index=indexes[index],\n        )\n        df.to_json(self.fname, orient=\"records\", lines=True)", "name": "io.json.ReadJSONLines.peakmem_read_json_lines", "param_names": ["index"], "params": [["'int'", "'datetime'"]], "timeout": 60.0, "type": "peakmemory", "unit": "bytes", "version": "fced1333ed6ef50926ba752d6eea2aee10f15cc17f9083db263457f5505fab40"}, "io.json.ReadJSONLines.peakmem_read_json_lines_concat": {"code": "class ReadJSONLines:\n    def peakmem_read_json_lines_concat(self, index):\n        concat(read_json(self.fname, orient=\"records\", lines=True, chunksize=25000))\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ReadJSONLines:\n    def setup(self, index):\n        N = 100000\n        indexes = {\n            \"int\": np.arange(N),\n            \"datetime\": date_range(\"20000101\", periods=N, freq=\"H\"),\n        }\n        df = DataFrame(\n            np.random.randn(N, 5),\n            columns=[f\"float_{i}\" for i in range(5)],\n            index=indexes[index],\n        )\n        df.to_json(self.fname, orient=\"records\", lines=True)", "name": "io.json.ReadJSONLines.peakmem_read_json_lines_concat", "param_names": ["index"], "params": [["'int'", "'datetime'"]], "timeout": 60.0, "type": "peakmemory", "unit": "bytes", "version": "3753e5a97992c5f90ebacd5cbb7de30dabc2ce781c590e31f20930dfbb2a2b2c"}, "io.json.ReadJSONLines.peakmem_read_json_lines_nrows": {"code": "class ReadJSONLines:\n    def peakmem_read_json_lines_nrows(self, index):\n        read_json(self.fname, orient=\"records\", lines=True, nrows=15000)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ReadJSONLines:\n    def setup(self, index):\n        N = 100000\n        indexes = {\n            \"int\": np.arange(N),\n            \"datetime\": date_range(\"20000101\", periods=N, freq=\"H\"),\n        }\n        df = DataFrame(\n            np.random.randn(N, 5),\n            columns=[f\"float_{i}\" for i in range(5)],\n            index=indexes[index],\n        )\n        df.to_json(self.fname, orient=\"records\", lines=True)", "name": "io.json.ReadJSONLines.peakmem_read_json_lines_nrows", "param_names": ["index"], "params": [["'int'", "'datetime'"]], "timeout": 60.0, "type": "peakmemory", "unit": "bytes", "version": "aaac83799b11da0d6b844ebbb1247cc25cee374c56d01f29168f9d16f17c1d49"}, "io.json.ReadJSONLines.time_read_json_lines": {"code": "class ReadJSONLines:\n    def time_read_json_lines(self, index):\n        read_json(self.fname, orient=\"records\", lines=True)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ReadJSONLines:\n    def setup(self, index):\n        N = 100000\n        indexes = {\n            \"int\": np.arange(N),\n            \"datetime\": date_range(\"20000101\", periods=N, freq=\"H\"),\n        }\n        df = DataFrame(\n            np.random.randn(N, 5),\n            columns=[f\"float_{i}\" for i in range(5)],\n            index=indexes[index],\n        )\n        df.to_json(self.fname, orient=\"records\", lines=True)", "min_run_count": 2, "name": "io.json.ReadJSONLines.time_read_json_lines", "number": 0, "param_names": ["index"], "params": [["'int'", "'datetime'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "c2f51ad2fdab3e2bf25fae93709d02119432db14e1842ce603e2f13a1c128286", "warmup_time": -1}, "io.json.ReadJSONLines.time_read_json_lines_concat": {"code": "class ReadJSONLines:\n    def time_read_json_lines_concat(self, index):\n        concat(read_json(self.fname, orient=\"records\", lines=True, chunksize=25000))\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ReadJSONLines:\n    def setup(self, index):\n        N = 100000\n        indexes = {\n            \"int\": np.arange(N),\n            \"datetime\": date_range(\"20000101\", periods=N, freq=\"H\"),\n        }\n        df = DataFrame(\n            np.random.randn(N, 5),\n            columns=[f\"float_{i}\" for i in range(5)],\n            index=indexes[index],\n        )\n        df.to_json(self.fname, orient=\"records\", lines=True)", "min_run_count": 2, "name": "io.json.ReadJSONLines.time_read_json_lines_concat", "number": 0, "param_names": ["index"], "params": [["'int'", "'datetime'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "342cb2570c1aa9c8f74d8d089479641e545984a9c1fcc9d158e22c00f93f278a", "warmup_time": -1}, "io.json.ReadJSONLines.time_read_json_lines_nrows": {"code": "class ReadJSONLines:\n    def time_read_json_lines_nrows(self, index):\n        read_json(self.fname, orient=\"records\", lines=True, nrows=25000)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ReadJSONLines:\n    def setup(self, index):\n        N = 100000\n        indexes = {\n            \"int\": np.arange(N),\n            \"datetime\": date_range(\"20000101\", periods=N, freq=\"H\"),\n        }\n        df = DataFrame(\n            np.random.randn(N, 5),\n            columns=[f\"float_{i}\" for i in range(5)],\n            index=indexes[index],\n        )\n        df.to_json(self.fname, orient=\"records\", lines=True)", "min_run_count": 2, "name": "io.json.ReadJSONLines.time_read_json_lines_nrows", "number": 0, "param_names": ["index"], "params": [["'int'", "'datetime'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "e44d38a5bde453e73625c16e6c33c05c07928b99505a20234085a00aaa76b3ec", "warmup_time": -1}, "io.json.ToJSON.peakmem_to_json": {"code": "class ToJSON:\n    def peakmem_to_json(self, orient, frame):\n        getattr(self, frame).to_json(self.fname, orient=orient)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToJSON:\n    def setup(self, orient, frame):\n        N = 10**5\n        ncols = 5\n        index = date_range(\"20000101\", periods=N, freq=\"H\")\n        timedeltas = timedelta_range(start=1, periods=N, freq=\"s\")\n        datetimes = date_range(start=1, periods=N, freq=\"s\")\n        ints = np.random.randint(100000000, size=N)\n        longints = sys.maxsize * np.random.randint(100000000, size=N)\n        floats = np.random.randn(N)\n        strings = tm.makeStringIndex(N)\n        self.df = DataFrame(np.random.randn(N, ncols), index=np.arange(N))\n        self.df_date_idx = DataFrame(np.random.randn(N, ncols), index=index)\n        self.df_td_int_ts = DataFrame(\n            {\n                \"td_1\": timedeltas,\n                \"td_2\": timedeltas,\n                \"int_1\": ints,\n                \"int_2\": ints,\n                \"ts_1\": datetimes,\n                \"ts_2\": datetimes,\n            },\n            index=index,\n        )\n        self.df_int_floats = DataFrame(\n            {\n                \"int_1\": ints,\n                \"int_2\": ints,\n                \"int_3\": ints,\n                \"float_1\": floats,\n                \"float_2\": floats,\n                \"float_3\": floats,\n            },\n            index=index,\n        )\n        self.df_int_float_str = DataFrame(\n            {\n                \"int_1\": ints,\n                \"int_2\": ints,\n                \"float_1\": floats,\n                \"float_2\": floats,\n                \"str_1\": strings,\n                \"str_2\": strings,\n            },\n            index=index,\n        )\n    \n        self.df_longint_float_str = DataFrame(\n            {\n                \"longint_1\": longints,\n                \"longint_2\": longints,\n                \"float_1\": floats,\n                \"float_2\": floats,\n                \"str_1\": strings,\n                \"str_2\": strings,\n            },\n            index=index,\n        )", "name": "io.json.ToJSON.peakmem_to_json", "param_names": ["orient", "frame"], "params": [["'split'", "'columns'", "'index'", "'values'", "'records'"], ["'df'", "'df_date_idx'", "'df_td_int_ts'", "'df_int_floats'", "'df_int_float_str'"]], "timeout": 60.0, "type": "peakmemory", "unit": "bytes", "version": "a3f03b5c3ee15c8b148c400ecf6ea63bdc954cb6619214527fe0dbd84ff9655b"}, "io.json.ToJSON.time_to_json": {"code": "class ToJSON:\n    def time_to_json(self, orient, frame):\n        getattr(self, frame).to_json(self.fname, orient=orient)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToJSON:\n    def setup(self, orient, frame):\n        N = 10**5\n        ncols = 5\n        index = date_range(\"20000101\", periods=N, freq=\"H\")\n        timedeltas = timedelta_range(start=1, periods=N, freq=\"s\")\n        datetimes = date_range(start=1, periods=N, freq=\"s\")\n        ints = np.random.randint(100000000, size=N)\n        longints = sys.maxsize * np.random.randint(100000000, size=N)\n        floats = np.random.randn(N)\n        strings = tm.makeStringIndex(N)\n        self.df = DataFrame(np.random.randn(N, ncols), index=np.arange(N))\n        self.df_date_idx = DataFrame(np.random.randn(N, ncols), index=index)\n        self.df_td_int_ts = DataFrame(\n            {\n                \"td_1\": timedeltas,\n                \"td_2\": timedeltas,\n                \"int_1\": ints,\n                \"int_2\": ints,\n                \"ts_1\": datetimes,\n                \"ts_2\": datetimes,\n            },\n            index=index,\n        )\n        self.df_int_floats = DataFrame(\n            {\n                \"int_1\": ints,\n                \"int_2\": ints,\n                \"int_3\": ints,\n                \"float_1\": floats,\n                \"float_2\": floats,\n                \"float_3\": floats,\n            },\n            index=index,\n        )\n        self.df_int_float_str = DataFrame(\n            {\n                \"int_1\": ints,\n                \"int_2\": ints,\n                \"float_1\": floats,\n                \"float_2\": floats,\n                \"str_1\": strings,\n                \"str_2\": strings,\n            },\n            index=index,\n        )\n    \n        self.df_longint_float_str = DataFrame(\n            {\n                \"longint_1\": longints,\n                \"longint_2\": longints,\n                \"float_1\": floats,\n                \"float_2\": floats,\n                \"str_1\": strings,\n                \"str_2\": strings,\n            },\n            index=index,\n        )", "min_run_count": 2, "name": "io.json.ToJSON.time_to_json", "number": 0, "param_names": ["orient", "frame"], "params": [["'split'", "'columns'", "'index'", "'values'", "'records'"], ["'df'", "'df_date_idx'", "'df_td_int_ts'", "'df_int_floats'", "'df_int_float_str'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "47fd79bf2550f6404c10a2bea0f5b4b8125be4c847f73e2b252de048d2455621", "warmup_time": -1}, "io.json.ToJSONISO.time_iso_format": {"code": "class ToJSONISO:\n    def time_iso_format(self, orient):\n        self.df.to_json(orient=orient, date_format=\"iso\")\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToJSONISO:\n    def setup(self, orient):\n        N = 10**5\n        index = date_range(\"20000101\", periods=N, freq=\"H\")\n        timedeltas = timedelta_range(start=1, periods=N, freq=\"s\")\n        datetimes = date_range(start=1, periods=N, freq=\"s\")\n        self.df = DataFrame(\n            {\n                \"td_1\": timedeltas,\n                \"td_2\": timedeltas,\n                \"ts_1\": datetimes,\n                \"ts_2\": datetimes,\n            },\n            index=index,\n        )", "min_run_count": 2, "name": "io.json.ToJSONISO.time_iso_format", "number": 0, "param_names": ["orient"], "params": [["'split'", "'columns'", "'index'", "'values'", "'records'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "7a1fb2a8d742af4adb8a38f980783a3a8987226ac8edaf6063df2e2d468e447c", "warmup_time": -1}, "io.json.ToJSONLines.time_delta_int_tstamp_lines": {"code": "class ToJSONLines:\n    def time_delta_int_tstamp_lines(self):\n        self.df_td_int_ts.to_json(self.fname, orient=\"records\", lines=True)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToJSONLines:\n    def setup(self):\n        N = 10**5\n        ncols = 5\n        index = date_range(\"20000101\", periods=N, freq=\"H\")\n        timedeltas = timedelta_range(start=1, periods=N, freq=\"s\")\n        datetimes = date_range(start=1, periods=N, freq=\"s\")\n        ints = np.random.randint(100000000, size=N)\n        longints = sys.maxsize * np.random.randint(100000000, size=N)\n        floats = np.random.randn(N)\n        strings = tm.makeStringIndex(N)\n        self.df = DataFrame(np.random.randn(N, ncols), index=np.arange(N))\n        self.df_date_idx = DataFrame(np.random.randn(N, ncols), index=index)\n        self.df_td_int_ts = DataFrame(\n            {\n                \"td_1\": timedeltas,\n                \"td_2\": timedeltas,\n                \"int_1\": ints,\n                \"int_2\": ints,\n                \"ts_1\": datetimes,\n                \"ts_2\": datetimes,\n            },\n            index=index,\n        )\n        self.df_int_floats = DataFrame(\n            {\n                \"int_1\": ints,\n                \"int_2\": ints,\n                \"int_3\": ints,\n                \"float_1\": floats,\n                \"float_2\": floats,\n                \"float_3\": floats,\n            },\n            index=index,\n        )\n        self.df_int_float_str = DataFrame(\n            {\n                \"int_1\": ints,\n                \"int_2\": ints,\n                \"float_1\": floats,\n                \"float_2\": floats,\n                \"str_1\": strings,\n                \"str_2\": strings,\n            },\n            index=index,\n        )\n        self.df_longint_float_str = DataFrame(\n            {\n                \"longint_1\": longints,\n                \"longint_2\": longints,\n                \"float_1\": floats,\n                \"float_2\": floats,\n                \"str_1\": strings,\n                \"str_2\": strings,\n            },\n            index=index,\n        )", "min_run_count": 2, "name": "io.json.ToJSONLines.time_delta_int_tstamp_lines", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "2ad28033b254a2d008d6500780ec6b1981378a7cdf10f495de4ac03c0eafd701", "warmup_time": -1}, "io.json.ToJSONLines.time_float_int_lines": {"code": "class ToJSONLines:\n    def time_float_int_lines(self):\n        self.df_int_floats.to_json(self.fname, orient=\"records\", lines=True)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToJSONLines:\n    def setup(self):\n        N = 10**5\n        ncols = 5\n        index = date_range(\"20000101\", periods=N, freq=\"H\")\n        timedeltas = timedelta_range(start=1, periods=N, freq=\"s\")\n        datetimes = date_range(start=1, periods=N, freq=\"s\")\n        ints = np.random.randint(100000000, size=N)\n        longints = sys.maxsize * np.random.randint(100000000, size=N)\n        floats = np.random.randn(N)\n        strings = tm.makeStringIndex(N)\n        self.df = DataFrame(np.random.randn(N, ncols), index=np.arange(N))\n        self.df_date_idx = DataFrame(np.random.randn(N, ncols), index=index)\n        self.df_td_int_ts = DataFrame(\n            {\n                \"td_1\": timedeltas,\n                \"td_2\": timedeltas,\n                \"int_1\": ints,\n                \"int_2\": ints,\n                \"ts_1\": datetimes,\n                \"ts_2\": datetimes,\n            },\n            index=index,\n        )\n        self.df_int_floats = DataFrame(\n            {\n                \"int_1\": ints,\n                \"int_2\": ints,\n                \"int_3\": ints,\n                \"float_1\": floats,\n                \"float_2\": floats,\n                \"float_3\": floats,\n            },\n            index=index,\n        )\n        self.df_int_float_str = DataFrame(\n            {\n                \"int_1\": ints,\n                \"int_2\": ints,\n                \"float_1\": floats,\n                \"float_2\": floats,\n                \"str_1\": strings,\n                \"str_2\": strings,\n            },\n            index=index,\n        )\n        self.df_longint_float_str = DataFrame(\n            {\n                \"longint_1\": longints,\n                \"longint_2\": longints,\n                \"float_1\": floats,\n                \"float_2\": floats,\n                \"str_1\": strings,\n                \"str_2\": strings,\n            },\n            index=index,\n        )", "min_run_count": 2, "name": "io.json.ToJSONLines.time_float_int_lines", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "122cb2a741e98a030328ed2ed8826ec94897836458dd46f772310c7805d18168", "warmup_time": -1}, "io.json.ToJSONLines.time_float_int_str_lines": {"code": "class ToJSONLines:\n    def time_float_int_str_lines(self):\n        self.df_int_float_str.to_json(self.fname, orient=\"records\", lines=True)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToJSONLines:\n    def setup(self):\n        N = 10**5\n        ncols = 5\n        index = date_range(\"20000101\", periods=N, freq=\"H\")\n        timedeltas = timedelta_range(start=1, periods=N, freq=\"s\")\n        datetimes = date_range(start=1, periods=N, freq=\"s\")\n        ints = np.random.randint(100000000, size=N)\n        longints = sys.maxsize * np.random.randint(100000000, size=N)\n        floats = np.random.randn(N)\n        strings = tm.makeStringIndex(N)\n        self.df = DataFrame(np.random.randn(N, ncols), index=np.arange(N))\n        self.df_date_idx = DataFrame(np.random.randn(N, ncols), index=index)\n        self.df_td_int_ts = DataFrame(\n            {\n                \"td_1\": timedeltas,\n                \"td_2\": timedeltas,\n                \"int_1\": ints,\n                \"int_2\": ints,\n                \"ts_1\": datetimes,\n                \"ts_2\": datetimes,\n            },\n            index=index,\n        )\n        self.df_int_floats = DataFrame(\n            {\n                \"int_1\": ints,\n                \"int_2\": ints,\n                \"int_3\": ints,\n                \"float_1\": floats,\n                \"float_2\": floats,\n                \"float_3\": floats,\n            },\n            index=index,\n        )\n        self.df_int_float_str = DataFrame(\n            {\n                \"int_1\": ints,\n                \"int_2\": ints,\n                \"float_1\": floats,\n                \"float_2\": floats,\n                \"str_1\": strings,\n                \"str_2\": strings,\n            },\n            index=index,\n        )\n        self.df_longint_float_str = DataFrame(\n            {\n                \"longint_1\": longints,\n                \"longint_2\": longints,\n                \"float_1\": floats,\n                \"float_2\": floats,\n                \"str_1\": strings,\n                \"str_2\": strings,\n            },\n            index=index,\n        )", "min_run_count": 2, "name": "io.json.ToJSONLines.time_float_int_str_lines", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "ed5999820d3b678aa0495306ec67c1c701f689bcadfb15c1919f3560c0ce9dda", "warmup_time": -1}, "io.json.ToJSONLines.time_float_longint_str_lines": {"code": "class ToJSONLines:\n    def time_float_longint_str_lines(self):\n        self.df_longint_float_str.to_json(self.fname, orient=\"records\", lines=True)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToJSONLines:\n    def setup(self):\n        N = 10**5\n        ncols = 5\n        index = date_range(\"20000101\", periods=N, freq=\"H\")\n        timedeltas = timedelta_range(start=1, periods=N, freq=\"s\")\n        datetimes = date_range(start=1, periods=N, freq=\"s\")\n        ints = np.random.randint(100000000, size=N)\n        longints = sys.maxsize * np.random.randint(100000000, size=N)\n        floats = np.random.randn(N)\n        strings = tm.makeStringIndex(N)\n        self.df = DataFrame(np.random.randn(N, ncols), index=np.arange(N))\n        self.df_date_idx = DataFrame(np.random.randn(N, ncols), index=index)\n        self.df_td_int_ts = DataFrame(\n            {\n                \"td_1\": timedeltas,\n                \"td_2\": timedeltas,\n                \"int_1\": ints,\n                \"int_2\": ints,\n                \"ts_1\": datetimes,\n                \"ts_2\": datetimes,\n            },\n            index=index,\n        )\n        self.df_int_floats = DataFrame(\n            {\n                \"int_1\": ints,\n                \"int_2\": ints,\n                \"int_3\": ints,\n                \"float_1\": floats,\n                \"float_2\": floats,\n                \"float_3\": floats,\n            },\n            index=index,\n        )\n        self.df_int_float_str = DataFrame(\n            {\n                \"int_1\": ints,\n                \"int_2\": ints,\n                \"float_1\": floats,\n                \"float_2\": floats,\n                \"str_1\": strings,\n                \"str_2\": strings,\n            },\n            index=index,\n        )\n        self.df_longint_float_str = DataFrame(\n            {\n                \"longint_1\": longints,\n                \"longint_2\": longints,\n                \"float_1\": floats,\n                \"float_2\": floats,\n                \"str_1\": strings,\n                \"str_2\": strings,\n            },\n            index=index,\n        )", "min_run_count": 2, "name": "io.json.ToJSONLines.time_float_longint_str_lines", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "66bf7e9b19dd1a5a2451f62140113db55063e4bda7b211513e159149abe14718", "warmup_time": -1}, "io.json.ToJSONLines.time_floats_with_dt_index_lines": {"code": "class ToJSONLines:\n    def time_floats_with_dt_index_lines(self):\n        self.df_date_idx.to_json(self.fname, orient=\"records\", lines=True)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToJSONLines:\n    def setup(self):\n        N = 10**5\n        ncols = 5\n        index = date_range(\"20000101\", periods=N, freq=\"H\")\n        timedeltas = timedelta_range(start=1, periods=N, freq=\"s\")\n        datetimes = date_range(start=1, periods=N, freq=\"s\")\n        ints = np.random.randint(100000000, size=N)\n        longints = sys.maxsize * np.random.randint(100000000, size=N)\n        floats = np.random.randn(N)\n        strings = tm.makeStringIndex(N)\n        self.df = DataFrame(np.random.randn(N, ncols), index=np.arange(N))\n        self.df_date_idx = DataFrame(np.random.randn(N, ncols), index=index)\n        self.df_td_int_ts = DataFrame(\n            {\n                \"td_1\": timedeltas,\n                \"td_2\": timedeltas,\n                \"int_1\": ints,\n                \"int_2\": ints,\n                \"ts_1\": datetimes,\n                \"ts_2\": datetimes,\n            },\n            index=index,\n        )\n        self.df_int_floats = DataFrame(\n            {\n                \"int_1\": ints,\n                \"int_2\": ints,\n                \"int_3\": ints,\n                \"float_1\": floats,\n                \"float_2\": floats,\n                \"float_3\": floats,\n            },\n            index=index,\n        )\n        self.df_int_float_str = DataFrame(\n            {\n                \"int_1\": ints,\n                \"int_2\": ints,\n                \"float_1\": floats,\n                \"float_2\": floats,\n                \"str_1\": strings,\n                \"str_2\": strings,\n            },\n            index=index,\n        )\n        self.df_longint_float_str = DataFrame(\n            {\n                \"longint_1\": longints,\n                \"longint_2\": longints,\n                \"float_1\": floats,\n                \"float_2\": floats,\n                \"str_1\": strings,\n                \"str_2\": strings,\n            },\n            index=index,\n        )", "min_run_count": 2, "name": "io.json.ToJSONLines.time_floats_with_dt_index_lines", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "49c5a821810d54aa0ac73768e53794c064e0ea4f40c24190f91465b3cef545a7", "warmup_time": -1}, "io.json.ToJSONLines.time_floats_with_int_idex_lines": {"code": "class ToJSONLines:\n    def time_floats_with_int_idex_lines(self):\n        self.df.to_json(self.fname, orient=\"records\", lines=True)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToJSONLines:\n    def setup(self):\n        N = 10**5\n        ncols = 5\n        index = date_range(\"20000101\", periods=N, freq=\"H\")\n        timedeltas = timedelta_range(start=1, periods=N, freq=\"s\")\n        datetimes = date_range(start=1, periods=N, freq=\"s\")\n        ints = np.random.randint(100000000, size=N)\n        longints = sys.maxsize * np.random.randint(100000000, size=N)\n        floats = np.random.randn(N)\n        strings = tm.makeStringIndex(N)\n        self.df = DataFrame(np.random.randn(N, ncols), index=np.arange(N))\n        self.df_date_idx = DataFrame(np.random.randn(N, ncols), index=index)\n        self.df_td_int_ts = DataFrame(\n            {\n                \"td_1\": timedeltas,\n                \"td_2\": timedeltas,\n                \"int_1\": ints,\n                \"int_2\": ints,\n                \"ts_1\": datetimes,\n                \"ts_2\": datetimes,\n            },\n            index=index,\n        )\n        self.df_int_floats = DataFrame(\n            {\n                \"int_1\": ints,\n                \"int_2\": ints,\n                \"int_3\": ints,\n                \"float_1\": floats,\n                \"float_2\": floats,\n                \"float_3\": floats,\n            },\n            index=index,\n        )\n        self.df_int_float_str = DataFrame(\n            {\n                \"int_1\": ints,\n                \"int_2\": ints,\n                \"float_1\": floats,\n                \"float_2\": floats,\n                \"str_1\": strings,\n                \"str_2\": strings,\n            },\n            index=index,\n        )\n        self.df_longint_float_str = DataFrame(\n            {\n                \"longint_1\": longints,\n                \"longint_2\": longints,\n                \"float_1\": floats,\n                \"float_2\": floats,\n                \"str_1\": strings,\n                \"str_2\": strings,\n            },\n            index=index,\n        )", "min_run_count": 2, "name": "io.json.ToJSONLines.time_floats_with_int_idex_lines", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "b0e434e1f04e407c653a05a0ea2bc44885187a07c6f26ef0bc2e67771b51cc0a", "warmup_time": -1}, "io.json.ToJSONMem.peakmem_float": {"code": "class ToJSONMem:\n    def peakmem_float(self, frames):\n        df = frames[\"float\"]\n        for _ in range(100_000):\n            df.to_json()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToJSONMem:\n    def setup_cache(self):\n        df = DataFrame([[1]])\n        df2 = DataFrame(range(8), date_range(\"1/1/2000\", periods=8, freq=\"T\"))\n        frames = {\"int\": df, \"float\": df.astype(float), \"datetime\": df2}\n    \n        return frames", "name": "io.json.ToJSONMem.peakmem_float", "param_names": [], "params": [], "setup_cache_key": "io.json:291", "timeout": 60.0, "type": "peakmemory", "unit": "bytes", "version": "f5a6f669b3779ee79cb4686336b28b3dfb8752cf7911a65d4de5ad9d35f65ead"}, "io.json.ToJSONMem.peakmem_int": {"code": "class ToJSONMem:\n    def peakmem_int(self, frames):\n        df = frames[\"int\"]\n        for _ in range(100_000):\n            df.to_json()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToJSONMem:\n    def setup_cache(self):\n        df = DataFrame([[1]])\n        df2 = DataFrame(range(8), date_range(\"1/1/2000\", periods=8, freq=\"T\"))\n        frames = {\"int\": df, \"float\": df.astype(float), \"datetime\": df2}\n    \n        return frames", "name": "io.json.ToJSONMem.peakmem_int", "param_names": [], "params": [], "setup_cache_key": "io.json:291", "timeout": 60.0, "type": "peakmemory", "unit": "bytes", "version": "1862be9789582fc513cd16591ff66d737c440b59e1f509207a97c2608a86ae5d"}, "io.json.ToJSONMem.peakmem_time": {"code": "class ToJSONMem:\n    def peakmem_time(self, frames):\n        df = frames[\"datetime\"]\n        for _ in range(10_000):\n            df.to_json(orient=\"table\")\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToJSONMem:\n    def setup_cache(self):\n        df = DataFrame([[1]])\n        df2 = DataFrame(range(8), date_range(\"1/1/2000\", periods=8, freq=\"T\"))\n        frames = {\"int\": df, \"float\": df.astype(float), \"datetime\": df2}\n    \n        return frames", "name": "io.json.ToJSONMem.peakmem_time", "param_names": [], "params": [], "setup_cache_key": "io.json:291", "timeout": 60.0, "type": "peakmemory", "unit": "bytes", "version": "88eb13f259b948522fb8d4b0e57a2fd3b64c3242967a6744a2a6421b20587356"}, "io.json.ToJSONWide.peakmem_to_json": {"code": "class ToJSON:\n    def peakmem_to_json(self, orient, frame):\n        getattr(self, frame).to_json(self.fname, orient=orient)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToJSONWide:\n    def setup(self, orient, frame):\n        super().setup(orient, frame)\n        base_df = getattr(self, frame).copy()\n        df_wide = concat([base_df.iloc[:100]] * 1000, ignore_index=True, axis=1)\n        self.df_wide = df_wide", "name": "io.json.ToJSONWide.peakmem_to_json", "param_names": ["orient", "frame"], "params": [["'split'", "'columns'", "'index'", "'values'", "'records'"], ["'df'", "'df_date_idx'", "'df_td_int_ts'", "'df_int_floats'", "'df_int_float_str'"]], "timeout": 60.0, "type": "peakmemory", "unit": "bytes", "version": "f179e468594888d4ad11b82d624fc4c3925d4831054986c7642b6a7938e395d8"}, "io.json.ToJSONWide.peakmem_to_json_wide": {"code": "class ToJSONWide:\n    def peakmem_to_json_wide(self, orient, frame):\n        self.df_wide.to_json(self.fname, orient=orient)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToJSONWide:\n    def setup(self, orient, frame):\n        super().setup(orient, frame)\n        base_df = getattr(self, frame).copy()\n        df_wide = concat([base_df.iloc[:100]] * 1000, ignore_index=True, axis=1)\n        self.df_wide = df_wide", "name": "io.json.ToJSONWide.peakmem_to_json_wide", "param_names": ["orient", "frame"], "params": [["'split'", "'columns'", "'index'", "'values'", "'records'"], ["'df'", "'df_date_idx'", "'df_td_int_ts'", "'df_int_floats'", "'df_int_float_str'"]], "timeout": 60.0, "type": "peakmemory", "unit": "bytes", "version": "350c040ee03cb09b3b2af80aacdb6f89f0b64fb12027e7abfcecf1754316da0d"}, "io.json.ToJSONWide.time_to_json": {"code": "class ToJSON:\n    def time_to_json(self, orient, frame):\n        getattr(self, frame).to_json(self.fname, orient=orient)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToJSONWide:\n    def setup(self, orient, frame):\n        super().setup(orient, frame)\n        base_df = getattr(self, frame).copy()\n        df_wide = concat([base_df.iloc[:100]] * 1000, ignore_index=True, axis=1)\n        self.df_wide = df_wide", "min_run_count": 2, "name": "io.json.ToJSONWide.time_to_json", "number": 0, "param_names": ["orient", "frame"], "params": [["'split'", "'columns'", "'index'", "'values'", "'records'"], ["'df'", "'df_date_idx'", "'df_td_int_ts'", "'df_int_floats'", "'df_int_float_str'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "3efe5275ae2f37aaa5320e63422ce5b375719e691728af347d4018c67aef213a", "warmup_time": -1}, "io.json.ToJSONWide.time_to_json_wide": {"code": "class ToJSONWide:\n    def time_to_json_wide(self, orient, frame):\n        self.df_wide.to_json(self.fname, orient=orient)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToJSONWide:\n    def setup(self, orient, frame):\n        super().setup(orient, frame)\n        base_df = getattr(self, frame).copy()\n        df_wide = concat([base_df.iloc[:100]] * 1000, ignore_index=True, axis=1)\n        self.df_wide = df_wide", "min_run_count": 2, "name": "io.json.ToJSONWide.time_to_json_wide", "number": 0, "param_names": ["orient", "frame"], "params": [["'split'", "'columns'", "'index'", "'values'", "'records'"], ["'df'", "'df_date_idx'", "'df_td_int_ts'", "'df_int_floats'", "'df_int_float_str'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "aae5665173eb24e14595380fcf07cfeeab21783b5862479ee4e358e042ba6c38", "warmup_time": -1}, "io.parsers.ConcatDateCols.time_check_concat": {"code": "class ConcatDateCols:\n    def time_check_concat(self, value, dim):\n        concat_date_cols(self.object)\n\n    def setup(self, value, dim):\n        count_elem = 10000\n        if dim == 1:\n            self.object = (np.array([value] * count_elem),)\n        if dim == 2:\n            self.object = (\n                np.array([value] * count_elem),\n                np.array([value] * count_elem),\n            )", "min_run_count": 2, "name": "io.parsers.ConcatDateCols.time_check_concat", "number": 0, "param_names": ["value", "dim"], "params": [["1234567890", "'AAAA'"], ["1", "2"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "9aa4efe73a0a7fdff0a0c0b2ffa389e83a44520cd250bfea1d40fde51c49d9d8", "warmup_time": -1}, "io.parsers.DoesStringLookLikeDatetime.time_check_datetimes": {"code": "class DoesStringLookLikeDatetime:\n    def time_check_datetimes(self, value):\n        for obj in self.objects:\n            _does_string_look_like_datetime(obj)\n\n    def setup(self, value):\n        self.objects = [value] * 1000000", "min_run_count": 2, "name": "io.parsers.DoesStringLookLikeDatetime.time_check_datetimes", "number": 0, "param_names": ["value"], "params": [["'2Q2005'", "'0.0'", "'10000'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "a023015f4dc4ff2fbfce3252f6fd4b6c28970e462a5e405f7c2febd9b2256de7", "warmup_time": -1}, "io.pickle.Pickle.peakmem_read_pickle": {"code": "class Pickle:\n    def peakmem_read_pickle(self):\n        read_pickle(self.fname)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Pickle:\n    def setup(self):\n        self.fname = \"__test__.pkl\"\n        N = 100000\n        C = 5\n        self.df = DataFrame(\n            np.random.randn(N, C),\n            columns=[f\"float{i}\" for i in range(C)],\n            index=date_range(\"20000101\", periods=N, freq=\"H\"),\n        )\n        self.df[\"object\"] = tm.makeStringIndex(N)\n        self.df.to_pickle(self.fname)", "name": "io.pickle.Pickle.peakmem_read_pickle", "param_names": [], "params": [], "timeout": 60.0, "type": "peakmemory", "unit": "bytes", "version": "32588a86b2897062ab806a649b772d609575da1519a6e12c42484150b1367904"}, "io.pickle.Pickle.peakmem_write_pickle": {"code": "class Pickle:\n    def peakmem_write_pickle(self):\n        self.df.to_pickle(self.fname)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Pickle:\n    def setup(self):\n        self.fname = \"__test__.pkl\"\n        N = 100000\n        C = 5\n        self.df = DataFrame(\n            np.random.randn(N, C),\n            columns=[f\"float{i}\" for i in range(C)],\n            index=date_range(\"20000101\", periods=N, freq=\"H\"),\n        )\n        self.df[\"object\"] = tm.makeStringIndex(N)\n        self.df.to_pickle(self.fname)", "name": "io.pickle.Pickle.peakmem_write_pickle", "param_names": [], "params": [], "timeout": 60.0, "type": "peakmemory", "unit": "bytes", "version": "839a5ff1f363bfec3346c4bf60f8a8bab063593f1c603f5d2187989e53993f18"}, "io.pickle.Pickle.time_read_pickle": {"code": "class Pickle:\n    def time_read_pickle(self):\n        read_pickle(self.fname)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Pickle:\n    def setup(self):\n        self.fname = \"__test__.pkl\"\n        N = 100000\n        C = 5\n        self.df = DataFrame(\n            np.random.randn(N, C),\n            columns=[f\"float{i}\" for i in range(C)],\n            index=date_range(\"20000101\", periods=N, freq=\"H\"),\n        )\n        self.df[\"object\"] = tm.makeStringIndex(N)\n        self.df.to_pickle(self.fname)", "min_run_count": 2, "name": "io.pickle.Pickle.time_read_pickle", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "0162d5f685117e8f1bcd5a6d79be23fbb5dbe4448a13b5bce289925a6e251566", "warmup_time": -1}, "io.pickle.Pickle.time_write_pickle": {"code": "class Pickle:\n    def time_write_pickle(self):\n        self.df.to_pickle(self.fname)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Pickle:\n    def setup(self):\n        self.fname = \"__test__.pkl\"\n        N = 100000\n        C = 5\n        self.df = DataFrame(\n            np.random.randn(N, C),\n            columns=[f\"float{i}\" for i in range(C)],\n            index=date_range(\"20000101\", periods=N, freq=\"H\"),\n        )\n        self.df[\"object\"] = tm.makeStringIndex(N)\n        self.df.to_pickle(self.fname)", "min_run_count": 2, "name": "io.pickle.Pickle.time_write_pickle", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "80f443c19927866fbbaef6c821598e7249c2d7c7dada4dffc558abcee53f2fc9", "warmup_time": -1}, "io.sas.SAS.time_read_sas7bdat": {"code": "class SAS:\n    def time_read_sas7bdat(self):\n        read_sas(ROOT / \"test1.sas7bdat\")", "min_run_count": 2, "name": "io.sas.SAS.time_read_sas7bdat", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "90750b4b8570b3ae59cde41f15ee1b854b9ab5ce81313090b40ed33623373ac0", "warmup_time": -1}, "io.sas.SAS.time_read_sas7bdat_2": {"code": "class SAS:\n    def time_read_sas7bdat_2(self):\n        next(read_sas(ROOT / \"0x00controlbyte.sas7bdat.bz2\", chunksize=11000))", "min_run_count": 2, "name": "io.sas.SAS.time_read_sas7bdat_2", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "6634a822c4810085a951c2a037c4c61eeb579b792626fe9e9258ee6c42746e28", "warmup_time": -1}, "io.sas.SAS.time_read_sas7bdat_2_chunked": {"code": "class SAS:\n    def time_read_sas7bdat_2_chunked(self):\n        for i, _ in enumerate(\n            read_sas(ROOT / \"0x00controlbyte.sas7bdat.bz2\", chunksize=1000)\n        ):\n            if i == 10:\n                break", "min_run_count": 2, "name": "io.sas.SAS.time_read_sas7bdat_2_chunked", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "d10bf08f751bef710fda95bf4064e7efe3c337d520294711968c04867570b2e1", "warmup_time": -1}, "io.sas.SAS.time_read_xpt": {"code": "class SAS:\n    def time_read_xpt(self):\n        read_sas(ROOT / \"paxraw_d_short.xpt\")", "min_run_count": 2, "name": "io.sas.SAS.time_read_xpt", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "e400235073dafa325dfdd6e6eda51419eff1337191b1178a5f5ab43af9d3bb9a", "warmup_time": -1}, "io.sql.ReadSQLTable.time_read_sql_table_all": {"code": "class ReadSQLTable:\n    def time_read_sql_table_all(self):\n        read_sql_table(self.table_name, self.con)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ReadSQLTable:\n    def setup(self):\n        N = 10000\n        self.table_name = \"test\"\n        self.con = create_engine(\"sqlite:///:memory:\")\n        self.df = DataFrame(\n            {\n                \"float\": np.random.randn(N),\n                \"float_with_nan\": np.random.randn(N),\n                \"string\": [\"foo\"] * N,\n                \"bool\": [True] * N,\n                \"int\": np.random.randint(0, N, size=N),\n                \"datetime\": date_range(\"2000-01-01\", periods=N, freq=\"s\"),\n            },\n            index=tm.makeStringIndex(N),\n        )\n        self.df.iloc[1000:3000, 1] = np.nan\n        self.df[\"date\"] = self.df[\"datetime\"].dt.date\n        self.df[\"time\"] = self.df[\"datetime\"].dt.time\n        self.df[\"datetime_string\"] = self.df[\"datetime\"].astype(str)\n        self.df.to_sql(self.table_name, self.con, if_exists=\"replace\")", "min_run_count": 2, "name": "io.sql.ReadSQLTable.time_read_sql_table_all", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "83699e730bdc4a1c55b4fe45152ce4e30a7b4cacff1ca5015c643721d9bab006", "warmup_time": -1}, "io.sql.ReadSQLTable.time_read_sql_table_parse_dates": {"code": "class ReadSQLTable:\n    def time_read_sql_table_parse_dates(self):\n        read_sql_table(\n            self.table_name,\n            self.con,\n            columns=[\"datetime_string\"],\n            parse_dates=[\"datetime_string\"],\n        )\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ReadSQLTable:\n    def setup(self):\n        N = 10000\n        self.table_name = \"test\"\n        self.con = create_engine(\"sqlite:///:memory:\")\n        self.df = DataFrame(\n            {\n                \"float\": np.random.randn(N),\n                \"float_with_nan\": np.random.randn(N),\n                \"string\": [\"foo\"] * N,\n                \"bool\": [True] * N,\n                \"int\": np.random.randint(0, N, size=N),\n                \"datetime\": date_range(\"2000-01-01\", periods=N, freq=\"s\"),\n            },\n            index=tm.makeStringIndex(N),\n        )\n        self.df.iloc[1000:3000, 1] = np.nan\n        self.df[\"date\"] = self.df[\"datetime\"].dt.date\n        self.df[\"time\"] = self.df[\"datetime\"].dt.time\n        self.df[\"datetime_string\"] = self.df[\"datetime\"].astype(str)\n        self.df.to_sql(self.table_name, self.con, if_exists=\"replace\")", "min_run_count": 2, "name": "io.sql.ReadSQLTable.time_read_sql_table_parse_dates", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "711ed944de8c18bec59fa71af79ac73945d51ae76d76548717efaa71baa78eab", "warmup_time": -1}, "io.sql.ReadSQLTableDtypes.time_read_sql_table_column": {"code": "class ReadSQLTableDtypes:\n    def time_read_sql_table_column(self, dtype):\n        read_sql_table(self.table_name, self.con, columns=[dtype])\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ReadSQLTableDtypes:\n    def setup(self, dtype):\n        N = 10000\n        self.table_name = \"test\"\n        self.con = create_engine(\"sqlite:///:memory:\")\n        self.df = DataFrame(\n            {\n                \"float\": np.random.randn(N),\n                \"float_with_nan\": np.random.randn(N),\n                \"string\": [\"foo\"] * N,\n                \"bool\": [True] * N,\n                \"int\": np.random.randint(0, N, size=N),\n                \"datetime\": date_range(\"2000-01-01\", periods=N, freq=\"s\"),\n            },\n            index=tm.makeStringIndex(N),\n        )\n        self.df.iloc[1000:3000, 1] = np.nan\n        self.df[\"date\"] = self.df[\"datetime\"].dt.date\n        self.df[\"time\"] = self.df[\"datetime\"].dt.time\n        self.df[\"datetime_string\"] = self.df[\"datetime\"].astype(str)\n        self.df.to_sql(self.table_name, self.con, if_exists=\"replace\")", "min_run_count": 2, "name": "io.sql.ReadSQLTableDtypes.time_read_sql_table_column", "number": 0, "param_names": ["dtype"], "params": [["'float'", "'float_with_nan'", "'string'", "'bool'", "'int'", "'date'", "'time'", "'datetime'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "1f1957d2b098c3a95d2980cbe0928b80a3d18431f503d901aeea7e01d20329b0", "warmup_time": -1}, "io.sql.SQL.time_read_sql_query": {"code": "class SQL:\n    def time_read_sql_query(self, connection):\n        read_sql_query(self.query_all, self.con)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass SQL:\n    def setup(self, connection):\n        N = 10000\n        con = {\n            \"sqlalchemy\": create_engine(\"sqlite:///:memory:\"),\n            \"sqlite\": sqlite3.connect(\":memory:\"),\n        }\n        self.table_name = \"test_type\"\n        self.query_all = f\"SELECT * FROM {self.table_name}\"\n        self.con = con[connection]\n        self.df = DataFrame(\n            {\n                \"float\": np.random.randn(N),\n                \"float_with_nan\": np.random.randn(N),\n                \"string\": [\"foo\"] * N,\n                \"bool\": [True] * N,\n                \"int\": np.random.randint(0, N, size=N),\n                \"datetime\": date_range(\"2000-01-01\", periods=N, freq=\"s\"),\n            },\n            index=tm.makeStringIndex(N),\n        )\n        self.df.iloc[1000:3000, 1] = np.nan\n        self.df[\"date\"] = self.df[\"datetime\"].dt.date\n        self.df[\"time\"] = self.df[\"datetime\"].dt.time\n        self.df[\"datetime_string\"] = self.df[\"datetime\"].astype(str)\n        self.df.to_sql(self.table_name, self.con, if_exists=\"replace\")", "min_run_count": 2, "name": "io.sql.SQL.time_read_sql_query", "number": 0, "param_names": ["connection"], "params": [["'sqlalchemy'", "'sqlite'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "6372a262183066242b5579b87e68a407c85bccbfeb8ff6f9cb674c399cfa4b88", "warmup_time": -1}, "io.sql.SQL.time_to_sql_dataframe": {"code": "class SQL:\n    def time_to_sql_dataframe(self, connection):\n        self.df.to_sql(\"test1\", self.con, if_exists=\"replace\")\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass SQL:\n    def setup(self, connection):\n        N = 10000\n        con = {\n            \"sqlalchemy\": create_engine(\"sqlite:///:memory:\"),\n            \"sqlite\": sqlite3.connect(\":memory:\"),\n        }\n        self.table_name = \"test_type\"\n        self.query_all = f\"SELECT * FROM {self.table_name}\"\n        self.con = con[connection]\n        self.df = DataFrame(\n            {\n                \"float\": np.random.randn(N),\n                \"float_with_nan\": np.random.randn(N),\n                \"string\": [\"foo\"] * N,\n                \"bool\": [True] * N,\n                \"int\": np.random.randint(0, N, size=N),\n                \"datetime\": date_range(\"2000-01-01\", periods=N, freq=\"s\"),\n            },\n            index=tm.makeStringIndex(N),\n        )\n        self.df.iloc[1000:3000, 1] = np.nan\n        self.df[\"date\"] = self.df[\"datetime\"].dt.date\n        self.df[\"time\"] = self.df[\"datetime\"].dt.time\n        self.df[\"datetime_string\"] = self.df[\"datetime\"].astype(str)\n        self.df.to_sql(self.table_name, self.con, if_exists=\"replace\")", "min_run_count": 2, "name": "io.sql.SQL.time_to_sql_dataframe", "number": 0, "param_names": ["connection"], "params": [["'sqlalchemy'", "'sqlite'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "60f73f8a2055ab95c0f2a266bdc662e8d36aa57ae691f83a86c2af7b1398a770", "warmup_time": -1}, "io.sql.WriteSQLDtypes.time_read_sql_query_select_column": {"code": "class WriteSQLDtypes:\n    def time_read_sql_query_select_column(self, connection, dtype):\n        read_sql_query(self.query_col, self.con)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass WriteSQLDtypes:\n    def setup(self, connection, dtype):\n        N = 10000\n        con = {\n            \"sqlalchemy\": create_engine(\"sqlite:///:memory:\"),\n            \"sqlite\": sqlite3.connect(\":memory:\"),\n        }\n        self.table_name = \"test_type\"\n        self.query_col = f\"SELECT {dtype} FROM {self.table_name}\"\n        self.con = con[connection]\n        self.df = DataFrame(\n            {\n                \"float\": np.random.randn(N),\n                \"float_with_nan\": np.random.randn(N),\n                \"string\": [\"foo\"] * N,\n                \"bool\": [True] * N,\n                \"int\": np.random.randint(0, N, size=N),\n                \"datetime\": date_range(\"2000-01-01\", periods=N, freq=\"s\"),\n            },\n            index=tm.makeStringIndex(N),\n        )\n        self.df.iloc[1000:3000, 1] = np.nan\n        self.df[\"date\"] = self.df[\"datetime\"].dt.date\n        self.df[\"time\"] = self.df[\"datetime\"].dt.time\n        self.df[\"datetime_string\"] = self.df[\"datetime\"].astype(str)\n        self.df.to_sql(self.table_name, self.con, if_exists=\"replace\")", "min_run_count": 2, "name": "io.sql.WriteSQLDtypes.time_read_sql_query_select_column", "number": 0, "param_names": ["connection", "dtype"], "params": [["'sqlalchemy'", "'sqlite'"], ["'float'", "'float_with_nan'", "'string'", "'bool'", "'int'", "'date'", "'time'", "'datetime'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "3aa8b04f58b2f23465a72a0e53528272808ca8726c691d7f0c9b4f42c8988e85", "warmup_time": -1}, "io.sql.WriteSQLDtypes.time_to_sql_dataframe_column": {"code": "class WriteSQLDtypes:\n    def time_to_sql_dataframe_column(self, connection, dtype):\n        self.df[[dtype]].to_sql(\"test1\", self.con, if_exists=\"replace\")\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass WriteSQLDtypes:\n    def setup(self, connection, dtype):\n        N = 10000\n        con = {\n            \"sqlalchemy\": create_engine(\"sqlite:///:memory:\"),\n            \"sqlite\": sqlite3.connect(\":memory:\"),\n        }\n        self.table_name = \"test_type\"\n        self.query_col = f\"SELECT {dtype} FROM {self.table_name}\"\n        self.con = con[connection]\n        self.df = DataFrame(\n            {\n                \"float\": np.random.randn(N),\n                \"float_with_nan\": np.random.randn(N),\n                \"string\": [\"foo\"] * N,\n                \"bool\": [True] * N,\n                \"int\": np.random.randint(0, N, size=N),\n                \"datetime\": date_range(\"2000-01-01\", periods=N, freq=\"s\"),\n            },\n            index=tm.makeStringIndex(N),\n        )\n        self.df.iloc[1000:3000, 1] = np.nan\n        self.df[\"date\"] = self.df[\"datetime\"].dt.date\n        self.df[\"time\"] = self.df[\"datetime\"].dt.time\n        self.df[\"datetime_string\"] = self.df[\"datetime\"].astype(str)\n        self.df.to_sql(self.table_name, self.con, if_exists=\"replace\")", "min_run_count": 2, "name": "io.sql.WriteSQLDtypes.time_to_sql_dataframe_column", "number": 0, "param_names": ["connection", "dtype"], "params": [["'sqlalchemy'", "'sqlite'"], ["'float'", "'float_with_nan'", "'string'", "'bool'", "'int'", "'date'", "'time'", "'datetime'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "ad79b557afe9e4b464f54ca23be23064cf36a9b35f50c7aa4c0eeb5fdb19e784", "warmup_time": -1}, "io.stata.Stata.time_read_stata": {"code": "class Stata:\n    def time_read_stata(self, convert_dates):\n        read_stata(self.fname)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Stata:\n    def setup(self, convert_dates):\n        self.fname = \"__test__.dta\"\n        N = self.N = 100000\n        C = self.C = 5\n        self.df = DataFrame(\n            np.random.randn(N, C),\n            columns=[f\"float{i}\" for i in range(C)],\n            index=date_range(\"20000101\", periods=N, freq=\"H\"),\n        )\n        self.df[\"object\"] = tm.makeStringIndex(self.N)\n        self.df[\"int8_\"] = np.random.randint(\n            np.iinfo(np.int8).min, np.iinfo(np.int8).max - 27, N\n        )\n        self.df[\"int16_\"] = np.random.randint(\n            np.iinfo(np.int16).min, np.iinfo(np.int16).max - 27, N\n        )\n        self.df[\"int32_\"] = np.random.randint(\n            np.iinfo(np.int32).min, np.iinfo(np.int32).max - 27, N\n        )\n        self.df[\"float32_\"] = np.array(np.random.randn(N), dtype=np.float32)\n        self.convert_dates = {\"index\": convert_dates}\n        self.df.to_stata(self.fname, convert_dates=self.convert_dates)", "min_run_count": 2, "name": "io.stata.Stata.time_read_stata", "number": 0, "param_names": ["convert_dates"], "params": [["'tc'", "'td'", "'tm'", "'tw'", "'th'", "'tq'", "'ty'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "4bfe77d00e1f80b9da0b816ddcda21071df17caf1b9948c0f69971c12f875a35", "warmup_time": -1}, "io.stata.Stata.time_write_stata": {"code": "class Stata:\n    def time_write_stata(self, convert_dates):\n        self.df.to_stata(self.fname, convert_dates=self.convert_dates)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Stata:\n    def setup(self, convert_dates):\n        self.fname = \"__test__.dta\"\n        N = self.N = 100000\n        C = self.C = 5\n        self.df = DataFrame(\n            np.random.randn(N, C),\n            columns=[f\"float{i}\" for i in range(C)],\n            index=date_range(\"20000101\", periods=N, freq=\"H\"),\n        )\n        self.df[\"object\"] = tm.makeStringIndex(self.N)\n        self.df[\"int8_\"] = np.random.randint(\n            np.iinfo(np.int8).min, np.iinfo(np.int8).max - 27, N\n        )\n        self.df[\"int16_\"] = np.random.randint(\n            np.iinfo(np.int16).min, np.iinfo(np.int16).max - 27, N\n        )\n        self.df[\"int32_\"] = np.random.randint(\n            np.iinfo(np.int32).min, np.iinfo(np.int32).max - 27, N\n        )\n        self.df[\"float32_\"] = np.array(np.random.randn(N), dtype=np.float32)\n        self.convert_dates = {\"index\": convert_dates}\n        self.df.to_stata(self.fname, convert_dates=self.convert_dates)", "min_run_count": 2, "name": "io.stata.Stata.time_write_stata", "number": 0, "param_names": ["convert_dates"], "params": [["'tc'", "'td'", "'tm'", "'tw'", "'th'", "'tq'", "'ty'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "e79920413b66692a6f6243d14b2782107b0f84bf85712d2eb0123eecb5133aca", "warmup_time": -1}, "io.stata.StataMissing.time_read_stata": {"code": "class Stata:\n    def time_read_stata(self, convert_dates):\n        read_stata(self.fname)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass StataMissing:\n    def setup(self, convert_dates):\n        super().setup(convert_dates)\n        for i in range(10):\n            missing_data = np.random.randn(self.N)\n            missing_data[missing_data < 0] = np.nan\n            self.df[f\"missing_{i}\"] = missing_data\n        self.df.to_stata(self.fname, convert_dates=self.convert_dates)", "min_run_count": 2, "name": "io.stata.StataMissing.time_read_stata", "number": 0, "param_names": ["convert_dates"], "params": [["'tc'", "'td'", "'tm'", "'tw'", "'th'", "'tq'", "'ty'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "b28404f018d5ce3e6f6e9f4f573bfc333203130ac26b6ad0a55ab363d4091d56", "warmup_time": -1}, "io.stata.StataMissing.time_write_stata": {"code": "class Stata:\n    def time_write_stata(self, convert_dates):\n        self.df.to_stata(self.fname, convert_dates=self.convert_dates)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass StataMissing:\n    def setup(self, convert_dates):\n        super().setup(convert_dates)\n        for i in range(10):\n            missing_data = np.random.randn(self.N)\n            missing_data[missing_data < 0] = np.nan\n            self.df[f\"missing_{i}\"] = missing_data\n        self.df.to_stata(self.fname, convert_dates=self.convert_dates)", "min_run_count": 2, "name": "io.stata.StataMissing.time_write_stata", "number": 0, "param_names": ["convert_dates"], "params": [["'tc'", "'td'", "'tm'", "'tw'", "'th'", "'tq'", "'ty'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "12dd8e544d5d5dc0ff5c73373ffa7a2338cc235fc3829df79060f21c721b21c1", "warmup_time": -1}, "io.style.Render.peakmem_apply_format_hide_render": {"code": "class Render:\n    def peakmem_apply_format_hide_render(self, cols, rows):\n        self._style_apply_format_hide()\n        self.st._render_html(True, True)\n\n    def setup(self, cols, rows):\n        self.df = DataFrame(\n            np.random.randn(rows, cols),\n            columns=[f\"float_{i+1}\" for i in range(cols)],\n            index=[f\"row_{i+1}\" for i in range(rows)],\n        )", "name": "io.style.Render.peakmem_apply_format_hide_render", "param_names": ["cols", "rows"], "params": [["12", "24", "36"], ["12", "120"]], "timeout": 60.0, "type": "peakmemory", "unit": "bytes", "version": "24efee29e9f4259b3dc32b50ebebd07120a2cc59672b5f07aaf694b3350ffc33"}, "io.style.Render.peakmem_apply_render": {"code": "class Render:\n    def peakmem_apply_render(self, cols, rows):\n        self._style_apply()\n        self.st._render_html(True, True)\n\n    def setup(self, cols, rows):\n        self.df = DataFrame(\n            np.random.randn(rows, cols),\n            columns=[f\"float_{i+1}\" for i in range(cols)],\n            index=[f\"row_{i+1}\" for i in range(rows)],\n        )", "name": "io.style.Render.peakmem_apply_render", "param_names": ["cols", "rows"], "params": [["12", "24", "36"], ["12", "120"]], "timeout": 60.0, "type": "peakmemory", "unit": "bytes", "version": "f1291d9b0cee2ed29164614c2827a58907e0943d031efe0a1f700dd7bb3ea1ef"}, "io.style.Render.peakmem_classes_render": {"code": "class Render:\n    def peakmem_classes_render(self, cols, rows):\n        self._style_classes()\n        self.st._render_html(True, True)\n\n    def setup(self, cols, rows):\n        self.df = DataFrame(\n            np.random.randn(rows, cols),\n            columns=[f\"float_{i+1}\" for i in range(cols)],\n            index=[f\"row_{i+1}\" for i in range(rows)],\n        )", "name": "io.style.Render.peakmem_classes_render", "param_names": ["cols", "rows"], "params": [["12", "24", "36"], ["12", "120"]], "timeout": 60.0, "type": "peakmemory", "unit": "bytes", "version": "1d74d0ee63b8ddbcb67f37a2c6260ebe84c54ec1d2650db12d284630efa672c9"}, "io.style.Render.peakmem_format_render": {"code": "class Render:\n    def peakmem_format_render(self, cols, rows):\n        self._style_format()\n        self.st._render_html(True, True)\n\n    def setup(self, cols, rows):\n        self.df = DataFrame(\n            np.random.randn(rows, cols),\n            columns=[f\"float_{i+1}\" for i in range(cols)],\n            index=[f\"row_{i+1}\" for i in range(rows)],\n        )", "name": "io.style.Render.peakmem_format_render", "param_names": ["cols", "rows"], "params": [["12", "24", "36"], ["12", "120"]], "timeout": 60.0, "type": "peakmemory", "unit": "bytes", "version": "2d2ae2b598964ca4ec2ce6befed05ff0ed2c8833539c314cbc42c2a006d9abcf"}, "io.style.Render.peakmem_tooltips_render": {"code": "class Render:\n    def peakmem_tooltips_render(self, cols, rows):\n        self._style_tooltips()\n        self.st._render_html(True, True)\n\n    def setup(self, cols, rows):\n        self.df = DataFrame(\n            np.random.randn(rows, cols),\n            columns=[f\"float_{i+1}\" for i in range(cols)],\n            index=[f\"row_{i+1}\" for i in range(rows)],\n        )", "name": "io.style.Render.peakmem_tooltips_render", "param_names": ["cols", "rows"], "params": [["12", "24", "36"], ["12", "120"]], "timeout": 60.0, "type": "peakmemory", "unit": "bytes", "version": "f3165d89bad8a5256ce768ec97faaca1dc322cc15dfc6cce5c8f629872c4b625"}, "io.style.Render.time_apply_format_hide_render": {"code": "class Render:\n    def time_apply_format_hide_render(self, cols, rows):\n        self._style_apply_format_hide()\n        self.st._render_html(True, True)\n\n    def setup(self, cols, rows):\n        self.df = DataFrame(\n            np.random.randn(rows, cols),\n            columns=[f\"float_{i+1}\" for i in range(cols)],\n            index=[f\"row_{i+1}\" for i in range(rows)],\n        )", "min_run_count": 2, "name": "io.style.Render.time_apply_format_hide_render", "number": 0, "param_names": ["cols", "rows"], "params": [["12", "24", "36"], ["12", "120"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "4624b648242dbd72367816b07786b7bb20dec67fcf4d8b269046640a281b891b", "warmup_time": -1}, "io.style.Render.time_apply_render": {"code": "class Render:\n    def time_apply_render(self, cols, rows):\n        self._style_apply()\n        self.st._render_html(True, True)\n\n    def setup(self, cols, rows):\n        self.df = DataFrame(\n            np.random.randn(rows, cols),\n            columns=[f\"float_{i+1}\" for i in range(cols)],\n            index=[f\"row_{i+1}\" for i in range(rows)],\n        )", "min_run_count": 2, "name": "io.style.Render.time_apply_render", "number": 0, "param_names": ["cols", "rows"], "params": [["12", "24", "36"], ["12", "120"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "b7713a928f5b63249a63e44399f6d18a893bff35ae8541e666af0885aec0a166", "warmup_time": -1}, "io.style.Render.time_classes_render": {"code": "class Render:\n    def time_classes_render(self, cols, rows):\n        self._style_classes()\n        self.st._render_html(True, True)\n\n    def setup(self, cols, rows):\n        self.df = DataFrame(\n            np.random.randn(rows, cols),\n            columns=[f\"float_{i+1}\" for i in range(cols)],\n            index=[f\"row_{i+1}\" for i in range(rows)],\n        )", "min_run_count": 2, "name": "io.style.Render.time_classes_render", "number": 0, "param_names": ["cols", "rows"], "params": [["12", "24", "36"], ["12", "120"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "e385c7e77a27a0e29b3941e7cf3c0727f5f83d8b6279cd9500e63fb1f630d7d5", "warmup_time": -1}, "io.style.Render.time_format_render": {"code": "class Render:\n    def time_format_render(self, cols, rows):\n        self._style_format()\n        self.st._render_html(True, True)\n\n    def setup(self, cols, rows):\n        self.df = DataFrame(\n            np.random.randn(rows, cols),\n            columns=[f\"float_{i+1}\" for i in range(cols)],\n            index=[f\"row_{i+1}\" for i in range(rows)],\n        )", "min_run_count": 2, "name": "io.style.Render.time_format_render", "number": 0, "param_names": ["cols", "rows"], "params": [["12", "24", "36"], ["12", "120"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "2fe7b97954d549aadb2eb134d3d09b8c1334a640488b36869090ed4c430365ed", "warmup_time": -1}, "io.style.Render.time_tooltips_render": {"code": "class Render:\n    def time_tooltips_render(self, cols, rows):\n        self._style_tooltips()\n        self.st._render_html(True, True)\n\n    def setup(self, cols, rows):\n        self.df = DataFrame(\n            np.random.randn(rows, cols),\n            columns=[f\"float_{i+1}\" for i in range(cols)],\n            index=[f\"row_{i+1}\" for i in range(rows)],\n        )", "min_run_count": 2, "name": "io.style.Render.time_tooltips_render", "number": 0, "param_names": ["cols", "rows"], "params": [["12", "24", "36"], ["12", "120"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "bf6a27f9959b331a6f71cda4f842f4ceb8df92624979f2a522fe57cc98a5e34d", "warmup_time": -1}, "join_merge.Align.time_series_align_int64_index": {"code": "class Align:\n    def time_series_align_int64_index(self):\n        self.ts1 + self.ts2\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Align:\n    def setup(self):\n        size = 5 * 10**5\n        rng = np.arange(0, 10**13, 10**7)\n        stamps = np.datetime64(\"now\").view(\"i8\") + rng\n        idx1 = np.sort(np.random.choice(stamps, size, replace=False))\n        idx2 = np.sort(np.random.choice(stamps, size, replace=False))\n        self.ts1 = Series(np.random.randn(size), idx1)\n        self.ts2 = Series(np.random.randn(size), idx2)", "min_run_count": 2, "name": "join_merge.Align.time_series_align_int64_index", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "59ba8b3aa681ebdec8f5b793e2c2d9f7edd0cc1306163877b74d2788ac7102c0", "warmup_time": -1}, "join_merge.Align.time_series_align_left_monotonic": {"code": "class Align:\n    def time_series_align_left_monotonic(self):\n        self.ts1.align(self.ts2, join=\"left\")\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Align:\n    def setup(self):\n        size = 5 * 10**5\n        rng = np.arange(0, 10**13, 10**7)\n        stamps = np.datetime64(\"now\").view(\"i8\") + rng\n        idx1 = np.sort(np.random.choice(stamps, size, replace=False))\n        idx2 = np.sort(np.random.choice(stamps, size, replace=False))\n        self.ts1 = Series(np.random.randn(size), idx1)\n        self.ts2 = Series(np.random.randn(size), idx2)", "min_run_count": 2, "name": "join_merge.Align.time_series_align_left_monotonic", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "1c381483982c07fac3b6c437f2f740ae055cad4035d9a2bdf325a4acfe440e76", "warmup_time": -1}, "join_merge.Concat.time_concat_empty_left": {"code": "class Concat:\n    def time_concat_empty_left(self, axis):\n        concat(self.empty_left, axis=axis)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Concat:\n    def setup(self, axis):\n        N = 1000\n        s = Series(N, index=tm.makeStringIndex(N))\n        self.series = [s[i:-i] for i in range(1, 10)] * 50\n        self.small_frames = [DataFrame(np.random.randn(5, 4))] * 1000\n        df = DataFrame(\n            {\"A\": range(N)}, index=date_range(\"20130101\", periods=N, freq=\"s\")\n        )\n        self.empty_left = [DataFrame(), df]\n        self.empty_right = [df, DataFrame()]\n        self.mixed_ndims = [df, df.head(N // 2)]", "min_run_count": 2, "name": "join_merge.Concat.time_concat_empty_left", "number": 0, "param_names": ["axis"], "params": [["0", "1"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "771951eead3fb1607414b81e64c6c4f545f98d91587d9aa690f2c16527848107", "warmup_time": -1}, "join_merge.Concat.time_concat_empty_right": {"code": "class Concat:\n    def time_concat_empty_right(self, axis):\n        concat(self.empty_right, axis=axis)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Concat:\n    def setup(self, axis):\n        N = 1000\n        s = Series(N, index=tm.makeStringIndex(N))\n        self.series = [s[i:-i] for i in range(1, 10)] * 50\n        self.small_frames = [DataFrame(np.random.randn(5, 4))] * 1000\n        df = DataFrame(\n            {\"A\": range(N)}, index=date_range(\"20130101\", periods=N, freq=\"s\")\n        )\n        self.empty_left = [DataFrame(), df]\n        self.empty_right = [df, DataFrame()]\n        self.mixed_ndims = [df, df.head(N // 2)]", "min_run_count": 2, "name": "join_merge.Concat.time_concat_empty_right", "number": 0, "param_names": ["axis"], "params": [["0", "1"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "cf76d8a470d6bd253ad17cebe44463f95276cb7ffd53aff671a6cf14d7347a46", "warmup_time": -1}, "join_merge.Concat.time_concat_mixed_ndims": {"code": "class Concat:\n    def time_concat_mixed_ndims(self, axis):\n        concat(self.mixed_ndims, axis=axis)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Concat:\n    def setup(self, axis):\n        N = 1000\n        s = Series(N, index=tm.makeStringIndex(N))\n        self.series = [s[i:-i] for i in range(1, 10)] * 50\n        self.small_frames = [DataFrame(np.random.randn(5, 4))] * 1000\n        df = DataFrame(\n            {\"A\": range(N)}, index=date_range(\"20130101\", periods=N, freq=\"s\")\n        )\n        self.empty_left = [DataFrame(), df]\n        self.empty_right = [df, DataFrame()]\n        self.mixed_ndims = [df, df.head(N // 2)]", "min_run_count": 2, "name": "join_merge.Concat.time_concat_mixed_ndims", "number": 0, "param_names": ["axis"], "params": [["0", "1"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "17be1136e0e93d3aef782ad81cbe89cf034bcd3f6813fb941787d9e15078c5ff", "warmup_time": -1}, "join_merge.Concat.time_concat_series": {"code": "class Concat:\n    def time_concat_series(self, axis):\n        concat(self.series, axis=axis, sort=False)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Concat:\n    def setup(self, axis):\n        N = 1000\n        s = Series(N, index=tm.makeStringIndex(N))\n        self.series = [s[i:-i] for i in range(1, 10)] * 50\n        self.small_frames = [DataFrame(np.random.randn(5, 4))] * 1000\n        df = DataFrame(\n            {\"A\": range(N)}, index=date_range(\"20130101\", periods=N, freq=\"s\")\n        )\n        self.empty_left = [DataFrame(), df]\n        self.empty_right = [df, DataFrame()]\n        self.mixed_ndims = [df, df.head(N // 2)]", "min_run_count": 2, "name": "join_merge.Concat.time_concat_series", "number": 0, "param_names": ["axis"], "params": [["0", "1"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "8f0c73be876789117e57f2f232e4b74816d6eae4cb9dd656640e8e739bcebf0f", "warmup_time": -1}, "join_merge.Concat.time_concat_small_frames": {"code": "class Concat:\n    def time_concat_small_frames(self, axis):\n        concat(self.small_frames, axis=axis)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Concat:\n    def setup(self, axis):\n        N = 1000\n        s = Series(N, index=tm.makeStringIndex(N))\n        self.series = [s[i:-i] for i in range(1, 10)] * 50\n        self.small_frames = [DataFrame(np.random.randn(5, 4))] * 1000\n        df = DataFrame(\n            {\"A\": range(N)}, index=date_range(\"20130101\", periods=N, freq=\"s\")\n        )\n        self.empty_left = [DataFrame(), df]\n        self.empty_right = [df, DataFrame()]\n        self.mixed_ndims = [df, df.head(N // 2)]", "min_run_count": 2, "name": "join_merge.Concat.time_concat_small_frames", "number": 0, "param_names": ["axis"], "params": [["0", "1"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "d449c480b723a83ee34e5dae91211f19d62bbe8beb54d6cbcd7dafe417a710b2", "warmup_time": -1}, "join_merge.ConcatDataFrames.time_c_ordered": {"code": "class ConcatDataFrames:\n    def time_c_ordered(self, axis, ignore_index):\n        concat(self.frame_c, axis=axis, ignore_index=ignore_index)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ConcatDataFrames:\n    def setup(self, axis, ignore_index):\n        frame_c = DataFrame(np.zeros((10000, 200), dtype=np.float32, order=\"C\"))\n        self.frame_c = [frame_c] * 20\n        frame_f = DataFrame(np.zeros((10000, 200), dtype=np.float32, order=\"F\"))\n        self.frame_f = [frame_f] * 20", "min_run_count": 2, "name": "join_merge.ConcatDataFrames.time_c_ordered", "number": 0, "param_names": ["axis", "ignore_index"], "params": [["0", "1"], ["True", "False"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "a747cecacb0f57e2d282f77dbc9ba6108bb55d137dcb4cdef4d0cb94bd2ef909", "warmup_time": -1}, "join_merge.ConcatDataFrames.time_f_ordered": {"code": "class ConcatDataFrames:\n    def time_f_ordered(self, axis, ignore_index):\n        concat(self.frame_f, axis=axis, ignore_index=ignore_index)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ConcatDataFrames:\n    def setup(self, axis, ignore_index):\n        frame_c = DataFrame(np.zeros((10000, 200), dtype=np.float32, order=\"C\"))\n        self.frame_c = [frame_c] * 20\n        frame_f = DataFrame(np.zeros((10000, 200), dtype=np.float32, order=\"F\"))\n        self.frame_f = [frame_f] * 20", "min_run_count": 2, "name": "join_merge.ConcatDataFrames.time_f_ordered", "number": 0, "param_names": ["axis", "ignore_index"], "params": [["0", "1"], ["True", "False"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "4ae3b6dda3a99cfd094de14c2550530e69a1ede87ff9911c02706ef1acf501eb", "warmup_time": -1}, "join_merge.ConcatIndexDtype.time_concat_series": {"code": "class ConcatIndexDtype:\n    def time_concat_series(self, dtype, structure, axis, sort):\n        concat(self.series, axis=axis, sort=sort)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ConcatIndexDtype:\n    def setup(self, dtype, structure, axis, sort):\n        N = 10_000\n        if dtype == \"datetime64[ns]\":\n            vals = date_range(\"1970-01-01\", periods=N)\n        elif dtype in (\"int64\", \"Int64\"):\n            vals = np.arange(N, dtype=np.int64)\n        elif dtype in (\"string[python]\", \"string[pyarrow]\"):\n            vals = tm.makeStringIndex(N)\n        else:\n            raise NotImplementedError\n    \n        idx = Index(vals, dtype=dtype)\n    \n        if structure == \"monotonic\":\n            idx = idx.sort_values()\n        elif structure == \"non_monotonic\":\n            idx = idx[::-1]\n        elif structure == \"has_na\":\n            if not idx._can_hold_na:\n                raise NotImplementedError\n            idx = Index([None], dtype=dtype).append(idx)\n        else:\n            raise NotImplementedError\n    \n        self.series = [Series(i, idx[:-i]) for i in range(1, 6)]", "min_run_count": 2, "name": "join_merge.ConcatIndexDtype.time_concat_series", "number": 0, "param_names": ["dtype", "structure", "axis", "sort"], "params": [["'datetime64[ns]'", "'int64'", "'Int64'", "'string[python]'", "'string[pyarrow]'"], ["'monotonic'", "'non_monotonic'", "'has_na'"], ["0", "1"], ["True", "False"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "2763139dff79b99cba985e6440707fc62ab869101f46aa0aa1799ccd41786214", "warmup_time": -1}, "join_merge.I8Merge.time_i8merge": {"code": "class I8Merge:\n    def time_i8merge(self, how):\n        merge(self.left, self.right, how=how)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass I8Merge:\n    def setup(self, how):\n        low, high, n = -1000, 1000, 10**6\n        self.left = DataFrame(\n            np.random.randint(low, high, (n, 7)), columns=list(\"ABCDEFG\")\n        )\n        self.left[\"left\"] = self.left.sum(axis=1)\n        self.right = self.left.sample(frac=1).rename({\"left\": \"right\"}, axis=1)\n        self.right = self.right.reset_index(drop=True)\n        self.right[\"right\"] *= -1", "min_run_count": 2, "name": "join_merge.I8Merge.time_i8merge", "number": 0, "param_names": ["how"], "params": [["'inner'", "'outer'", "'left'", "'right'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "d4abb49d5f599a151d5e78dad2990f16fe5bf60710912a404da24856006a297a", "warmup_time": -1}, "join_merge.Join.time_join_dataframe_index_multi": {"code": "class Join:\n    def time_join_dataframe_index_multi(self, sort):\n        self.df.join(self.df_multi, on=[\"key1\", \"key2\"], sort=sort)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Join:\n    def setup(self, sort):\n        level1 = tm.makeStringIndex(10).values\n        level2 = tm.makeStringIndex(1000).values\n        codes1 = np.arange(10).repeat(1000)\n        codes2 = np.tile(np.arange(1000), 10)\n        index2 = MultiIndex(levels=[level1, level2], codes=[codes1, codes2])\n        self.df_multi = DataFrame(\n            np.random.randn(len(index2), 4), index=index2, columns=[\"A\", \"B\", \"C\", \"D\"]\n        )\n    \n        self.key1 = np.tile(level1.take(codes1), 10)\n        self.key2 = np.tile(level2.take(codes2), 10)\n        self.df = DataFrame(\n            {\n                \"data1\": np.random.randn(100000),\n                \"data2\": np.random.randn(100000),\n                \"key1\": self.key1,\n                \"key2\": self.key2,\n            }\n        )\n    \n        self.df_key1 = DataFrame(\n            np.random.randn(len(level1), 4), index=level1, columns=[\"A\", \"B\", \"C\", \"D\"]\n        )\n        self.df_key2 = DataFrame(\n            np.random.randn(len(level2), 4), index=level2, columns=[\"A\", \"B\", \"C\", \"D\"]\n        )\n    \n        shuf = np.arange(100000)\n        np.random.shuffle(shuf)\n        self.df_shuf = self.df.reindex(self.df.index[shuf])", "min_run_count": 2, "name": "join_merge.Join.time_join_dataframe_index_multi", "number": 0, "param_names": ["sort"], "params": [["True", "False"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "04d60570ed4f205d4a485419cd0a4631cdc89807af8a7314d9cf5972a451de31", "warmup_time": -1}, "join_merge.Join.time_join_dataframe_index_shuffle_key_bigger_sort": {"code": "class Join:\n    def time_join_dataframe_index_shuffle_key_bigger_sort(self, sort):\n        self.df_shuf.join(self.df_key2, on=\"key2\", sort=sort)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Join:\n    def setup(self, sort):\n        level1 = tm.makeStringIndex(10).values\n        level2 = tm.makeStringIndex(1000).values\n        codes1 = np.arange(10).repeat(1000)\n        codes2 = np.tile(np.arange(1000), 10)\n        index2 = MultiIndex(levels=[level1, level2], codes=[codes1, codes2])\n        self.df_multi = DataFrame(\n            np.random.randn(len(index2), 4), index=index2, columns=[\"A\", \"B\", \"C\", \"D\"]\n        )\n    \n        self.key1 = np.tile(level1.take(codes1), 10)\n        self.key2 = np.tile(level2.take(codes2), 10)\n        self.df = DataFrame(\n            {\n                \"data1\": np.random.randn(100000),\n                \"data2\": np.random.randn(100000),\n                \"key1\": self.key1,\n                \"key2\": self.key2,\n            }\n        )\n    \n        self.df_key1 = DataFrame(\n            np.random.randn(len(level1), 4), index=level1, columns=[\"A\", \"B\", \"C\", \"D\"]\n        )\n        self.df_key2 = DataFrame(\n            np.random.randn(len(level2), 4), index=level2, columns=[\"A\", \"B\", \"C\", \"D\"]\n        )\n    \n        shuf = np.arange(100000)\n        np.random.shuffle(shuf)\n        self.df_shuf = self.df.reindex(self.df.index[shuf])", "min_run_count": 2, "name": "join_merge.Join.time_join_dataframe_index_shuffle_key_bigger_sort", "number": 0, "param_names": ["sort"], "params": [["True", "False"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "fdd6e003a0b8d50ed40a79334a136c2088017b024563f7e53d502e74b1904909", "warmup_time": -1}, "join_merge.Join.time_join_dataframe_index_single_key_bigger": {"code": "class Join:\n    def time_join_dataframe_index_single_key_bigger(self, sort):\n        self.df.join(self.df_key2, on=\"key2\", sort=sort)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Join:\n    def setup(self, sort):\n        level1 = tm.makeStringIndex(10).values\n        level2 = tm.makeStringIndex(1000).values\n        codes1 = np.arange(10).repeat(1000)\n        codes2 = np.tile(np.arange(1000), 10)\n        index2 = MultiIndex(levels=[level1, level2], codes=[codes1, codes2])\n        self.df_multi = DataFrame(\n            np.random.randn(len(index2), 4), index=index2, columns=[\"A\", \"B\", \"C\", \"D\"]\n        )\n    \n        self.key1 = np.tile(level1.take(codes1), 10)\n        self.key2 = np.tile(level2.take(codes2), 10)\n        self.df = DataFrame(\n            {\n                \"data1\": np.random.randn(100000),\n                \"data2\": np.random.randn(100000),\n                \"key1\": self.key1,\n                \"key2\": self.key2,\n            }\n        )\n    \n        self.df_key1 = DataFrame(\n            np.random.randn(len(level1), 4), index=level1, columns=[\"A\", \"B\", \"C\", \"D\"]\n        )\n        self.df_key2 = DataFrame(\n            np.random.randn(len(level2), 4), index=level2, columns=[\"A\", \"B\", \"C\", \"D\"]\n        )\n    \n        shuf = np.arange(100000)\n        np.random.shuffle(shuf)\n        self.df_shuf = self.df.reindex(self.df.index[shuf])", "min_run_count": 2, "name": "join_merge.Join.time_join_dataframe_index_single_key_bigger", "number": 0, "param_names": ["sort"], "params": [["True", "False"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "a24325ee21efd415bc66a6cb7038a38be9952023beec11e90f057dd95353625a", "warmup_time": -1}, "join_merge.Join.time_join_dataframe_index_single_key_small": {"code": "class Join:\n    def time_join_dataframe_index_single_key_small(self, sort):\n        self.df.join(self.df_key1, on=\"key1\", sort=sort)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Join:\n    def setup(self, sort):\n        level1 = tm.makeStringIndex(10).values\n        level2 = tm.makeStringIndex(1000).values\n        codes1 = np.arange(10).repeat(1000)\n        codes2 = np.tile(np.arange(1000), 10)\n        index2 = MultiIndex(levels=[level1, level2], codes=[codes1, codes2])\n        self.df_multi = DataFrame(\n            np.random.randn(len(index2), 4), index=index2, columns=[\"A\", \"B\", \"C\", \"D\"]\n        )\n    \n        self.key1 = np.tile(level1.take(codes1), 10)\n        self.key2 = np.tile(level2.take(codes2), 10)\n        self.df = DataFrame(\n            {\n                \"data1\": np.random.randn(100000),\n                \"data2\": np.random.randn(100000),\n                \"key1\": self.key1,\n                \"key2\": self.key2,\n            }\n        )\n    \n        self.df_key1 = DataFrame(\n            np.random.randn(len(level1), 4), index=level1, columns=[\"A\", \"B\", \"C\", \"D\"]\n        )\n        self.df_key2 = DataFrame(\n            np.random.randn(len(level2), 4), index=level2, columns=[\"A\", \"B\", \"C\", \"D\"]\n        )\n    \n        shuf = np.arange(100000)\n        np.random.shuffle(shuf)\n        self.df_shuf = self.df.reindex(self.df.index[shuf])", "min_run_count": 2, "name": "join_merge.Join.time_join_dataframe_index_single_key_small", "number": 0, "param_names": ["sort"], "params": [["True", "False"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "c7baaed1de356a5b88295125fa91b5842f03ca0a46dcdb4760be8099aa133e05", "warmup_time": -1}, "join_merge.Join.time_join_dataframes_cross": {"code": "class Join:\n    def time_join_dataframes_cross(self, sort):\n        self.df.loc[:2000].join(self.df_key1, how=\"cross\", sort=sort)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Join:\n    def setup(self, sort):\n        level1 = tm.makeStringIndex(10).values\n        level2 = tm.makeStringIndex(1000).values\n        codes1 = np.arange(10).repeat(1000)\n        codes2 = np.tile(np.arange(1000), 10)\n        index2 = MultiIndex(levels=[level1, level2], codes=[codes1, codes2])\n        self.df_multi = DataFrame(\n            np.random.randn(len(index2), 4), index=index2, columns=[\"A\", \"B\", \"C\", \"D\"]\n        )\n    \n        self.key1 = np.tile(level1.take(codes1), 10)\n        self.key2 = np.tile(level2.take(codes2), 10)\n        self.df = DataFrame(\n            {\n                \"data1\": np.random.randn(100000),\n                \"data2\": np.random.randn(100000),\n                \"key1\": self.key1,\n                \"key2\": self.key2,\n            }\n        )\n    \n        self.df_key1 = DataFrame(\n            np.random.randn(len(level1), 4), index=level1, columns=[\"A\", \"B\", \"C\", \"D\"]\n        )\n        self.df_key2 = DataFrame(\n            np.random.randn(len(level2), 4), index=level2, columns=[\"A\", \"B\", \"C\", \"D\"]\n        )\n    \n        shuf = np.arange(100000)\n        np.random.shuffle(shuf)\n        self.df_shuf = self.df.reindex(self.df.index[shuf])", "min_run_count": 2, "name": "join_merge.Join.time_join_dataframes_cross", "number": 0, "param_names": ["sort"], "params": [["True", "False"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "8d164a39efe7f9060207ec93194fdf100dc393428439ef0b3994a5b46877adf2", "warmup_time": -1}, "join_merge.JoinEmpty.time_inner_join_left_empty": {"code": "class JoinEmpty:\n    def time_inner_join_left_empty(self):\n        self.df_empty.join(self.df, how=\"inner\")\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass JoinEmpty:\n    def setup(self):\n        N = 100_000\n        self.df = DataFrame({\"A\": np.arange(N)})\n        self.df_empty = DataFrame(columns=[\"B\", \"C\"], dtype=\"int64\")", "min_run_count": 2, "name": "join_merge.JoinEmpty.time_inner_join_left_empty", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "bfdd1b4564785774724d06a1078e1417803a55bc67f678a1cdd417a1aedc2f04", "warmup_time": -1}, "join_merge.JoinEmpty.time_inner_join_right_empty": {"code": "class JoinEmpty:\n    def time_inner_join_right_empty(self):\n        self.df.join(self.df_empty, how=\"inner\")\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass JoinEmpty:\n    def setup(self):\n        N = 100_000\n        self.df = DataFrame({\"A\": np.arange(N)})\n        self.df_empty = DataFrame(columns=[\"B\", \"C\"], dtype=\"int64\")", "min_run_count": 2, "name": "join_merge.JoinEmpty.time_inner_join_right_empty", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "dcfe17741af364f20337e68e1210e4775f3da625571f7a163b7a94dd7ba6ab00", "warmup_time": -1}, "join_merge.JoinIndex.time_left_outer_join_index": {"code": "class JoinIndex:\n    def time_left_outer_join_index(self):\n        self.left.join(self.right, on=\"jim\")\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass JoinIndex:\n    def setup(self):\n        N = 50000\n        self.left = DataFrame(\n            np.random.randint(1, N / 500, (N, 2)), columns=[\"jim\", \"joe\"]\n        )\n        self.right = DataFrame(\n            np.random.randint(1, N / 500, (N, 2)), columns=[\"jolie\", \"jolia\"]\n        ).set_index(\"jolie\")", "min_run_count": 2, "name": "join_merge.JoinIndex.time_left_outer_join_index", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "234696a7a1b723cc8541c1bd6f5ffa740dcdd0c9e3a7dbf3305179c84f0fad1a", "warmup_time": -1}, "join_merge.JoinMultiindexSubset.time_join_multiindex_subset": {"code": "class JoinMultiindexSubset:\n    def time_join_multiindex_subset(self):\n        self.left.join(self.right)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass JoinMultiindexSubset:\n    def setup(self):\n        N = 100_000\n        mi1 = MultiIndex.from_arrays([np.arange(N)] * 4, names=[\"a\", \"b\", \"c\", \"d\"])\n        mi2 = MultiIndex.from_arrays([np.arange(N)] * 2, names=[\"a\", \"b\"])\n        self.left = DataFrame({\"col1\": 1}, index=mi1)\n        self.right = DataFrame({\"col2\": 2}, index=mi2)", "min_run_count": 2, "name": "join_merge.JoinMultiindexSubset.time_join_multiindex_subset", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "27bf46b67e61ae20d7d34733a62c67fd8dd46b37dcd0a578e046d57b6c6a5751", "warmup_time": -1}, "join_merge.JoinNonUnique.time_join_non_unique_equal": {"code": "class JoinNonUnique:\n    def time_join_non_unique_equal(self):\n        self.fracofday * self.temp\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass JoinNonUnique:\n    def setup(self):\n        date_index = date_range(\"01-Jan-2013\", \"23-Jan-2013\", freq=\"T\")\n        daily_dates = date_index.to_period(\"D\").to_timestamp(\"S\", \"S\")\n        self.fracofday = date_index.values - daily_dates.values\n        self.fracofday = self.fracofday.astype(\"timedelta64[ns]\")\n        self.fracofday = self.fracofday.astype(np.float64) / 86_400_000_000_000\n        self.fracofday = Series(self.fracofday, daily_dates)\n        index = date_range(date_index.min(), date_index.max(), freq=\"D\")\n        self.temp = Series(1.0, index)[self.fracofday.index]", "min_run_count": 2, "name": "join_merge.JoinNonUnique.time_join_non_unique_equal", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "da02c75be43afdad1e753b0332fc63ac84ee37c47b12fb2595401365d7989cdf", "warmup_time": -1}, "join_merge.Merge.time_merge_2intkey": {"code": "class Merge:\n    def time_merge_2intkey(self, sort):\n        merge(self.left, self.right, sort=sort)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Merge:\n    def setup(self, sort):\n        N = 10000\n        indices = tm.makeStringIndex(N).values\n        indices2 = tm.makeStringIndex(N).values\n        key = np.tile(indices[:8000], 10)\n        key2 = np.tile(indices2[:8000], 10)\n        self.left = DataFrame(\n            {\"key\": key, \"key2\": key2, \"value\": np.random.randn(80000)}\n        )\n        self.right = DataFrame(\n            {\n                \"key\": indices[2000:],\n                \"key2\": indices2[2000:],\n                \"value2\": np.random.randn(8000),\n            }\n        )\n    \n        self.df = DataFrame(\n            {\n                \"key1\": np.tile(np.arange(500).repeat(10), 2),\n                \"key2\": np.tile(np.arange(250).repeat(10), 4),\n                \"value\": np.random.randn(10000),\n            }\n        )\n        self.df2 = DataFrame({\"key1\": np.arange(500), \"value2\": np.random.randn(500)})\n        self.df3 = self.df[:5000]", "min_run_count": 2, "name": "join_merge.Merge.time_merge_2intkey", "number": 0, "param_names": ["sort"], "params": [["True", "False"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "d018a32e48407380b39c62527e1de18b8ebfc5721b5302df50c3145d74b0f246", "warmup_time": -1}, "join_merge.Merge.time_merge_dataframe_empty_left": {"code": "class Merge:\n    def time_merge_dataframe_empty_left(self, sort):\n        merge(self.left.iloc[:0], self.right, sort=sort)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Merge:\n    def setup(self, sort):\n        N = 10000\n        indices = tm.makeStringIndex(N).values\n        indices2 = tm.makeStringIndex(N).values\n        key = np.tile(indices[:8000], 10)\n        key2 = np.tile(indices2[:8000], 10)\n        self.left = DataFrame(\n            {\"key\": key, \"key2\": key2, \"value\": np.random.randn(80000)}\n        )\n        self.right = DataFrame(\n            {\n                \"key\": indices[2000:],\n                \"key2\": indices2[2000:],\n                \"value2\": np.random.randn(8000),\n            }\n        )\n    \n        self.df = DataFrame(\n            {\n                \"key1\": np.tile(np.arange(500).repeat(10), 2),\n                \"key2\": np.tile(np.arange(250).repeat(10), 4),\n                \"value\": np.random.randn(10000),\n            }\n        )\n        self.df2 = DataFrame({\"key1\": np.arange(500), \"value2\": np.random.randn(500)})\n        self.df3 = self.df[:5000]", "min_run_count": 2, "name": "join_merge.Merge.time_merge_dataframe_empty_left", "number": 0, "param_names": ["sort"], "params": [["True", "False"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "48a242f170786592ed98db0e88b1db0ca086e79ded88d4553490cbb7efe9010f", "warmup_time": -1}, "join_merge.Merge.time_merge_dataframe_empty_right": {"code": "class Merge:\n    def time_merge_dataframe_empty_right(self, sort):\n        merge(self.left, self.right.iloc[:0], sort=sort)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Merge:\n    def setup(self, sort):\n        N = 10000\n        indices = tm.makeStringIndex(N).values\n        indices2 = tm.makeStringIndex(N).values\n        key = np.tile(indices[:8000], 10)\n        key2 = np.tile(indices2[:8000], 10)\n        self.left = DataFrame(\n            {\"key\": key, \"key2\": key2, \"value\": np.random.randn(80000)}\n        )\n        self.right = DataFrame(\n            {\n                \"key\": indices[2000:],\n                \"key2\": indices2[2000:],\n                \"value2\": np.random.randn(8000),\n            }\n        )\n    \n        self.df = DataFrame(\n            {\n                \"key1\": np.tile(np.arange(500).repeat(10), 2),\n                \"key2\": np.tile(np.arange(250).repeat(10), 4),\n                \"value\": np.random.randn(10000),\n            }\n        )\n        self.df2 = DataFrame({\"key1\": np.arange(500), \"value2\": np.random.randn(500)})\n        self.df3 = self.df[:5000]", "min_run_count": 2, "name": "join_merge.Merge.time_merge_dataframe_empty_right", "number": 0, "param_names": ["sort"], "params": [["True", "False"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "9cce0a9dc4235950fee6478302c3d210536ab55767b00395ff2238f5e13059bc", "warmup_time": -1}, "join_merge.Merge.time_merge_dataframe_integer_2key": {"code": "class Merge:\n    def time_merge_dataframe_integer_2key(self, sort):\n        merge(self.df, self.df3, sort=sort)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Merge:\n    def setup(self, sort):\n        N = 10000\n        indices = tm.makeStringIndex(N).values\n        indices2 = tm.makeStringIndex(N).values\n        key = np.tile(indices[:8000], 10)\n        key2 = np.tile(indices2[:8000], 10)\n        self.left = DataFrame(\n            {\"key\": key, \"key2\": key2, \"value\": np.random.randn(80000)}\n        )\n        self.right = DataFrame(\n            {\n                \"key\": indices[2000:],\n                \"key2\": indices2[2000:],\n                \"value2\": np.random.randn(8000),\n            }\n        )\n    \n        self.df = DataFrame(\n            {\n                \"key1\": np.tile(np.arange(500).repeat(10), 2),\n                \"key2\": np.tile(np.arange(250).repeat(10), 4),\n                \"value\": np.random.randn(10000),\n            }\n        )\n        self.df2 = DataFrame({\"key1\": np.arange(500), \"value2\": np.random.randn(500)})\n        self.df3 = self.df[:5000]", "min_run_count": 2, "name": "join_merge.Merge.time_merge_dataframe_integer_2key", "number": 0, "param_names": ["sort"], "params": [["True", "False"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "39d8692590ca9746a4f331094fcb81476adb504db6f9ee3e982c9616a8eec137", "warmup_time": -1}, "join_merge.Merge.time_merge_dataframe_integer_key": {"code": "class Merge:\n    def time_merge_dataframe_integer_key(self, sort):\n        merge(self.df, self.df2, on=\"key1\", sort=sort)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Merge:\n    def setup(self, sort):\n        N = 10000\n        indices = tm.makeStringIndex(N).values\n        indices2 = tm.makeStringIndex(N).values\n        key = np.tile(indices[:8000], 10)\n        key2 = np.tile(indices2[:8000], 10)\n        self.left = DataFrame(\n            {\"key\": key, \"key2\": key2, \"value\": np.random.randn(80000)}\n        )\n        self.right = DataFrame(\n            {\n                \"key\": indices[2000:],\n                \"key2\": indices2[2000:],\n                \"value2\": np.random.randn(8000),\n            }\n        )\n    \n        self.df = DataFrame(\n            {\n                \"key1\": np.tile(np.arange(500).repeat(10), 2),\n                \"key2\": np.tile(np.arange(250).repeat(10), 4),\n                \"value\": np.random.randn(10000),\n            }\n        )\n        self.df2 = DataFrame({\"key1\": np.arange(500), \"value2\": np.random.randn(500)})\n        self.df3 = self.df[:5000]", "min_run_count": 2, "name": "join_merge.Merge.time_merge_dataframe_integer_key", "number": 0, "param_names": ["sort"], "params": [["True", "False"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "92f383156ff8ad9c40e0c435dbf32a3c5a448df755cd8312c922858f4ddb0cb2", "warmup_time": -1}, "join_merge.Merge.time_merge_dataframes_cross": {"code": "class Merge:\n    def time_merge_dataframes_cross(self, sort):\n        merge(self.left.loc[:2000], self.right.loc[:2000], how=\"cross\", sort=sort)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Merge:\n    def setup(self, sort):\n        N = 10000\n        indices = tm.makeStringIndex(N).values\n        indices2 = tm.makeStringIndex(N).values\n        key = np.tile(indices[:8000], 10)\n        key2 = np.tile(indices2[:8000], 10)\n        self.left = DataFrame(\n            {\"key\": key, \"key2\": key2, \"value\": np.random.randn(80000)}\n        )\n        self.right = DataFrame(\n            {\n                \"key\": indices[2000:],\n                \"key2\": indices2[2000:],\n                \"value2\": np.random.randn(8000),\n            }\n        )\n    \n        self.df = DataFrame(\n            {\n                \"key1\": np.tile(np.arange(500).repeat(10), 2),\n                \"key2\": np.tile(np.arange(250).repeat(10), 4),\n                \"value\": np.random.randn(10000),\n            }\n        )\n        self.df2 = DataFrame({\"key1\": np.arange(500), \"value2\": np.random.randn(500)})\n        self.df3 = self.df[:5000]", "min_run_count": 2, "name": "join_merge.Merge.time_merge_dataframes_cross", "number": 0, "param_names": ["sort"], "params": [["True", "False"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "6b9f6476e14b77f687462e3381bf77e3d1248656a9201faf8bf92a80e887c962", "warmup_time": -1}, "join_merge.MergeAsof.time_by_int": {"code": "class MergeAsof:\n    def time_by_int(self, direction, tolerance):\n        merge_asof(\n            self.df1c,\n            self.df2c,\n            on=\"time\",\n            by=\"key2\",\n            direction=direction,\n            tolerance=tolerance,\n        )\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass MergeAsof:\n    def setup(self, direction, tolerance):\n        one_count = 200000\n        two_count = 1000000\n    \n        df1 = DataFrame(\n            {\n                \"time\": np.random.randint(0, one_count / 20, one_count),\n                \"key\": np.random.choice(list(string.ascii_uppercase), one_count),\n                \"key2\": np.random.randint(0, 25, one_count),\n                \"value1\": np.random.randn(one_count),\n            }\n        )\n        df2 = DataFrame(\n            {\n                \"time\": np.random.randint(0, two_count / 20, two_count),\n                \"key\": np.random.choice(list(string.ascii_uppercase), two_count),\n                \"key2\": np.random.randint(0, 25, two_count),\n                \"value2\": np.random.randn(two_count),\n            }\n        )\n    \n        df1 = df1.sort_values(\"time\")\n        df2 = df2.sort_values(\"time\")\n    \n        df1[\"time32\"] = np.int32(df1.time)\n        df2[\"time32\"] = np.int32(df2.time)\n    \n        df1[\"timeu64\"] = np.uint64(df1.time)\n        df2[\"timeu64\"] = np.uint64(df2.time)\n    \n        self.df1a = df1[[\"time\", \"value1\"]]\n        self.df2a = df2[[\"time\", \"value2\"]]\n        self.df1b = df1[[\"time\", \"key\", \"value1\"]]\n        self.df2b = df2[[\"time\", \"key\", \"value2\"]]\n        self.df1c = df1[[\"time\", \"key2\", \"value1\"]]\n        self.df2c = df2[[\"time\", \"key2\", \"value2\"]]\n        self.df1d = df1[[\"time32\", \"value1\"]]\n        self.df2d = df2[[\"time32\", \"value2\"]]\n        self.df1e = df1[[\"time\", \"key\", \"key2\", \"value1\"]]\n        self.df2e = df2[[\"time\", \"key\", \"key2\", \"value2\"]]\n        self.df1f = df1[[\"timeu64\", \"value1\"]]\n        self.df2f = df2[[\"timeu64\", \"value2\"]]", "min_run_count": 2, "name": "join_merge.MergeAsof.time_by_int", "number": 0, "param_names": ["direction", "tolerance"], "params": [["'backward'", "'forward'", "'nearest'"], ["None", "5"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "9388814b37a8f7c3e8196e0e5e974f1114e5d09931e00ac3f102f86743babca9", "warmup_time": -1}, "join_merge.MergeAsof.time_by_object": {"code": "class MergeAsof:\n    def time_by_object(self, direction, tolerance):\n        merge_asof(\n            self.df1b,\n            self.df2b,\n            on=\"time\",\n            by=\"key\",\n            direction=direction,\n            tolerance=tolerance,\n        )\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass MergeAsof:\n    def setup(self, direction, tolerance):\n        one_count = 200000\n        two_count = 1000000\n    \n        df1 = DataFrame(\n            {\n                \"time\": np.random.randint(0, one_count / 20, one_count),\n                \"key\": np.random.choice(list(string.ascii_uppercase), one_count),\n                \"key2\": np.random.randint(0, 25, one_count),\n                \"value1\": np.random.randn(one_count),\n            }\n        )\n        df2 = DataFrame(\n            {\n                \"time\": np.random.randint(0, two_count / 20, two_count),\n                \"key\": np.random.choice(list(string.ascii_uppercase), two_count),\n                \"key2\": np.random.randint(0, 25, two_count),\n                \"value2\": np.random.randn(two_count),\n            }\n        )\n    \n        df1 = df1.sort_values(\"time\")\n        df2 = df2.sort_values(\"time\")\n    \n        df1[\"time32\"] = np.int32(df1.time)\n        df2[\"time32\"] = np.int32(df2.time)\n    \n        df1[\"timeu64\"] = np.uint64(df1.time)\n        df2[\"timeu64\"] = np.uint64(df2.time)\n    \n        self.df1a = df1[[\"time\", \"value1\"]]\n        self.df2a = df2[[\"time\", \"value2\"]]\n        self.df1b = df1[[\"time\", \"key\", \"value1\"]]\n        self.df2b = df2[[\"time\", \"key\", \"value2\"]]\n        self.df1c = df1[[\"time\", \"key2\", \"value1\"]]\n        self.df2c = df2[[\"time\", \"key2\", \"value2\"]]\n        self.df1d = df1[[\"time32\", \"value1\"]]\n        self.df2d = df2[[\"time32\", \"value2\"]]\n        self.df1e = df1[[\"time\", \"key\", \"key2\", \"value1\"]]\n        self.df2e = df2[[\"time\", \"key\", \"key2\", \"value2\"]]\n        self.df1f = df1[[\"timeu64\", \"value1\"]]\n        self.df2f = df2[[\"timeu64\", \"value2\"]]", "min_run_count": 2, "name": "join_merge.MergeAsof.time_by_object", "number": 0, "param_names": ["direction", "tolerance"], "params": [["'backward'", "'forward'", "'nearest'"], ["None", "5"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "164ee691bc50a6d10e4f62c99daae4dce68786d7b02f5bd35af7bf33191d0405", "warmup_time": -1}, "join_merge.MergeAsof.time_multiby": {"code": "class MergeAsof:\n    def time_multiby(self, direction, tolerance):\n        merge_asof(\n            self.df1e,\n            self.df2e,\n            on=\"time\",\n            by=[\"key\", \"key2\"],\n            direction=direction,\n            tolerance=tolerance,\n        )\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass MergeAsof:\n    def setup(self, direction, tolerance):\n        one_count = 200000\n        two_count = 1000000\n    \n        df1 = DataFrame(\n            {\n                \"time\": np.random.randint(0, one_count / 20, one_count),\n                \"key\": np.random.choice(list(string.ascii_uppercase), one_count),\n                \"key2\": np.random.randint(0, 25, one_count),\n                \"value1\": np.random.randn(one_count),\n            }\n        )\n        df2 = DataFrame(\n            {\n                \"time\": np.random.randint(0, two_count / 20, two_count),\n                \"key\": np.random.choice(list(string.ascii_uppercase), two_count),\n                \"key2\": np.random.randint(0, 25, two_count),\n                \"value2\": np.random.randn(two_count),\n            }\n        )\n    \n        df1 = df1.sort_values(\"time\")\n        df2 = df2.sort_values(\"time\")\n    \n        df1[\"time32\"] = np.int32(df1.time)\n        df2[\"time32\"] = np.int32(df2.time)\n    \n        df1[\"timeu64\"] = np.uint64(df1.time)\n        df2[\"timeu64\"] = np.uint64(df2.time)\n    \n        self.df1a = df1[[\"time\", \"value1\"]]\n        self.df2a = df2[[\"time\", \"value2\"]]\n        self.df1b = df1[[\"time\", \"key\", \"value1\"]]\n        self.df2b = df2[[\"time\", \"key\", \"value2\"]]\n        self.df1c = df1[[\"time\", \"key2\", \"value1\"]]\n        self.df2c = df2[[\"time\", \"key2\", \"value2\"]]\n        self.df1d = df1[[\"time32\", \"value1\"]]\n        self.df2d = df2[[\"time32\", \"value2\"]]\n        self.df1e = df1[[\"time\", \"key\", \"key2\", \"value1\"]]\n        self.df2e = df2[[\"time\", \"key\", \"key2\", \"value2\"]]\n        self.df1f = df1[[\"timeu64\", \"value1\"]]\n        self.df2f = df2[[\"timeu64\", \"value2\"]]", "min_run_count": 2, "name": "join_merge.MergeAsof.time_multiby", "number": 0, "param_names": ["direction", "tolerance"], "params": [["'backward'", "'forward'", "'nearest'"], ["None", "5"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "464ed78df4c5a78bcd7350edc12851af5dd87d18c63ed889b0ee80e806eed6a1", "warmup_time": -1}, "join_merge.MergeAsof.time_on_int": {"code": "class MergeAsof:\n    def time_on_int(self, direction, tolerance):\n        merge_asof(\n            self.df1a, self.df2a, on=\"time\", direction=direction, tolerance=tolerance\n        )\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass MergeAsof:\n    def setup(self, direction, tolerance):\n        one_count = 200000\n        two_count = 1000000\n    \n        df1 = DataFrame(\n            {\n                \"time\": np.random.randint(0, one_count / 20, one_count),\n                \"key\": np.random.choice(list(string.ascii_uppercase), one_count),\n                \"key2\": np.random.randint(0, 25, one_count),\n                \"value1\": np.random.randn(one_count),\n            }\n        )\n        df2 = DataFrame(\n            {\n                \"time\": np.random.randint(0, two_count / 20, two_count),\n                \"key\": np.random.choice(list(string.ascii_uppercase), two_count),\n                \"key2\": np.random.randint(0, 25, two_count),\n                \"value2\": np.random.randn(two_count),\n            }\n        )\n    \n        df1 = df1.sort_values(\"time\")\n        df2 = df2.sort_values(\"time\")\n    \n        df1[\"time32\"] = np.int32(df1.time)\n        df2[\"time32\"] = np.int32(df2.time)\n    \n        df1[\"timeu64\"] = np.uint64(df1.time)\n        df2[\"timeu64\"] = np.uint64(df2.time)\n    \n        self.df1a = df1[[\"time\", \"value1\"]]\n        self.df2a = df2[[\"time\", \"value2\"]]\n        self.df1b = df1[[\"time\", \"key\", \"value1\"]]\n        self.df2b = df2[[\"time\", \"key\", \"value2\"]]\n        self.df1c = df1[[\"time\", \"key2\", \"value1\"]]\n        self.df2c = df2[[\"time\", \"key2\", \"value2\"]]\n        self.df1d = df1[[\"time32\", \"value1\"]]\n        self.df2d = df2[[\"time32\", \"value2\"]]\n        self.df1e = df1[[\"time\", \"key\", \"key2\", \"value1\"]]\n        self.df2e = df2[[\"time\", \"key\", \"key2\", \"value2\"]]\n        self.df1f = df1[[\"timeu64\", \"value1\"]]\n        self.df2f = df2[[\"timeu64\", \"value2\"]]", "min_run_count": 2, "name": "join_merge.MergeAsof.time_on_int", "number": 0, "param_names": ["direction", "tolerance"], "params": [["'backward'", "'forward'", "'nearest'"], ["None", "5"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "a0ba76e01b99515f8c84950f1a4683fb1e2b601110a25798072287f3d1574ca1", "warmup_time": -1}, "join_merge.MergeAsof.time_on_int32": {"code": "class MergeAsof:\n    def time_on_int32(self, direction, tolerance):\n        merge_asof(\n            self.df1d, self.df2d, on=\"time32\", direction=direction, tolerance=tolerance\n        )\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass MergeAsof:\n    def setup(self, direction, tolerance):\n        one_count = 200000\n        two_count = 1000000\n    \n        df1 = DataFrame(\n            {\n                \"time\": np.random.randint(0, one_count / 20, one_count),\n                \"key\": np.random.choice(list(string.ascii_uppercase), one_count),\n                \"key2\": np.random.randint(0, 25, one_count),\n                \"value1\": np.random.randn(one_count),\n            }\n        )\n        df2 = DataFrame(\n            {\n                \"time\": np.random.randint(0, two_count / 20, two_count),\n                \"key\": np.random.choice(list(string.ascii_uppercase), two_count),\n                \"key2\": np.random.randint(0, 25, two_count),\n                \"value2\": np.random.randn(two_count),\n            }\n        )\n    \n        df1 = df1.sort_values(\"time\")\n        df2 = df2.sort_values(\"time\")\n    \n        df1[\"time32\"] = np.int32(df1.time)\n        df2[\"time32\"] = np.int32(df2.time)\n    \n        df1[\"timeu64\"] = np.uint64(df1.time)\n        df2[\"timeu64\"] = np.uint64(df2.time)\n    \n        self.df1a = df1[[\"time\", \"value1\"]]\n        self.df2a = df2[[\"time\", \"value2\"]]\n        self.df1b = df1[[\"time\", \"key\", \"value1\"]]\n        self.df2b = df2[[\"time\", \"key\", \"value2\"]]\n        self.df1c = df1[[\"time\", \"key2\", \"value1\"]]\n        self.df2c = df2[[\"time\", \"key2\", \"value2\"]]\n        self.df1d = df1[[\"time32\", \"value1\"]]\n        self.df2d = df2[[\"time32\", \"value2\"]]\n        self.df1e = df1[[\"time\", \"key\", \"key2\", \"value1\"]]\n        self.df2e = df2[[\"time\", \"key\", \"key2\", \"value2\"]]\n        self.df1f = df1[[\"timeu64\", \"value1\"]]\n        self.df2f = df2[[\"timeu64\", \"value2\"]]", "min_run_count": 2, "name": "join_merge.MergeAsof.time_on_int32", "number": 0, "param_names": ["direction", "tolerance"], "params": [["'backward'", "'forward'", "'nearest'"], ["None", "5"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "5c26b3578593ec04d313f1cbf97df60936516fb7691a67ad03f78d68554fa57f", "warmup_time": -1}, "join_merge.MergeAsof.time_on_uint64": {"code": "class MergeAsof:\n    def time_on_uint64(self, direction, tolerance):\n        merge_asof(\n            self.df1f, self.df2f, on=\"timeu64\", direction=direction, tolerance=tolerance\n        )\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass MergeAsof:\n    def setup(self, direction, tolerance):\n        one_count = 200000\n        two_count = 1000000\n    \n        df1 = DataFrame(\n            {\n                \"time\": np.random.randint(0, one_count / 20, one_count),\n                \"key\": np.random.choice(list(string.ascii_uppercase), one_count),\n                \"key2\": np.random.randint(0, 25, one_count),\n                \"value1\": np.random.randn(one_count),\n            }\n        )\n        df2 = DataFrame(\n            {\n                \"time\": np.random.randint(0, two_count / 20, two_count),\n                \"key\": np.random.choice(list(string.ascii_uppercase), two_count),\n                \"key2\": np.random.randint(0, 25, two_count),\n                \"value2\": np.random.randn(two_count),\n            }\n        )\n    \n        df1 = df1.sort_values(\"time\")\n        df2 = df2.sort_values(\"time\")\n    \n        df1[\"time32\"] = np.int32(df1.time)\n        df2[\"time32\"] = np.int32(df2.time)\n    \n        df1[\"timeu64\"] = np.uint64(df1.time)\n        df2[\"timeu64\"] = np.uint64(df2.time)\n    \n        self.df1a = df1[[\"time\", \"value1\"]]\n        self.df2a = df2[[\"time\", \"value2\"]]\n        self.df1b = df1[[\"time\", \"key\", \"value1\"]]\n        self.df2b = df2[[\"time\", \"key\", \"value2\"]]\n        self.df1c = df1[[\"time\", \"key2\", \"value1\"]]\n        self.df2c = df2[[\"time\", \"key2\", \"value2\"]]\n        self.df1d = df1[[\"time32\", \"value1\"]]\n        self.df2d = df2[[\"time32\", \"value2\"]]\n        self.df1e = df1[[\"time\", \"key\", \"key2\", \"value1\"]]\n        self.df2e = df2[[\"time\", \"key\", \"key2\", \"value2\"]]\n        self.df1f = df1[[\"timeu64\", \"value1\"]]\n        self.df2f = df2[[\"timeu64\", \"value2\"]]", "min_run_count": 2, "name": "join_merge.MergeAsof.time_on_uint64", "number": 0, "param_names": ["direction", "tolerance"], "params": [["'backward'", "'forward'", "'nearest'"], ["None", "5"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "272c9034f60d2e7af35cd9d80009bb4f6d2ed987924efec03f83106e40c406be", "warmup_time": -1}, "join_merge.MergeCategoricals.time_merge_cat": {"code": "class MergeCategoricals:\n    def time_merge_cat(self):\n        merge(self.left_cat, self.right_cat, on=\"X\")\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass MergeCategoricals:\n    def setup(self):\n        self.left_object = DataFrame(\n            {\n                \"X\": np.random.choice(range(0, 10), size=(10000,)),\n                \"Y\": np.random.choice([\"one\", \"two\", \"three\"], size=(10000,)),\n            }\n        )\n    \n        self.right_object = DataFrame(\n            {\n                \"X\": np.random.choice(range(0, 10), size=(10000,)),\n                \"Z\": np.random.choice([\"jjj\", \"kkk\", \"sss\"], size=(10000,)),\n            }\n        )\n    \n        self.left_cat = self.left_object.assign(\n            Y=self.left_object[\"Y\"].astype(\"category\")\n        )\n        self.right_cat = self.right_object.assign(\n            Z=self.right_object[\"Z\"].astype(\"category\")\n        )\n    \n        self.left_cat_col = self.left_object.astype({\"X\": \"category\"})\n        self.right_cat_col = self.right_object.astype({\"X\": \"category\"})\n    \n        self.left_cat_idx = self.left_cat_col.set_index(\"X\")\n        self.right_cat_idx = self.right_cat_col.set_index(\"X\")", "min_run_count": 2, "name": "join_merge.MergeCategoricals.time_merge_cat", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "711443ac78f3e0da92e3dbb4fde0a17fe06574cdc6cd0aaa00beb11a09a1d2f3", "warmup_time": -1}, "join_merge.MergeCategoricals.time_merge_object": {"code": "class MergeCategoricals:\n    def time_merge_object(self):\n        merge(self.left_object, self.right_object, on=\"X\")\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass MergeCategoricals:\n    def setup(self):\n        self.left_object = DataFrame(\n            {\n                \"X\": np.random.choice(range(0, 10), size=(10000,)),\n                \"Y\": np.random.choice([\"one\", \"two\", \"three\"], size=(10000,)),\n            }\n        )\n    \n        self.right_object = DataFrame(\n            {\n                \"X\": np.random.choice(range(0, 10), size=(10000,)),\n                \"Z\": np.random.choice([\"jjj\", \"kkk\", \"sss\"], size=(10000,)),\n            }\n        )\n    \n        self.left_cat = self.left_object.assign(\n            Y=self.left_object[\"Y\"].astype(\"category\")\n        )\n        self.right_cat = self.right_object.assign(\n            Z=self.right_object[\"Z\"].astype(\"category\")\n        )\n    \n        self.left_cat_col = self.left_object.astype({\"X\": \"category\"})\n        self.right_cat_col = self.right_object.astype({\"X\": \"category\"})\n    \n        self.left_cat_idx = self.left_cat_col.set_index(\"X\")\n        self.right_cat_idx = self.right_cat_col.set_index(\"X\")", "min_run_count": 2, "name": "join_merge.MergeCategoricals.time_merge_object", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "2b253a88c16dec23e4a2951e978500d8e2a82fa6969933f3dc87105005b89b83", "warmup_time": -1}, "join_merge.MergeCategoricals.time_merge_on_cat_col": {"code": "class MergeCategoricals:\n    def time_merge_on_cat_col(self):\n        merge(self.left_cat_col, self.right_cat_col, on=\"X\")\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass MergeCategoricals:\n    def setup(self):\n        self.left_object = DataFrame(\n            {\n                \"X\": np.random.choice(range(0, 10), size=(10000,)),\n                \"Y\": np.random.choice([\"one\", \"two\", \"three\"], size=(10000,)),\n            }\n        )\n    \n        self.right_object = DataFrame(\n            {\n                \"X\": np.random.choice(range(0, 10), size=(10000,)),\n                \"Z\": np.random.choice([\"jjj\", \"kkk\", \"sss\"], size=(10000,)),\n            }\n        )\n    \n        self.left_cat = self.left_object.assign(\n            Y=self.left_object[\"Y\"].astype(\"category\")\n        )\n        self.right_cat = self.right_object.assign(\n            Z=self.right_object[\"Z\"].astype(\"category\")\n        )\n    \n        self.left_cat_col = self.left_object.astype({\"X\": \"category\"})\n        self.right_cat_col = self.right_object.astype({\"X\": \"category\"})\n    \n        self.left_cat_idx = self.left_cat_col.set_index(\"X\")\n        self.right_cat_idx = self.right_cat_col.set_index(\"X\")", "min_run_count": 2, "name": "join_merge.MergeCategoricals.time_merge_on_cat_col", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "2d2d7fdaa7f52db6b61176141c7274677ed263c1a828f7c98b9039c5c12034b5", "warmup_time": -1}, "join_merge.MergeCategoricals.time_merge_on_cat_idx": {"code": "class MergeCategoricals:\n    def time_merge_on_cat_idx(self):\n        merge(self.left_cat_idx, self.right_cat_idx, on=\"X\")\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass MergeCategoricals:\n    def setup(self):\n        self.left_object = DataFrame(\n            {\n                \"X\": np.random.choice(range(0, 10), size=(10000,)),\n                \"Y\": np.random.choice([\"one\", \"two\", \"three\"], size=(10000,)),\n            }\n        )\n    \n        self.right_object = DataFrame(\n            {\n                \"X\": np.random.choice(range(0, 10), size=(10000,)),\n                \"Z\": np.random.choice([\"jjj\", \"kkk\", \"sss\"], size=(10000,)),\n            }\n        )\n    \n        self.left_cat = self.left_object.assign(\n            Y=self.left_object[\"Y\"].astype(\"category\")\n        )\n        self.right_cat = self.right_object.assign(\n            Z=self.right_object[\"Z\"].astype(\"category\")\n        )\n    \n        self.left_cat_col = self.left_object.astype({\"X\": \"category\"})\n        self.right_cat_col = self.right_object.astype({\"X\": \"category\"})\n    \n        self.left_cat_idx = self.left_cat_col.set_index(\"X\")\n        self.right_cat_idx = self.right_cat_col.set_index(\"X\")", "min_run_count": 2, "name": "join_merge.MergeCategoricals.time_merge_on_cat_idx", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "d00e2efc22eee3113d2903548062c173519ccc6008a1f8d71af1914a223c5ae5", "warmup_time": -1}, "join_merge.MergeEA.time_merge": {"code": "class MergeEA:\n    def time_merge(self, dtype):\n        merge(self.left, self.right)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass MergeEA:\n    def setup(self, dtype):\n        N = 10_000\n        indices = np.arange(1, N)\n        key = np.tile(indices[:8000], 10)\n        self.left = DataFrame(\n            {\"key\": Series(key, dtype=dtype), \"value\": np.random.randn(80000)}\n        )\n        self.right = DataFrame(\n            {\n                \"key\": Series(indices[2000:], dtype=dtype),\n                \"value2\": np.random.randn(7999),\n            }\n        )", "min_run_count": 2, "name": "join_merge.MergeEA.time_merge", "number": 0, "param_names": ["dtype"], "params": [["'Int64'", "'Int32'", "'Int16'", "'UInt64'", "'UInt32'", "'UInt16'", "'Float64'", "'Float32'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "69437e83c98d632ad587ca5a55a302c079d47b8747daa15d3049500a0fe3811a", "warmup_time": -1}, "join_merge.MergeMultiIndex.time_merge_sorted_multiindex": {"code": "class MergeMultiIndex:\n    def time_merge_sorted_multiindex(self, dtypes, how):\n        # copy to avoid MultiIndex._values caching\n        df1 = self.df1.copy()\n        df2 = self.df2.copy()\n        merge(df1, df2, how=how, left_index=True, right_index=True)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass MergeMultiIndex:\n    def setup(self, dtypes, how):\n        n = 100_000\n        offset = 50_000\n        mi1 = MultiIndex.from_arrays(\n            [\n                array(np.arange(n), dtype=dtypes[0]),\n                array(np.arange(n), dtype=dtypes[1]),\n            ]\n        )\n        mi2 = MultiIndex.from_arrays(\n            [\n                array(np.arange(offset, n + offset), dtype=dtypes[0]),\n                array(np.arange(offset, n + offset), dtype=dtypes[1]),\n            ]\n        )\n        self.df1 = DataFrame({\"col1\": 1}, index=mi1)\n        self.df2 = DataFrame({\"col2\": 2}, index=mi2)", "min_run_count": 2, "name": "join_merge.MergeMultiIndex.time_merge_sorted_multiindex", "number": 0, "param_names": ["dtypes", "how"], "params": [["('int64', 'int64')", "('datetime64[ns]', 'int64')", "('Int64', 'Int64')"], ["'left'", "'right'", "'inner'", "'outer'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "87d6032a44f31143b8c18c1f04684f8a2aa12fbf908500d9bb17310283004aa3", "warmup_time": -1}, "join_merge.MergeOrdered.time_merge_ordered": {"code": "class MergeOrdered:\n    def time_merge_ordered(self):\n        merge_ordered(self.left, self.right, on=\"key\", left_by=\"group\")\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass MergeOrdered:\n    def setup(self):\n        groups = tm.makeStringIndex(10).values\n        self.left = DataFrame(\n            {\n                \"group\": groups.repeat(5000),\n                \"key\": np.tile(np.arange(0, 10000, 2), 10),\n                \"lvalue\": np.random.randn(50000),\n            }\n        )\n        self.right = DataFrame(\n            {\"key\": np.arange(10000), \"rvalue\": np.random.randn(10000)}\n        )", "min_run_count": 2, "name": "join_merge.MergeOrdered.time_merge_ordered", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "5112a00cde6581c94729aa5bf94cb97a7e4bbc7887d6cee6e2fd3ba7aaf8bf5e", "warmup_time": -1}, "libs.CacheReadonly.time_cache_readonly": {"code": "class CacheReadonly:\n    def time_cache_readonly(self):\n        self.obj.prop\n\n    def setup(self):\n        class Foo:\n            @cache_readonly\n            def prop(self):\n                return 5\n    \n        self.obj = Foo()", "min_run_count": 2, "name": "libs.CacheReadonly.time_cache_readonly", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "0c1cb69a185e93f75c8a4df1942cf6b4e0cf583d0eb2f7e80d1df4e75305b788", "warmup_time": -1}, "libs.FastZip.time_lib_fast_zip": {"code": "class FastZip:\n    def time_lib_fast_zip(self):\n        lib.fast_zip(self.col_array_list)\n\n    def setup(self):\n        N = 10000\n        K = 10\n        key1 = tm.makeStringIndex(N).values.repeat(K)\n        key2 = tm.makeStringIndex(N).values.repeat(K)\n        col_array = np.vstack([key1, key2, np.random.randn(N * K)])\n        col_array2 = col_array.copy()\n        col_array2[:, :10000] = np.nan\n        self.col_array_list = list(col_array)", "min_run_count": 2, "name": "libs.FastZip.time_lib_fast_zip", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "517a0b5f8fe63a2ad52291c0793f9bf201fbe1c44d21e698e04e880eaa98b0b4", "warmup_time": -1}, "libs.InferDtype.time_infer_dtype": {"code": "class InferDtype:\n    def time_infer_dtype(self, dtype):\n        infer_dtype(self.data_dict[dtype], skipna=False)", "min_run_count": 2, "name": "libs.InferDtype.time_infer_dtype", "number": 0, "param_names": ["dtype"], "params": [["'np-object'", "'py-object'", "'np-null'", "'py-null'", "'np-int'", "'np-floating'", "'empty'", "'bytes'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "125f86966c05a7552f7d61e8833a505c865982149242f645b314a569f9830a3e", "warmup_time": -1}, "libs.InferDtype.time_infer_dtype_skipna": {"code": "class InferDtype:\n    def time_infer_dtype_skipna(self, dtype):\n        infer_dtype(self.data_dict[dtype], skipna=True)", "min_run_count": 2, "name": "libs.InferDtype.time_infer_dtype_skipna", "number": 0, "param_names": ["dtype"], "params": [["'np-object'", "'py-object'", "'np-null'", "'py-null'", "'np-int'", "'np-floating'", "'empty'", "'bytes'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "92424cbc247a56269a3db019273c9b16434c61cd8f83fd7210ea2168ac4e31e0", "warmup_time": -1}, "libs.ScalarListLike.time_is_list_like": {"code": "class ScalarListLike:\n    def time_is_list_like(self, param):\n        is_list_like(param)", "min_run_count": 2, "name": "libs.ScalarListLike.time_is_list_like", "number": 0, "param_names": ["param1"], "params": [["0", "1.0", "(1+2j)", "True", "'foo'", "b'bar'", "None", "numpy.datetime64('1970-01-01T00:00:00.000000123')", "numpy.timedelta64(123,'ns')", "NaT", "<NA>", "array('123', dtype='<U3')", "array([1, 2, 3])", "{0: 1}", "{1, 2, 3}", "[1, 2, 3]", "(1, 2, 3)"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "f12c7f398bcc1c4a71e6dbe7b8aec6631a2565dd2a614a6f834dee7e64388bf8", "warmup_time": -1}, "libs.ScalarListLike.time_is_scalar": {"code": "class ScalarListLike:\n    def time_is_scalar(self, param):\n        is_scalar(param)", "min_run_count": 2, "name": "libs.ScalarListLike.time_is_scalar", "number": 0, "param_names": ["param1"], "params": [["0", "1.0", "(1+2j)", "True", "'foo'", "b'bar'", "None", "numpy.datetime64('1970-01-01T00:00:00.000000123')", "numpy.timedelta64(123,'ns')", "NaT", "<NA>", "array('123', dtype='<U3')", "array([1, 2, 3])", "{0: 1}", "{1, 2, 3}", "[1, 2, 3]", "(1, 2, 3)"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "ec357011e1e42690c47ad59e42ea37c1b167ef442f92e787301c3ef26d40a34d", "warmup_time": -1}, "multiindex_object.CategoricalLevel.time_categorical_level": {"code": "class CategoricalLevel:\n    def time_categorical_level(self):\n        self.df.set_index([\"a\", \"b\"])\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass CategoricalLevel:\n    def setup(self):\n        self.df = DataFrame(\n            {\n                \"a\": np.arange(1_000_000, dtype=np.int32),\n                \"b\": np.arange(1_000_000, dtype=np.int64),\n                \"c\": np.arange(1_000_000, dtype=float),\n            }\n        ).astype({\"a\": \"category\", \"b\": \"category\"})", "min_run_count": 2, "name": "multiindex_object.CategoricalLevel.time_categorical_level", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "95746db84674b4c2c4a999d967e65da698fe749fb6a989c5cfa92e4a34dfe20f", "warmup_time": -1}, "multiindex_object.Difference.time_difference": {"code": "class Difference:\n    def time_difference(self, dtype):\n        self.left.difference(self.right)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Difference:\n    def setup(self, dtype):\n        N = 10**4 * 2\n        level1 = range(1000)\n    \n        level2 = date_range(start=\"1/1/2000\", periods=N // 1000)\n        dates_left = MultiIndex.from_product([level1, level2])\n    \n        level2 = range(N // 1000)\n        int_left = MultiIndex.from_product([level1, level2])\n    \n        level2 = Series(range(N // 1000), dtype=\"Int64\")\n        level2[0] = NA\n        ea_int_left = MultiIndex.from_product([level1, level2])\n    \n        level2 = tm.makeStringIndex(N // 1000).values\n        str_left = MultiIndex.from_product([level1, level2])\n    \n        data = {\n            \"datetime\": dates_left,\n            \"int\": int_left,\n            \"ea_int\": ea_int_left,\n            \"string\": str_left,\n        }\n    \n        data = {k: {\"left\": mi, \"right\": mi[:5]} for k, mi in data.items()}\n        self.left = data[dtype][\"left\"]\n        self.right = data[dtype][\"right\"]", "min_run_count": 2, "name": "multiindex_object.Difference.time_difference", "number": 0, "param_names": ["dtype"], "params": [["'datetime'", "'int'", "'string'", "'ea_int'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "a0976faa44ac44f9827029268565360fbf4f90e719fe35fdd9b07bf727870e0d", "warmup_time": -1}, "multiindex_object.Duplicated.time_duplicated": {"code": "class Duplicated:\n    def time_duplicated(self):\n        self.mi.duplicated()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Duplicated:\n    def setup(self):\n        n, k = 200, 5000\n        levels = [np.arange(n), tm.makeStringIndex(n).values, 1000 + np.arange(n)]\n        codes = [np.random.choice(n, (k * n)) for lev in levels]\n        self.mi = MultiIndex(levels=levels, codes=codes)", "min_run_count": 2, "name": "multiindex_object.Duplicated.time_duplicated", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "dc96303f763f936d1ea9761a0820f81dfa38bff3c381e63bde16ef21be991fe9", "warmup_time": -1}, "multiindex_object.Duplicates.time_remove_unused_levels": {"code": "class Duplicates:\n    def time_remove_unused_levels(self):\n        self.mi_unused_levels.remove_unused_levels()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Duplicates:\n    def setup(self):\n        size = 65536\n        arrays = [np.random.randint(0, 8192, size), np.random.randint(0, 1024, size)]\n        mask = np.random.rand(size) < 0.1\n        self.mi_unused_levels = MultiIndex.from_arrays(arrays)\n        self.mi_unused_levels = self.mi_unused_levels[mask]", "min_run_count": 2, "name": "multiindex_object.Duplicates.time_remove_unused_levels", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "858a4d9728167fda18b01dd248d011becaf52569cc3789ebc23781748020a547", "warmup_time": -1}, "multiindex_object.Equals.time_equals_non_object_index": {"code": "class Equals:\n    def time_equals_non_object_index(self):\n        self.mi_large_slow.equals(self.idx_non_object)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Equals:\n    def setup(self):\n        idx_large_fast = RangeIndex(100000)\n        idx_small_slow = date_range(start=\"1/1/2012\", periods=1)\n        self.mi_large_slow = MultiIndex.from_product([idx_large_fast, idx_small_slow])\n    \n        self.idx_non_object = RangeIndex(1)", "min_run_count": 2, "name": "multiindex_object.Equals.time_equals_non_object_index", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "670ae29fa38e3f25c93a8fe7085dd856137ada08f63f625b17da442a35a357b8", "warmup_time": -1}, "multiindex_object.GetLoc.time_large_get_loc": {"code": "class GetLoc:\n    def time_large_get_loc(self):\n        self.mi_large.get_loc((999, 19, \"Z\"))\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass GetLoc:\n    def setup(self):\n        self.mi_large = MultiIndex.from_product(\n            [np.arange(1000), np.arange(20), list(string.ascii_letters)],\n            names=[\"one\", \"two\", \"three\"],\n        )\n        self.mi_med = MultiIndex.from_product(\n            [np.arange(1000), np.arange(10), list(\"A\")], names=[\"one\", \"two\", \"three\"]\n        )\n        self.mi_small = MultiIndex.from_product(\n            [np.arange(100), list(\"A\"), list(\"A\")], names=[\"one\", \"two\", \"three\"]\n        )", "min_run_count": 2, "name": "multiindex_object.GetLoc.time_large_get_loc", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "dd084286aabcc048d0407dfacebe59f29ed1f976d92d013a0a10f35ba2e96bdb", "warmup_time": -1}, "multiindex_object.GetLoc.time_large_get_loc_warm": {"code": "class GetLoc:\n    def time_large_get_loc_warm(self):\n        for _ in range(1000):\n            self.mi_large.get_loc((999, 19, \"Z\"))\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass GetLoc:\n    def setup(self):\n        self.mi_large = MultiIndex.from_product(\n            [np.arange(1000), np.arange(20), list(string.ascii_letters)],\n            names=[\"one\", \"two\", \"three\"],\n        )\n        self.mi_med = MultiIndex.from_product(\n            [np.arange(1000), np.arange(10), list(\"A\")], names=[\"one\", \"two\", \"three\"]\n        )\n        self.mi_small = MultiIndex.from_product(\n            [np.arange(100), list(\"A\"), list(\"A\")], names=[\"one\", \"two\", \"three\"]\n        )", "min_run_count": 2, "name": "multiindex_object.GetLoc.time_large_get_loc_warm", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "137653619e4d1b432e07d94aa7a9cf46441e320de449aa65f5129efc13888912", "warmup_time": -1}, "multiindex_object.GetLoc.time_med_get_loc": {"code": "class GetLoc:\n    def time_med_get_loc(self):\n        self.mi_med.get_loc((999, 9, \"A\"))\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass GetLoc:\n    def setup(self):\n        self.mi_large = MultiIndex.from_product(\n            [np.arange(1000), np.arange(20), list(string.ascii_letters)],\n            names=[\"one\", \"two\", \"three\"],\n        )\n        self.mi_med = MultiIndex.from_product(\n            [np.arange(1000), np.arange(10), list(\"A\")], names=[\"one\", \"two\", \"three\"]\n        )\n        self.mi_small = MultiIndex.from_product(\n            [np.arange(100), list(\"A\"), list(\"A\")], names=[\"one\", \"two\", \"three\"]\n        )", "min_run_count": 2, "name": "multiindex_object.GetLoc.time_med_get_loc", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "b783d9cb5dbdc6787a0879e0f8c0862c4014d5ea0611abb97c342d46f77826e1", "warmup_time": -1}, "multiindex_object.GetLoc.time_med_get_loc_warm": {"code": "class GetLoc:\n    def time_med_get_loc_warm(self):\n        for _ in range(1000):\n            self.mi_med.get_loc((999, 9, \"A\"))\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass GetLoc:\n    def setup(self):\n        self.mi_large = MultiIndex.from_product(\n            [np.arange(1000), np.arange(20), list(string.ascii_letters)],\n            names=[\"one\", \"two\", \"three\"],\n        )\n        self.mi_med = MultiIndex.from_product(\n            [np.arange(1000), np.arange(10), list(\"A\")], names=[\"one\", \"two\", \"three\"]\n        )\n        self.mi_small = MultiIndex.from_product(\n            [np.arange(100), list(\"A\"), list(\"A\")], names=[\"one\", \"two\", \"three\"]\n        )", "min_run_count": 2, "name": "multiindex_object.GetLoc.time_med_get_loc_warm", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "50ea4f6a67d9f88227e60e668996edef05b7564987506a1145e7b2c23a2ccb41", "warmup_time": -1}, "multiindex_object.GetLoc.time_small_get_loc_warm": {"code": "class GetLoc:\n    def time_small_get_loc_warm(self):\n        for _ in range(1000):\n            self.mi_small.get_loc((99, \"A\", \"A\"))\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass GetLoc:\n    def setup(self):\n        self.mi_large = MultiIndex.from_product(\n            [np.arange(1000), np.arange(20), list(string.ascii_letters)],\n            names=[\"one\", \"two\", \"three\"],\n        )\n        self.mi_med = MultiIndex.from_product(\n            [np.arange(1000), np.arange(10), list(\"A\")], names=[\"one\", \"two\", \"three\"]\n        )\n        self.mi_small = MultiIndex.from_product(\n            [np.arange(100), list(\"A\"), list(\"A\")], names=[\"one\", \"two\", \"three\"]\n        )", "min_run_count": 2, "name": "multiindex_object.GetLoc.time_small_get_loc_warm", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "fe1c2475d50cac160a619e2371fc123f6053a4346c2f4d01018f499d4cfec4e7", "warmup_time": -1}, "multiindex_object.GetLoc.time_string_get_loc": {"code": "class GetLoc:\n    def time_string_get_loc(self):\n        self.mi_small.get_loc((99, \"A\", \"A\"))\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass GetLoc:\n    def setup(self):\n        self.mi_large = MultiIndex.from_product(\n            [np.arange(1000), np.arange(20), list(string.ascii_letters)],\n            names=[\"one\", \"two\", \"three\"],\n        )\n        self.mi_med = MultiIndex.from_product(\n            [np.arange(1000), np.arange(10), list(\"A\")], names=[\"one\", \"two\", \"three\"]\n        )\n        self.mi_small = MultiIndex.from_product(\n            [np.arange(100), list(\"A\"), list(\"A\")], names=[\"one\", \"two\", \"three\"]\n        )", "min_run_count": 2, "name": "multiindex_object.GetLoc.time_string_get_loc", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "e96912b143865fa80131f906e8f63d1f3c40b3d142b8571de3b1b9615adf1801", "warmup_time": -1}, "multiindex_object.GetLocs.time_large_get_locs": {"code": "class GetLocs:\n    def time_large_get_locs(self):\n        self.mi_large.get_locs([999, 19, \"Z\"])\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass GetLocs:\n    def setup(self):\n        self.mi_large = MultiIndex.from_product(\n            [np.arange(1000), np.arange(20), list(string.ascii_letters)],\n            names=[\"one\", \"two\", \"three\"],\n        )\n        self.mi_med = MultiIndex.from_product(\n            [np.arange(1000), np.arange(10), list(\"A\")], names=[\"one\", \"two\", \"three\"]\n        )\n        self.mi_small = MultiIndex.from_product(\n            [np.arange(100), list(\"A\"), list(\"A\")], names=[\"one\", \"two\", \"three\"]\n        )", "min_run_count": 2, "name": "multiindex_object.GetLocs.time_large_get_locs", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "f6945fa307f8737f7231a2a44181eb523a78c225bc91dbcb18e3b75194dfc5bc", "warmup_time": -1}, "multiindex_object.GetLocs.time_med_get_locs": {"code": "class GetLocs:\n    def time_med_get_locs(self):\n        self.mi_med.get_locs([999, 9, \"A\"])\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass GetLocs:\n    def setup(self):\n        self.mi_large = MultiIndex.from_product(\n            [np.arange(1000), np.arange(20), list(string.ascii_letters)],\n            names=[\"one\", \"two\", \"three\"],\n        )\n        self.mi_med = MultiIndex.from_product(\n            [np.arange(1000), np.arange(10), list(\"A\")], names=[\"one\", \"two\", \"three\"]\n        )\n        self.mi_small = MultiIndex.from_product(\n            [np.arange(100), list(\"A\"), list(\"A\")], names=[\"one\", \"two\", \"three\"]\n        )", "min_run_count": 2, "name": "multiindex_object.GetLocs.time_med_get_locs", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "cf1640cb0f946d097ff83e7740951339843061148884ca31b8394c7abfa2c016", "warmup_time": -1}, "multiindex_object.GetLocs.time_small_get_locs": {"code": "class GetLocs:\n    def time_small_get_locs(self):\n        self.mi_small.get_locs([99, \"A\", \"A\"])\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass GetLocs:\n    def setup(self):\n        self.mi_large = MultiIndex.from_product(\n            [np.arange(1000), np.arange(20), list(string.ascii_letters)],\n            names=[\"one\", \"two\", \"three\"],\n        )\n        self.mi_med = MultiIndex.from_product(\n            [np.arange(1000), np.arange(10), list(\"A\")], names=[\"one\", \"two\", \"three\"]\n        )\n        self.mi_small = MultiIndex.from_product(\n            [np.arange(100), list(\"A\"), list(\"A\")], names=[\"one\", \"two\", \"three\"]\n        )", "min_run_count": 2, "name": "multiindex_object.GetLocs.time_small_get_locs", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "e20e0ac51b10b4dd999beefc7d99e3da94d32206cbb5cad3f13e2f9f110c765e", "warmup_time": -1}, "multiindex_object.Integer.time_get_indexer": {"code": "class Integer:\n    def time_get_indexer(self):\n        self.mi_int.get_indexer(self.obj_index)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Integer:\n    def setup(self):\n        self.mi_int = MultiIndex.from_product(\n            [np.arange(1000), np.arange(1000)], names=[\"one\", \"two\"]\n        )\n        self.obj_index = np.array(\n            [\n                (0, 10),\n                (0, 11),\n                (0, 12),\n                (0, 13),\n                (0, 14),\n                (0, 15),\n                (0, 16),\n                (0, 17),\n                (0, 18),\n                (0, 19),\n            ],\n            dtype=object,\n        )\n        self.other_mi_many_mismatches = MultiIndex.from_tuples(\n            [\n                (-7, 41),\n                (-2, 3),\n                (-0.7, 5),\n                (0, 0),\n                (0, 1.5),\n                (0, 340),\n                (0, 1001),\n                (1, -4),\n                (1, 20),\n                (1, 1040),\n                (432, -5),\n                (432, 17),\n                (439, 165.5),\n                (998, -4),\n                (998, 24065),\n                (999, 865.2),\n                (999, 1000),\n                (1045, -843),\n            ]\n        )", "min_run_count": 2, "name": "multiindex_object.Integer.time_get_indexer", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "fbdc58718b979f87ea6a8c82f9bc10f0b1ebc5fb70ea385528f54cff5edb41e7", "warmup_time": -1}, "multiindex_object.Integer.time_get_indexer_and_backfill": {"code": "class Integer:\n    def time_get_indexer_and_backfill(self):\n        self.mi_int.get_indexer(self.other_mi_many_mismatches, method=\"backfill\")\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Integer:\n    def setup(self):\n        self.mi_int = MultiIndex.from_product(\n            [np.arange(1000), np.arange(1000)], names=[\"one\", \"two\"]\n        )\n        self.obj_index = np.array(\n            [\n                (0, 10),\n                (0, 11),\n                (0, 12),\n                (0, 13),\n                (0, 14),\n                (0, 15),\n                (0, 16),\n                (0, 17),\n                (0, 18),\n                (0, 19),\n            ],\n            dtype=object,\n        )\n        self.other_mi_many_mismatches = MultiIndex.from_tuples(\n            [\n                (-7, 41),\n                (-2, 3),\n                (-0.7, 5),\n                (0, 0),\n                (0, 1.5),\n                (0, 340),\n                (0, 1001),\n                (1, -4),\n                (1, 20),\n                (1, 1040),\n                (432, -5),\n                (432, 17),\n                (439, 165.5),\n                (998, -4),\n                (998, 24065),\n                (999, 865.2),\n                (999, 1000),\n                (1045, -843),\n            ]\n        )", "min_run_count": 2, "name": "multiindex_object.Integer.time_get_indexer_and_backfill", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "f3a337ce0bc68b9b181e2f10744c48edfc0aea4481ed3ae1d3daf65dc1c9d53b", "warmup_time": -1}, "multiindex_object.Integer.time_get_indexer_and_pad": {"code": "class Integer:\n    def time_get_indexer_and_pad(self):\n        self.mi_int.get_indexer(self.other_mi_many_mismatches, method=\"pad\")\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Integer:\n    def setup(self):\n        self.mi_int = MultiIndex.from_product(\n            [np.arange(1000), np.arange(1000)], names=[\"one\", \"two\"]\n        )\n        self.obj_index = np.array(\n            [\n                (0, 10),\n                (0, 11),\n                (0, 12),\n                (0, 13),\n                (0, 14),\n                (0, 15),\n                (0, 16),\n                (0, 17),\n                (0, 18),\n                (0, 19),\n            ],\n            dtype=object,\n        )\n        self.other_mi_many_mismatches = MultiIndex.from_tuples(\n            [\n                (-7, 41),\n                (-2, 3),\n                (-0.7, 5),\n                (0, 0),\n                (0, 1.5),\n                (0, 340),\n                (0, 1001),\n                (1, -4),\n                (1, 20),\n                (1, 1040),\n                (432, -5),\n                (432, 17),\n                (439, 165.5),\n                (998, -4),\n                (998, 24065),\n                (999, 865.2),\n                (999, 1000),\n                (1045, -843),\n            ]\n        )", "min_run_count": 2, "name": "multiindex_object.Integer.time_get_indexer_and_pad", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "ee2af65e57a49d84022609e04c926f032e6e248514ffaccf6af4a25038d13f78", "warmup_time": -1}, "multiindex_object.Integer.time_is_monotonic": {"code": "class Integer:\n    def time_is_monotonic(self):\n        self.mi_int.is_monotonic_increasing\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Integer:\n    def setup(self):\n        self.mi_int = MultiIndex.from_product(\n            [np.arange(1000), np.arange(1000)], names=[\"one\", \"two\"]\n        )\n        self.obj_index = np.array(\n            [\n                (0, 10),\n                (0, 11),\n                (0, 12),\n                (0, 13),\n                (0, 14),\n                (0, 15),\n                (0, 16),\n                (0, 17),\n                (0, 18),\n                (0, 19),\n            ],\n            dtype=object,\n        )\n        self.other_mi_many_mismatches = MultiIndex.from_tuples(\n            [\n                (-7, 41),\n                (-2, 3),\n                (-0.7, 5),\n                (0, 0),\n                (0, 1.5),\n                (0, 340),\n                (0, 1001),\n                (1, -4),\n                (1, 20),\n                (1, 1040),\n                (432, -5),\n                (432, 17),\n                (439, 165.5),\n                (998, -4),\n                (998, 24065),\n                (999, 865.2),\n                (999, 1000),\n                (1045, -843),\n            ]\n        )", "min_run_count": 2, "name": "multiindex_object.Integer.time_is_monotonic", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "fe8e8d89536abf16fb7a6ef01595817776ab712a6865435f65f407568be53b2b", "warmup_time": -1}, "multiindex_object.Isin.time_isin_large": {"code": "class Isin:\n    def time_isin_large(self, dtype):\n        self.midx.isin(self.values_large)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Isin:\n    def setup(self, dtype):\n        N = 10**5\n        level1 = range(1000)\n    \n        level2 = date_range(start=\"1/1/2000\", periods=N // 1000)\n        dates_midx = MultiIndex.from_product([level1, level2])\n    \n        level2 = range(N // 1000)\n        int_midx = MultiIndex.from_product([level1, level2])\n    \n        level2 = tm.makeStringIndex(N // 1000).values\n        str_midx = MultiIndex.from_product([level1, level2])\n    \n        data = {\n            \"datetime\": dates_midx,\n            \"int\": int_midx,\n            \"string\": str_midx,\n        }\n    \n        self.midx = data[dtype]\n        self.values_small = self.midx[:100]\n        self.values_large = self.midx[100:]", "min_run_count": 2, "name": "multiindex_object.Isin.time_isin_large", "number": 0, "param_names": ["dtype"], "params": [["'string'", "'int'", "'datetime'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "2fde11d3465403f173fac0b9f1e87edb2bb29d20091944cb317016977dc57c0e", "warmup_time": -1}, "multiindex_object.Isin.time_isin_small": {"code": "class Isin:\n    def time_isin_small(self, dtype):\n        self.midx.isin(self.values_small)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Isin:\n    def setup(self, dtype):\n        N = 10**5\n        level1 = range(1000)\n    \n        level2 = date_range(start=\"1/1/2000\", periods=N // 1000)\n        dates_midx = MultiIndex.from_product([level1, level2])\n    \n        level2 = range(N // 1000)\n        int_midx = MultiIndex.from_product([level1, level2])\n    \n        level2 = tm.makeStringIndex(N // 1000).values\n        str_midx = MultiIndex.from_product([level1, level2])\n    \n        data = {\n            \"datetime\": dates_midx,\n            \"int\": int_midx,\n            \"string\": str_midx,\n        }\n    \n        self.midx = data[dtype]\n        self.values_small = self.midx[:100]\n        self.values_large = self.midx[100:]", "min_run_count": 2, "name": "multiindex_object.Isin.time_isin_small", "number": 0, "param_names": ["dtype"], "params": [["'string'", "'int'", "'datetime'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "fed24b7f92abd1dc58eb8c6574442b48ea28d2e8c0942daa313b6f46578530f1", "warmup_time": -1}, "multiindex_object.Putmask.time_putmask": {"code": "class Putmask:\n    def time_putmask(self):\n        self.midx.putmask(self.mask, self.midx_values)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Putmask:\n    def setup(self):\n        N = 10**5\n        level1 = range(1_000)\n    \n        level2 = date_range(start=\"1/1/2000\", periods=N // 1000)\n        self.midx = MultiIndex.from_product([level1, level2])\n    \n        level1 = range(1_000, 2_000)\n        self.midx_values = MultiIndex.from_product([level1, level2])\n    \n        level2 = date_range(start=\"1/1/2010\", periods=N // 1000)\n        self.midx_values_different = MultiIndex.from_product([level1, level2])\n        self.mask = np.array([True, False] * (N // 2))", "min_run_count": 2, "name": "multiindex_object.Putmask.time_putmask", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "50b446c4932ddf04ca8086ddae7020ac3b1392556c9a5ec0bceee4a3471b774c", "warmup_time": -1}, "multiindex_object.Putmask.time_putmask_all_different": {"code": "class Putmask:\n    def time_putmask_all_different(self):\n        self.midx.putmask(self.mask, self.midx_values_different)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Putmask:\n    def setup(self):\n        N = 10**5\n        level1 = range(1_000)\n    \n        level2 = date_range(start=\"1/1/2000\", periods=N // 1000)\n        self.midx = MultiIndex.from_product([level1, level2])\n    \n        level1 = range(1_000, 2_000)\n        self.midx_values = MultiIndex.from_product([level1, level2])\n    \n        level2 = date_range(start=\"1/1/2010\", periods=N // 1000)\n        self.midx_values_different = MultiIndex.from_product([level1, level2])\n        self.mask = np.array([True, False] * (N // 2))", "min_run_count": 2, "name": "multiindex_object.Putmask.time_putmask_all_different", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "df38cba739c0876f17aa511e01ea4c5d6ae937fab90a3c6ba526fe149c270ac5", "warmup_time": -1}, "multiindex_object.SetOperations.time_operation": {"code": "class SetOperations:\n    def time_operation(self, index_structure, dtype, method, sort):\n        getattr(self.left, method)(self.right, sort=sort)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass SetOperations:\n    def setup(self, index_structure, dtype, method, sort):\n        N = 10**5\n        level1 = range(1000)\n    \n        level2 = date_range(start=\"1/1/2000\", periods=N // 1000)\n        dates_left = MultiIndex.from_product([level1, level2])\n    \n        level2 = range(N // 1000)\n        int_left = MultiIndex.from_product([level1, level2])\n    \n        level2 = tm.makeStringIndex(N // 1000).values\n        str_left = MultiIndex.from_product([level1, level2])\n    \n        level2 = range(N // 1000)\n        ea_int_left = MultiIndex.from_product([level1, Series(level2, dtype=\"Int64\")])\n    \n        data = {\n            \"datetime\": dates_left,\n            \"int\": int_left,\n            \"string\": str_left,\n            \"ea_int\": ea_int_left,\n        }\n    \n        if index_structure == \"non_monotonic\":\n            data = {k: mi[::-1] for k, mi in data.items()}\n    \n        data = {k: {\"left\": mi, \"right\": mi[:-1]} for k, mi in data.items()}\n        self.left = data[dtype][\"left\"]\n        self.right = data[dtype][\"right\"]", "min_run_count": 2, "name": "multiindex_object.SetOperations.time_operation", "number": 0, "param_names": ["index_structure", "dtype", "method", "sort"], "params": [["'monotonic'", "'non_monotonic'"], ["'datetime'", "'int'", "'string'", "'ea_int'"], ["'intersection'", "'union'", "'symmetric_difference'"], ["False", "None"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "1917f9eb6d02ae1187f3f9730881ab650062f065d27eafa9a56e227d05dfd0cf", "warmup_time": -1}, "multiindex_object.SortValues.time_sort_values": {"code": "class SortValues:\n    def time_sort_values(self, dtype):\n        self.mi.sort_values()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass SortValues:\n    def setup(self, dtype):\n        a = array(np.tile(np.arange(100), 1000), dtype=dtype)\n        b = array(np.tile(np.arange(1000), 100), dtype=dtype)\n        self.mi = MultiIndex.from_arrays([a, b])", "min_run_count": 2, "name": "multiindex_object.SortValues.time_sort_values", "number": 0, "param_names": ["dtype"], "params": [["'int64'", "'Int64'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "eb98215f2130dc70e3c3979ccb2442480cccf2a7f1fe46dabae490de9fa669ce", "warmup_time": -1}, "multiindex_object.Sortlevel.time_sortlevel_int64": {"code": "class Sortlevel:\n    def time_sortlevel_int64(self):\n        self.mi_int.sortlevel()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Sortlevel:\n    def setup(self):\n        n = 1182720\n        low, high = -4096, 4096\n        arrs = [\n            np.repeat(np.random.randint(low, high, (n // k)), k)\n            for k in [11, 7, 5, 3, 1]\n        ]\n        self.mi_int = MultiIndex.from_arrays(arrs)[np.random.permutation(n)]\n    \n        a = np.repeat(np.arange(100), 1000)\n        b = np.tile(np.arange(1000), 100)\n        self.mi = MultiIndex.from_arrays([a, b])\n        self.mi = self.mi.take(np.random.permutation(np.arange(100000)))", "min_run_count": 2, "name": "multiindex_object.Sortlevel.time_sortlevel_int64", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "a8b2951c7f045b903e0cd3abcea3295e405768580e65c267316e5d7993c375e4", "warmup_time": -1}, "multiindex_object.Sortlevel.time_sortlevel_one": {"code": "class Sortlevel:\n    def time_sortlevel_one(self):\n        self.mi.sortlevel(1)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Sortlevel:\n    def setup(self):\n        n = 1182720\n        low, high = -4096, 4096\n        arrs = [\n            np.repeat(np.random.randint(low, high, (n // k)), k)\n            for k in [11, 7, 5, 3, 1]\n        ]\n        self.mi_int = MultiIndex.from_arrays(arrs)[np.random.permutation(n)]\n    \n        a = np.repeat(np.arange(100), 1000)\n        b = np.tile(np.arange(1000), 100)\n        self.mi = MultiIndex.from_arrays([a, b])\n        self.mi = self.mi.take(np.random.permutation(np.arange(100000)))", "min_run_count": 2, "name": "multiindex_object.Sortlevel.time_sortlevel_one", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "17b98983847e3899dd3aecd51f007b8eee9219cafba180bcd18d23a273f074e4", "warmup_time": -1}, "multiindex_object.Sortlevel.time_sortlevel_zero": {"code": "class Sortlevel:\n    def time_sortlevel_zero(self):\n        self.mi.sortlevel(0)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Sortlevel:\n    def setup(self):\n        n = 1182720\n        low, high = -4096, 4096\n        arrs = [\n            np.repeat(np.random.randint(low, high, (n // k)), k)\n            for k in [11, 7, 5, 3, 1]\n        ]\n        self.mi_int = MultiIndex.from_arrays(arrs)[np.random.permutation(n)]\n    \n        a = np.repeat(np.arange(100), 1000)\n        b = np.tile(np.arange(1000), 100)\n        self.mi = MultiIndex.from_arrays([a, b])\n        self.mi = self.mi.take(np.random.permutation(np.arange(100000)))", "min_run_count": 2, "name": "multiindex_object.Sortlevel.time_sortlevel_zero", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "1f7d209d70d9ce641fdba817c8598ab8212457073e4f1218e5ecec974b8af00b", "warmup_time": -1}, "multiindex_object.Unique.time_unique": {"code": "class Unique:\n    def time_unique(self, dtype_val):\n        self.midx.unique()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Unique:\n    def setup(self, dtype_val):\n        level = Series(\n            [1, 2, dtype_val[1], dtype_val[1]] + list(range(1_000_000)),\n            dtype=dtype_val[0],\n        )\n        self.midx = MultiIndex.from_arrays([level, level])\n    \n        level_dups = Series(\n            [1, 2, dtype_val[1], dtype_val[1]] + list(range(500_000)) * 2,\n            dtype=dtype_val[0],\n        )\n    \n        self.midx_dups = MultiIndex.from_arrays([level_dups, level_dups])", "min_run_count": 2, "name": "multiindex_object.Unique.time_unique", "number": 0, "param_names": ["dtype_val"], "params": [["('Int64', <NA>)", "('int64', 0)"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "92002a61c3c2deb0be986b18be58b6f290334692a0ddda344728454264d8c69f", "warmup_time": -1}, "multiindex_object.Unique.time_unique_dups": {"code": "class Unique:\n    def time_unique_dups(self, dtype_val):\n        self.midx_dups.unique()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Unique:\n    def setup(self, dtype_val):\n        level = Series(\n            [1, 2, dtype_val[1], dtype_val[1]] + list(range(1_000_000)),\n            dtype=dtype_val[0],\n        )\n        self.midx = MultiIndex.from_arrays([level, level])\n    \n        level_dups = Series(\n            [1, 2, dtype_val[1], dtype_val[1]] + list(range(500_000)) * 2,\n            dtype=dtype_val[0],\n        )\n    \n        self.midx_dups = MultiIndex.from_arrays([level_dups, level_dups])", "min_run_count": 2, "name": "multiindex_object.Unique.time_unique_dups", "number": 0, "param_names": ["dtype_val"], "params": [["('Int64', <NA>)", "('int64', 0)"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "e7f6ae2612b4e61ab7e9b6ec0fa03d09c37653dcccd19cf141ea041ff0d0eec7", "warmup_time": -1}, "multiindex_object.Values.time_datetime_level_values_copy": {"code": "class Values:\n    def time_datetime_level_values_copy(self, mi):\n        mi.copy().values\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Values:\n    def setup_cache(self):\n        level1 = range(1000)\n        level2 = date_range(start=\"1/1/2012\", periods=100)\n        mi = MultiIndex.from_product([level1, level2])\n        return mi", "min_run_count": 2, "name": "multiindex_object.Values.time_datetime_level_values_copy", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "setup_cache_key": "multiindex_object:194", "timeout": 60.0, "type": "time", "unit": "seconds", "version": "63e7a47c0b022503f19576c75633ea3ca8a93ecce618be6e102892f9bd42dc33", "warmup_time": -1}, "multiindex_object.Values.time_datetime_level_values_sliced": {"code": "class Values:\n    def time_datetime_level_values_sliced(self, mi):\n        mi[:10].values\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Values:\n    def setup_cache(self):\n        level1 = range(1000)\n        level2 = date_range(start=\"1/1/2012\", periods=100)\n        mi = MultiIndex.from_product([level1, level2])\n        return mi", "min_run_count": 2, "name": "multiindex_object.Values.time_datetime_level_values_sliced", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "setup_cache_key": "multiindex_object:194", "timeout": 60.0, "type": "time", "unit": "seconds", "version": "6cfa5ee6916e13b58f6d108ca083f0ce269ffc3682b201c7fb24a2c4f82119bf", "warmup_time": -1}, "package.TimeImport.time_import": {"code": "class TimeImport:\n    def time_import(self):\n        # on py37+ we the \"-X importtime\" usage gives us a more precise\n        #  measurement of the import time we actually care about,\n        #  without the subprocess or interpreter overhead\n        cmd = [sys.executable, \"-X\", \"importtime\", \"-c\", \"import pandas as pd\"]\n        p = subprocess.run(cmd, stderr=subprocess.PIPE, check=True)\n    \n        line = p.stderr.splitlines()[-1]\n        field = line.split(b\"|\")[-2].strip()\n        total = int(field)  # microseconds\n        return total", "min_run_count": 2, "name": "package.TimeImport.time_import", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "83a56070bd7dda7f68a557d63e6b32341f956e6303d5820f6f5f3cfd62ac924b", "warmup_time": -1}, "period.Algorithms.time_drop_duplicates": {"code": "class Algorithms:\n    def time_drop_duplicates(self, typ):\n        self.vector.drop_duplicates()\n\n    def setup(self, typ):\n        data = [\n            Period(\"2011-01\", freq=\"M\"),\n            Period(\"2011-02\", freq=\"M\"),\n            Period(\"2011-03\", freq=\"M\"),\n            Period(\"2011-04\", freq=\"M\"),\n        ]\n    \n        if typ == \"index\":\n            self.vector = PeriodIndex(data * 1000, freq=\"M\")\n        elif typ == \"series\":\n            self.vector = Series(data * 1000)", "min_run_count": 2, "name": "period.Algorithms.time_drop_duplicates", "number": 0, "param_names": ["typ"], "params": [["'index'", "'series'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "5ed71a0e29ea9fe94acdf37fe778becc6a166703e59fe06b43693190e73c358c", "warmup_time": -1}, "period.Algorithms.time_value_counts": {"code": "class Algorithms:\n    def time_value_counts(self, typ):\n        self.vector.value_counts()\n\n    def setup(self, typ):\n        data = [\n            Period(\"2011-01\", freq=\"M\"),\n            Period(\"2011-02\", freq=\"M\"),\n            Period(\"2011-03\", freq=\"M\"),\n            Period(\"2011-04\", freq=\"M\"),\n        ]\n    \n        if typ == \"index\":\n            self.vector = PeriodIndex(data * 1000, freq=\"M\")\n        elif typ == \"series\":\n            self.vector = Series(data * 1000)", "min_run_count": 2, "name": "period.Algorithms.time_value_counts", "number": 0, "param_names": ["typ"], "params": [["'index'", "'series'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "7aaad3304a09d800100a2dc5f7da82c36953722c7da6aca2ca4c2e446a3badc8", "warmup_time": -1}, "period.DataFramePeriodColumn.time_set_index": {"code": "class DataFramePeriodColumn:\n    def time_set_index(self):\n        # GH#21582 limited by comparisons of Period objects\n        self.df[\"col2\"] = self.rng\n        self.df.set_index(\"col2\", append=True)\n\n    def setup(self):\n        self.rng = period_range(start=\"1/1/1990\", freq=\"S\", periods=20000)\n        self.df = DataFrame(index=range(len(self.rng)))", "min_run_count": 2, "name": "period.DataFramePeriodColumn.time_set_index", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "223baa21285346a0b70e9d11fe853a0b156662cd2530575dc66cfcb8d65cf46a", "warmup_time": -1}, "period.DataFramePeriodColumn.time_setitem_period_column": {"code": "class DataFramePeriodColumn:\n    def time_setitem_period_column(self):\n        self.df[\"col\"] = self.rng\n\n    def setup(self):\n        self.rng = period_range(start=\"1/1/1990\", freq=\"S\", periods=20000)\n        self.df = DataFrame(index=range(len(self.rng)))", "min_run_count": 2, "name": "period.DataFramePeriodColumn.time_setitem_period_column", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "e7044b31af083678ecf627851ca14fa1108e6ec19cd7acf41ebe60f0283fefe8", "warmup_time": -1}, "period.Indexing.time_align": {"code": "class Indexing:\n    def time_align(self):\n        DataFrame({\"a\": self.series, \"b\": self.series[:500]})\n\n    def setup(self):\n        self.index = period_range(start=\"1985\", periods=1000, freq=\"D\")\n        self.series = Series(range(1000), index=self.index)\n        self.period = self.index[500]", "min_run_count": 2, "name": "period.Indexing.time_align", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "7ba91f5b4184a97b1e578ce06acd5823a15ef927984c534ef97a97209494f3e9", "warmup_time": -1}, "period.Indexing.time_get_loc": {"code": "class Indexing:\n    def time_get_loc(self):\n        self.index.get_loc(self.period)\n\n    def setup(self):\n        self.index = period_range(start=\"1985\", periods=1000, freq=\"D\")\n        self.series = Series(range(1000), index=self.index)\n        self.period = self.index[500]", "min_run_count": 2, "name": "period.Indexing.time_get_loc", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "16c0233f1354d0efad7e0568b42faab3ceda761dbe321e610db062449c038b2b", "warmup_time": -1}, "period.Indexing.time_intersection": {"code": "class Indexing:\n    def time_intersection(self):\n        self.index[:750].intersection(self.index[250:])\n\n    def setup(self):\n        self.index = period_range(start=\"1985\", periods=1000, freq=\"D\")\n        self.series = Series(range(1000), index=self.index)\n        self.period = self.index[500]", "min_run_count": 2, "name": "period.Indexing.time_intersection", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "e473ad8ce23861754e1a2322452188035f32546b5106e9c354504575f161c9dc", "warmup_time": -1}, "period.Indexing.time_series_loc": {"code": "class Indexing:\n    def time_series_loc(self):\n        self.series.loc[self.period]\n\n    def setup(self):\n        self.index = period_range(start=\"1985\", periods=1000, freq=\"D\")\n        self.series = Series(range(1000), index=self.index)\n        self.period = self.index[500]", "min_run_count": 2, "name": "period.Indexing.time_series_loc", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "051bdec8fea0886aa445b372b56bf9dc434ca870d0168882015b967bb1545aa4", "warmup_time": -1}, "period.Indexing.time_shallow_copy": {"code": "class Indexing:\n    def time_shallow_copy(self):\n        self.index._view()\n\n    def setup(self):\n        self.index = period_range(start=\"1985\", periods=1000, freq=\"D\")\n        self.series = Series(range(1000), index=self.index)\n        self.period = self.index[500]", "min_run_count": 2, "name": "period.Indexing.time_shallow_copy", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "ec340ef909e8666710788924d6a879a98eceecf319ce9ddaa3afaef7f7c6a891", "warmup_time": -1}, "period.Indexing.time_unique": {"code": "class Indexing:\n    def time_unique(self):\n        self.index.unique()\n\n    def setup(self):\n        self.index = period_range(start=\"1985\", periods=1000, freq=\"D\")\n        self.series = Series(range(1000), index=self.index)\n        self.period = self.index[500]", "min_run_count": 2, "name": "period.Indexing.time_unique", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "c4ce9c886be5dcc91f24921a741cee9552a169c54f69f0ec4893b19145ca6cda", "warmup_time": -1}, "period.PeriodIndexConstructor.time_from_date_range": {"code": "class PeriodIndexConstructor:\n    def time_from_date_range(self, freq, is_offset):\n        PeriodIndex(self.rng, freq=freq)\n\n    def setup(self, freq, is_offset):\n        self.rng = date_range(\"1985\", periods=1000)\n        self.rng2 = date_range(\"1985\", periods=1000).to_pydatetime()\n        self.ints = list(range(2000, 3000))\n        self.daily_ints = (\n            date_range(\"1/1/2000\", periods=1000, freq=freq).strftime(\"%Y%m%d\").map(int)\n        )\n        if is_offset:\n            self.freq = to_offset(freq)\n        else:\n            self.freq = freq", "min_run_count": 2, "name": "period.PeriodIndexConstructor.time_from_date_range", "number": 0, "param_names": ["freq", "is_offset"], "params": [["'D'"], ["True", "False"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "90341c890b6fd853e93fe5ad5a5d9935048545a0c2bf70da9324aca627215961", "warmup_time": -1}, "period.PeriodIndexConstructor.time_from_ints": {"code": "class PeriodIndexConstructor:\n    def time_from_ints(self, freq, is_offset):\n        PeriodIndex(self.ints, freq=freq)\n\n    def setup(self, freq, is_offset):\n        self.rng = date_range(\"1985\", periods=1000)\n        self.rng2 = date_range(\"1985\", periods=1000).to_pydatetime()\n        self.ints = list(range(2000, 3000))\n        self.daily_ints = (\n            date_range(\"1/1/2000\", periods=1000, freq=freq).strftime(\"%Y%m%d\").map(int)\n        )\n        if is_offset:\n            self.freq = to_offset(freq)\n        else:\n            self.freq = freq", "min_run_count": 2, "name": "period.PeriodIndexConstructor.time_from_ints", "number": 0, "param_names": ["freq", "is_offset"], "params": [["'D'"], ["True", "False"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "40e20dbe294496152b0cab99ad8277ec6836602167d363e0c665de9915971d7d", "warmup_time": -1}, "period.PeriodIndexConstructor.time_from_ints_daily": {"code": "class PeriodIndexConstructor:\n    def time_from_ints_daily(self, freq, is_offset):\n        PeriodIndex(self.daily_ints, freq=freq)\n\n    def setup(self, freq, is_offset):\n        self.rng = date_range(\"1985\", periods=1000)\n        self.rng2 = date_range(\"1985\", periods=1000).to_pydatetime()\n        self.ints = list(range(2000, 3000))\n        self.daily_ints = (\n            date_range(\"1/1/2000\", periods=1000, freq=freq).strftime(\"%Y%m%d\").map(int)\n        )\n        if is_offset:\n            self.freq = to_offset(freq)\n        else:\n            self.freq = freq", "min_run_count": 2, "name": "period.PeriodIndexConstructor.time_from_ints_daily", "number": 0, "param_names": ["freq", "is_offset"], "params": [["'D'"], ["True", "False"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "7ec1c957be1d06e33b08c4eb1a645648cba0172013a8b73a1e8c8d8f8e5725a8", "warmup_time": -1}, "period.PeriodIndexConstructor.time_from_pydatetime": {"code": "class PeriodIndexConstructor:\n    def time_from_pydatetime(self, freq, is_offset):\n        PeriodIndex(self.rng2, freq=freq)\n\n    def setup(self, freq, is_offset):\n        self.rng = date_range(\"1985\", periods=1000)\n        self.rng2 = date_range(\"1985\", periods=1000).to_pydatetime()\n        self.ints = list(range(2000, 3000))\n        self.daily_ints = (\n            date_range(\"1/1/2000\", periods=1000, freq=freq).strftime(\"%Y%m%d\").map(int)\n        )\n        if is_offset:\n            self.freq = to_offset(freq)\n        else:\n            self.freq = freq", "min_run_count": 2, "name": "period.PeriodIndexConstructor.time_from_pydatetime", "number": 0, "param_names": ["freq", "is_offset"], "params": [["'D'"], ["True", "False"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "2e9a86e7434b9d0777e5ccc8fc9165eaf99b3ae701c88bb9a2f2bfbb3a8742c1", "warmup_time": -1}, "plotting.BackendLoading.time_get_plot_backend": {"code": "class BackendLoading:\n    def time_get_plot_backend(self):\n        # finds the first my_ep_backend\n        _get_plot_backend(\"my_ep_backend\")\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass BackendLoading:\n    def setup(self):\n        mod = importlib.util.module_from_spec(\n            importlib.machinery.ModuleSpec(\"pandas_dummy_backend\", None)\n        )\n        mod.plot = lambda *args, **kwargs: 1\n    \n        with contextlib.ExitStack() as stack:\n            stack.enter_context(\n                mock.patch.dict(sys.modules, {\"pandas_dummy_backend\": mod})\n            )\n            tmp_path = pathlib.Path(stack.enter_context(tempfile.TemporaryDirectory()))\n    \n            sys.path.insert(0, os.fsdecode(tmp_path))\n            stack.callback(sys.path.remove, os.fsdecode(tmp_path))\n    \n            dist_info = tmp_path / \"my_backend-0.0.0.dist-info\"\n            dist_info.mkdir()\n            (dist_info / \"entry_points.txt\").write_bytes(\n                b\"[pandas_plotting_backends]\\n\"\n                b\"my_ep_backend = pandas_dummy_backend\\n\"\n                b\"my_ep_backend0 = pandas_dummy_backend\\n\"\n                b\"my_ep_backend1 = pandas_dummy_backend\\n\"\n                b\"my_ep_backend2 = pandas_dummy_backend\\n\"\n                b\"my_ep_backend3 = pandas_dummy_backend\\n\"\n                b\"my_ep_backend4 = pandas_dummy_backend\\n\"\n                b\"my_ep_backend5 = pandas_dummy_backend\\n\"\n                b\"my_ep_backend6 = pandas_dummy_backend\\n\"\n                b\"my_ep_backend7 = pandas_dummy_backend\\n\"\n                b\"my_ep_backend8 = pandas_dummy_backend\\n\"\n                b\"my_ep_backend9 = pandas_dummy_backend\\n\"\n            )\n            self.stack = stack.pop_all()", "min_run_count": 2, "name": "plotting.BackendLoading.time_get_plot_backend", "number": 1, "param_names": [], "params": [], "repeat": 1, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "275ed8f1d87eb6e40f19e678ae4e0130a88ef153363ae407c9576044f4455591", "warmup_time": 0}, "plotting.BackendLoading.time_get_plot_backend_fallback": {"code": "class BackendLoading:\n    def time_get_plot_backend_fallback(self):\n        # iterates through all the my_ep_backend[0-9] before falling back\n        # to importlib.import_module\n        _get_plot_backend(\"pandas_dummy_backend\")\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass BackendLoading:\n    def setup(self):\n        mod = importlib.util.module_from_spec(\n            importlib.machinery.ModuleSpec(\"pandas_dummy_backend\", None)\n        )\n        mod.plot = lambda *args, **kwargs: 1\n    \n        with contextlib.ExitStack() as stack:\n            stack.enter_context(\n                mock.patch.dict(sys.modules, {\"pandas_dummy_backend\": mod})\n            )\n            tmp_path = pathlib.Path(stack.enter_context(tempfile.TemporaryDirectory()))\n    \n            sys.path.insert(0, os.fsdecode(tmp_path))\n            stack.callback(sys.path.remove, os.fsdecode(tmp_path))\n    \n            dist_info = tmp_path / \"my_backend-0.0.0.dist-info\"\n            dist_info.mkdir()\n            (dist_info / \"entry_points.txt\").write_bytes(\n                b\"[pandas_plotting_backends]\\n\"\n                b\"my_ep_backend = pandas_dummy_backend\\n\"\n                b\"my_ep_backend0 = pandas_dummy_backend\\n\"\n                b\"my_ep_backend1 = pandas_dummy_backend\\n\"\n                b\"my_ep_backend2 = pandas_dummy_backend\\n\"\n                b\"my_ep_backend3 = pandas_dummy_backend\\n\"\n                b\"my_ep_backend4 = pandas_dummy_backend\\n\"\n                b\"my_ep_backend5 = pandas_dummy_backend\\n\"\n                b\"my_ep_backend6 = pandas_dummy_backend\\n\"\n                b\"my_ep_backend7 = pandas_dummy_backend\\n\"\n                b\"my_ep_backend8 = pandas_dummy_backend\\n\"\n                b\"my_ep_backend9 = pandas_dummy_backend\\n\"\n            )\n            self.stack = stack.pop_all()", "min_run_count": 2, "name": "plotting.BackendLoading.time_get_plot_backend_fallback", "number": 1, "param_names": [], "params": [], "repeat": 1, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "5910845eb9f1e056392eea6799696858a13e4b42bcc4462d896f69e4c4e69fdc", "warmup_time": 0}, "plotting.FramePlotting.time_frame_plot": {"code": "class FramePlotting:\n    def time_frame_plot(self, kind):\n        self.df.plot(x=\"x\", y=\"y\", kind=kind)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass FramePlotting:\n    def setup(self, kind):\n        if kind in [\"bar\", \"barh\", \"pie\"]:\n            n = 100\n        elif kind in [\"kde\", \"scatter\", \"hexbin\"]:\n            n = 10000\n        else:\n            n = 1000000\n    \n        self.x = Series(np.random.randn(n))\n        self.y = Series(np.random.randn(n))\n        if kind in [\"area\", \"pie\"]:\n            self.x = self.x.abs()\n            self.y = self.y.abs()\n        self.df = DataFrame({\"x\": self.x, \"y\": self.y})", "min_run_count": 2, "name": "plotting.FramePlotting.time_frame_plot", "number": 0, "param_names": ["kind"], "params": [["'line'", "'bar'", "'area'", "'barh'", "'hist'", "'kde'", "'pie'", "'scatter'", "'hexbin'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "d6c19f0e6ee8994eb981863b029fa07bc3dc6e28ca77fd1947a32124682e279a", "warmup_time": -1}, "plotting.Misc.time_plot_andrews_curves": {"code": "class Misc:\n    def time_plot_andrews_curves(self):\n        andrews_curves(self.df, \"Name\")\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Misc:\n    def setup(self):\n        N = 500\n        M = 10\n        self.df = DataFrame(np.random.randn(N, M))\n        self.df[\"Name\"] = [\"A\"] * N", "min_run_count": 2, "name": "plotting.Misc.time_plot_andrews_curves", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "c5cdb631131db0763b96053825ebc29d36564b7efc93174553deebff526d0e51", "warmup_time": -1}, "plotting.SeriesPlotting.time_series_plot": {"code": "class SeriesPlotting:\n    def time_series_plot(self, kind):\n        self.s.plot(kind=kind)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass SeriesPlotting:\n    def setup(self, kind):\n        if kind in [\"bar\", \"barh\", \"pie\"]:\n            n = 100\n        elif kind in [\"kde\"]:\n            n = 10000\n        else:\n            n = 1000000\n    \n        self.s = Series(np.random.randn(n))\n        if kind in [\"area\", \"pie\"]:\n            self.s = self.s.abs()", "min_run_count": 2, "name": "plotting.SeriesPlotting.time_series_plot", "number": 0, "param_names": ["kind"], "params": [["'line'", "'bar'", "'area'", "'barh'", "'hist'", "'kde'", "'pie'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "160ab68dd1bbcfdc4cb7ac7c745857d954d7b49e2140f072e93341253436ffb2", "warmup_time": -1}, "plotting.TimeseriesPlotting.time_plot_irregular": {"code": "class TimeseriesPlotting:\n    def time_plot_irregular(self):\n        self.df2.plot()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass TimeseriesPlotting:\n    def setup(self):\n        N = 2000\n        M = 5\n        idx = date_range(\"1/1/1975\", periods=N)\n        self.df = DataFrame(np.random.randn(N, M), index=idx)\n    \n        idx_irregular = DatetimeIndex(\n            np.concatenate((idx.values[0:10], idx.values[12:]))\n        )\n        self.df2 = DataFrame(\n            np.random.randn(len(idx_irregular), M), index=idx_irregular\n        )", "min_run_count": 2, "name": "plotting.TimeseriesPlotting.time_plot_irregular", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "eebbebf937fc740e9be07af175a3643c600ac60a98e1f1606d1ed7150b2966b0", "warmup_time": -1}, "plotting.TimeseriesPlotting.time_plot_regular": {"code": "class TimeseriesPlotting:\n    def time_plot_regular(self):\n        self.df.plot()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass TimeseriesPlotting:\n    def setup(self):\n        N = 2000\n        M = 5\n        idx = date_range(\"1/1/1975\", periods=N)\n        self.df = DataFrame(np.random.randn(N, M), index=idx)\n    \n        idx_irregular = DatetimeIndex(\n            np.concatenate((idx.values[0:10], idx.values[12:]))\n        )\n        self.df2 = DataFrame(\n            np.random.randn(len(idx_irregular), M), index=idx_irregular\n        )", "min_run_count": 2, "name": "plotting.TimeseriesPlotting.time_plot_regular", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "c3871908c149bdf0cd9d3c7cdce5ed7bd993762db8bacec201061775ac030be2", "warmup_time": -1}, "plotting.TimeseriesPlotting.time_plot_regular_compat": {"code": "class TimeseriesPlotting:\n    def time_plot_regular_compat(self):\n        self.df.plot(x_compat=True)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass TimeseriesPlotting:\n    def setup(self):\n        N = 2000\n        M = 5\n        idx = date_range(\"1/1/1975\", periods=N)\n        self.df = DataFrame(np.random.randn(N, M), index=idx)\n    \n        idx_irregular = DatetimeIndex(\n            np.concatenate((idx.values[0:10], idx.values[12:]))\n        )\n        self.df2 = DataFrame(\n            np.random.randn(len(idx_irregular), M), index=idx_irregular\n        )", "min_run_count": 2, "name": "plotting.TimeseriesPlotting.time_plot_regular_compat", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "6b83eb693399183277a784aee0704171f06e4913b66ddd6bddde0dcc2fb427ff", "warmup_time": -1}, "plotting.TimeseriesPlotting.time_plot_table": {"code": "class TimeseriesPlotting:\n    def time_plot_table(self):\n        self.df.plot(table=True)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass TimeseriesPlotting:\n    def setup(self):\n        N = 2000\n        M = 5\n        idx = date_range(\"1/1/1975\", periods=N)\n        self.df = DataFrame(np.random.randn(N, M), index=idx)\n    \n        idx_irregular = DatetimeIndex(\n            np.concatenate((idx.values[0:10], idx.values[12:]))\n        )\n        self.df2 = DataFrame(\n            np.random.randn(len(idx_irregular), M), index=idx_irregular\n        )", "min_run_count": 2, "name": "plotting.TimeseriesPlotting.time_plot_table", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "2c526eb7965a6c381c8aa22565224994f1cbd2c378f4a0aa87af283821f76da3", "warmup_time": -1}, "reindex.Align.time_align_series_irregular_string": {"code": "class Align:\n    def time_align_series_irregular_string(self):\n        self.x + self.y\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Align:\n    def setup(self):\n        n = 50000\n        indices = tm.makeStringIndex(n)\n        subsample_size = 40000\n        self.x = Series(np.random.randn(n), indices)\n        self.y = Series(\n            np.random.randn(subsample_size),\n            index=np.random.choice(indices, subsample_size, replace=False),\n        )", "min_run_count": 2, "name": "reindex.Align.time_align_series_irregular_string", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "5317d292c85b136c6b3c6d6afee0e3e55ee2ebe744d776079d6343067c2cf36a", "warmup_time": -1}, "reindex.DropDuplicates.time_frame_drop_dups": {"code": "class DropDuplicates:\n    def time_frame_drop_dups(self, inplace):\n        self.df.drop_duplicates([\"key1\", \"key2\"], inplace=inplace)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass DropDuplicates:\n    def setup(self, inplace):\n        N = 10000\n        K = 10\n        key1 = tm.makeStringIndex(N).values.repeat(K)\n        key2 = tm.makeStringIndex(N).values.repeat(K)\n        self.df = DataFrame(\n            {\"key1\": key1, \"key2\": key2, \"value\": np.random.randn(N * K)}\n        )\n        self.df_nan = self.df.copy()\n        self.df_nan.iloc[:10000, :] = np.nan\n    \n        self.s = Series(np.random.randint(0, 1000, size=10000))\n        self.s_str = Series(np.tile(tm.makeStringIndex(1000).values, 10))\n    \n        N = 1000000\n        K = 10000\n        key1 = np.random.randint(0, K, size=N)\n        self.df_int = DataFrame({\"key1\": key1})\n        self.df_bool = DataFrame(np.random.randint(0, 2, size=(K, 10), dtype=bool))", "min_run_count": 2, "name": "reindex.DropDuplicates.time_frame_drop_dups", "number": 0, "param_names": ["inplace"], "params": [["True", "False"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "5601e84063057792b96f079167feef132981d69442c96b9925041d93fc0695f3", "warmup_time": -1}, "reindex.DropDuplicates.time_frame_drop_dups_bool": {"code": "class DropDuplicates:\n    def time_frame_drop_dups_bool(self, inplace):\n        self.df_bool.drop_duplicates(inplace=inplace)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass DropDuplicates:\n    def setup(self, inplace):\n        N = 10000\n        K = 10\n        key1 = tm.makeStringIndex(N).values.repeat(K)\n        key2 = tm.makeStringIndex(N).values.repeat(K)\n        self.df = DataFrame(\n            {\"key1\": key1, \"key2\": key2, \"value\": np.random.randn(N * K)}\n        )\n        self.df_nan = self.df.copy()\n        self.df_nan.iloc[:10000, :] = np.nan\n    \n        self.s = Series(np.random.randint(0, 1000, size=10000))\n        self.s_str = Series(np.tile(tm.makeStringIndex(1000).values, 10))\n    \n        N = 1000000\n        K = 10000\n        key1 = np.random.randint(0, K, size=N)\n        self.df_int = DataFrame({\"key1\": key1})\n        self.df_bool = DataFrame(np.random.randint(0, 2, size=(K, 10), dtype=bool))", "min_run_count": 2, "name": "reindex.DropDuplicates.time_frame_drop_dups_bool", "number": 0, "param_names": ["inplace"], "params": [["True", "False"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "07a191dda9869dd1ff45d8e8c24e5f1dc8743f52d1c79a43aff5caf7138065d4", "warmup_time": -1}, "reindex.DropDuplicates.time_frame_drop_dups_int": {"code": "class DropDuplicates:\n    def time_frame_drop_dups_int(self, inplace):\n        self.df_int.drop_duplicates(inplace=inplace)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass DropDuplicates:\n    def setup(self, inplace):\n        N = 10000\n        K = 10\n        key1 = tm.makeStringIndex(N).values.repeat(K)\n        key2 = tm.makeStringIndex(N).values.repeat(K)\n        self.df = DataFrame(\n            {\"key1\": key1, \"key2\": key2, \"value\": np.random.randn(N * K)}\n        )\n        self.df_nan = self.df.copy()\n        self.df_nan.iloc[:10000, :] = np.nan\n    \n        self.s = Series(np.random.randint(0, 1000, size=10000))\n        self.s_str = Series(np.tile(tm.makeStringIndex(1000).values, 10))\n    \n        N = 1000000\n        K = 10000\n        key1 = np.random.randint(0, K, size=N)\n        self.df_int = DataFrame({\"key1\": key1})\n        self.df_bool = DataFrame(np.random.randint(0, 2, size=(K, 10), dtype=bool))", "min_run_count": 2, "name": "reindex.DropDuplicates.time_frame_drop_dups_int", "number": 0, "param_names": ["inplace"], "params": [["True", "False"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "12a616d1f0f8f398f549d4b0ac3dac2debd8da94ac4c6593e17c7ccd76c2d49f", "warmup_time": -1}, "reindex.DropDuplicates.time_frame_drop_dups_na": {"code": "class DropDuplicates:\n    def time_frame_drop_dups_na(self, inplace):\n        self.df_nan.drop_duplicates([\"key1\", \"key2\"], inplace=inplace)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass DropDuplicates:\n    def setup(self, inplace):\n        N = 10000\n        K = 10\n        key1 = tm.makeStringIndex(N).values.repeat(K)\n        key2 = tm.makeStringIndex(N).values.repeat(K)\n        self.df = DataFrame(\n            {\"key1\": key1, \"key2\": key2, \"value\": np.random.randn(N * K)}\n        )\n        self.df_nan = self.df.copy()\n        self.df_nan.iloc[:10000, :] = np.nan\n    \n        self.s = Series(np.random.randint(0, 1000, size=10000))\n        self.s_str = Series(np.tile(tm.makeStringIndex(1000).values, 10))\n    \n        N = 1000000\n        K = 10000\n        key1 = np.random.randint(0, K, size=N)\n        self.df_int = DataFrame({\"key1\": key1})\n        self.df_bool = DataFrame(np.random.randint(0, 2, size=(K, 10), dtype=bool))", "min_run_count": 2, "name": "reindex.DropDuplicates.time_frame_drop_dups_na", "number": 0, "param_names": ["inplace"], "params": [["True", "False"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "4e56e5907b5b39bbc60adf72b6012b2650441408d0ccdc903c1cb1d2c0ef0e38", "warmup_time": -1}, "reindex.DropDuplicates.time_series_drop_dups_int": {"code": "class DropDuplicates:\n    def time_series_drop_dups_int(self, inplace):\n        self.s.drop_duplicates(inplace=inplace)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass DropDuplicates:\n    def setup(self, inplace):\n        N = 10000\n        K = 10\n        key1 = tm.makeStringIndex(N).values.repeat(K)\n        key2 = tm.makeStringIndex(N).values.repeat(K)\n        self.df = DataFrame(\n            {\"key1\": key1, \"key2\": key2, \"value\": np.random.randn(N * K)}\n        )\n        self.df_nan = self.df.copy()\n        self.df_nan.iloc[:10000, :] = np.nan\n    \n        self.s = Series(np.random.randint(0, 1000, size=10000))\n        self.s_str = Series(np.tile(tm.makeStringIndex(1000).values, 10))\n    \n        N = 1000000\n        K = 10000\n        key1 = np.random.randint(0, K, size=N)\n        self.df_int = DataFrame({\"key1\": key1})\n        self.df_bool = DataFrame(np.random.randint(0, 2, size=(K, 10), dtype=bool))", "min_run_count": 2, "name": "reindex.DropDuplicates.time_series_drop_dups_int", "number": 0, "param_names": ["inplace"], "params": [["True", "False"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "00b3ba44340a5448eea11f3eaf2869149b056d6b590cb8837529de4a00e1eefd", "warmup_time": -1}, "reindex.DropDuplicates.time_series_drop_dups_string": {"code": "class DropDuplicates:\n    def time_series_drop_dups_string(self, inplace):\n        self.s_str.drop_duplicates(inplace=inplace)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass DropDuplicates:\n    def setup(self, inplace):\n        N = 10000\n        K = 10\n        key1 = tm.makeStringIndex(N).values.repeat(K)\n        key2 = tm.makeStringIndex(N).values.repeat(K)\n        self.df = DataFrame(\n            {\"key1\": key1, \"key2\": key2, \"value\": np.random.randn(N * K)}\n        )\n        self.df_nan = self.df.copy()\n        self.df_nan.iloc[:10000, :] = np.nan\n    \n        self.s = Series(np.random.randint(0, 1000, size=10000))\n        self.s_str = Series(np.tile(tm.makeStringIndex(1000).values, 10))\n    \n        N = 1000000\n        K = 10000\n        key1 = np.random.randint(0, K, size=N)\n        self.df_int = DataFrame({\"key1\": key1})\n        self.df_bool = DataFrame(np.random.randint(0, 2, size=(K, 10), dtype=bool))", "min_run_count": 2, "name": "reindex.DropDuplicates.time_series_drop_dups_string", "number": 0, "param_names": ["inplace"], "params": [["True", "False"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "a5aff11532f4e1c1e669a5d97eda9ac45dbe689892e787fc8fd287a623862bd5", "warmup_time": -1}, "reindex.Fillna.time_float_32": {"code": "class Fillna:\n    def time_float_32(self, method):\n        self.ts_float32.fillna(method=method)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Fillna:\n    def setup(self, method):\n        N = 100000\n        self.idx = date_range(\"1/1/2000\", periods=N, freq=\"1min\")\n        ts = Series(np.random.randn(N), index=self.idx)[::2]\n        self.ts_reindexed = ts.reindex(self.idx)\n        self.ts_float32 = self.ts_reindexed.astype(\"float32\")", "min_run_count": 2, "name": "reindex.Fillna.time_float_32", "number": 0, "param_names": ["method"], "params": [["'pad'", "'backfill'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "603854c2615c955a22b92209cae44d5d4b8524235d08f0336c955170faa1ca03", "warmup_time": -1}, "reindex.Fillna.time_reindexed": {"code": "class Fillna:\n    def time_reindexed(self, method):\n        self.ts_reindexed.fillna(method=method)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Fillna:\n    def setup(self, method):\n        N = 100000\n        self.idx = date_range(\"1/1/2000\", periods=N, freq=\"1min\")\n        ts = Series(np.random.randn(N), index=self.idx)[::2]\n        self.ts_reindexed = ts.reindex(self.idx)\n        self.ts_float32 = self.ts_reindexed.astype(\"float32\")", "min_run_count": 2, "name": "reindex.Fillna.time_reindexed", "number": 0, "param_names": ["method"], "params": [["'pad'", "'backfill'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "a1ff25b418f5286adef892c902a1ab7521aefd0fd6cb8f9881c0d86eb0b62533", "warmup_time": -1}, "reindex.LevelAlign.time_align_level": {"code": "class LevelAlign:\n    def time_align_level(self):\n        self.df.align(self.df_level, level=1, copy=False)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass LevelAlign:\n    def setup(self):\n        self.index = MultiIndex(\n            levels=[np.arange(10), np.arange(100), np.arange(100)],\n            codes=[\n                np.arange(10).repeat(10000),\n                np.tile(np.arange(100).repeat(100), 10),\n                np.tile(np.tile(np.arange(100), 100), 10),\n            ],\n        )\n        self.df = DataFrame(np.random.randn(len(self.index), 4), index=self.index)\n        self.df_level = DataFrame(np.random.randn(100, 4), index=self.index.levels[1])", "min_run_count": 2, "name": "reindex.LevelAlign.time_align_level", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "cced19c77cf2154fcd7f760f955314b571a4c552f1c3dda834b08449c39cf96a", "warmup_time": -1}, "reindex.LevelAlign.time_reindex_level": {"code": "class LevelAlign:\n    def time_reindex_level(self):\n        self.df_level.reindex(self.index, level=1)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass LevelAlign:\n    def setup(self):\n        self.index = MultiIndex(\n            levels=[np.arange(10), np.arange(100), np.arange(100)],\n            codes=[\n                np.arange(10).repeat(10000),\n                np.tile(np.arange(100).repeat(100), 10),\n                np.tile(np.tile(np.arange(100), 100), 10),\n            ],\n        )\n        self.df = DataFrame(np.random.randn(len(self.index), 4), index=self.index)\n        self.df_level = DataFrame(np.random.randn(100, 4), index=self.index.levels[1])", "min_run_count": 2, "name": "reindex.LevelAlign.time_reindex_level", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "9c4e829ee0f877d248f2dca88a52830e615dd62d42be7dc5b046cd79771b41d2", "warmup_time": -1}, "reindex.Reindex.time_reindex_columns": {"code": "class Reindex:\n    def time_reindex_columns(self):\n        self.df2.reindex(columns=self.df.columns[1:5])\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Reindex:\n    def setup(self):\n        rng = date_range(start=\"1/1/1970\", periods=10000, freq=\"1min\")\n        self.df = DataFrame(np.random.rand(10000, 10), index=rng, columns=range(10))\n        self.df[\"foo\"] = \"bar\"\n        self.rng_subset = Index(rng[::2])\n        self.df2 = DataFrame(\n            index=range(10000), data=np.random.rand(10000, 30), columns=range(30)\n        )\n        N = 5000\n        K = 200\n        level1 = tm.makeStringIndex(N).values.repeat(K)\n        level2 = np.tile(tm.makeStringIndex(K).values, N)\n        index = MultiIndex.from_arrays([level1, level2])\n        self.s = Series(np.random.randn(N * K), index=index)\n        self.s_subset = self.s[::2]\n        self.s_subset_no_cache = self.s[::2].copy()\n    \n        mi = MultiIndex.from_product([rng, range(100)])\n        self.s2 = Series(np.random.randn(len(mi)), index=mi)\n        self.s2_subset = self.s2[::2].copy()", "min_run_count": 2, "name": "reindex.Reindex.time_reindex_columns", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "d736c382558e423ce3f118dc4c679178358ee153b5a9a75520028a69266bd93c", "warmup_time": -1}, "reindex.Reindex.time_reindex_dates": {"code": "class Reindex:\n    def time_reindex_dates(self):\n        self.df.reindex(self.rng_subset)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Reindex:\n    def setup(self):\n        rng = date_range(start=\"1/1/1970\", periods=10000, freq=\"1min\")\n        self.df = DataFrame(np.random.rand(10000, 10), index=rng, columns=range(10))\n        self.df[\"foo\"] = \"bar\"\n        self.rng_subset = Index(rng[::2])\n        self.df2 = DataFrame(\n            index=range(10000), data=np.random.rand(10000, 30), columns=range(30)\n        )\n        N = 5000\n        K = 200\n        level1 = tm.makeStringIndex(N).values.repeat(K)\n        level2 = np.tile(tm.makeStringIndex(K).values, N)\n        index = MultiIndex.from_arrays([level1, level2])\n        self.s = Series(np.random.randn(N * K), index=index)\n        self.s_subset = self.s[::2]\n        self.s_subset_no_cache = self.s[::2].copy()\n    \n        mi = MultiIndex.from_product([rng, range(100)])\n        self.s2 = Series(np.random.randn(len(mi)), index=mi)\n        self.s2_subset = self.s2[::2].copy()", "min_run_count": 2, "name": "reindex.Reindex.time_reindex_dates", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "5dd72b1d62d4e2f13dce28f4cbfc270e6adb9b2f80fc09ba783f93b948a25cf5", "warmup_time": -1}, "reindex.Reindex.time_reindex_multiindex_no_cache": {"code": "class Reindex:\n    def time_reindex_multiindex_no_cache(self):\n        # Copy to avoid MultiIndex._values getting cached\n        self.s.reindex(self.s_subset_no_cache.index.copy())\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Reindex:\n    def setup(self):\n        rng = date_range(start=\"1/1/1970\", periods=10000, freq=\"1min\")\n        self.df = DataFrame(np.random.rand(10000, 10), index=rng, columns=range(10))\n        self.df[\"foo\"] = \"bar\"\n        self.rng_subset = Index(rng[::2])\n        self.df2 = DataFrame(\n            index=range(10000), data=np.random.rand(10000, 30), columns=range(30)\n        )\n        N = 5000\n        K = 200\n        level1 = tm.makeStringIndex(N).values.repeat(K)\n        level2 = np.tile(tm.makeStringIndex(K).values, N)\n        index = MultiIndex.from_arrays([level1, level2])\n        self.s = Series(np.random.randn(N * K), index=index)\n        self.s_subset = self.s[::2]\n        self.s_subset_no_cache = self.s[::2].copy()\n    \n        mi = MultiIndex.from_product([rng, range(100)])\n        self.s2 = Series(np.random.randn(len(mi)), index=mi)\n        self.s2_subset = self.s2[::2].copy()", "min_run_count": 2, "name": "reindex.Reindex.time_reindex_multiindex_no_cache", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "e4db7ca546b43f1b9828c7cbdda698dd3c77a95fb67b27bcea00cec27878310e", "warmup_time": -1}, "reindex.Reindex.time_reindex_multiindex_no_cache_dates": {"code": "class Reindex:\n    def time_reindex_multiindex_no_cache_dates(self):\n        # Copy to avoid MultiIndex._values getting cached\n        self.s2_subset.reindex(self.s2.index.copy())\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Reindex:\n    def setup(self):\n        rng = date_range(start=\"1/1/1970\", periods=10000, freq=\"1min\")\n        self.df = DataFrame(np.random.rand(10000, 10), index=rng, columns=range(10))\n        self.df[\"foo\"] = \"bar\"\n        self.rng_subset = Index(rng[::2])\n        self.df2 = DataFrame(\n            index=range(10000), data=np.random.rand(10000, 30), columns=range(30)\n        )\n        N = 5000\n        K = 200\n        level1 = tm.makeStringIndex(N).values.repeat(K)\n        level2 = np.tile(tm.makeStringIndex(K).values, N)\n        index = MultiIndex.from_arrays([level1, level2])\n        self.s = Series(np.random.randn(N * K), index=index)\n        self.s_subset = self.s[::2]\n        self.s_subset_no_cache = self.s[::2].copy()\n    \n        mi = MultiIndex.from_product([rng, range(100)])\n        self.s2 = Series(np.random.randn(len(mi)), index=mi)\n        self.s2_subset = self.s2[::2].copy()", "min_run_count": 2, "name": "reindex.Reindex.time_reindex_multiindex_no_cache_dates", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "8170611d9272f1557beb04fce8043939f3603cc4d563dadfe5494d38efa54824", "warmup_time": -1}, "reindex.Reindex.time_reindex_multiindex_with_cache": {"code": "class Reindex:\n    def time_reindex_multiindex_with_cache(self):\n        # MultiIndex._values gets cached\n        self.s.reindex(self.s_subset.index)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Reindex:\n    def setup(self):\n        rng = date_range(start=\"1/1/1970\", periods=10000, freq=\"1min\")\n        self.df = DataFrame(np.random.rand(10000, 10), index=rng, columns=range(10))\n        self.df[\"foo\"] = \"bar\"\n        self.rng_subset = Index(rng[::2])\n        self.df2 = DataFrame(\n            index=range(10000), data=np.random.rand(10000, 30), columns=range(30)\n        )\n        N = 5000\n        K = 200\n        level1 = tm.makeStringIndex(N).values.repeat(K)\n        level2 = np.tile(tm.makeStringIndex(K).values, N)\n        index = MultiIndex.from_arrays([level1, level2])\n        self.s = Series(np.random.randn(N * K), index=index)\n        self.s_subset = self.s[::2]\n        self.s_subset_no_cache = self.s[::2].copy()\n    \n        mi = MultiIndex.from_product([rng, range(100)])\n        self.s2 = Series(np.random.randn(len(mi)), index=mi)\n        self.s2_subset = self.s2[::2].copy()", "min_run_count": 2, "name": "reindex.Reindex.time_reindex_multiindex_with_cache", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "f271a063d57d787077862f0382183a06c57df4b8e48e89a165513dfff9152e65", "warmup_time": -1}, "reindex.ReindexMethod.time_reindex_method": {"code": "class ReindexMethod:\n    def time_reindex_method(self, method, constructor):\n        self.ts.reindex(self.idx, method=method)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ReindexMethod:\n    def setup(self, method, constructor):\n        N = 100000\n        self.idx = constructor(\"1/1/2000\", periods=N, freq=\"1min\")\n        self.ts = Series(np.random.randn(N), index=self.idx)[::2]", "min_run_count": 2, "name": "reindex.ReindexMethod.time_reindex_method", "number": 0, "param_names": ["method", "constructor"], "params": [["'pad'", "'backfill'"], ["<function date_range>", "<function period_range>"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "52e66df756313fc255334a8a0cb3c1dbaf796d0b655126ff3c140d0a2207a3bc", "warmup_time": -1}, "replace.Convert.time_replace": {"code": "class Convert:\n    def time_replace(self, constructor, replace_data):\n        self.data.replace(self.to_replace)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Convert:\n    def setup(self, constructor, replace_data):\n        N = 10**3\n        data = {\n            \"Series\": pd.Series(np.random.randint(N, size=N)),\n            \"DataFrame\": pd.DataFrame(\n                {\"A\": np.random.randint(N, size=N), \"B\": np.random.randint(N, size=N)}\n            ),\n        }\n        self.to_replace = {i: getattr(pd, replace_data) for i in range(N)}\n        self.data = data[constructor]", "min_run_count": 2, "name": "replace.Convert.time_replace", "number": 0, "param_names": ["constructor", "replace_data"], "params": [["'DataFrame'", "'Series'"], ["'Timestamp'", "'Timedelta'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "a744fa5ba9e82cf960d86890e5316fd597568f0134b134ef39e6a068d4a6fcaa", "warmup_time": -1}, "replace.FillNa.time_fillna": {"code": "class FillNa:\n    def time_fillna(self, inplace):\n        self.ts.fillna(0.0, inplace=inplace)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass FillNa:\n    def setup(self, inplace):\n        N = 10**6\n        rng = pd.date_range(\"1/1/2000\", periods=N, freq=\"min\")\n        data = np.random.randn(N)\n        data[::2] = np.nan\n        self.ts = pd.Series(data, index=rng)", "min_run_count": 2, "name": "replace.FillNa.time_fillna", "number": 0, "param_names": ["inplace"], "params": [["True", "False"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "0b76c4847fb4ab0037ada56a69ae0191854beb20a29f7c1fdb937679f1a20cfa", "warmup_time": -1}, "replace.FillNa.time_replace": {"code": "class FillNa:\n    def time_replace(self, inplace):\n        self.ts.replace(np.nan, 0.0, inplace=inplace)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass FillNa:\n    def setup(self, inplace):\n        N = 10**6\n        rng = pd.date_range(\"1/1/2000\", periods=N, freq=\"min\")\n        data = np.random.randn(N)\n        data[::2] = np.nan\n        self.ts = pd.Series(data, index=rng)", "min_run_count": 2, "name": "replace.FillNa.time_replace", "number": 0, "param_names": ["inplace"], "params": [["True", "False"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "ce112dec862dc388710999d0a5afaf6410c6e73eb37747f783c8f0f031390817", "warmup_time": -1}, "replace.ReplaceDict.time_replace_series": {"code": "class ReplaceDict:\n    def time_replace_series(self, inplace):\n        self.s.replace(self.to_rep, inplace=inplace)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ReplaceDict:\n    def setup(self, inplace):\n        N = 10**5\n        start_value = 10**5\n        self.to_rep = dict(enumerate(np.arange(N) + start_value))\n        self.s = pd.Series(np.random.randint(N, size=10**3))", "min_run_count": 2, "name": "replace.ReplaceDict.time_replace_series", "number": 0, "param_names": ["inplace"], "params": [["True", "False"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "8597d90cda40f0b788096a546f8abbf5caa952c6eea9f9e47eb8d4ce2d3c1aa2", "warmup_time": -1}, "replace.ReplaceList.time_replace_list": {"code": "class ReplaceList:\n    def time_replace_list(self, inplace):\n        self.df.replace([np.inf, -np.inf], np.nan, inplace=inplace)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ReplaceList:\n    def setup(self, inplace):\n        self.df = pd.DataFrame({\"A\": 0, \"B\": 0}, index=range(4 * 10**7))", "min_run_count": 2, "name": "replace.ReplaceList.time_replace_list", "number": 0, "param_names": ["inplace"], "params": [["True", "False"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "b83839f3b0ab7b066f2981fb89ce717d6efe61a8e0ceec49e62cf34e93d25574", "warmup_time": -1}, "replace.ReplaceList.time_replace_list_one_match": {"code": "class ReplaceList:\n    def time_replace_list_one_match(self, inplace):\n        # the 1 can be held in self._df.blocks[0], while the inf and -inf can't\n        self.df.replace([np.inf, -np.inf, 1], np.nan, inplace=inplace)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ReplaceList:\n    def setup(self, inplace):\n        self.df = pd.DataFrame({\"A\": 0, \"B\": 0}, index=range(4 * 10**7))", "min_run_count": 2, "name": "replace.ReplaceList.time_replace_list_one_match", "number": 0, "param_names": ["inplace"], "params": [["True", "False"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "23a9d275429ac396e005aaa7402a2da8d09bda88a06976371866e38aee41c6be", "warmup_time": -1}, "reshape.Crosstab.time_crosstab": {"code": "class Crosstab:\n    def time_crosstab(self):\n        pd.crosstab(self.vec1, self.vec2)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Crosstab:\n    def setup(self):\n        N = 100000\n        fac1 = np.array([\"A\", \"B\", \"C\"], dtype=\"O\")\n        fac2 = np.array([\"one\", \"two\"], dtype=\"O\")\n        self.ind1 = np.random.randint(0, 3, size=N)\n        self.ind2 = np.random.randint(0, 2, size=N)\n        self.vec1 = fac1.take(self.ind1)\n        self.vec2 = fac2.take(self.ind2)", "min_run_count": 2, "name": "reshape.Crosstab.time_crosstab", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "9111a9ad9a258688c45ba6a0c05b7b226f360b676432ed650b695e5397fde93e", "warmup_time": -1}, "reshape.Crosstab.time_crosstab_normalize": {"code": "class Crosstab:\n    def time_crosstab_normalize(self):\n        pd.crosstab(self.vec1, self.vec2, normalize=True)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Crosstab:\n    def setup(self):\n        N = 100000\n        fac1 = np.array([\"A\", \"B\", \"C\"], dtype=\"O\")\n        fac2 = np.array([\"one\", \"two\"], dtype=\"O\")\n        self.ind1 = np.random.randint(0, 3, size=N)\n        self.ind2 = np.random.randint(0, 2, size=N)\n        self.vec1 = fac1.take(self.ind1)\n        self.vec2 = fac2.take(self.ind2)", "min_run_count": 2, "name": "reshape.Crosstab.time_crosstab_normalize", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "5aca65001068430d0914d98785bddb8561273e9c8aa15b387c7dd93043ebf568", "warmup_time": -1}, "reshape.Crosstab.time_crosstab_normalize_margins": {"code": "class Crosstab:\n    def time_crosstab_normalize_margins(self):\n        pd.crosstab(self.vec1, self.vec2, normalize=True, margins=True)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Crosstab:\n    def setup(self):\n        N = 100000\n        fac1 = np.array([\"A\", \"B\", \"C\"], dtype=\"O\")\n        fac2 = np.array([\"one\", \"two\"], dtype=\"O\")\n        self.ind1 = np.random.randint(0, 3, size=N)\n        self.ind2 = np.random.randint(0, 2, size=N)\n        self.vec1 = fac1.take(self.ind1)\n        self.vec2 = fac2.take(self.ind2)", "min_run_count": 2, "name": "reshape.Crosstab.time_crosstab_normalize_margins", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "4c136fc000722c789e91a8ae69e2c658c5bedd669b2178c0fc2a1f4f2b42727b", "warmup_time": -1}, "reshape.Crosstab.time_crosstab_values": {"code": "class Crosstab:\n    def time_crosstab_values(self):\n        pd.crosstab(self.vec1, self.vec2, values=self.ind1, aggfunc=\"sum\")\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Crosstab:\n    def setup(self):\n        N = 100000\n        fac1 = np.array([\"A\", \"B\", \"C\"], dtype=\"O\")\n        fac2 = np.array([\"one\", \"two\"], dtype=\"O\")\n        self.ind1 = np.random.randint(0, 3, size=N)\n        self.ind2 = np.random.randint(0, 2, size=N)\n        self.vec1 = fac1.take(self.ind1)\n        self.vec2 = fac2.take(self.ind2)", "min_run_count": 2, "name": "reshape.Crosstab.time_crosstab_values", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "3b4ec27deb69daa12d4b65e15cc4b7b2edcc88df3a066962121c333f57a3423e", "warmup_time": -1}, "reshape.Cut.peakmem_cut_interval": {"code": "class Cut:\n    def peakmem_cut_interval(self, bins):\n        # GH 27668\n        pd.cut(self.int_series, self.interval_bins)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Cut:\n    def setup(self, bins):\n        N = 10**5\n        self.int_series = pd.Series(np.arange(N).repeat(5))\n        self.float_series = pd.Series(np.random.randn(N).repeat(5))\n        self.timedelta_series = pd.Series(\n            np.random.randint(N, size=N), dtype=\"timedelta64[ns]\"\n        )\n        self.datetime_series = pd.Series(\n            np.random.randint(N, size=N), dtype=\"datetime64[ns]\"\n        )\n        self.interval_bins = pd.IntervalIndex.from_breaks(np.linspace(0, N, bins))", "name": "reshape.Cut.peakmem_cut_interval", "param_names": ["bins"], "params": [["4", "10", "1000"]], "timeout": 60.0, "type": "peakmemory", "unit": "bytes", "version": "4a50cdb22148145d78b66b3246a5d917de2b2b2c2a79baab6c336150c6028996"}, "reshape.Cut.time_cut_datetime": {"code": "class Cut:\n    def time_cut_datetime(self, bins):\n        pd.cut(self.datetime_series, bins)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Cut:\n    def setup(self, bins):\n        N = 10**5\n        self.int_series = pd.Series(np.arange(N).repeat(5))\n        self.float_series = pd.Series(np.random.randn(N).repeat(5))\n        self.timedelta_series = pd.Series(\n            np.random.randint(N, size=N), dtype=\"timedelta64[ns]\"\n        )\n        self.datetime_series = pd.Series(\n            np.random.randint(N, size=N), dtype=\"datetime64[ns]\"\n        )\n        self.interval_bins = pd.IntervalIndex.from_breaks(np.linspace(0, N, bins))", "min_run_count": 2, "name": "reshape.Cut.time_cut_datetime", "number": 0, "param_names": ["bins"], "params": [["4", "10", "1000"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "58412e44ffc063ce05ec9eabf6599316b54c12e85398a5cd91280e5f2eaec7de", "warmup_time": -1}, "reshape.Cut.time_cut_float": {"code": "class Cut:\n    def time_cut_float(self, bins):\n        pd.cut(self.float_series, bins)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Cut:\n    def setup(self, bins):\n        N = 10**5\n        self.int_series = pd.Series(np.arange(N).repeat(5))\n        self.float_series = pd.Series(np.random.randn(N).repeat(5))\n        self.timedelta_series = pd.Series(\n            np.random.randint(N, size=N), dtype=\"timedelta64[ns]\"\n        )\n        self.datetime_series = pd.Series(\n            np.random.randint(N, size=N), dtype=\"datetime64[ns]\"\n        )\n        self.interval_bins = pd.IntervalIndex.from_breaks(np.linspace(0, N, bins))", "min_run_count": 2, "name": "reshape.Cut.time_cut_float", "number": 0, "param_names": ["bins"], "params": [["4", "10", "1000"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "85096ca698be2f3208680d4f35d7aeded90a2e9795781508cbc5dfdf35e7e36b", "warmup_time": -1}, "reshape.Cut.time_cut_int": {"code": "class Cut:\n    def time_cut_int(self, bins):\n        pd.cut(self.int_series, bins)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Cut:\n    def setup(self, bins):\n        N = 10**5\n        self.int_series = pd.Series(np.arange(N).repeat(5))\n        self.float_series = pd.Series(np.random.randn(N).repeat(5))\n        self.timedelta_series = pd.Series(\n            np.random.randint(N, size=N), dtype=\"timedelta64[ns]\"\n        )\n        self.datetime_series = pd.Series(\n            np.random.randint(N, size=N), dtype=\"datetime64[ns]\"\n        )\n        self.interval_bins = pd.IntervalIndex.from_breaks(np.linspace(0, N, bins))", "min_run_count": 2, "name": "reshape.Cut.time_cut_int", "number": 0, "param_names": ["bins"], "params": [["4", "10", "1000"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "e8b43cd5e06cec8978579ef14b528be88fb90d1577ba5cc34c0c00559616d982", "warmup_time": -1}, "reshape.Cut.time_cut_interval": {"code": "class Cut:\n    def time_cut_interval(self, bins):\n        # GH 27668\n        pd.cut(self.int_series, self.interval_bins)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Cut:\n    def setup(self, bins):\n        N = 10**5\n        self.int_series = pd.Series(np.arange(N).repeat(5))\n        self.float_series = pd.Series(np.random.randn(N).repeat(5))\n        self.timedelta_series = pd.Series(\n            np.random.randint(N, size=N), dtype=\"timedelta64[ns]\"\n        )\n        self.datetime_series = pd.Series(\n            np.random.randint(N, size=N), dtype=\"datetime64[ns]\"\n        )\n        self.interval_bins = pd.IntervalIndex.from_breaks(np.linspace(0, N, bins))", "min_run_count": 2, "name": "reshape.Cut.time_cut_interval", "number": 0, "param_names": ["bins"], "params": [["4", "10", "1000"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "379c2ec4450e760810c91f3626fdd11aad35e5d872d5b8912a9db3362f42e133", "warmup_time": -1}, "reshape.Cut.time_cut_timedelta": {"code": "class Cut:\n    def time_cut_timedelta(self, bins):\n        pd.cut(self.timedelta_series, bins)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Cut:\n    def setup(self, bins):\n        N = 10**5\n        self.int_series = pd.Series(np.arange(N).repeat(5))\n        self.float_series = pd.Series(np.random.randn(N).repeat(5))\n        self.timedelta_series = pd.Series(\n            np.random.randint(N, size=N), dtype=\"timedelta64[ns]\"\n        )\n        self.datetime_series = pd.Series(\n            np.random.randint(N, size=N), dtype=\"datetime64[ns]\"\n        )\n        self.interval_bins = pd.IntervalIndex.from_breaks(np.linspace(0, N, bins))", "min_run_count": 2, "name": "reshape.Cut.time_cut_timedelta", "number": 0, "param_names": ["bins"], "params": [["4", "10", "1000"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "758ab752e664d48441ccb021304bc8e71171846cee22a64b2e72be3351f00447", "warmup_time": -1}, "reshape.Cut.time_qcut_datetime": {"code": "class Cut:\n    def time_qcut_datetime(self, bins):\n        pd.qcut(self.datetime_series, bins)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Cut:\n    def setup(self, bins):\n        N = 10**5\n        self.int_series = pd.Series(np.arange(N).repeat(5))\n        self.float_series = pd.Series(np.random.randn(N).repeat(5))\n        self.timedelta_series = pd.Series(\n            np.random.randint(N, size=N), dtype=\"timedelta64[ns]\"\n        )\n        self.datetime_series = pd.Series(\n            np.random.randint(N, size=N), dtype=\"datetime64[ns]\"\n        )\n        self.interval_bins = pd.IntervalIndex.from_breaks(np.linspace(0, N, bins))", "min_run_count": 2, "name": "reshape.Cut.time_qcut_datetime", "number": 0, "param_names": ["bins"], "params": [["4", "10", "1000"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "d04a2db349c29907a75caab0e3a9c580e577e50262df736e1650eb96f77d134d", "warmup_time": -1}, "reshape.Cut.time_qcut_float": {"code": "class Cut:\n    def time_qcut_float(self, bins):\n        pd.qcut(self.float_series, bins)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Cut:\n    def setup(self, bins):\n        N = 10**5\n        self.int_series = pd.Series(np.arange(N).repeat(5))\n        self.float_series = pd.Series(np.random.randn(N).repeat(5))\n        self.timedelta_series = pd.Series(\n            np.random.randint(N, size=N), dtype=\"timedelta64[ns]\"\n        )\n        self.datetime_series = pd.Series(\n            np.random.randint(N, size=N), dtype=\"datetime64[ns]\"\n        )\n        self.interval_bins = pd.IntervalIndex.from_breaks(np.linspace(0, N, bins))", "min_run_count": 2, "name": "reshape.Cut.time_qcut_float", "number": 0, "param_names": ["bins"], "params": [["4", "10", "1000"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "0482097ddcc850236edbae620fd920d073c84d385fe332eaefbfb40041f64df2", "warmup_time": -1}, "reshape.Cut.time_qcut_int": {"code": "class Cut:\n    def time_qcut_int(self, bins):\n        pd.qcut(self.int_series, bins)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Cut:\n    def setup(self, bins):\n        N = 10**5\n        self.int_series = pd.Series(np.arange(N).repeat(5))\n        self.float_series = pd.Series(np.random.randn(N).repeat(5))\n        self.timedelta_series = pd.Series(\n            np.random.randint(N, size=N), dtype=\"timedelta64[ns]\"\n        )\n        self.datetime_series = pd.Series(\n            np.random.randint(N, size=N), dtype=\"datetime64[ns]\"\n        )\n        self.interval_bins = pd.IntervalIndex.from_breaks(np.linspace(0, N, bins))", "min_run_count": 2, "name": "reshape.Cut.time_qcut_int", "number": 0, "param_names": ["bins"], "params": [["4", "10", "1000"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "83d5a7e00e70a8e2dae57a0f38abad70d2db20c1bc5fe39c202f1d94ba5f6360", "warmup_time": -1}, "reshape.Cut.time_qcut_timedelta": {"code": "class Cut:\n    def time_qcut_timedelta(self, bins):\n        pd.qcut(self.timedelta_series, bins)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Cut:\n    def setup(self, bins):\n        N = 10**5\n        self.int_series = pd.Series(np.arange(N).repeat(5))\n        self.float_series = pd.Series(np.random.randn(N).repeat(5))\n        self.timedelta_series = pd.Series(\n            np.random.randint(N, size=N), dtype=\"timedelta64[ns]\"\n        )\n        self.datetime_series = pd.Series(\n            np.random.randint(N, size=N), dtype=\"datetime64[ns]\"\n        )\n        self.interval_bins = pd.IntervalIndex.from_breaks(np.linspace(0, N, bins))", "min_run_count": 2, "name": "reshape.Cut.time_qcut_timedelta", "number": 0, "param_names": ["bins"], "params": [["4", "10", "1000"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "ce5e325613d980c2c58926140ecd066ba1caa5ff13d1f13c4b028bf98cb83b0f", "warmup_time": -1}, "reshape.Explode.time_explode": {"code": "class Explode:\n    def time_explode(self, n_rows, max_list_length):\n        self.series.explode()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Explode:\n    def setup(self, n_rows, max_list_length):\n        data = [np.arange(np.random.randint(max_list_length)) for _ in range(n_rows)]\n        self.series = pd.Series(data)", "min_run_count": 2, "name": "reshape.Explode.time_explode", "number": 0, "param_names": ["n_rows", "max_list_length"], "params": [["100", "1000", "10000"], ["3", "5", "10"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "1e8e8da03418f2a12d85f80f073278296ec8c8f9e43fc8bcc690b704c5f258de", "warmup_time": -1}, "reshape.GetDummies.time_get_dummies_1d": {"code": "class GetDummies:\n    def time_get_dummies_1d(self):\n        pd.get_dummies(self.s, sparse=False)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass GetDummies:\n    def setup(self):\n        categories = list(string.ascii_letters[:12])\n        s = pd.Series(\n            np.random.choice(categories, size=1000000),\n            dtype=CategoricalDtype(categories),\n        )\n        self.s = s", "min_run_count": 2, "name": "reshape.GetDummies.time_get_dummies_1d", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "f6981c8b44fbd13f60eff496356529e393625318426d340155a55ed3d7ffb4ee", "warmup_time": -1}, "reshape.GetDummies.time_get_dummies_1d_sparse": {"code": "class GetDummies:\n    def time_get_dummies_1d_sparse(self):\n        pd.get_dummies(self.s, sparse=True)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass GetDummies:\n    def setup(self):\n        categories = list(string.ascii_letters[:12])\n        s = pd.Series(\n            np.random.choice(categories, size=1000000),\n            dtype=CategoricalDtype(categories),\n        )\n        self.s = s", "min_run_count": 2, "name": "reshape.GetDummies.time_get_dummies_1d_sparse", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "f4b85a94bf96350e6ae89b0267fcb36cf05e306063a0915e425fc9e5a1a4467e", "warmup_time": -1}, "reshape.Melt.time_melt_dataframe": {"code": "class Melt:\n    def time_melt_dataframe(self, dtype):\n        melt(self.df, id_vars=[\"id1\", \"id2\"])\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Melt:\n    def setup(self, dtype):\n        self.df = DataFrame(\n            np.random.randn(100_000, 3), columns=[\"A\", \"B\", \"C\"], dtype=dtype\n        )\n        self.df[\"id1\"] = pd.Series(np.random.randint(0, 10, 10000))\n        self.df[\"id2\"] = pd.Series(np.random.randint(100, 1000, 10000))", "min_run_count": 2, "name": "reshape.Melt.time_melt_dataframe", "number": 0, "param_names": ["dtype"], "params": [["'float64'", "'Float64'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "22a1727a0e67859dc0ec65b547a3d44f8c9725863c959eba27153fb0d8f66d4c", "warmup_time": -1}, "reshape.Pivot.time_reshape_pivot_time_series": {"code": "class Pivot:\n    def time_reshape_pivot_time_series(self):\n        self.df.pivot(index=\"date\", columns=\"variable\", values=\"value\")\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Pivot:\n    def setup(self):\n        N = 10000\n        index = date_range(\"1/1/2000\", periods=N, freq=\"h\")\n        data = {\n            \"value\": np.random.randn(N * 50),\n            \"variable\": np.arange(50).repeat(N),\n            \"date\": np.tile(index.values, 50),\n        }\n        self.df = DataFrame(data)", "min_run_count": 2, "name": "reshape.Pivot.time_reshape_pivot_time_series", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "7466faab8bdadd61fa94c30f9a91cca68cb993c7d0bcf34c64f2b9a31994d7b8", "warmup_time": -1}, "reshape.PivotTable.time_pivot_table": {"code": "class PivotTable:\n    def time_pivot_table(self):\n        self.df.pivot_table(index=\"key1\", columns=[\"key2\", \"key3\"])\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass PivotTable:\n    def setup(self):\n        N = 100000\n        fac1 = np.array([\"A\", \"B\", \"C\"], dtype=\"O\")\n        fac2 = np.array([\"one\", \"two\"], dtype=\"O\")\n        ind1 = np.random.randint(0, 3, size=N)\n        ind2 = np.random.randint(0, 2, size=N)\n        self.df = DataFrame(\n            {\n                \"key1\": fac1.take(ind1),\n                \"key2\": fac2.take(ind2),\n                \"key3\": fac2.take(ind2),\n                \"value1\": np.random.randn(N),\n                \"value2\": np.random.randn(N),\n                \"value3\": np.random.randn(N),\n            }\n        )\n        self.df2 = DataFrame(\n            {\"col1\": list(\"abcde\"), \"col2\": list(\"fghij\"), \"col3\": [1, 2, 3, 4, 5]}\n        )\n        self.df2.col1 = self.df2.col1.astype(\"category\")\n        self.df2.col2 = self.df2.col2.astype(\"category\")", "min_run_count": 2, "name": "reshape.PivotTable.time_pivot_table", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "03f1827427df23f7923b9d2b4ff8790a8896570fbbccf7ccd79cda77f3b29fb6", "warmup_time": -1}, "reshape.PivotTable.time_pivot_table_agg": {"code": "class PivotTable:\n    def time_pivot_table_agg(self):\n        self.df.pivot_table(\n            index=\"key1\", columns=[\"key2\", \"key3\"], aggfunc=[\"sum\", \"mean\"]\n        )\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass PivotTable:\n    def setup(self):\n        N = 100000\n        fac1 = np.array([\"A\", \"B\", \"C\"], dtype=\"O\")\n        fac2 = np.array([\"one\", \"two\"], dtype=\"O\")\n        ind1 = np.random.randint(0, 3, size=N)\n        ind2 = np.random.randint(0, 2, size=N)\n        self.df = DataFrame(\n            {\n                \"key1\": fac1.take(ind1),\n                \"key2\": fac2.take(ind2),\n                \"key3\": fac2.take(ind2),\n                \"value1\": np.random.randn(N),\n                \"value2\": np.random.randn(N),\n                \"value3\": np.random.randn(N),\n            }\n        )\n        self.df2 = DataFrame(\n            {\"col1\": list(\"abcde\"), \"col2\": list(\"fghij\"), \"col3\": [1, 2, 3, 4, 5]}\n        )\n        self.df2.col1 = self.df2.col1.astype(\"category\")\n        self.df2.col2 = self.df2.col2.astype(\"category\")", "min_run_count": 2, "name": "reshape.PivotTable.time_pivot_table_agg", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "e31596884db26ad8a96fbca432b50937254b59d0e4139cefbc2d930b6835d13b", "warmup_time": -1}, "reshape.PivotTable.time_pivot_table_categorical": {"code": "class PivotTable:\n    def time_pivot_table_categorical(self):\n        self.df2.pivot_table(\n            index=\"col1\", values=\"col3\", columns=\"col2\", aggfunc=np.sum, fill_value=0\n        )\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass PivotTable:\n    def setup(self):\n        N = 100000\n        fac1 = np.array([\"A\", \"B\", \"C\"], dtype=\"O\")\n        fac2 = np.array([\"one\", \"two\"], dtype=\"O\")\n        ind1 = np.random.randint(0, 3, size=N)\n        ind2 = np.random.randint(0, 2, size=N)\n        self.df = DataFrame(\n            {\n                \"key1\": fac1.take(ind1),\n                \"key2\": fac2.take(ind2),\n                \"key3\": fac2.take(ind2),\n                \"value1\": np.random.randn(N),\n                \"value2\": np.random.randn(N),\n                \"value3\": np.random.randn(N),\n            }\n        )\n        self.df2 = DataFrame(\n            {\"col1\": list(\"abcde\"), \"col2\": list(\"fghij\"), \"col3\": [1, 2, 3, 4, 5]}\n        )\n        self.df2.col1 = self.df2.col1.astype(\"category\")\n        self.df2.col2 = self.df2.col2.astype(\"category\")", "min_run_count": 2, "name": "reshape.PivotTable.time_pivot_table_categorical", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "9ef4ae37c73ff3879061357527840ad44914df57b2018d7659a559efef8c85bd", "warmup_time": -1}, "reshape.PivotTable.time_pivot_table_categorical_observed": {"code": "class PivotTable:\n    def time_pivot_table_categorical_observed(self):\n        self.df2.pivot_table(\n            index=\"col1\",\n            values=\"col3\",\n            columns=\"col2\",\n            aggfunc=np.sum,\n            fill_value=0,\n            observed=True,\n        )\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass PivotTable:\n    def setup(self):\n        N = 100000\n        fac1 = np.array([\"A\", \"B\", \"C\"], dtype=\"O\")\n        fac2 = np.array([\"one\", \"two\"], dtype=\"O\")\n        ind1 = np.random.randint(0, 3, size=N)\n        ind2 = np.random.randint(0, 2, size=N)\n        self.df = DataFrame(\n            {\n                \"key1\": fac1.take(ind1),\n                \"key2\": fac2.take(ind2),\n                \"key3\": fac2.take(ind2),\n                \"value1\": np.random.randn(N),\n                \"value2\": np.random.randn(N),\n                \"value3\": np.random.randn(N),\n            }\n        )\n        self.df2 = DataFrame(\n            {\"col1\": list(\"abcde\"), \"col2\": list(\"fghij\"), \"col3\": [1, 2, 3, 4, 5]}\n        )\n        self.df2.col1 = self.df2.col1.astype(\"category\")\n        self.df2.col2 = self.df2.col2.astype(\"category\")", "min_run_count": 2, "name": "reshape.PivotTable.time_pivot_table_categorical_observed", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "431e23a2024cc29bc9b1fe0ec05dc21a362cc6acf6d87b93b9f0c52b56163874", "warmup_time": -1}, "reshape.PivotTable.time_pivot_table_margins": {"code": "class PivotTable:\n    def time_pivot_table_margins(self):\n        self.df.pivot_table(index=\"key1\", columns=[\"key2\", \"key3\"], margins=True)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass PivotTable:\n    def setup(self):\n        N = 100000\n        fac1 = np.array([\"A\", \"B\", \"C\"], dtype=\"O\")\n        fac2 = np.array([\"one\", \"two\"], dtype=\"O\")\n        ind1 = np.random.randint(0, 3, size=N)\n        ind2 = np.random.randint(0, 2, size=N)\n        self.df = DataFrame(\n            {\n                \"key1\": fac1.take(ind1),\n                \"key2\": fac2.take(ind2),\n                \"key3\": fac2.take(ind2),\n                \"value1\": np.random.randn(N),\n                \"value2\": np.random.randn(N),\n                \"value3\": np.random.randn(N),\n            }\n        )\n        self.df2 = DataFrame(\n            {\"col1\": list(\"abcde\"), \"col2\": list(\"fghij\"), \"col3\": [1, 2, 3, 4, 5]}\n        )\n        self.df2.col1 = self.df2.col1.astype(\"category\")\n        self.df2.col2 = self.df2.col2.astype(\"category\")", "min_run_count": 2, "name": "reshape.PivotTable.time_pivot_table_margins", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "0afefd1f2578cc7e47b9f9ef6791eac3f77b8ec807c5725b2ef687d228c99241", "warmup_time": -1}, "reshape.PivotTable.time_pivot_table_margins_only_column": {"code": "class PivotTable:\n    def time_pivot_table_margins_only_column(self):\n        self.df.pivot_table(columns=[\"key1\", \"key2\", \"key3\"], margins=True)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass PivotTable:\n    def setup(self):\n        N = 100000\n        fac1 = np.array([\"A\", \"B\", \"C\"], dtype=\"O\")\n        fac2 = np.array([\"one\", \"two\"], dtype=\"O\")\n        ind1 = np.random.randint(0, 3, size=N)\n        ind2 = np.random.randint(0, 2, size=N)\n        self.df = DataFrame(\n            {\n                \"key1\": fac1.take(ind1),\n                \"key2\": fac2.take(ind2),\n                \"key3\": fac2.take(ind2),\n                \"value1\": np.random.randn(N),\n                \"value2\": np.random.randn(N),\n                \"value3\": np.random.randn(N),\n            }\n        )\n        self.df2 = DataFrame(\n            {\"col1\": list(\"abcde\"), \"col2\": list(\"fghij\"), \"col3\": [1, 2, 3, 4, 5]}\n        )\n        self.df2.col1 = self.df2.col1.astype(\"category\")\n        self.df2.col2 = self.df2.col2.astype(\"category\")", "min_run_count": 2, "name": "reshape.PivotTable.time_pivot_table_margins_only_column", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "21e105d206932a8572d6c9e47758f4bc5a6ee77cb384c346e1d145fd2bb9bbfe", "warmup_time": -1}, "reshape.ReshapeExtensionDtype.time_stack": {"code": "class ReshapeExtensionDtype:\n    def time_stack(self, dtype):\n        self.df.stack()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ReshapeExtensionDtype:\n    def setup(self, dtype):\n        lev = pd.Index(list(\"ABCDEFGHIJ\"))\n        ri = pd.Index(range(1000))\n        mi = MultiIndex.from_product([lev, ri], names=[\"foo\", \"bar\"])\n    \n        index = date_range(\"2016-01-01\", periods=10000, freq=\"s\", tz=\"US/Pacific\")\n        if dtype == \"Period[s]\":\n            index = index.tz_localize(None).to_period(\"s\")\n    \n        ser = pd.Series(index, index=mi)\n        df = ser.unstack(\"bar\")\n        # roundtrips -> df.stack().equals(ser)\n    \n        self.ser = ser\n        self.df = df", "min_run_count": 2, "name": "reshape.ReshapeExtensionDtype.time_stack", "number": 0, "param_names": ["dtype"], "params": [["'datetime64[ns, US/Pacific]'", "'Period[s]'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "71f50c1837c91a2ab25587dc3675ead2ce4cc6662b0442f0b8aabc7677405330", "warmup_time": -1}, "reshape.ReshapeExtensionDtype.time_transpose": {"code": "class ReshapeExtensionDtype:\n    def time_transpose(self, dtype):\n        self.df.T\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ReshapeExtensionDtype:\n    def setup(self, dtype):\n        lev = pd.Index(list(\"ABCDEFGHIJ\"))\n        ri = pd.Index(range(1000))\n        mi = MultiIndex.from_product([lev, ri], names=[\"foo\", \"bar\"])\n    \n        index = date_range(\"2016-01-01\", periods=10000, freq=\"s\", tz=\"US/Pacific\")\n        if dtype == \"Period[s]\":\n            index = index.tz_localize(None).to_period(\"s\")\n    \n        ser = pd.Series(index, index=mi)\n        df = ser.unstack(\"bar\")\n        # roundtrips -> df.stack().equals(ser)\n    \n        self.ser = ser\n        self.df = df", "min_run_count": 2, "name": "reshape.ReshapeExtensionDtype.time_transpose", "number": 0, "param_names": ["dtype"], "params": [["'datetime64[ns, US/Pacific]'", "'Period[s]'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "de98fb88e477fc5bd7f6b256e4a9b735100ef3450027db1f429fee20265ecde3", "warmup_time": -1}, "reshape.ReshapeExtensionDtype.time_unstack_fast": {"code": "class ReshapeExtensionDtype:\n    def time_unstack_fast(self, dtype):\n        # last level -> doesn't have to make copies\n        self.ser.unstack(\"bar\")\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ReshapeExtensionDtype:\n    def setup(self, dtype):\n        lev = pd.Index(list(\"ABCDEFGHIJ\"))\n        ri = pd.Index(range(1000))\n        mi = MultiIndex.from_product([lev, ri], names=[\"foo\", \"bar\"])\n    \n        index = date_range(\"2016-01-01\", periods=10000, freq=\"s\", tz=\"US/Pacific\")\n        if dtype == \"Period[s]\":\n            index = index.tz_localize(None).to_period(\"s\")\n    \n        ser = pd.Series(index, index=mi)\n        df = ser.unstack(\"bar\")\n        # roundtrips -> df.stack().equals(ser)\n    \n        self.ser = ser\n        self.df = df", "min_run_count": 2, "name": "reshape.ReshapeExtensionDtype.time_unstack_fast", "number": 0, "param_names": ["dtype"], "params": [["'datetime64[ns, US/Pacific]'", "'Period[s]'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "bfb452390fbd0c8f64654a5fa654ae3cba890d1d7668880d51f418f1c2ea0059", "warmup_time": -1}, "reshape.ReshapeExtensionDtype.time_unstack_slow": {"code": "class ReshapeExtensionDtype:\n    def time_unstack_slow(self, dtype):\n        # first level -> must make copies\n        self.ser.unstack(\"foo\")\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ReshapeExtensionDtype:\n    def setup(self, dtype):\n        lev = pd.Index(list(\"ABCDEFGHIJ\"))\n        ri = pd.Index(range(1000))\n        mi = MultiIndex.from_product([lev, ri], names=[\"foo\", \"bar\"])\n    \n        index = date_range(\"2016-01-01\", periods=10000, freq=\"s\", tz=\"US/Pacific\")\n        if dtype == \"Period[s]\":\n            index = index.tz_localize(None).to_period(\"s\")\n    \n        ser = pd.Series(index, index=mi)\n        df = ser.unstack(\"bar\")\n        # roundtrips -> df.stack().equals(ser)\n    \n        self.ser = ser\n        self.df = df", "min_run_count": 2, "name": "reshape.ReshapeExtensionDtype.time_unstack_slow", "number": 0, "param_names": ["dtype"], "params": [["'datetime64[ns, US/Pacific]'", "'Period[s]'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "19cf929eb6cc86687d322f9c25207cd480041be2aafd11fe37cf4815e5be49c8", "warmup_time": -1}, "reshape.SimpleReshape.time_stack": {"code": "class SimpleReshape:\n    def time_stack(self):\n        self.udf.stack()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass SimpleReshape:\n    def setup(self):\n        arrays = [np.arange(100).repeat(100), np.roll(np.tile(np.arange(100), 100), 25)]\n        index = MultiIndex.from_arrays(arrays)\n        self.df = DataFrame(np.random.randn(10000, 4), index=index)\n        self.udf = self.df.unstack(1)", "min_run_count": 2, "name": "reshape.SimpleReshape.time_stack", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "a6d770036abb815e9c3a58b1e211a9731ce733599757aa8153db703496818011", "warmup_time": -1}, "reshape.SimpleReshape.time_unstack": {"code": "class SimpleReshape:\n    def time_unstack(self):\n        self.df.unstack(1)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass SimpleReshape:\n    def setup(self):\n        arrays = [np.arange(100).repeat(100), np.roll(np.tile(np.arange(100), 100), 25)]\n        index = MultiIndex.from_arrays(arrays)\n        self.df = DataFrame(np.random.randn(10000, 4), index=index)\n        self.udf = self.df.unstack(1)", "min_run_count": 2, "name": "reshape.SimpleReshape.time_unstack", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "ee883fcccbd0ef7d6c8bb60b550c2de5d2bc5b98458113c63b9f23a2f652e873", "warmup_time": -1}, "reshape.SparseIndex.time_unstack": {"code": "class SparseIndex:\n    def time_unstack(self):\n        self.df.unstack()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass SparseIndex:\n    def setup(self):\n        NUM_ROWS = 1000\n        self.df = DataFrame(\n            {\n                \"A\": np.random.randint(50, size=NUM_ROWS),\n                \"B\": np.random.randint(50, size=NUM_ROWS),\n                \"C\": np.random.randint(-10, 10, size=NUM_ROWS),\n                \"D\": np.random.randint(-10, 10, size=NUM_ROWS),\n                \"E\": np.random.randint(10, size=NUM_ROWS),\n                \"F\": np.random.randn(NUM_ROWS),\n            }\n        )\n        self.df = self.df.set_index([\"A\", \"B\", \"C\", \"D\", \"E\"])", "min_run_count": 2, "name": "reshape.SparseIndex.time_unstack", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "41381253268a24b9d6ee1f0c20e6602a24860a05d0e483f11a992776103b51be", "warmup_time": -1}, "reshape.Unstack.time_full_product": {"code": "class Unstack:\n    def time_full_product(self, dtype):\n        self.df.unstack()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Unstack:\n    def setup(self, dtype):\n        m = 100\n        n = 1000\n    \n        levels = np.arange(m)\n        index = MultiIndex.from_product([levels] * 2)\n        columns = np.arange(n)\n        if dtype == \"int\":\n            values = np.arange(m * m * n).reshape(m * m, n)\n            self.df = DataFrame(values, index, columns)\n        else:\n            # the category branch is ~20x slower than int. So we\n            # cut down the size a bit. Now it's only ~3x slower.\n            n = 50\n            columns = columns[:n]\n            indices = np.random.randint(0, 52, size=(m * m, n))\n            values = np.take(list(string.ascii_letters), indices)\n            values = [pd.Categorical(v) for v in values.T]\n    \n            self.df = DataFrame(dict(enumerate(values)), index, columns)\n    \n        self.df2 = self.df.iloc[:-1]", "min_run_count": 2, "name": "reshape.Unstack.time_full_product", "number": 0, "param_names": ["param1"], "params": [["'int'", "'category'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "b28492d9054e9dc56a19db0f8cd8638ff873d22ea2faeb49de210add68896584", "warmup_time": -1}, "reshape.Unstack.time_without_last_row": {"code": "class Unstack:\n    def time_without_last_row(self, dtype):\n        self.df2.unstack()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Unstack:\n    def setup(self, dtype):\n        m = 100\n        n = 1000\n    \n        levels = np.arange(m)\n        index = MultiIndex.from_product([levels] * 2)\n        columns = np.arange(n)\n        if dtype == \"int\":\n            values = np.arange(m * m * n).reshape(m * m, n)\n            self.df = DataFrame(values, index, columns)\n        else:\n            # the category branch is ~20x slower than int. So we\n            # cut down the size a bit. Now it's only ~3x slower.\n            n = 50\n            columns = columns[:n]\n            indices = np.random.randint(0, 52, size=(m * m, n))\n            values = np.take(list(string.ascii_letters), indices)\n            values = [pd.Categorical(v) for v in values.T]\n    \n            self.df = DataFrame(dict(enumerate(values)), index, columns)\n    \n        self.df2 = self.df.iloc[:-1]", "min_run_count": 2, "name": "reshape.Unstack.time_without_last_row", "number": 0, "param_names": ["param1"], "params": [["'int'", "'category'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "0c546381b8ec02b2e96bf78f998f4f2a191ac77f0045346909d25e8b88f3e1e1", "warmup_time": -1}, "reshape.WideToLong.time_wide_to_long_big": {"code": "class WideToLong:\n    def time_wide_to_long_big(self):\n        wide_to_long(self.df, self.letters, i=\"id\", j=\"year\")\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass WideToLong:\n    def setup(self):\n        nyrs = 20\n        nidvars = 20\n        N = 5000\n        self.letters = list(\"ABCD\")\n        yrvars = [\n            letter + str(num)\n            for letter, num in product(self.letters, range(1, nyrs + 1))\n        ]\n        columns = [str(i) for i in range(nidvars)] + yrvars\n        self.df = DataFrame(np.random.randn(N, nidvars + len(yrvars)), columns=columns)\n        self.df[\"id\"] = self.df.index", "min_run_count": 2, "name": "reshape.WideToLong.time_wide_to_long_big", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "38b6ee0820735de02ad64b598a14cbe298769f714808e915411fde11e73f8598", "warmup_time": -1}, "rolling.Apply.time_rolling": {"code": "class Apply:\n    def time_rolling(self, constructor, window, dtype, function, raw):\n        self.roll.apply(function, raw=raw)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Apply:\n    def setup(self, constructor, window, dtype, function, raw):\n        N = 10**3\n        arr = (100 * np.random.random(N)).astype(dtype)\n        self.roll = getattr(pd, constructor)(arr).rolling(window)", "min_run_count": 2, "name": "rolling.Apply.time_rolling", "number": 0, "param_names": ["constructor", "window", "dtype", "function", "raw"], "params": [["'DataFrame'", "'Series'"], ["3", "300"], ["'int'", "'float'"], ["<built-in function sum>", "<function sum>", "<function Apply.<lambda>>"], ["True", "False"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "871accb43f689bd0f04df4d9d50bb65a4d3403027f3ff0b5e49789cf4cf80a70", "warmup_time": -1}, "rolling.EWMMethods.time_ewm": {"code": "class EWMMethods:\n    def time_ewm(self, constructor, kwargs_method, dtype):\n        getattr(self.ewm, self.method)()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass EWMMethods:\n    def setup(self, constructor, kwargs_method, dtype):\n        N = 10**5\n        kwargs, method = kwargs_method\n        arr = (100 * np.random.random(N)).astype(dtype)\n        self.method = method\n        self.ewm = getattr(pd, constructor)(arr).ewm(**kwargs)", "min_run_count": 2, "name": "rolling.EWMMethods.time_ewm", "number": 0, "param_names": ["constructor", "kwargs_method", "dtype"], "params": [["'DataFrame'", "'Series'"], ["({'halflife': 10}, 'mean')", "({'halflife': 10}, 'std')", "({'halflife': 1000}, 'mean')", "({'halflife': 1000}, 'std')", "({'halflife': '1 Day', 'times': DatetimeIndex(['1900-01-01 00:00:00', '1900-01-01 00:00:23',\n               '1900-01-01 00:00:46', '1900-01-01 00:01:09',\n               '1900-01-01 00:01:32', '1900-01-01 00:01:55',\n               '1900-01-01 00:02:18', '1900-01-01 00:02:41',\n               '1900-01-01 00:03:04', '1900-01-01 00:03:27',\n               ...\n               '1900-01-27 14:49:30', '1900-01-27 14:49:53',\n               '1900-01-27 14:50:16', '1900-01-27 14:50:39',\n               '1900-01-27 14:51:02', '1900-01-27 14:51:25',\n               '1900-01-27 14:51:48', '1900-01-27 14:52:11',\n               '1900-01-27 14:52:34', '1900-01-27 14:52:57'],\n              dtype='datetime64[ns]', length=100000, freq='23S')}, 'mean')"], ["'int'", "'float'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "44cf214a28e488cb440a036e0178da2f3f3ea426055c4f0952f4fdedbd55eff8", "warmup_time": -1}, "rolling.ForwardWindowMethods.peakmem_rolling": {"code": "class ForwardWindowMethods:\n    def peakmem_rolling(self, constructor, window_size, dtype, method):\n        getattr(self.roll, method)()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ForwardWindowMethods:\n    def setup(self, constructor, window_size, dtype, method):\n        N = 10**5\n        arr = np.random.random(N).astype(dtype)\n        indexer = pd.api.indexers.FixedForwardWindowIndexer(window_size=window_size)\n        self.roll = getattr(pd, constructor)(arr).rolling(window=indexer)", "name": "rolling.ForwardWindowMethods.peakmem_rolling", "param_names": ["constructor", "window_size", "dtype", "method"], "params": [["'DataFrame'", "'Series'"], ["10", "1000"], ["'int'", "'float'"], ["'median'", "'mean'", "'max'", "'min'", "'kurt'", "'sum'"]], "timeout": 60.0, "type": "peakmemory", "unit": "bytes", "version": "9ac3a0bf8c769f331e8cd492fdbc30f03ab699681211d932253349936b2ec964"}, "rolling.ForwardWindowMethods.time_rolling": {"code": "class ForwardWindowMethods:\n    def time_rolling(self, constructor, window_size, dtype, method):\n        getattr(self.roll, method)()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ForwardWindowMethods:\n    def setup(self, constructor, window_size, dtype, method):\n        N = 10**5\n        arr = np.random.random(N).astype(dtype)\n        indexer = pd.api.indexers.FixedForwardWindowIndexer(window_size=window_size)\n        self.roll = getattr(pd, constructor)(arr).rolling(window=indexer)", "min_run_count": 2, "name": "rolling.ForwardWindowMethods.time_rolling", "number": 0, "param_names": ["constructor", "window_size", "dtype", "method"], "params": [["'DataFrame'", "'Series'"], ["10", "1000"], ["'int'", "'float'"], ["'median'", "'mean'", "'max'", "'min'", "'kurt'", "'sum'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "6dfc98201296ab54c1be4d985a80b8f835a8c4b225f3719c6869e418405eac45", "warmup_time": -1}, "rolling.Groupby.time_method": {"code": "class Groupby:\n    def time_method(self, method, window_kwargs):\n        getattr(self.groupby_window, method)()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Groupby:\n    def setup(self, method, window_kwargs):\n        N = 1000\n        window, kwargs = window_kwargs\n        df = pd.DataFrame(\n            {\n                \"A\": [str(i) for i in range(N)] * 10,\n                \"B\": list(range(N)) * 10,\n            }\n        )\n        if isinstance(kwargs.get(\"window\", None), str):\n            df.index = pd.date_range(start=\"1900-01-01\", freq=\"1min\", periods=N * 10)\n        self.groupby_window = getattr(df.groupby(\"A\"), window)(**kwargs)", "min_run_count": 2, "name": "rolling.Groupby.time_method", "number": 0, "param_names": ["param1", "param2"], "params": [["'sum' (0)", "'median'", "'mean'", "'max'", "'min'", "'kurt'", "'sum' (1)"], ["('rolling', {'window': 2})", "('rolling', {'window': '30s'})", "('expanding', {})"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "1f0550f768119c2d4aa887f71e8c464ca76822e8f39b17def026e6701ff98501", "warmup_time": -1}, "rolling.GroupbyEWM.time_groupby_method": {"code": "class GroupbyEWM:\n    def time_groupby_method(self, method):\n        getattr(self.gb_ewm, method)()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass GroupbyEWM:\n    def setup(self, method):\n        df = pd.DataFrame({\"A\": range(50), \"B\": range(50)})\n        self.gb_ewm = df.groupby(\"A\").ewm(com=1.0)", "min_run_count": 2, "name": "rolling.GroupbyEWM.time_groupby_method", "number": 0, "param_names": ["method"], "params": [["'var'", "'std'", "'cov'", "'corr'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "ad6a51326eb042f1ee88615e2048d6bc92adf02dfecb26d43ba24834f3c61150", "warmup_time": -1}, "rolling.GroupbyEWMEngine.time_groupby_mean": {"code": "class GroupbyEWMEngine:\n    def time_groupby_mean(self, engine):\n        self.gb_ewm.mean(engine=engine)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass GroupbyEWMEngine:\n    def setup(self, engine):\n        df = pd.DataFrame({\"A\": range(50), \"B\": range(50)})\n        self.gb_ewm = df.groupby(\"A\").ewm(com=1.0)", "min_run_count": 2, "name": "rolling.GroupbyEWMEngine.time_groupby_mean", "number": 0, "param_names": ["engine"], "params": [["'cython'", "'numba'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "d69e116193dcb411ee111f0a146b8d596d2d73236f686eb16ef4e9221bd2bd52", "warmup_time": -1}, "rolling.GroupbyLargeGroups.time_rolling_multiindex_creation": {"code": "class GroupbyLargeGroups:\n    def time_rolling_multiindex_creation(self):\n        self.df.groupby(\"A\").rolling(3).mean()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass GroupbyLargeGroups:\n    def setup(self):\n        N = 100000\n        self.df = pd.DataFrame({\"A\": [1, 2] * (N // 2), \"B\": np.random.randn(N)})", "min_run_count": 2, "name": "rolling.GroupbyLargeGroups.time_rolling_multiindex_creation", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "31a34a6b020d62e4c7b595aeb804a131f135c1fd1497365577c3bbf2fe7c511c", "warmup_time": -1}, "rolling.Methods.peakmem_method": {"code": "class Methods:\n    def peakmem_method(self, constructor, window_kwargs, dtype, method):\n        getattr(self.window, method)()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Methods:\n    def setup(self, constructor, window_kwargs, dtype, method):\n        N = 10**5\n        window, kwargs = window_kwargs\n        arr = (100 * np.random.random(N)).astype(dtype)\n        obj = getattr(pd, constructor)(arr)\n        self.window = getattr(obj, window)(**kwargs)", "name": "rolling.Methods.peakmem_method", "param_names": ["constructor", "window_kwargs", "dtype", "method"], "params": [["'DataFrame'", "'Series'"], ["('rolling', {'window': 10})", "('rolling', {'window': 1000})", "('expanding', {})"], ["'int'", "'float'"], ["'median'", "'mean'", "'max'", "'min'", "'std'", "'count'", "'skew'", "'kurt'", "'sum'", "'sem'"]], "timeout": 60.0, "type": "peakmemory", "unit": "bytes", "version": "0c01a9273a20049fc5dfd09ead608a5e199977644711bc856c0dbaf525d6d0d5"}, "rolling.Methods.time_method": {"code": "class Methods:\n    def time_method(self, constructor, window_kwargs, dtype, method):\n        getattr(self.window, method)()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Methods:\n    def setup(self, constructor, window_kwargs, dtype, method):\n        N = 10**5\n        window, kwargs = window_kwargs\n        arr = (100 * np.random.random(N)).astype(dtype)\n        obj = getattr(pd, constructor)(arr)\n        self.window = getattr(obj, window)(**kwargs)", "min_run_count": 2, "name": "rolling.Methods.time_method", "number": 0, "param_names": ["constructor", "window_kwargs", "dtype", "method"], "params": [["'DataFrame'", "'Series'"], ["('rolling', {'window': 10})", "('rolling', {'window': 1000})", "('expanding', {})"], ["'int'", "'float'"], ["'median'", "'mean'", "'max'", "'min'", "'std'", "'count'", "'skew'", "'kurt'", "'sum'", "'sem'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "5402683efd6d1e8b4bab7594be55921fa6334cec6319e73a3f3660d99df1a7a5", "warmup_time": -1}, "rolling.Pairwise.time_groupby": {"code": "class Pairwise:\n    def time_groupby(self, kwargs_window, method, pairwise):\n        getattr(self.window_group, method)(self.df, pairwise=pairwise)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Pairwise:\n    def setup(self, kwargs_window, method, pairwise):\n        N = 10**4\n        n_groups = 20\n        kwargs, window = kwargs_window\n        groups = [i for _ in range(N // n_groups) for i in range(n_groups)]\n        arr = np.random.random(N)\n        self.df = pd.DataFrame(arr)\n        self.window = getattr(self.df, window)(**kwargs)\n        self.window_group = getattr(\n            pd.DataFrame({\"A\": groups, \"B\": arr}).groupby(\"A\"), window\n        )(**kwargs)", "min_run_count": 2, "name": "rolling.Pairwise.time_groupby", "number": 0, "param_names": ["window_kwargs", "method", "pairwise"], "params": [["({'window': 10}, 'rolling')", "({'window': 1000}, 'rolling')", "({}, 'expanding')"], ["'corr'", "'cov'"], ["True", "False"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "f1e4be4e4d441bdc8b2cebdbc678ae970eb20874fa682bb1ca41352d98a0a23e", "warmup_time": -1}, "rolling.Pairwise.time_pairwise": {"code": "class Pairwise:\n    def time_pairwise(self, kwargs_window, method, pairwise):\n        getattr(self.window, method)(self.df, pairwise=pairwise)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Pairwise:\n    def setup(self, kwargs_window, method, pairwise):\n        N = 10**4\n        n_groups = 20\n        kwargs, window = kwargs_window\n        groups = [i for _ in range(N // n_groups) for i in range(n_groups)]\n        arr = np.random.random(N)\n        self.df = pd.DataFrame(arr)\n        self.window = getattr(self.df, window)(**kwargs)\n        self.window_group = getattr(\n            pd.DataFrame({\"A\": groups, \"B\": arr}).groupby(\"A\"), window\n        )(**kwargs)", "min_run_count": 2, "name": "rolling.Pairwise.time_pairwise", "number": 0, "param_names": ["window_kwargs", "method", "pairwise"], "params": [["({'window': 10}, 'rolling')", "({'window': 1000}, 'rolling')", "({}, 'expanding')"], ["'corr'", "'cov'"], ["True", "False"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "315ccdf22c0f4d21fa6ee729bdd8f21c51913704006fbcdfc1f4e2500d816ef3", "warmup_time": -1}, "rolling.PeakMemFixedWindowMinMax.peakmem_fixed": {"code": "class PeakMemFixedWindowMinMax:\n    def peakmem_fixed(self, operation):\n        for x in range(5):\n            getattr(self.roll, operation)()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass PeakMemFixedWindowMinMax:\n    def setup(self, operation):\n        N = 10**6\n        arr = np.random.random(N)\n        self.roll = pd.Series(arr).rolling(2)", "name": "rolling.PeakMemFixedWindowMinMax.peakmem_fixed", "param_names": ["param1"], "params": [["'min'", "'max'"]], "timeout": 60.0, "type": "peakmemory", "unit": "bytes", "version": "b9767f691709345094cdfdc4984bb728c9e78389a22aa1bae02462af8dd67ec2"}, "rolling.Quantile.time_quantile": {"code": "class Quantile:\n    def time_quantile(self, constructor, window, dtype, percentile, interpolation):\n        self.roll.quantile(percentile, interpolation=interpolation)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Quantile:\n    def setup(self, constructor, window, dtype, percentile, interpolation):\n        N = 10**5\n        arr = np.random.random(N).astype(dtype)\n        self.roll = getattr(pd, constructor)(arr).rolling(window)", "min_run_count": 2, "name": "rolling.Quantile.time_quantile", "number": 0, "param_names": ["constructor", "window", "dtype", "percentile", "param5"], "params": [["'DataFrame'", "'Series'"], ["10", "1000"], ["'int'", "'float'"], ["0", "0.5", "1"], ["'linear'", "'nearest'", "'lower'", "'higher'", "'midpoint'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "f94389cbc4b3cca82ab4db4970a4acd0daa3c0fbf9cc3f230a6b7d69e841bc4f", "warmup_time": -1}, "rolling.Rank.time_rank": {"code": "class Rank:\n    def time_rank(self, constructor, window, dtype, percentile, ascending, method):\n        self.roll.rank(pct=percentile, ascending=ascending, method=method)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Rank:\n    def setup(self, constructor, window, dtype, percentile, ascending, method):\n        N = 10**5\n        arr = np.random.random(N).astype(dtype)\n        self.roll = getattr(pd, constructor)(arr).rolling(window)", "min_run_count": 2, "name": "rolling.Rank.time_rank", "number": 0, "param_names": ["constructor", "window", "dtype", "percentile", "ascending", "method"], "params": [["'DataFrame'", "'Series'"], ["10", "1000"], ["'int'", "'float'"], ["True", "False"], ["True", "False"], ["'min'", "'max'", "'average'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "f02fd2586b260b9f5ab15f641e1279b2d47c07b805c6059cdf5f0e5f424a5b6c", "warmup_time": -1}, "rolling.TableMethod.time_apply": {"code": "class TableMethod:\n    def time_apply(self, method):\n        self.df.rolling(2, method=method).apply(\n            table_method_func, raw=True, engine=\"numba\"\n        )\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass TableMethod:\n    def setup(self, method):\n        self.df = pd.DataFrame(np.random.randn(10, 1000))", "min_run_count": 2, "name": "rolling.TableMethod.time_apply", "number": 0, "param_names": ["method"], "params": [["'single'", "'table'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "30880eb453b9d41a953d95fc25ba24088b0a48b94ab49ea12406e4abc0b976ac", "warmup_time": -1}, "rolling.TableMethod.time_ewm_mean": {"code": "class TableMethod:\n    def time_ewm_mean(self, method):\n        self.df.ewm(1, method=method).mean(engine=\"numba\")\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass TableMethod:\n    def setup(self, method):\n        self.df = pd.DataFrame(np.random.randn(10, 1000))", "min_run_count": 2, "name": "rolling.TableMethod.time_ewm_mean", "number": 0, "param_names": ["method"], "params": [["'single'", "'table'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "446dcdc251bda1381a3cf943305e8a6a22ea15ca4513ec2dc7454a8692ab99ad", "warmup_time": -1}, "rolling.VariableWindowMethods.peakmem_method": {"code": "class Methods:\n    def peakmem_method(self, constructor, window_kwargs, dtype, method):\n        getattr(self.window, method)()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass VariableWindowMethods:\n    def setup(self, constructor, window, dtype, method):\n        N = 10**5\n        arr = (100 * np.random.random(N)).astype(dtype)\n        index = pd.date_range(\"2017-01-01\", periods=N, freq=\"5s\")\n        self.window = getattr(pd, constructor)(arr, index=index).rolling(window)", "name": "rolling.VariableWindowMethods.peakmem_method", "param_names": ["constructor", "window", "dtype", "method"], "params": [["'DataFrame'", "'Series'"], ["'50s'", "'1h'", "'1d'"], ["'int'", "'float'"], ["'median'", "'mean'", "'max'", "'min'", "'std'", "'count'", "'skew'", "'kurt'", "'sum'", "'sem'"]], "timeout": 60.0, "type": "peakmemory", "unit": "bytes", "version": "7b52c11d6e1b242c90ddaa78b88fb15e12a3676d5faf98af9807087e0243c3e8"}, "rolling.VariableWindowMethods.time_method": {"code": "class Methods:\n    def time_method(self, constructor, window_kwargs, dtype, method):\n        getattr(self.window, method)()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass VariableWindowMethods:\n    def setup(self, constructor, window, dtype, method):\n        N = 10**5\n        arr = (100 * np.random.random(N)).astype(dtype)\n        index = pd.date_range(\"2017-01-01\", periods=N, freq=\"5s\")\n        self.window = getattr(pd, constructor)(arr, index=index).rolling(window)", "min_run_count": 2, "name": "rolling.VariableWindowMethods.time_method", "number": 0, "param_names": ["constructor", "window", "dtype", "method"], "params": [["'DataFrame'", "'Series'"], ["'50s'", "'1h'", "'1d'"], ["'int'", "'float'"], ["'median'", "'mean'", "'max'", "'min'", "'std'", "'count'", "'skew'", "'kurt'", "'sum'", "'sem'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "f5b8129df64b00950a4dbfbcf89e760f149ee8ffb5df1d544c0b87cceb86c41b", "warmup_time": -1}, "series_methods.All.time_all": {"code": "class All:\n    def time_all(self, N, case, dtype):\n        self.s.all()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass All:\n    def setup(self, N, case, dtype):\n        val = case != \"fast\"\n        self.s = Series([val] * N, dtype=dtype)", "min_run_count": 2, "name": "series_methods.All.time_all", "number": 0, "param_names": ["N", "case", "dtype"], "params": [["1000", "1000000"], ["'fast'", "'slow'"], ["'bool'", "'boolean'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "45f86547ce03394cb299551fd376fc8a763de3a613d475e1b9b2e71852b8c4f9", "warmup_time": -1}, "series_methods.Any.time_any": {"code": "class Any:\n    def time_any(self, N, case, dtype):\n        self.s.any()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Any:\n    def setup(self, N, case, dtype):\n        val = case == \"fast\"\n        self.s = Series([val] * N, dtype=dtype)", "min_run_count": 2, "name": "series_methods.Any.time_any", "number": 0, "param_names": ["N", "case", "dtype"], "params": [["1000", "1000000"], ["'fast'", "'slow'"], ["'bool'", "'boolean'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "2e53bbc75704910ed273c169cc5a41b3037436503911ac1dd4fa9a62a7261c44", "warmup_time": -1}, "series_methods.Clip.time_clip": {"code": "class Clip:\n    def time_clip(self, n):\n        self.s.clip(0, 1)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Clip:\n    def setup(self, n):\n        self.s = Series(np.random.randn(n))", "min_run_count": 2, "name": "series_methods.Clip.time_clip", "number": 0, "param_names": ["n"], "params": [["50", "1000", "100000"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "8179a96510fbe69a1326ac0c3cdb1466db7b5719d20b59a243564362d9b56a4a", "warmup_time": -1}, "series_methods.ClipDt.time_clip": {"code": "class ClipDt:\n    def time_clip(self):\n        self.s.clip(upper=self.clipper_dt)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ClipDt:\n    def setup(self):\n        dr = date_range(\"20220101\", periods=100_000, freq=\"s\", tz=\"UTC\")\n        self.clipper_dt = dr[0:1_000].repeat(100)\n        self.s = Series(dr)", "min_run_count": 2, "name": "series_methods.ClipDt.time_clip", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "5e24ee89ae59664da88494ca3070b3c7d1a6c1fe48429471f94661dbff272408", "warmup_time": -1}, "series_methods.Dir.time_dir_strings": {"code": "class Dir:\n    def time_dir_strings(self):\n        dir(self.s)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Dir:\n    def setup(self):\n        self.s = Series(index=tm.makeStringIndex(10000))", "min_run_count": 2, "name": "series_methods.Dir.time_dir_strings", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "cebc60823e26e6539c07906cb467feba1e35568d660a21659f8de8c992dc4904", "warmup_time": -1}, "series_methods.Dropna.time_dropna": {"code": "class Dropna:\n    def time_dropna(self, dtype):\n        self.s.dropna()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Dropna:\n    def setup(self, dtype):\n        N = 10**6\n        data = {\n            \"int\": np.random.randint(1, 10, N),\n            \"datetime\": date_range(\"2000-01-01\", freq=\"S\", periods=N),\n        }\n        self.s = Series(data[dtype])\n        if dtype == \"datetime\":\n            self.s[np.random.randint(1, N, 100)] = NaT", "min_run_count": 2, "name": "series_methods.Dropna.time_dropna", "number": 0, "param_names": ["dtype"], "params": [["'int'", "'datetime'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "abe462a44e5ead4a6ea744fd92e44ca472b4359573af4850381ce811f0f29043", "warmup_time": -1}, "series_methods.Fillna.time_fillna": {"code": "class Fillna:\n    def time_fillna(self, dtype, method):\n        value = self.fill_value if method is None else None\n        self.ser.fillna(value=value, method=method)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Fillna:\n    def setup(self, dtype, method):\n        N = 10**6\n        if dtype == \"datetime64[ns]\":\n            data = date_range(\"2000-01-01\", freq=\"S\", periods=N)\n            na_value = NaT\n        elif dtype in (\"float64\", \"Float64\"):\n            data = np.random.randn(N)\n            na_value = np.nan\n        elif dtype in (\"Int64\", \"int64[pyarrow]\"):\n            data = np.arange(N)\n            na_value = NA\n        elif dtype in (\"string\", \"string[pyarrow]\"):\n            data = tm.rands_array(5, N)\n            na_value = NA\n        else:\n            raise NotImplementedError\n        fill_value = data[0]\n        ser = Series(data, dtype=dtype)\n        ser[::2] = na_value\n        self.ser = ser\n        self.fill_value = fill_value", "min_run_count": 2, "name": "series_methods.Fillna.time_fillna", "number": 0, "param_names": ["dtype", "method"], "params": [["'datetime64[ns]'", "'float64'", "'Float64'", "'Int64'", "'int64[pyarrow]'", "'string'", "'string[pyarrow]'"], ["None", "'pad'", "'backfill'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "d06173d733e0a1fd98cc043cb1ea020782cf019744acba25ff35b544d9c3a645", "warmup_time": -1}, "series_methods.Iter.time_iter": {"code": "class Iter:\n    def time_iter(self, dtype):\n        for v in self.s:\n            pass\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Iter:\n    def setup(self, dtype):\n        N = 10**5\n        if dtype in [\"bool\", \"boolean\"]:\n            data = np.repeat([True, False], N // 2)\n        elif dtype in [\"int64\", \"Int64\"]:\n            data = np.arange(N)\n        elif dtype in [\"float64\", \"Float64\"]:\n            data = np.random.randn(N)\n        elif dtype == \"datetime64[ns]\":\n            data = date_range(\"2000-01-01\", freq=\"s\", periods=N)\n        else:\n            raise NotImplementedError\n    \n        self.s = Series(data, dtype=dtype)", "min_run_count": 2, "name": "series_methods.Iter.time_iter", "number": 0, "param_names": ["dtype"], "params": [["'bool'", "'boolean'", "'int64'", "'Int64'", "'float64'", "'Float64'", "'datetime64[ns]'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "8d4391387859c36e6cb82fe13b7d67993a73ba3541e8bc6e6e2c3d8c28a11a42", "warmup_time": -1}, "series_methods.Map.time_map": {"code": "class Map:\n    def time_map(self, mapper, *args, **kwargs):\n        self.s.map(self.map_data)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Map:\n    def setup(self, mapper, dtype):\n        map_size = 1000\n        map_data = Series(map_size - np.arange(map_size), dtype=dtype)\n    \n        # construct mapper\n        if mapper == \"Series\":\n            self.map_data = map_data\n        elif mapper == \"dict\":\n            self.map_data = map_data.to_dict()\n        elif mapper == \"lambda\":\n            map_dict = map_data.to_dict()\n            self.map_data = lambda x: map_dict[x]\n        else:\n            raise NotImplementedError\n    \n        self.s = Series(np.random.randint(0, map_size, 10000), dtype=dtype)", "min_run_count": 2, "name": "series_methods.Map.time_map", "number": 0, "param_names": ["m", "a"], "params": [["'dict'", "'Series'", "'lambda'"], ["'object'", "'category'", "'int'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "fc78503b1588b9f3f6ca02d55c628c9cf0ea126fdb6ebdcec3080a88d01028bd", "warmup_time": -1}, "series_methods.Mode.time_mode": {"code": "class Mode:\n    def time_mode(self, N, dtype):\n        self.s.mode()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Mode:\n    def setup(self, N, dtype):\n        self.s = Series(np.random.randint(0, N, size=10 * N)).astype(dtype)", "min_run_count": 2, "name": "series_methods.Mode.time_mode", "number": 0, "param_names": ["N", "dtype"], "params": [["1000", "10000", "100000"], ["'int'", "'uint'", "'float'", "'object'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "293b41b446df29f5e77e19b14540c5af87a0168e4710d64dbb12037435ef4202", "warmup_time": -1}, "series_methods.ModeObjectDropNAFalse.time_mode": {"code": "class ModeObjectDropNAFalse:\n    def time_mode(self, N):\n        self.s.mode(dropna=False)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ModeObjectDropNAFalse:\n    def setup(self, N):\n        self.s = Series(np.random.randint(0, N, size=10 * N)).astype(\"object\")", "min_run_count": 2, "name": "series_methods.ModeObjectDropNAFalse.time_mode", "number": 0, "param_names": ["N"], "params": [["1000", "10000", "100000"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "e2488dac5c2fdbcfe29cc7e9e32e32b33227ebda39debbcf7e35dbc59aea3f4a", "warmup_time": -1}, "series_methods.NSort.time_nlargest": {"code": "class NSort:\n    def time_nlargest(self, keep):\n        self.s.nlargest(3, keep=keep)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass NSort:\n    def setup(self, keep):\n        self.s = Series(np.random.randint(1, 10, 100000))", "min_run_count": 2, "name": "series_methods.NSort.time_nlargest", "number": 0, "param_names": ["keep"], "params": [["'first'", "'last'", "'all'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "b2d7318a10dc119adee969b91b3e8224c14af04542e29aea061c0c549cfbe264", "warmup_time": -1}, "series_methods.NSort.time_nsmallest": {"code": "class NSort:\n    def time_nsmallest(self, keep):\n        self.s.nsmallest(3, keep=keep)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass NSort:\n    def setup(self, keep):\n        self.s = Series(np.random.randint(1, 10, 100000))", "min_run_count": 2, "name": "series_methods.NSort.time_nsmallest", "number": 0, "param_names": ["keep"], "params": [["'first'", "'last'", "'all'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "8b1f411ecb151ecb227a739c4be77e69ccde5647917c3adb93dca8fbcae978e1", "warmup_time": -1}, "series_methods.NanOps.time_func": {"code": "class NanOps:\n    def time_func(self, func, N, dtype):\n        self.func()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass NanOps:\n    def setup(self, func, N, dtype):\n        if func == \"argmax\" and dtype in {\"Int64\", \"boolean\"}:\n            # Skip argmax for nullable int since this doesn't work yet (GH-24382)\n            raise NotImplementedError\n        self.s = Series([1] * N, dtype=dtype)\n        self.func = getattr(self.s, func)", "min_run_count": 2, "name": "series_methods.NanOps.time_func", "number": 0, "param_names": ["func", "N", "dtype"], "params": [["'var'", "'mean'", "'median'", "'max'", "'min'", "'sum'", "'std'", "'sem'", "'argmax'", "'skew'", "'kurt'", "'prod'"], ["1000", "1000000"], ["'int8'", "'int32'", "'int64'", "'float64'", "'Int64'", "'boolean'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "13a058b93e316c8d60340bbe9a4966cf10a61120c7b885f40c8424029be388d8", "warmup_time": -1}, "series_methods.Rank.time_rank": {"code": "class Rank:\n    def time_rank(self, dtype):\n        self.s.rank()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Rank:\n    def setup(self, dtype):\n        self.s = Series(np.random.randint(0, 1000, size=100000), dtype=dtype)", "min_run_count": 2, "name": "series_methods.Rank.time_rank", "number": 0, "param_names": ["dtype"], "params": [["'int'", "'uint'", "'float'", "'object'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "cf912b236884d1fded0314151a2a53dce2cf23529a155f2103666ee9d002bff7", "warmup_time": -1}, "series_methods.Replace.peakmem_replace_dict": {"code": "class Replace:\n    def peakmem_replace_dict(self, num_to_replace):\n        self.ser.replace(self.replace_dict)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Replace:\n    def setup(self, num_to_replace):\n        N = 1_000_000\n        self.arr = np.random.randn(N)\n        self.arr1 = self.arr.copy()\n        np.random.shuffle(self.arr1)\n        self.ser = Series(self.arr)\n    \n        self.to_replace_list = np.random.choice(self.arr, num_to_replace)\n        self.values_list = np.random.choice(self.arr1, num_to_replace)\n    \n        self.replace_dict = dict(zip(self.to_replace_list, self.values_list))", "name": "series_methods.Replace.peakmem_replace_dict", "param_names": ["num_to_replace"], "params": [["100", "1000"]], "timeout": 60.0, "type": "peakmemory", "unit": "bytes", "version": "82dfd71ffd244c5b1205af03154e4e4547227fe2551d07660db4b7656efdac03"}, "series_methods.Replace.peakmem_replace_list": {"code": "class Replace:\n    def peakmem_replace_list(self, num_to_replace):\n        self.ser.replace(self.to_replace_list, self.values_list)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Replace:\n    def setup(self, num_to_replace):\n        N = 1_000_000\n        self.arr = np.random.randn(N)\n        self.arr1 = self.arr.copy()\n        np.random.shuffle(self.arr1)\n        self.ser = Series(self.arr)\n    \n        self.to_replace_list = np.random.choice(self.arr, num_to_replace)\n        self.values_list = np.random.choice(self.arr1, num_to_replace)\n    \n        self.replace_dict = dict(zip(self.to_replace_list, self.values_list))", "name": "series_methods.Replace.peakmem_replace_list", "param_names": ["num_to_replace"], "params": [["100", "1000"]], "timeout": 60.0, "type": "peakmemory", "unit": "bytes", "version": "11d050f21303f90f57bfaf0eef0535a9459a8ef82e29053f7e1a7090ef4b226c"}, "series_methods.Replace.time_replace_dict": {"code": "class Replace:\n    def time_replace_dict(self, num_to_replace):\n        self.ser.replace(self.replace_dict)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Replace:\n    def setup(self, num_to_replace):\n        N = 1_000_000\n        self.arr = np.random.randn(N)\n        self.arr1 = self.arr.copy()\n        np.random.shuffle(self.arr1)\n        self.ser = Series(self.arr)\n    \n        self.to_replace_list = np.random.choice(self.arr, num_to_replace)\n        self.values_list = np.random.choice(self.arr1, num_to_replace)\n    \n        self.replace_dict = dict(zip(self.to_replace_list, self.values_list))", "min_run_count": 2, "name": "series_methods.Replace.time_replace_dict", "number": 0, "param_names": ["num_to_replace"], "params": [["100", "1000"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "61cb7f463d734dcaf1edbd292af75ede0994c5b2aed3311d7807aac689771d2d", "warmup_time": -1}, "series_methods.Replace.time_replace_list": {"code": "class Replace:\n    def time_replace_list(self, num_to_replace):\n        self.ser.replace(self.to_replace_list, self.values_list)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Replace:\n    def setup(self, num_to_replace):\n        N = 1_000_000\n        self.arr = np.random.randn(N)\n        self.arr1 = self.arr.copy()\n        np.random.shuffle(self.arr1)\n        self.ser = Series(self.arr)\n    \n        self.to_replace_list = np.random.choice(self.arr, num_to_replace)\n        self.values_list = np.random.choice(self.arr1, num_to_replace)\n    \n        self.replace_dict = dict(zip(self.to_replace_list, self.values_list))", "min_run_count": 2, "name": "series_methods.Replace.time_replace_list", "number": 0, "param_names": ["num_to_replace"], "params": [["100", "1000"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "bb772d4b5c8a9a6917a2f3b97f69478c55a246981d6e2350802c926011741b0a", "warmup_time": -1}, "series_methods.SearchSorted.time_searchsorted": {"code": "class SearchSorted:\n    def time_searchsorted(self, dtype):\n        key = \"2\" if dtype == \"str\" else 2\n        self.s.searchsorted(key)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass SearchSorted:\n    def setup(self, dtype):\n        N = 10**5\n        data = np.array([1] * N + [2] * N + [3] * N).astype(dtype)\n        self.s = Series(data)", "min_run_count": 2, "name": "series_methods.SearchSorted.time_searchsorted", "number": 0, "param_names": ["dtype"], "params": [["'int8'", "'int16'", "'int32'", "'int64'", "'uint8'", "'uint16'", "'uint32'", "'uint64'", "'float16'", "'float32'", "'float64'", "'str'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "323b35cab3b64f29d4f839af05bd6b12ad82170fc35bfee718e2e9d52b7fd61e", "warmup_time": -1}, "series_methods.SeriesConstructor.time_constructor_dict": {"code": "class SeriesConstructor:\n    def time_constructor_dict(self):\n        Series(data=self.data, index=self.idx)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass SeriesConstructor:\n    def setup(self):\n        self.idx = date_range(\n            start=datetime(2015, 10, 26), end=datetime(2016, 1, 1), freq=\"50s\"\n        )\n        self.data = dict(zip(self.idx, range(len(self.idx))))\n        self.array = np.array([1, 2, 3])\n        self.idx2 = Index([\"a\", \"b\", \"c\"])", "min_run_count": 2, "name": "series_methods.SeriesConstructor.time_constructor_dict", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "e71f5d93471f71f757d994db2550ae233bb7f18e13e21aca22dafa53f833fb4e", "warmup_time": -1}, "series_methods.SeriesConstructor.time_constructor_fastpath": {"code": "class SeriesConstructor:\n    def time_constructor_fastpath(self):\n        Series(self.array, index=self.idx2, name=\"name\", fastpath=True)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass SeriesConstructor:\n    def setup(self):\n        self.idx = date_range(\n            start=datetime(2015, 10, 26), end=datetime(2016, 1, 1), freq=\"50s\"\n        )\n        self.data = dict(zip(self.idx, range(len(self.idx))))\n        self.array = np.array([1, 2, 3])\n        self.idx2 = Index([\"a\", \"b\", \"c\"])", "min_run_count": 2, "name": "series_methods.SeriesConstructor.time_constructor_fastpath", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "cde55b86f57afd27b74991442fed2f3359d33886df3e04072d631b20c46602f7", "warmup_time": -1}, "series_methods.SeriesConstructor.time_constructor_no_data": {"code": "class SeriesConstructor:\n    def time_constructor_no_data(self):\n        Series(data=None, index=self.idx)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass SeriesConstructor:\n    def setup(self):\n        self.idx = date_range(\n            start=datetime(2015, 10, 26), end=datetime(2016, 1, 1), freq=\"50s\"\n        )\n        self.data = dict(zip(self.idx, range(len(self.idx))))\n        self.array = np.array([1, 2, 3])\n        self.idx2 = Index([\"a\", \"b\", \"c\"])", "min_run_count": 2, "name": "series_methods.SeriesConstructor.time_constructor_no_data", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "c55e26955fd47febad07ecd223347b24a08ae3454ba16023ad6bb73ec4aaf43a", "warmup_time": -1}, "series_methods.SeriesGetattr.time_series_datetimeindex_repr": {"code": "class SeriesGetattr:\n    def time_series_datetimeindex_repr(self):\n        getattr(self.s, \"a\", None)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass SeriesGetattr:\n    def setup(self):\n        self.s = Series(1, index=date_range(\"2012-01-01\", freq=\"s\", periods=10**6))", "min_run_count": 2, "name": "series_methods.SeriesGetattr.time_series_datetimeindex_repr", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "a1c5e293ae62939d93cd88e2ea4047f3f42f8c318db822e2539805b7e16b72a7", "warmup_time": -1}, "series_methods.ToFrame.time_to_frame": {"code": "class ToFrame:\n    def time_to_frame(self, dtype, name):\n        self.ser.to_frame(name)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToFrame:\n    def setup(self, dtype, name):\n        arr = np.arange(10**5)\n        ser = Series(arr, dtype=dtype)\n        self.ser = ser", "min_run_count": 2, "name": "series_methods.ToFrame.time_to_frame", "number": 0, "param_names": ["dtype", "name"], "params": [["'int64'", "'datetime64[ns]'", "'category'", "'Int64'"], ["None", "'foo'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "9837bd38099b9a8813a9b22a59b46e9e9afd7614361947eb24b302192b97eb20", "warmup_time": -1}, "series_methods.ToNumpy.time_to_numpy": {"code": "class ToNumpy:\n    def time_to_numpy(self):\n        self.ser.to_numpy()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToNumpy:\n    def setup(self):\n        N = 1_000_000\n        self.ser = Series(\n            np.random.randn(\n                N,\n            )\n        )", "min_run_count": 2, "name": "series_methods.ToNumpy.time_to_numpy", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "0ffdc5fb3536043b1cc8a7e1f7f402cf3fe4a601504d03eef9003017585b1037", "warmup_time": -1}, "series_methods.ToNumpy.time_to_numpy_copy": {"code": "class ToNumpy:\n    def time_to_numpy_copy(self):\n        self.ser.to_numpy(copy=True)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToNumpy:\n    def setup(self):\n        N = 1_000_000\n        self.ser = Series(\n            np.random.randn(\n                N,\n            )\n        )", "min_run_count": 2, "name": "series_methods.ToNumpy.time_to_numpy_copy", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "d702db82db43d7f93cd41a3786618d602a7938313ff783cfc0a836026c2997dd", "warmup_time": -1}, "series_methods.ToNumpy.time_to_numpy_double_copy": {"code": "class ToNumpy:\n    def time_to_numpy_double_copy(self):\n        self.ser.to_numpy(dtype=\"float64\", copy=True)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToNumpy:\n    def setup(self):\n        N = 1_000_000\n        self.ser = Series(\n            np.random.randn(\n                N,\n            )\n        )", "min_run_count": 2, "name": "series_methods.ToNumpy.time_to_numpy_double_copy", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "5ef7c18c63ba7e87e2f511e1b4eb1466a36198dbd621bc47d2c7ac5cde81682d", "warmup_time": -1}, "series_methods.ValueCounts.time_value_counts": {"code": "class ValueCounts:\n    def time_value_counts(self, N, dtype):\n        self.s.value_counts()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ValueCounts:\n    def setup(self, N, dtype):\n        self.s = Series(np.random.randint(0, N, size=10 * N)).astype(dtype)", "min_run_count": 2, "name": "series_methods.ValueCounts.time_value_counts", "number": 0, "param_names": ["N", "dtype"], "params": [["1000", "10000", "100000"], ["'int'", "'uint'", "'float'", "'object'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "1f5bd690b4a0f777032140a9e0c26ed03c57e4402268b2e8a64b3e1a88d4ee63", "warmup_time": -1}, "series_methods.ValueCountsEA.time_value_counts": {"code": "class ValueCountsEA:\n    def time_value_counts(self, N, dropna):\n        self.s.value_counts(dropna=dropna)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ValueCountsEA:\n    def setup(self, N, dropna):\n        self.s = Series(np.random.randint(0, N, size=10 * N), dtype=\"Int64\")\n        self.s.loc[1] = NA", "min_run_count": 2, "name": "series_methods.ValueCountsEA.time_value_counts", "number": 0, "param_names": ["N", "dropna"], "params": [["1000", "10000", "100000"], ["True", "False"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "b1c2f96329a2881dd15f3586facaa30e4405bf239449cae6534cde266ed71cd4", "warmup_time": -1}, "series_methods.ValueCountsObjectDropNAFalse.time_value_counts": {"code": "class ValueCountsObjectDropNAFalse:\n    def time_value_counts(self, N):\n        self.s.value_counts(dropna=False)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ValueCountsObjectDropNAFalse:\n    def setup(self, N):\n        self.s = Series(np.random.randint(0, N, size=10 * N)).astype(\"object\")", "min_run_count": 2, "name": "series_methods.ValueCountsObjectDropNAFalse.time_value_counts", "number": 0, "param_names": ["N"], "params": [["1000", "10000", "100000"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "a95ddcf5298c1d0d3e53729949f04ee80696bd4b75829dc18ba02781f93d57eb", "warmup_time": -1}, "sparse.Arithmetic.time_add": {"code": "class Arithmetic:\n    def time_add(self, dense_proportion, fill_value):\n        self.array1 + self.array2\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Arithmetic:\n    def setup(self, dense_proportion, fill_value):\n        N = 10**6\n        arr1 = make_array(N, dense_proportion, fill_value, np.int64)\n        self.array1 = SparseArray(arr1, fill_value=fill_value)\n        arr2 = make_array(N, dense_proportion, fill_value, np.int64)\n        self.array2 = SparseArray(arr2, fill_value=fill_value)", "min_run_count": 2, "name": "sparse.Arithmetic.time_add", "number": 0, "param_names": ["dense_proportion", "fill_value"], "params": [["0.1", "0.01"], ["0", "nan"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "de0c48747f8d85c11b89324f25d19e454599ce8ea41d8a20d4ad622ee0df72f2", "warmup_time": -1}, "sparse.Arithmetic.time_divide": {"code": "class Arithmetic:\n    def time_divide(self, dense_proportion, fill_value):\n        self.array1 / self.array2\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Arithmetic:\n    def setup(self, dense_proportion, fill_value):\n        N = 10**6\n        arr1 = make_array(N, dense_proportion, fill_value, np.int64)\n        self.array1 = SparseArray(arr1, fill_value=fill_value)\n        arr2 = make_array(N, dense_proportion, fill_value, np.int64)\n        self.array2 = SparseArray(arr2, fill_value=fill_value)", "min_run_count": 2, "name": "sparse.Arithmetic.time_divide", "number": 0, "param_names": ["dense_proportion", "fill_value"], "params": [["0.1", "0.01"], ["0", "nan"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "3144ab0a952cbf5c353d0326f3901df201f82d17b53a4384714904cb31a1d650", "warmup_time": -1}, "sparse.Arithmetic.time_intersect": {"code": "class Arithmetic:\n    def time_intersect(self, dense_proportion, fill_value):\n        self.array1.sp_index.intersect(self.array2.sp_index)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Arithmetic:\n    def setup(self, dense_proportion, fill_value):\n        N = 10**6\n        arr1 = make_array(N, dense_proportion, fill_value, np.int64)\n        self.array1 = SparseArray(arr1, fill_value=fill_value)\n        arr2 = make_array(N, dense_proportion, fill_value, np.int64)\n        self.array2 = SparseArray(arr2, fill_value=fill_value)", "min_run_count": 2, "name": "sparse.Arithmetic.time_intersect", "number": 0, "param_names": ["dense_proportion", "fill_value"], "params": [["0.1", "0.01"], ["0", "nan"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "7ac983ea31ec4919e8b0a02237314df70f5fc22fccdc3f2873c848da78bf7bf1", "warmup_time": -1}, "sparse.Arithmetic.time_make_union": {"code": "class Arithmetic:\n    def time_make_union(self, dense_proportion, fill_value):\n        self.array1.sp_index.make_union(self.array2.sp_index)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Arithmetic:\n    def setup(self, dense_proportion, fill_value):\n        N = 10**6\n        arr1 = make_array(N, dense_proportion, fill_value, np.int64)\n        self.array1 = SparseArray(arr1, fill_value=fill_value)\n        arr2 = make_array(N, dense_proportion, fill_value, np.int64)\n        self.array2 = SparseArray(arr2, fill_value=fill_value)", "min_run_count": 2, "name": "sparse.Arithmetic.time_make_union", "number": 0, "param_names": ["dense_proportion", "fill_value"], "params": [["0.1", "0.01"], ["0", "nan"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "024b326e3d80e2aa19a052c3e01a3a543974a28c12de2b047b91eb1b4a166106", "warmup_time": -1}, "sparse.ArithmeticBlock.time_addition": {"code": "class ArithmeticBlock:\n    def time_addition(self, fill_value):\n        self.arr1 + self.arr2\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ArithmeticBlock:\n    def setup(self, fill_value):\n        N = 10**6\n        self.arr1 = self.make_block_array(\n            length=N, num_blocks=1000, block_size=10, fill_value=fill_value\n        )\n        self.arr2 = self.make_block_array(\n            length=N, num_blocks=1000, block_size=10, fill_value=fill_value\n        )", "min_run_count": 2, "name": "sparse.ArithmeticBlock.time_addition", "number": 0, "param_names": ["fill_value"], "params": [["nan", "0"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "23ca7b349bf4efc6f2264729829fecf63394a0b3c46d61c3f2259d925bb9fc8f", "warmup_time": -1}, "sparse.ArithmeticBlock.time_division": {"code": "class ArithmeticBlock:\n    def time_division(self, fill_value):\n        self.arr1 / self.arr2\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ArithmeticBlock:\n    def setup(self, fill_value):\n        N = 10**6\n        self.arr1 = self.make_block_array(\n            length=N, num_blocks=1000, block_size=10, fill_value=fill_value\n        )\n        self.arr2 = self.make_block_array(\n            length=N, num_blocks=1000, block_size=10, fill_value=fill_value\n        )", "min_run_count": 2, "name": "sparse.ArithmeticBlock.time_division", "number": 0, "param_names": ["fill_value"], "params": [["nan", "0"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "642210e7c27c272426725acf65d9abba4f9ef4960d2f195e11b7a83598035d72", "warmup_time": -1}, "sparse.ArithmeticBlock.time_intersect": {"code": "class ArithmeticBlock:\n    def time_intersect(self, fill_value):\n        self.arr2.sp_index.intersect(self.arr2.sp_index)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ArithmeticBlock:\n    def setup(self, fill_value):\n        N = 10**6\n        self.arr1 = self.make_block_array(\n            length=N, num_blocks=1000, block_size=10, fill_value=fill_value\n        )\n        self.arr2 = self.make_block_array(\n            length=N, num_blocks=1000, block_size=10, fill_value=fill_value\n        )", "min_run_count": 2, "name": "sparse.ArithmeticBlock.time_intersect", "number": 0, "param_names": ["fill_value"], "params": [["nan", "0"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "163f2bc776313f35b5c130a63fa439494f45003c8ed9ad3fbf8d319b3d47d43f", "warmup_time": -1}, "sparse.ArithmeticBlock.time_make_union": {"code": "class ArithmeticBlock:\n    def time_make_union(self, fill_value):\n        self.arr1.sp_index.make_union(self.arr2.sp_index)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ArithmeticBlock:\n    def setup(self, fill_value):\n        N = 10**6\n        self.arr1 = self.make_block_array(\n            length=N, num_blocks=1000, block_size=10, fill_value=fill_value\n        )\n        self.arr2 = self.make_block_array(\n            length=N, num_blocks=1000, block_size=10, fill_value=fill_value\n        )", "min_run_count": 2, "name": "sparse.ArithmeticBlock.time_make_union", "number": 0, "param_names": ["fill_value"], "params": [["nan", "0"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "7d3b3e09ca0bfcd7880498366bd319799da49101f951ebee8cac1a364a829ace", "warmup_time": -1}, "sparse.FromCoo.time_sparse_series_from_coo": {"code": "class FromCoo:\n    def time_sparse_series_from_coo(self):\n        Series.sparse.from_coo(self.matrix)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass FromCoo:\n    def setup(self):\n        self.matrix = scipy.sparse.coo_matrix(\n            ([3.0, 1.0, 2.0], ([1, 0, 0], [0, 2, 3])), shape=(100, 100)\n        )", "min_run_count": 2, "name": "sparse.FromCoo.time_sparse_series_from_coo", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "195924096fa77c5284cc4c2886c3e4e1ec58441bb83c1afe52ee2d94f9987a1a", "warmup_time": -1}, "sparse.GetItem.time_integer_indexing": {"code": "class GetItem:\n    def time_integer_indexing(self):\n        self.sp_arr[78]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass GetItem:\n    def setup(self):\n        N = 1_000_000\n        d = 1e-5\n        arr = make_array(N, d, np.nan, np.float64)\n        self.sp_arr = SparseArray(arr)", "min_run_count": 2, "name": "sparse.GetItem.time_integer_indexing", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "33a91e68a6e5a68dc11115130afb1282d75e72c695768deefdefa5cd05f90191", "warmup_time": -1}, "sparse.GetItem.time_slice": {"code": "class GetItem:\n    def time_slice(self):\n        self.sp_arr[1:]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass GetItem:\n    def setup(self):\n        N = 1_000_000\n        d = 1e-5\n        arr = make_array(N, d, np.nan, np.float64)\n        self.sp_arr = SparseArray(arr)", "min_run_count": 2, "name": "sparse.GetItem.time_slice", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "b5ccb973e1258c02d5f387766bf0fea6895662936594235434c58e2ab78122e6", "warmup_time": -1}, "sparse.GetItemMask.time_mask": {"code": "class GetItemMask:\n    def time_mask(self, fill_value):\n        self.sp_arr[self.sp_b_arr]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass GetItemMask:\n    def setup(self, fill_value):\n        N = 1_000_000\n        d = 1e-5\n        arr = make_array(N, d, np.nan, np.float64)\n        self.sp_arr = SparseArray(arr)\n        b_arr = np.full(shape=N, fill_value=fill_value, dtype=np.bool_)\n        fv_inds = np.unique(\n            np.random.randint(low=0, high=N - 1, size=int(N * d), dtype=np.int32)\n        )\n        b_arr[fv_inds] = True if pd.isna(fill_value) else not fill_value\n        self.sp_b_arr = SparseArray(b_arr, dtype=np.bool_, fill_value=fill_value)", "min_run_count": 2, "name": "sparse.GetItemMask.time_mask", "number": 0, "param_names": ["fill_value"], "params": [["True", "False", "nan"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "faec0e7113d63984cae0b03f7857c1d88a455a72fd5f1dd15f082e047f8139c2", "warmup_time": -1}, "sparse.MinMax.time_min_max": {"code": "class MinMax:\n    def time_min_max(self, func, fill_value):\n        getattr(self.sp_arr, func)()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass MinMax:\n    def setup(self, func, fill_value):\n        N = 1_000_000\n        arr = make_array(N, 1e-5, fill_value, np.float64)\n        self.sp_arr = SparseArray(arr, fill_value=fill_value)", "min_run_count": 2, "name": "sparse.MinMax.time_min_max", "number": 0, "param_names": ["func", "fill_value"], "params": [["'min'", "'max'"], ["0.0", "nan"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "5666067aa9bdd3647031cbff0f601ab81231b8c4dc791adc44067a9f361d169a", "warmup_time": -1}, "sparse.SparseArrayConstructor.time_sparse_array": {"code": "class SparseArrayConstructor:\n    def time_sparse_array(self, dense_proportion, fill_value, dtype):\n        SparseArray(self.array, fill_value=fill_value, dtype=dtype)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass SparseArrayConstructor:\n    def setup(self, dense_proportion, fill_value, dtype):\n        N = 10**6\n        self.array = make_array(N, dense_proportion, fill_value, dtype)", "min_run_count": 2, "name": "sparse.SparseArrayConstructor.time_sparse_array", "number": 0, "param_names": ["dense_proportion", "fill_value", "dtype"], "params": [["0.1", "0.01"], ["0", "nan"], ["<class 'numpy.int64'>", "<class 'numpy.float64'>", "<class 'object'>"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "e55fb75aef7adab66fc35b1f00e5d38f4c21a7465625d0a1cce5873ce8096110", "warmup_time": -1}, "sparse.SparseDataFrameConstructor.time_from_scipy": {"code": "class SparseDataFrameConstructor:\n    def time_from_scipy(self):\n        pd.DataFrame.sparse.from_spmatrix(self.sparse)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass SparseDataFrameConstructor:\n    def setup(self):\n        N = 1000\n        self.sparse = scipy.sparse.rand(N, N, 0.005)", "min_run_count": 2, "name": "sparse.SparseDataFrameConstructor.time_from_scipy", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "177d56dfb0c583f7adb94c9adb8e996066558bf79bf5c7600620c4d85eac136f", "warmup_time": -1}, "sparse.SparseSeriesToFrame.time_series_to_frame": {"code": "class SparseSeriesToFrame:\n    def time_series_to_frame(self):\n        pd.DataFrame(self.series)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass SparseSeriesToFrame:\n    def setup(self):\n        K = 50\n        N = 50001\n        rng = date_range(\"1/1/2000\", periods=N, freq=\"T\")\n        self.series = {}\n        for i in range(1, K):\n            data = np.random.randn(N)[:-i]\n            idx = rng[:-i]\n            data[100:] = np.nan\n            self.series[i] = Series(SparseArray(data), index=idx)", "min_run_count": 2, "name": "sparse.SparseSeriesToFrame.time_series_to_frame", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "958fc2dfe9fbb7797c443ce83b375465a50d39572756f392d84591271d225ee5", "warmup_time": -1}, "sparse.Take.time_take": {"code": "class Take:\n    def time_take(self, indices, allow_fill):\n        self.sp_arr.take(indices, allow_fill=allow_fill)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Take:\n    def setup(self, indices, allow_fill):\n        N = 1_000_000\n        fill_value = 0.0\n        arr = make_array(N, 1e-5, fill_value, np.float64)\n        self.sp_arr = SparseArray(arr, fill_value=fill_value)", "min_run_count": 2, "name": "sparse.Take.time_take", "number": 0, "param_names": ["indices", "allow_fill"], "params": [["array([0])", "array([    0,     1,     2, ..., 99997, 99998, 99999])", "array([-1, -1, -1, ..., -1, -1, -1])"], ["True", "False"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "de40b85a6b156eead56c80f2a8a02564cec85e5cda7f49c947f0385fc4552dbb", "warmup_time": -1}, "sparse.ToCoo.time_sparse_series_to_coo": {"code": "class ToCoo:\n    def time_sparse_series_to_coo(self, sort_labels):\n        self.ss_mult_lvl.sparse.to_coo(\n            row_levels=[0, 1], column_levels=[2, 3], sort_labels=sort_labels\n        )\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToCoo:\n    def setup(self, sort_labels):\n        s = Series([np.nan] * 10000)\n        s[0] = 3.0\n        s[100] = -1.0\n        s[999] = 12.1\n    \n        s_mult_lvl = s.set_axis(MultiIndex.from_product([range(10)] * 4))\n        self.ss_mult_lvl = s_mult_lvl.astype(\"Sparse\")\n    \n        s_two_lvl = s.set_axis(MultiIndex.from_product([range(100)] * 2))\n        self.ss_two_lvl = s_two_lvl.astype(\"Sparse\")", "min_run_count": 2, "name": "sparse.ToCoo.time_sparse_series_to_coo", "number": 0, "param_names": ["sort_labels"], "params": [["True", "False"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "30ca6ac73768cb7fe0d759bfd836f6ccc90dbdfcd666842cfe90d333c4063300", "warmup_time": -1}, "sparse.ToCoo.time_sparse_series_to_coo_single_level": {"code": "class ToCoo:\n    def time_sparse_series_to_coo_single_level(self, sort_labels):\n        self.ss_two_lvl.sparse.to_coo(sort_labels=sort_labels)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToCoo:\n    def setup(self, sort_labels):\n        s = Series([np.nan] * 10000)\n        s[0] = 3.0\n        s[100] = -1.0\n        s[999] = 12.1\n    \n        s_mult_lvl = s.set_axis(MultiIndex.from_product([range(10)] * 4))\n        self.ss_mult_lvl = s_mult_lvl.astype(\"Sparse\")\n    \n        s_two_lvl = s.set_axis(MultiIndex.from_product([range(100)] * 2))\n        self.ss_two_lvl = s_two_lvl.astype(\"Sparse\")", "min_run_count": 2, "name": "sparse.ToCoo.time_sparse_series_to_coo_single_level", "number": 0, "param_names": ["sort_labels"], "params": [["True", "False"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "9f146457117b9ef50ec361711446aad79f7c706f074b3b9d901b5536c47680c0", "warmup_time": -1}, "sparse.ToCooFrame.time_to_coo": {"code": "class ToCooFrame:\n    def time_to_coo(self):\n        self.df.sparse.to_coo()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToCooFrame:\n    def setup(self):\n        N = 10000\n        k = 10\n        arr = np.zeros((N, k), dtype=float)\n        arr[0, 0] = 3.0\n        arr[12, 7] = -1.0\n        arr[0, 9] = 11.2\n        self.df = pd.DataFrame(arr, dtype=pd.SparseDtype(\"float\", fill_value=0.0))", "min_run_count": 2, "name": "sparse.ToCooFrame.time_to_coo", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "aa52b43e43b97a10066b7eb8a13b85c06203c3660e6293bf051b23418b51d48a", "warmup_time": -1}, "stat_ops.Correlation.peakmem_corr_wide": {"code": "class Correlation:\n    def peakmem_corr_wide(self, method):\n        self.df_wide.corr(method=method)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Correlation:\n    def setup(self, method):\n        self.df = pd.DataFrame(np.random.randn(500, 15))\n        self.df2 = pd.DataFrame(np.random.randn(500, 15))\n        self.df_wide = pd.DataFrame(np.random.randn(500, 100))\n        self.df_wide_nans = self.df_wide.where(np.random.random((500, 100)) < 0.9)\n        self.s = pd.Series(np.random.randn(500))\n        self.s2 = pd.Series(np.random.randn(500))", "name": "stat_ops.Correlation.peakmem_corr_wide", "param_names": ["method"], "params": [["'spearman'", "'kendall'", "'pearson'"]], "timeout": 60.0, "type": "peakmemory", "unit": "bytes", "version": "3ee8f436749f1f2d1f0a071b811c2fa8f22e5b7bfa05919d0449957533179b9a"}, "stat_ops.Correlation.time_corr": {"code": "class Correlation:\n    def time_corr(self, method):\n        self.df.corr(method=method)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Correlation:\n    def setup(self, method):\n        self.df = pd.DataFrame(np.random.randn(500, 15))\n        self.df2 = pd.DataFrame(np.random.randn(500, 15))\n        self.df_wide = pd.DataFrame(np.random.randn(500, 100))\n        self.df_wide_nans = self.df_wide.where(np.random.random((500, 100)) < 0.9)\n        self.s = pd.Series(np.random.randn(500))\n        self.s2 = pd.Series(np.random.randn(500))", "min_run_count": 2, "name": "stat_ops.Correlation.time_corr", "number": 0, "param_names": ["method"], "params": [["'spearman'", "'kendall'", "'pearson'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "985b3d9669fc0dfe69164a9a3e932c4cab6585326d0af33ff34da7dcfcc72ecd", "warmup_time": -1}, "stat_ops.Correlation.time_corr_series": {"code": "class Correlation:\n    def time_corr_series(self, method):\n        self.s.corr(self.s2, method=method)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Correlation:\n    def setup(self, method):\n        self.df = pd.DataFrame(np.random.randn(500, 15))\n        self.df2 = pd.DataFrame(np.random.randn(500, 15))\n        self.df_wide = pd.DataFrame(np.random.randn(500, 100))\n        self.df_wide_nans = self.df_wide.where(np.random.random((500, 100)) < 0.9)\n        self.s = pd.Series(np.random.randn(500))\n        self.s2 = pd.Series(np.random.randn(500))", "min_run_count": 2, "name": "stat_ops.Correlation.time_corr_series", "number": 0, "param_names": ["method"], "params": [["'spearman'", "'kendall'", "'pearson'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "15f8a4d1a6ad3002de031f6c6188e46257f89004dd83e0efb0133cda90ddfa33", "warmup_time": -1}, "stat_ops.Correlation.time_corr_wide": {"code": "class Correlation:\n    def time_corr_wide(self, method):\n        self.df_wide.corr(method=method)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Correlation:\n    def setup(self, method):\n        self.df = pd.DataFrame(np.random.randn(500, 15))\n        self.df2 = pd.DataFrame(np.random.randn(500, 15))\n        self.df_wide = pd.DataFrame(np.random.randn(500, 100))\n        self.df_wide_nans = self.df_wide.where(np.random.random((500, 100)) < 0.9)\n        self.s = pd.Series(np.random.randn(500))\n        self.s2 = pd.Series(np.random.randn(500))", "min_run_count": 2, "name": "stat_ops.Correlation.time_corr_wide", "number": 0, "param_names": ["method"], "params": [["'spearman'", "'kendall'", "'pearson'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "54637cc9be24613ba7ed8eb9724167b189a287c89fc91fcc80840fa02444d657", "warmup_time": -1}, "stat_ops.Correlation.time_corr_wide_nans": {"code": "class Correlation:\n    def time_corr_wide_nans(self, method):\n        self.df_wide_nans.corr(method=method)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Correlation:\n    def setup(self, method):\n        self.df = pd.DataFrame(np.random.randn(500, 15))\n        self.df2 = pd.DataFrame(np.random.randn(500, 15))\n        self.df_wide = pd.DataFrame(np.random.randn(500, 100))\n        self.df_wide_nans = self.df_wide.where(np.random.random((500, 100)) < 0.9)\n        self.s = pd.Series(np.random.randn(500))\n        self.s2 = pd.Series(np.random.randn(500))", "min_run_count": 2, "name": "stat_ops.Correlation.time_corr_wide_nans", "number": 0, "param_names": ["method"], "params": [["'spearman'", "'kendall'", "'pearson'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "07c00330d5c6a030d9e77e6aaec677ed606490cdf7f574cf00748a8a8d00c6b9", "warmup_time": -1}, "stat_ops.Correlation.time_corrwith_cols": {"code": "class Correlation:\n    def time_corrwith_cols(self, method):\n        self.df.corrwith(self.df2, method=method)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Correlation:\n    def setup(self, method):\n        self.df = pd.DataFrame(np.random.randn(500, 15))\n        self.df2 = pd.DataFrame(np.random.randn(500, 15))\n        self.df_wide = pd.DataFrame(np.random.randn(500, 100))\n        self.df_wide_nans = self.df_wide.where(np.random.random((500, 100)) < 0.9)\n        self.s = pd.Series(np.random.randn(500))\n        self.s2 = pd.Series(np.random.randn(500))", "min_run_count": 2, "name": "stat_ops.Correlation.time_corrwith_cols", "number": 0, "param_names": ["method"], "params": [["'spearman'", "'kendall'", "'pearson'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "5d0002de6d691b52406c99ef171a6bef8d6f9569a32c8223c1544b748f1cee3f", "warmup_time": -1}, "stat_ops.Correlation.time_corrwith_rows": {"code": "class Correlation:\n    def time_corrwith_rows(self, method):\n        self.df.corrwith(self.df2, axis=1, method=method)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Correlation:\n    def setup(self, method):\n        self.df = pd.DataFrame(np.random.randn(500, 15))\n        self.df2 = pd.DataFrame(np.random.randn(500, 15))\n        self.df_wide = pd.DataFrame(np.random.randn(500, 100))\n        self.df_wide_nans = self.df_wide.where(np.random.random((500, 100)) < 0.9)\n        self.s = pd.Series(np.random.randn(500))\n        self.s2 = pd.Series(np.random.randn(500))", "min_run_count": 2, "name": "stat_ops.Correlation.time_corrwith_rows", "number": 0, "param_names": ["method"], "params": [["'spearman'", "'kendall'", "'pearson'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "537c1ca1a5384e46898eef91e2a713efab1b5f27bece96d73baa8c1084a319eb", "warmup_time": -1}, "stat_ops.Covariance.time_cov_series": {"code": "class Covariance:\n    def time_cov_series(self):\n        self.s.cov(self.s2)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Covariance:\n    def setup(self):\n        self.s = pd.Series(np.random.randn(100000))\n        self.s2 = pd.Series(np.random.randn(100000))", "min_run_count": 2, "name": "stat_ops.Covariance.time_cov_series", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "5127b263e3a6473e609cbc77952bf516e224e61656efd15280caf5a2bd93ac5f", "warmup_time": -1}, "stat_ops.FrameMultiIndexOps.time_op": {"code": "class FrameMultiIndexOps:\n    def time_op(self, op):\n        self.df_func()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass FrameMultiIndexOps:\n    def setup(self, op):\n        levels = [np.arange(10), np.arange(100), np.arange(100)]\n        codes = [\n            np.arange(10).repeat(10000),\n            np.tile(np.arange(100).repeat(100), 10),\n            np.tile(np.tile(np.arange(100), 100), 10),\n        ]\n        index = pd.MultiIndex(levels=levels, codes=codes)\n        df = pd.DataFrame(np.random.randn(len(index), 4), index=index)\n        self.df_func = getattr(df, op)", "min_run_count": 2, "name": "stat_ops.FrameMultiIndexOps.time_op", "number": 0, "param_names": ["op"], "params": [["'mean'", "'sum'", "'median'", "'std'", "'skew'", "'kurt'", "'prod'", "'sem'", "'var'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "13a0374ca338a8b54f1bd16d1ffe134ba780a1d942f5be7ac191ba76b2be4f8f", "warmup_time": -1}, "stat_ops.FrameOps.time_op": {"code": "class FrameOps:\n    def time_op(self, op, dtype, axis):\n        self.df_func(axis=axis)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass FrameOps:\n    def setup(self, op, dtype, axis):\n        values = np.random.randn(100000, 4)\n        if dtype == \"Int64\":\n            values = values.astype(int)\n        df = pd.DataFrame(values).astype(dtype)\n        self.df_func = getattr(df, op)", "min_run_count": 2, "name": "stat_ops.FrameOps.time_op", "number": 0, "param_names": ["op", "dtype", "axis"], "params": [["'mean'", "'sum'", "'median'", "'std'", "'skew'", "'kurt'", "'prod'", "'sem'", "'var'"], ["'float'", "'int'", "'Int64'"], ["0", "1"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "b07391c064482d2f0ffb065b28ce25a0cc9d57d9d0281a2d85490c669a986f7e", "warmup_time": -1}, "stat_ops.Rank.time_average_old": {"code": "class Rank:\n    def time_average_old(self, constructor, pct):\n        self.data.rank(pct=pct) / len(self.data)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Rank:\n    def setup(self, constructor, pct):\n        values = np.random.randn(10**5)\n        self.data = getattr(pd, constructor)(values)", "min_run_count": 2, "name": "stat_ops.Rank.time_average_old", "number": 0, "param_names": ["constructor", "pct"], "params": [["'DataFrame'", "'Series'"], ["True", "False"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "82f64cd32e871ed31fd99deb14e611ab16a04df9a99cf92bf1e12863d0d82bda", "warmup_time": -1}, "stat_ops.Rank.time_rank": {"code": "class Rank:\n    def time_rank(self, constructor, pct):\n        self.data.rank(pct=pct)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Rank:\n    def setup(self, constructor, pct):\n        values = np.random.randn(10**5)\n        self.data = getattr(pd, constructor)(values)", "min_run_count": 2, "name": "stat_ops.Rank.time_rank", "number": 0, "param_names": ["constructor", "pct"], "params": [["'DataFrame'", "'Series'"], ["True", "False"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "f8b083c6f46cf347224b1f03549284db11f310cb7e3936a705627eddfeb01142", "warmup_time": -1}, "stat_ops.SeriesMultiIndexOps.time_op": {"code": "class SeriesMultiIndexOps:\n    def time_op(self, op):\n        self.s_func()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass SeriesMultiIndexOps:\n    def setup(self, op):\n        levels = [np.arange(10), np.arange(100), np.arange(100)]\n        codes = [\n            np.arange(10).repeat(10000),\n            np.tile(np.arange(100).repeat(100), 10),\n            np.tile(np.tile(np.arange(100), 100), 10),\n        ]\n        index = pd.MultiIndex(levels=levels, codes=codes)\n        s = pd.Series(np.random.randn(len(index)), index=index)\n        self.s_func = getattr(s, op)", "min_run_count": 2, "name": "stat_ops.SeriesMultiIndexOps.time_op", "number": 0, "param_names": ["op"], "params": [["'mean'", "'sum'", "'median'", "'std'", "'skew'", "'kurt'", "'prod'", "'sem'", "'var'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "fafe7c22ddf1ddd0aa6871d8d9537041f3e037adacdc1794d69166a0bfc9dbaa", "warmup_time": -1}, "stat_ops.SeriesOps.time_op": {"code": "class SeriesOps:\n    def time_op(self, op, dtype):\n        self.s_func()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass SeriesOps:\n    def setup(self, op, dtype):\n        s = pd.Series(np.random.randn(100000)).astype(dtype)\n        self.s_func = getattr(s, op)", "min_run_count": 2, "name": "stat_ops.SeriesOps.time_op", "number": 0, "param_names": ["op", "dtype"], "params": [["'mean'", "'sum'", "'median'", "'std'", "'skew'", "'kurt'", "'prod'", "'sem'", "'var'"], ["'float'", "'int'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "32cfffab59594606bcaccdcd64c3521e5ffec20c0dcf9b1c864e4d0a6dc41bd4", "warmup_time": -1}, "strftime.BusinessHourStrftime.time_frame_offset_repr": {"code": "class BusinessHourStrftime:\n    def time_frame_offset_repr(self, obs):\n        self.data[\"off\"].apply(repr)\n\n    def setup(self, obs):\n        self.data = pd.DataFrame(\n            {\n                \"off\": [offsets.BusinessHour()] * obs,\n            }\n        )", "min_run_count": 2, "name": "strftime.BusinessHourStrftime.time_frame_offset_repr", "number": 0, "param_names": ["obs"], "params": [["1000", "10000"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 1500, "type": "time", "unit": "seconds", "version": "e9ac97b3656d3bb095b304bc9042003500af746b4267cf5116b8c0dfe6447f49", "warmup_time": -1}, "strftime.BusinessHourStrftime.time_frame_offset_str": {"code": "class BusinessHourStrftime:\n    def time_frame_offset_str(self, obs):\n        self.data[\"off\"].apply(str)\n\n    def setup(self, obs):\n        self.data = pd.DataFrame(\n            {\n                \"off\": [offsets.BusinessHour()] * obs,\n            }\n        )", "min_run_count": 2, "name": "strftime.BusinessHourStrftime.time_frame_offset_str", "number": 0, "param_names": ["obs"], "params": [["1000", "10000"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 1500, "type": "time", "unit": "seconds", "version": "66fc106fa45f6b9d3ea49e25efc37aaba1e4be995c5fdbee485a5785b83a9961", "warmup_time": -1}, "strftime.DatetimeStrftime.time_frame_date_formatting_custom": {"code": "class DatetimeStrftime:\n    def time_frame_date_formatting_custom(self, obs):\n        self.data[\"d\"].dt.strftime(date_format=\"%Y---%m---%d\")\n\n    def setup(self, obs):\n        d = \"2018-11-29\"\n        dt = \"2018-11-26 11:18:27.0\"\n        self.data = pd.DataFrame(\n            {\n                \"dt\": [np.datetime64(dt)] * obs,\n                \"d\": [np.datetime64(d)] * obs,\n                \"r\": [np.random.uniform()] * obs,\n            }\n        )", "min_run_count": 2, "name": "strftime.DatetimeStrftime.time_frame_date_formatting_custom", "number": 0, "param_names": ["obs"], "params": [["1000", "10000"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 1500, "type": "time", "unit": "seconds", "version": "20fc3c1a07a1355c5bdecceef391d17577dc75d433ad8de87ab3ae7cd4f01058", "warmup_time": -1}, "strftime.DatetimeStrftime.time_frame_date_formatting_default": {"code": "class DatetimeStrftime:\n    def time_frame_date_formatting_default(self, obs):\n        self.data[\"d\"].dt.strftime(date_format=\"%Y-%m-%d\")\n\n    def setup(self, obs):\n        d = \"2018-11-29\"\n        dt = \"2018-11-26 11:18:27.0\"\n        self.data = pd.DataFrame(\n            {\n                \"dt\": [np.datetime64(dt)] * obs,\n                \"d\": [np.datetime64(d)] * obs,\n                \"r\": [np.random.uniform()] * obs,\n            }\n        )", "min_run_count": 2, "name": "strftime.DatetimeStrftime.time_frame_date_formatting_default", "number": 0, "param_names": ["obs"], "params": [["1000", "10000"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 1500, "type": "time", "unit": "seconds", "version": "cfccb3931dd052cead4dec3ecbbe0bf144d87cb7ada3b507106260608a26c3a0", "warmup_time": -1}, "strftime.DatetimeStrftime.time_frame_date_to_str": {"code": "class DatetimeStrftime:\n    def time_frame_date_to_str(self, obs):\n        self.data[\"d\"].astype(str)\n\n    def setup(self, obs):\n        d = \"2018-11-29\"\n        dt = \"2018-11-26 11:18:27.0\"\n        self.data = pd.DataFrame(\n            {\n                \"dt\": [np.datetime64(dt)] * obs,\n                \"d\": [np.datetime64(d)] * obs,\n                \"r\": [np.random.uniform()] * obs,\n            }\n        )", "min_run_count": 2, "name": "strftime.DatetimeStrftime.time_frame_date_to_str", "number": 0, "param_names": ["obs"], "params": [["1000", "10000"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 1500, "type": "time", "unit": "seconds", "version": "b6cd506654524695d645ff8c7a6a509f3d85de60a89e7bb96a65173536bf58d3", "warmup_time": -1}, "strftime.DatetimeStrftime.time_frame_datetime_formatting_custom": {"code": "class DatetimeStrftime:\n    def time_frame_datetime_formatting_custom(self, obs):\n        self.data[\"dt\"].dt.strftime(date_format=\"%Y-%m-%d --- %H:%M:%S\")\n\n    def setup(self, obs):\n        d = \"2018-11-29\"\n        dt = \"2018-11-26 11:18:27.0\"\n        self.data = pd.DataFrame(\n            {\n                \"dt\": [np.datetime64(dt)] * obs,\n                \"d\": [np.datetime64(d)] * obs,\n                \"r\": [np.random.uniform()] * obs,\n            }\n        )", "min_run_count": 2, "name": "strftime.DatetimeStrftime.time_frame_datetime_formatting_custom", "number": 0, "param_names": ["obs"], "params": [["1000", "10000"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 1500, "type": "time", "unit": "seconds", "version": "c8405c8376cb01e000c8239e8a6b3ac74b07c6c07fd0f11923ce6868d5cc1b1f", "warmup_time": -1}, "strftime.DatetimeStrftime.time_frame_datetime_formatting_default": {"code": "class DatetimeStrftime:\n    def time_frame_datetime_formatting_default(self, obs):\n        self.data[\"dt\"].dt.strftime(date_format=\"%Y-%m-%d %H:%M:%S\")\n\n    def setup(self, obs):\n        d = \"2018-11-29\"\n        dt = \"2018-11-26 11:18:27.0\"\n        self.data = pd.DataFrame(\n            {\n                \"dt\": [np.datetime64(dt)] * obs,\n                \"d\": [np.datetime64(d)] * obs,\n                \"r\": [np.random.uniform()] * obs,\n            }\n        )", "min_run_count": 2, "name": "strftime.DatetimeStrftime.time_frame_datetime_formatting_default", "number": 0, "param_names": ["obs"], "params": [["1000", "10000"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 1500, "type": "time", "unit": "seconds", "version": "8bd068d49c2ce057860ca3843058037ee18a2d4e1c9ece20196147456e7f3ccd", "warmup_time": -1}, "strftime.DatetimeStrftime.time_frame_datetime_formatting_default_date_only": {"code": "class DatetimeStrftime:\n    def time_frame_datetime_formatting_default_date_only(self, obs):\n        self.data[\"dt\"].dt.strftime(date_format=\"%Y-%m-%d\")\n\n    def setup(self, obs):\n        d = \"2018-11-29\"\n        dt = \"2018-11-26 11:18:27.0\"\n        self.data = pd.DataFrame(\n            {\n                \"dt\": [np.datetime64(dt)] * obs,\n                \"d\": [np.datetime64(d)] * obs,\n                \"r\": [np.random.uniform()] * obs,\n            }\n        )", "min_run_count": 2, "name": "strftime.DatetimeStrftime.time_frame_datetime_formatting_default_date_only", "number": 0, "param_names": ["obs"], "params": [["1000", "10000"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 1500, "type": "time", "unit": "seconds", "version": "1b42223473d3d945c344e8d91d0f17d06dcb7618760868c5e06dfff7a4d98684", "warmup_time": -1}, "strftime.DatetimeStrftime.time_frame_datetime_formatting_default_with_float": {"code": "class DatetimeStrftime:\n    def time_frame_datetime_formatting_default_with_float(self, obs):\n        self.data[\"dt\"].dt.strftime(date_format=\"%Y-%m-%d %H:%M:%S.%f\")\n\n    def setup(self, obs):\n        d = \"2018-11-29\"\n        dt = \"2018-11-26 11:18:27.0\"\n        self.data = pd.DataFrame(\n            {\n                \"dt\": [np.datetime64(dt)] * obs,\n                \"d\": [np.datetime64(d)] * obs,\n                \"r\": [np.random.uniform()] * obs,\n            }\n        )", "min_run_count": 2, "name": "strftime.DatetimeStrftime.time_frame_datetime_formatting_default_with_float", "number": 0, "param_names": ["obs"], "params": [["1000", "10000"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 1500, "type": "time", "unit": "seconds", "version": "6136c4315e774c7c045f71721badb4bad90d9029b07199160580274779f5e2a0", "warmup_time": -1}, "strftime.DatetimeStrftime.time_frame_datetime_to_str": {"code": "class DatetimeStrftime:\n    def time_frame_datetime_to_str(self, obs):\n        self.data[\"dt\"].astype(str)\n\n    def setup(self, obs):\n        d = \"2018-11-29\"\n        dt = \"2018-11-26 11:18:27.0\"\n        self.data = pd.DataFrame(\n            {\n                \"dt\": [np.datetime64(dt)] * obs,\n                \"d\": [np.datetime64(d)] * obs,\n                \"r\": [np.random.uniform()] * obs,\n            }\n        )", "min_run_count": 2, "name": "strftime.DatetimeStrftime.time_frame_datetime_to_str", "number": 0, "param_names": ["obs"], "params": [["1000", "10000"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 1500, "type": "time", "unit": "seconds", "version": "d296198f29e41a8d37967bd2e8cf9a23aa896f42a14679b1c0c3df67db3c7aab", "warmup_time": -1}, "strings.Cat.time_cat": {"code": "class Cat:\n    def time_cat(self, other_cols, sep, na_rep, na_frac):\n        # before the concatenation (one caller + other_cols columns), the total\n        # expected fraction of rows containing any NaN is:\n        # reduce(lambda t, _: t + (1 - t) * na_frac, range(other_cols + 1), 0)\n        # for other_cols=3 and na_frac=0.15, this works out to ~48%\n        self.s.str.cat(others=self.others, sep=sep, na_rep=na_rep)\n\n    def setup(self, other_cols, sep, na_rep, na_frac):\n        N = 10**5\n        mask_gen = lambda: np.random.choice([True, False], N, p=[1 - na_frac, na_frac])\n        self.s = Series(tm.makeStringIndex(N)).where(mask_gen())\n        if other_cols == 0:\n            # str.cat self-concatenates only for others=None\n            self.others = None\n        else:\n            self.others = DataFrame(\n                {i: tm.makeStringIndex(N).where(mask_gen()) for i in range(other_cols)}\n            )", "min_run_count": 2, "name": "strings.Cat.time_cat", "number": 0, "param_names": ["other_cols", "sep", "na_rep", "na_frac"], "params": [["0", "3"], ["None", "','"], ["None", "'-'"], ["0.0", "0.001", "0.15"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "7580a14f59b80ca9f3e39f8438787014b658b50839c3bcc4430f23eedd78bb32", "warmup_time": -1}, "strings.Construction.peakmem_cat_frame_construction": {"code": "class Construction:\n    def peakmem_cat_frame_construction(self, dtype):\n        DataFrame(self.frame_cat_arr, dtype=dtype)\n\n    def setup(self, dtype):\n        self.series_arr = tm.rands_array(nchars=10, size=10**5)\n        self.frame_arr = self.series_arr.reshape((50_000, 2)).copy()\n    \n        # GH37371. Testing construction of string series/frames from ExtensionArrays\n        self.series_cat_arr = Categorical(self.series_arr)\n        self.frame_cat_arr = Categorical(self.frame_arr)", "name": "strings.Construction.peakmem_cat_frame_construction", "param_names": ["dtype"], "params": [["'str'", "'string'"]], "timeout": 60.0, "type": "peakmemory", "unit": "bytes", "version": "2681a3a3ec49165a26eb4959a5898cc63c3218ceb10e3d9a2749d1c943ef1615"}, "strings.Construction.peakmem_cat_series_construction": {"code": "class Construction:\n    def peakmem_cat_series_construction(self, dtype):\n        Series(self.series_cat_arr, dtype=dtype)\n\n    def setup(self, dtype):\n        self.series_arr = tm.rands_array(nchars=10, size=10**5)\n        self.frame_arr = self.series_arr.reshape((50_000, 2)).copy()\n    \n        # GH37371. Testing construction of string series/frames from ExtensionArrays\n        self.series_cat_arr = Categorical(self.series_arr)\n        self.frame_cat_arr = Categorical(self.frame_arr)", "name": "strings.Construction.peakmem_cat_series_construction", "param_names": ["dtype"], "params": [["'str'", "'string'"]], "timeout": 60.0, "type": "peakmemory", "unit": "bytes", "version": "15b80fb3cfcfea04da1a1a4270807b08f80f70be3b2b0e66757dad51c8033464"}, "strings.Construction.peakmem_frame_construction": {"code": "class Construction:\n    def peakmem_frame_construction(self, dtype):\n        DataFrame(self.frame_arr, dtype=dtype)\n\n    def setup(self, dtype):\n        self.series_arr = tm.rands_array(nchars=10, size=10**5)\n        self.frame_arr = self.series_arr.reshape((50_000, 2)).copy()\n    \n        # GH37371. Testing construction of string series/frames from ExtensionArrays\n        self.series_cat_arr = Categorical(self.series_arr)\n        self.frame_cat_arr = Categorical(self.frame_arr)", "name": "strings.Construction.peakmem_frame_construction", "param_names": ["dtype"], "params": [["'str'", "'string'"]], "timeout": 60.0, "type": "peakmemory", "unit": "bytes", "version": "7e7a0d1ce09ffac1e456730d47cfff4918892e73a17f600b747866d4156e8cb7"}, "strings.Construction.peakmem_series_construction": {"code": "class Construction:\n    def peakmem_series_construction(self, dtype):\n        Series(self.series_arr, dtype=dtype)\n\n    def setup(self, dtype):\n        self.series_arr = tm.rands_array(nchars=10, size=10**5)\n        self.frame_arr = self.series_arr.reshape((50_000, 2)).copy()\n    \n        # GH37371. Testing construction of string series/frames from ExtensionArrays\n        self.series_cat_arr = Categorical(self.series_arr)\n        self.frame_cat_arr = Categorical(self.frame_arr)", "name": "strings.Construction.peakmem_series_construction", "param_names": ["dtype"], "params": [["'str'", "'string'"]], "timeout": 60.0, "type": "peakmemory", "unit": "bytes", "version": "06738a0b2bc95742bb8222f922a6c155f9bc9c3e16918ed7b6d5382db22072c9"}, "strings.Construction.time_cat_frame_construction": {"code": "class Construction:\n    def time_cat_frame_construction(self, dtype):\n        DataFrame(self.frame_cat_arr, dtype=dtype)\n\n    def setup(self, dtype):\n        self.series_arr = tm.rands_array(nchars=10, size=10**5)\n        self.frame_arr = self.series_arr.reshape((50_000, 2)).copy()\n    \n        # GH37371. Testing construction of string series/frames from ExtensionArrays\n        self.series_cat_arr = Categorical(self.series_arr)\n        self.frame_cat_arr = Categorical(self.frame_arr)", "min_run_count": 2, "name": "strings.Construction.time_cat_frame_construction", "number": 0, "param_names": ["dtype"], "params": [["'str'", "'string'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "39a8fce1e556a99c04c394c22e85df18088e76b32bb35cbfa446443209e77112", "warmup_time": -1}, "strings.Construction.time_cat_series_construction": {"code": "class Construction:\n    def time_cat_series_construction(self, dtype):\n        Series(self.series_cat_arr, dtype=dtype)\n\n    def setup(self, dtype):\n        self.series_arr = tm.rands_array(nchars=10, size=10**5)\n        self.frame_arr = self.series_arr.reshape((50_000, 2)).copy()\n    \n        # GH37371. Testing construction of string series/frames from ExtensionArrays\n        self.series_cat_arr = Categorical(self.series_arr)\n        self.frame_cat_arr = Categorical(self.frame_arr)", "min_run_count": 2, "name": "strings.Construction.time_cat_series_construction", "number": 0, "param_names": ["dtype"], "params": [["'str'", "'string'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "78b9c1dd1cf16c295f30096e31f739d1626917627fc0a6c4a129577495064c0f", "warmup_time": -1}, "strings.Construction.time_frame_construction": {"code": "class Construction:\n    def time_frame_construction(self, dtype):\n        DataFrame(self.frame_arr, dtype=dtype)\n\n    def setup(self, dtype):\n        self.series_arr = tm.rands_array(nchars=10, size=10**5)\n        self.frame_arr = self.series_arr.reshape((50_000, 2)).copy()\n    \n        # GH37371. Testing construction of string series/frames from ExtensionArrays\n        self.series_cat_arr = Categorical(self.series_arr)\n        self.frame_cat_arr = Categorical(self.frame_arr)", "min_run_count": 2, "name": "strings.Construction.time_frame_construction", "number": 0, "param_names": ["dtype"], "params": [["'str'", "'string'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "6dc7989c4e01d1a0e4d7897d002c92d618bc8f03046c2e876ed02e503e899d5f", "warmup_time": -1}, "strings.Construction.time_series_construction": {"code": "class Construction:\n    def time_series_construction(self, dtype):\n        Series(self.series_arr, dtype=dtype)\n\n    def setup(self, dtype):\n        self.series_arr = tm.rands_array(nchars=10, size=10**5)\n        self.frame_arr = self.series_arr.reshape((50_000, 2)).copy()\n    \n        # GH37371. Testing construction of string series/frames from ExtensionArrays\n        self.series_cat_arr = Categorical(self.series_arr)\n        self.frame_cat_arr = Categorical(self.frame_arr)", "min_run_count": 2, "name": "strings.Construction.time_series_construction", "number": 0, "param_names": ["dtype"], "params": [["'str'", "'string'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "0c9ca0706c7ea81a7c5d868e44d8f2fa7b6aba3683870ef811a20c7b8c188c68", "warmup_time": -1}, "strings.Contains.time_contains": {"code": "class Contains:\n    def time_contains(self, dtype, regex):\n        self.s.str.contains(\"A\", regex=regex)\n\n    def setup(self, dtype, regex):\n        super().setup(dtype)", "min_run_count": 2, "name": "strings.Contains.time_contains", "number": 0, "param_names": ["dtype", "regex"], "params": [["'str'", "'string[python]'", "'string[pyarrow]'"], ["True", "False"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "059d755b738e508f2767456a3bcb5561731b1d7d8ac1ad2e92fddc4828e30270", "warmup_time": -1}, "strings.Dummies.time_get_dummies": {"code": "class Dummies:\n    def time_get_dummies(self, dtype):\n        self.s.str.get_dummies(\"|\")\n\n    def setup(self, dtype):\n        super().setup(dtype)\n        self.s = self.s.str.join(\"|\")", "min_run_count": 2, "name": "strings.Dummies.time_get_dummies", "number": 0, "param_names": ["dtype"], "params": [["'str'", "'string[python]'", "'string[pyarrow]'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "05a8b467626fc1ca2b62daa6ea86653c41533ff9cba30dddb51f622ecbe0e6e6", "warmup_time": -1}, "strings.Encode.time_encode_decode": {"code": "class Encode:\n    def time_encode_decode(self):\n        self.ser.str.encode(\"utf-8\").str.decode(\"utf-8\")\n\n    def setup(self):\n        self.ser = Series(tm.makeStringIndex())", "min_run_count": 2, "name": "strings.Encode.time_encode_decode", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "920f7940a86a358f14b0b4fe631e57f2cf4c0d2c390c0ca40ae698a04b19d774", "warmup_time": -1}, "strings.Extract.time_extract_single_group": {"code": "class Extract:\n    def time_extract_single_group(self, dtype, expand):\n        with warnings.catch_warnings(record=True):\n            self.s.str.extract(\"(\\\\w*)A\", expand=expand)\n\n    def setup(self, dtype, expand):\n        super().setup(dtype)", "min_run_count": 2, "name": "strings.Extract.time_extract_single_group", "number": 0, "param_names": ["dtype", "expand"], "params": [["'str'", "'string[python]'", "'string[pyarrow]'"], ["True", "False"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "4a4c5c7bdd1645c137d0f4bcafc4eb9b92be955e5bb27fd6fe7994d2466c32e7", "warmup_time": -1}, "strings.Iter.time_iter": {"code": "class Iter:\n    def time_iter(self, dtype):\n        for i in self.s:\n            pass\n\nclass Dtypes:\n    def setup(self, dtype):\n        try:\n            self.s = Series(tm.makeStringIndex(10**5), dtype=dtype)\n        except ImportError:\n            raise NotImplementedError", "min_run_count": 2, "name": "strings.Iter.time_iter", "number": 0, "param_names": ["dtype"], "params": [["'str'", "'string[python]'", "'string[pyarrow]'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "0e13503a95796e27dccdd2fd1c60dad9d2eb0c3e804b3bff8fdc5daa05e3802e", "warmup_time": -1}, "strings.Methods.time_center": {"code": "class Methods:\n    def time_center(self, dtype):\n        self.s.str.center(100)\n\nclass Dtypes:\n    def setup(self, dtype):\n        try:\n            self.s = Series(tm.makeStringIndex(10**5), dtype=dtype)\n        except ImportError:\n            raise NotImplementedError", "min_run_count": 2, "name": "strings.Methods.time_center", "number": 0, "param_names": ["dtype"], "params": [["'str'", "'string[python]'", "'string[pyarrow]'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "c90fc5492c9db220fa5db062d963be0f95a5105e56c55272d0dc200e83a8e63d", "warmup_time": -1}, "strings.Methods.time_count": {"code": "class Methods:\n    def time_count(self, dtype):\n        self.s.str.count(\"A\")\n\nclass Dtypes:\n    def setup(self, dtype):\n        try:\n            self.s = Series(tm.makeStringIndex(10**5), dtype=dtype)\n        except ImportError:\n            raise NotImplementedError", "min_run_count": 2, "name": "strings.Methods.time_count", "number": 0, "param_names": ["dtype"], "params": [["'str'", "'string[python]'", "'string[pyarrow]'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "aa8a39af45b367dbca151afbb5918af52a2972fdd6734798e1c890efd7446322", "warmup_time": -1}, "strings.Methods.time_endswith": {"code": "class Methods:\n    def time_endswith(self, dtype):\n        self.s.str.endswith(\"A\")\n\nclass Dtypes:\n    def setup(self, dtype):\n        try:\n            self.s = Series(tm.makeStringIndex(10**5), dtype=dtype)\n        except ImportError:\n            raise NotImplementedError", "min_run_count": 2, "name": "strings.Methods.time_endswith", "number": 0, "param_names": ["dtype"], "params": [["'str'", "'string[python]'", "'string[pyarrow]'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "cf41fed24c9e4e421fd60969f4fee79cf730b3aef4fe1a8a7e0c51a61bc1fa02", "warmup_time": -1}, "strings.Methods.time_extract": {"code": "class Methods:\n    def time_extract(self, dtype):\n        with warnings.catch_warnings(record=True):\n            self.s.str.extract(\"(\\\\w*)A(\\\\w*)\")\n\nclass Dtypes:\n    def setup(self, dtype):\n        try:\n            self.s = Series(tm.makeStringIndex(10**5), dtype=dtype)\n        except ImportError:\n            raise NotImplementedError", "min_run_count": 2, "name": "strings.Methods.time_extract", "number": 0, "param_names": ["dtype"], "params": [["'str'", "'string[python]'", "'string[pyarrow]'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "bdac930a3463e117fc65e946aa51c01a07b19c915ccf662f424396740d4ab6cc", "warmup_time": -1}, "strings.Methods.time_find": {"code": "class Methods:\n    def time_find(self, dtype):\n        self.s.str.find(\"[A-Z]+\")\n\nclass Dtypes:\n    def setup(self, dtype):\n        try:\n            self.s = Series(tm.makeStringIndex(10**5), dtype=dtype)\n        except ImportError:\n            raise NotImplementedError", "min_run_count": 2, "name": "strings.Methods.time_find", "number": 0, "param_names": ["dtype"], "params": [["'str'", "'string[python]'", "'string[pyarrow]'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "d68e43b9a79ea76ff9de4385de4b7640a978478eb2c9596240f6b28ebc225309", "warmup_time": -1}, "strings.Methods.time_findall": {"code": "class Methods:\n    def time_findall(self, dtype):\n        self.s.str.findall(\"[A-Z]+\")\n\nclass Dtypes:\n    def setup(self, dtype):\n        try:\n            self.s = Series(tm.makeStringIndex(10**5), dtype=dtype)\n        except ImportError:\n            raise NotImplementedError", "min_run_count": 2, "name": "strings.Methods.time_findall", "number": 0, "param_names": ["dtype"], "params": [["'str'", "'string[python]'", "'string[pyarrow]'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "09a6ac803927a662f0acac6caf1a59bb397dee68d1cca6bd385dfeef5f401eda", "warmup_time": -1}, "strings.Methods.time_fullmatch": {"code": "class Methods:\n    def time_fullmatch(self, dtype):\n        self.s.str.fullmatch(\"A\")\n\nclass Dtypes:\n    def setup(self, dtype):\n        try:\n            self.s = Series(tm.makeStringIndex(10**5), dtype=dtype)\n        except ImportError:\n            raise NotImplementedError", "min_run_count": 2, "name": "strings.Methods.time_fullmatch", "number": 0, "param_names": ["dtype"], "params": [["'str'", "'string[python]'", "'string[pyarrow]'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "11ea3b0c74ae725d490c2ee20b0df3b26c88f93eb0de7f3ddf0e36f2f4882d13", "warmup_time": -1}, "strings.Methods.time_get": {"code": "class Methods:\n    def time_get(self, dtype):\n        self.s.str.get(0)\n\nclass Dtypes:\n    def setup(self, dtype):\n        try:\n            self.s = Series(tm.makeStringIndex(10**5), dtype=dtype)\n        except ImportError:\n            raise NotImplementedError", "min_run_count": 2, "name": "strings.Methods.time_get", "number": 0, "param_names": ["dtype"], "params": [["'str'", "'string[python]'", "'string[pyarrow]'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "163b9358aa7e758dbc8008f798f7ee72410c9fb3568086edb4fe0d7431120e16", "warmup_time": -1}, "strings.Methods.time_isalnum": {"code": "class Methods:\n    def time_isalnum(self, dtype):\n        self.s.str.isalnum()\n\nclass Dtypes:\n    def setup(self, dtype):\n        try:\n            self.s = Series(tm.makeStringIndex(10**5), dtype=dtype)\n        except ImportError:\n            raise NotImplementedError", "min_run_count": 2, "name": "strings.Methods.time_isalnum", "number": 0, "param_names": ["dtype"], "params": [["'str'", "'string[python]'", "'string[pyarrow]'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "274d4feabc32edd1c8c5747ac59f8ff0fd609d4467d3c5c4256a59e424766b07", "warmup_time": -1}, "strings.Methods.time_isalpha": {"code": "class Methods:\n    def time_isalpha(self, dtype):\n        self.s.str.isalpha()\n\nclass Dtypes:\n    def setup(self, dtype):\n        try:\n            self.s = Series(tm.makeStringIndex(10**5), dtype=dtype)\n        except ImportError:\n            raise NotImplementedError", "min_run_count": 2, "name": "strings.Methods.time_isalpha", "number": 0, "param_names": ["dtype"], "params": [["'str'", "'string[python]'", "'string[pyarrow]'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "7b596edc9989b64243b21f6ed4c27fabee5a636f543029512f3df49e7f6f0d63", "warmup_time": -1}, "strings.Methods.time_isdecimal": {"code": "class Methods:\n    def time_isdecimal(self, dtype):\n        self.s.str.isdecimal()\n\nclass Dtypes:\n    def setup(self, dtype):\n        try:\n            self.s = Series(tm.makeStringIndex(10**5), dtype=dtype)\n        except ImportError:\n            raise NotImplementedError", "min_run_count": 2, "name": "strings.Methods.time_isdecimal", "number": 0, "param_names": ["dtype"], "params": [["'str'", "'string[python]'", "'string[pyarrow]'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "aa85b4cb282965c7778b4a75c5f6a6ad4c8833b845d9f7b533f1b021739f3d8e", "warmup_time": -1}, "strings.Methods.time_isdigit": {"code": "class Methods:\n    def time_isdigit(self, dtype):\n        self.s.str.isdigit()\n\nclass Dtypes:\n    def setup(self, dtype):\n        try:\n            self.s = Series(tm.makeStringIndex(10**5), dtype=dtype)\n        except ImportError:\n            raise NotImplementedError", "min_run_count": 2, "name": "strings.Methods.time_isdigit", "number": 0, "param_names": ["dtype"], "params": [["'str'", "'string[python]'", "'string[pyarrow]'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "fb7e5f6fae185efa0278c8294f5f8376723153722ccd75c076cf4c3044b90569", "warmup_time": -1}, "strings.Methods.time_islower": {"code": "class Methods:\n    def time_islower(self, dtype):\n        self.s.str.islower()\n\nclass Dtypes:\n    def setup(self, dtype):\n        try:\n            self.s = Series(tm.makeStringIndex(10**5), dtype=dtype)\n        except ImportError:\n            raise NotImplementedError", "min_run_count": 2, "name": "strings.Methods.time_islower", "number": 0, "param_names": ["dtype"], "params": [["'str'", "'string[python]'", "'string[pyarrow]'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "59532c906dbfc24783d6b14fbf1c7b1a8b60d423a414cb8938a13c56e70ba114", "warmup_time": -1}, "strings.Methods.time_isnumeric": {"code": "class Methods:\n    def time_isnumeric(self, dtype):\n        self.s.str.isnumeric()\n\nclass Dtypes:\n    def setup(self, dtype):\n        try:\n            self.s = Series(tm.makeStringIndex(10**5), dtype=dtype)\n        except ImportError:\n            raise NotImplementedError", "min_run_count": 2, "name": "strings.Methods.time_isnumeric", "number": 0, "param_names": ["dtype"], "params": [["'str'", "'string[python]'", "'string[pyarrow]'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "7b3bdb5076ade2d78a2d54e5ff9d84a8045539189da326adeb09e9391e3db0a4", "warmup_time": -1}, "strings.Methods.time_isspace": {"code": "class Methods:\n    def time_isspace(self, dtype):\n        self.s.str.isspace()\n\nclass Dtypes:\n    def setup(self, dtype):\n        try:\n            self.s = Series(tm.makeStringIndex(10**5), dtype=dtype)\n        except ImportError:\n            raise NotImplementedError", "min_run_count": 2, "name": "strings.Methods.time_isspace", "number": 0, "param_names": ["dtype"], "params": [["'str'", "'string[python]'", "'string[pyarrow]'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "54dd193f9ad90942ca40ffa1e6ca3f861a4400808fd0a9c6addbdaa27b71f98e", "warmup_time": -1}, "strings.Methods.time_istitle": {"code": "class Methods:\n    def time_istitle(self, dtype):\n        self.s.str.istitle()\n\nclass Dtypes:\n    def setup(self, dtype):\n        try:\n            self.s = Series(tm.makeStringIndex(10**5), dtype=dtype)\n        except ImportError:\n            raise NotImplementedError", "min_run_count": 2, "name": "strings.Methods.time_istitle", "number": 0, "param_names": ["dtype"], "params": [["'str'", "'string[python]'", "'string[pyarrow]'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "4babffcdb8b57109b379071a256d91f269c50910ecf88d3f300888a68978ccd1", "warmup_time": -1}, "strings.Methods.time_isupper": {"code": "class Methods:\n    def time_isupper(self, dtype):\n        self.s.str.isupper()\n\nclass Dtypes:\n    def setup(self, dtype):\n        try:\n            self.s = Series(tm.makeStringIndex(10**5), dtype=dtype)\n        except ImportError:\n            raise NotImplementedError", "min_run_count": 2, "name": "strings.Methods.time_isupper", "number": 0, "param_names": ["dtype"], "params": [["'str'", "'string[python]'", "'string[pyarrow]'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "7ce1ce84619d4728435ee0906bc28eb7948b6f9a3cc51342de107971b4ebd909", "warmup_time": -1}, "strings.Methods.time_join": {"code": "class Methods:\n    def time_join(self, dtype):\n        self.s.str.join(\" \")\n\nclass Dtypes:\n    def setup(self, dtype):\n        try:\n            self.s = Series(tm.makeStringIndex(10**5), dtype=dtype)\n        except ImportError:\n            raise NotImplementedError", "min_run_count": 2, "name": "strings.Methods.time_join", "number": 0, "param_names": ["dtype"], "params": [["'str'", "'string[python]'", "'string[pyarrow]'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "f38cb5c4bd23bd6500c594e65b8970d4e7e0c1d237934428079187569777273f", "warmup_time": -1}, "strings.Methods.time_len": {"code": "class Methods:\n    def time_len(self, dtype):\n        self.s.str.len()\n\nclass Dtypes:\n    def setup(self, dtype):\n        try:\n            self.s = Series(tm.makeStringIndex(10**5), dtype=dtype)\n        except ImportError:\n            raise NotImplementedError", "min_run_count": 2, "name": "strings.Methods.time_len", "number": 0, "param_names": ["dtype"], "params": [["'str'", "'string[python]'", "'string[pyarrow]'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "401f2eae3d0b81c70965a405652dcd0659f5267ec4de912201111a450de96397", "warmup_time": -1}, "strings.Methods.time_lower": {"code": "class Methods:\n    def time_lower(self, dtype):\n        self.s.str.lower()\n\nclass Dtypes:\n    def setup(self, dtype):\n        try:\n            self.s = Series(tm.makeStringIndex(10**5), dtype=dtype)\n        except ImportError:\n            raise NotImplementedError", "min_run_count": 2, "name": "strings.Methods.time_lower", "number": 0, "param_names": ["dtype"], "params": [["'str'", "'string[python]'", "'string[pyarrow]'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "4d45b2a8051421781a5fa91281847333957b87eb0c1ceb450ef82153e84f274e", "warmup_time": -1}, "strings.Methods.time_lstrip": {"code": "class Methods:\n    def time_lstrip(self, dtype):\n        self.s.str.lstrip(\"A\")\n\nclass Dtypes:\n    def setup(self, dtype):\n        try:\n            self.s = Series(tm.makeStringIndex(10**5), dtype=dtype)\n        except ImportError:\n            raise NotImplementedError", "min_run_count": 2, "name": "strings.Methods.time_lstrip", "number": 0, "param_names": ["dtype"], "params": [["'str'", "'string[python]'", "'string[pyarrow]'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "1934b8e6b9d92178dffbe35e55f9d7feadc45a09faf82a2059fdf72547ed4bc5", "warmup_time": -1}, "strings.Methods.time_match": {"code": "class Methods:\n    def time_match(self, dtype):\n        self.s.str.match(\"A\")\n\nclass Dtypes:\n    def setup(self, dtype):\n        try:\n            self.s = Series(tm.makeStringIndex(10**5), dtype=dtype)\n        except ImportError:\n            raise NotImplementedError", "min_run_count": 2, "name": "strings.Methods.time_match", "number": 0, "param_names": ["dtype"], "params": [["'str'", "'string[python]'", "'string[pyarrow]'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "b524a53a636026536c3203b3c049e7662668fb7b8c4b9210ecada8c87c71191a", "warmup_time": -1}, "strings.Methods.time_normalize": {"code": "class Methods:\n    def time_normalize(self, dtype):\n        self.s.str.normalize(\"NFC\")\n\nclass Dtypes:\n    def setup(self, dtype):\n        try:\n            self.s = Series(tm.makeStringIndex(10**5), dtype=dtype)\n        except ImportError:\n            raise NotImplementedError", "min_run_count": 2, "name": "strings.Methods.time_normalize", "number": 0, "param_names": ["dtype"], "params": [["'str'", "'string[python]'", "'string[pyarrow]'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "d0e835b98205194ba4656c6fb7643c80d236ab4c61989f03cc7d253ec5d4b693", "warmup_time": -1}, "strings.Methods.time_pad": {"code": "class Methods:\n    def time_pad(self, dtype):\n        self.s.str.pad(100, side=\"both\")\n\nclass Dtypes:\n    def setup(self, dtype):\n        try:\n            self.s = Series(tm.makeStringIndex(10**5), dtype=dtype)\n        except ImportError:\n            raise NotImplementedError", "min_run_count": 2, "name": "strings.Methods.time_pad", "number": 0, "param_names": ["dtype"], "params": [["'str'", "'string[python]'", "'string[pyarrow]'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "2117c8aa91c07600447b4338c7bb046ca976036b8a02e737c05e8727a0c4842a", "warmup_time": -1}, "strings.Methods.time_partition": {"code": "class Methods:\n    def time_partition(self, dtype):\n        self.s.str.partition(\"A\")\n\nclass Dtypes:\n    def setup(self, dtype):\n        try:\n            self.s = Series(tm.makeStringIndex(10**5), dtype=dtype)\n        except ImportError:\n            raise NotImplementedError", "min_run_count": 2, "name": "strings.Methods.time_partition", "number": 0, "param_names": ["dtype"], "params": [["'str'", "'string[python]'", "'string[pyarrow]'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "bf3ed0ac89f1f4e06d40d30667cfa076777201f941a7489671fb671a27fd6760", "warmup_time": -1}, "strings.Methods.time_replace": {"code": "class Methods:\n    def time_replace(self, dtype):\n        self.s.str.replace(\"A\", \"\\x01\\x01\")\n\nclass Dtypes:\n    def setup(self, dtype):\n        try:\n            self.s = Series(tm.makeStringIndex(10**5), dtype=dtype)\n        except ImportError:\n            raise NotImplementedError", "min_run_count": 2, "name": "strings.Methods.time_replace", "number": 0, "param_names": ["dtype"], "params": [["'str'", "'string[python]'", "'string[pyarrow]'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "00004f4283f3821b83832becf8252dfa67918ee4d41b73e7b2e5537db63658c9", "warmup_time": -1}, "strings.Methods.time_rfind": {"code": "class Methods:\n    def time_rfind(self, dtype):\n        self.s.str.rfind(\"[A-Z]+\")\n\nclass Dtypes:\n    def setup(self, dtype):\n        try:\n            self.s = Series(tm.makeStringIndex(10**5), dtype=dtype)\n        except ImportError:\n            raise NotImplementedError", "min_run_count": 2, "name": "strings.Methods.time_rfind", "number": 0, "param_names": ["dtype"], "params": [["'str'", "'string[python]'", "'string[pyarrow]'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "41a699289fb6a9aa19d9bc0762745fcebac6d0a439b025aa64c4075412879dd2", "warmup_time": -1}, "strings.Methods.time_rpartition": {"code": "class Methods:\n    def time_rpartition(self, dtype):\n        self.s.str.rpartition(\"A\")\n\nclass Dtypes:\n    def setup(self, dtype):\n        try:\n            self.s = Series(tm.makeStringIndex(10**5), dtype=dtype)\n        except ImportError:\n            raise NotImplementedError", "min_run_count": 2, "name": "strings.Methods.time_rpartition", "number": 0, "param_names": ["dtype"], "params": [["'str'", "'string[python]'", "'string[pyarrow]'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "402e0a29a3ec182511df8777c2101886e889e984c8725f344e1f3e3428c24bac", "warmup_time": -1}, "strings.Methods.time_rstrip": {"code": "class Methods:\n    def time_rstrip(self, dtype):\n        self.s.str.rstrip(\"A\")\n\nclass Dtypes:\n    def setup(self, dtype):\n        try:\n            self.s = Series(tm.makeStringIndex(10**5), dtype=dtype)\n        except ImportError:\n            raise NotImplementedError", "min_run_count": 2, "name": "strings.Methods.time_rstrip", "number": 0, "param_names": ["dtype"], "params": [["'str'", "'string[python]'", "'string[pyarrow]'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "a7fb5a5015ffb77cf2d85fffb0d31841edb9a7cea5d1e879c70991d263325f42", "warmup_time": -1}, "strings.Methods.time_slice": {"code": "class Methods:\n    def time_slice(self, dtype):\n        self.s.str.slice(5, 15, 2)\n\nclass Dtypes:\n    def setup(self, dtype):\n        try:\n            self.s = Series(tm.makeStringIndex(10**5), dtype=dtype)\n        except ImportError:\n            raise NotImplementedError", "min_run_count": 2, "name": "strings.Methods.time_slice", "number": 0, "param_names": ["dtype"], "params": [["'str'", "'string[python]'", "'string[pyarrow]'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "5d8e27d1db3f39c85f472b9db3529bc86de2afc0a5a6e7b0ffff0d64f798ec5e", "warmup_time": -1}, "strings.Methods.time_startswith": {"code": "class Methods:\n    def time_startswith(self, dtype):\n        self.s.str.startswith(\"A\")\n\nclass Dtypes:\n    def setup(self, dtype):\n        try:\n            self.s = Series(tm.makeStringIndex(10**5), dtype=dtype)\n        except ImportError:\n            raise NotImplementedError", "min_run_count": 2, "name": "strings.Methods.time_startswith", "number": 0, "param_names": ["dtype"], "params": [["'str'", "'string[python]'", "'string[pyarrow]'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "2bcf5ec255a1a8cade382a55d3808e49194d49cabb0ff817cbd602867248996b", "warmup_time": -1}, "strings.Methods.time_strip": {"code": "class Methods:\n    def time_strip(self, dtype):\n        self.s.str.strip(\"A\")\n\nclass Dtypes:\n    def setup(self, dtype):\n        try:\n            self.s = Series(tm.makeStringIndex(10**5), dtype=dtype)\n        except ImportError:\n            raise NotImplementedError", "min_run_count": 2, "name": "strings.Methods.time_strip", "number": 0, "param_names": ["dtype"], "params": [["'str'", "'string[python]'", "'string[pyarrow]'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "6696863602a27acdc24deb1ad8849ba4f04141c4680fce4c62f42baaf13e4bfc", "warmup_time": -1}, "strings.Methods.time_title": {"code": "class Methods:\n    def time_title(self, dtype):\n        self.s.str.title()\n\nclass Dtypes:\n    def setup(self, dtype):\n        try:\n            self.s = Series(tm.makeStringIndex(10**5), dtype=dtype)\n        except ImportError:\n            raise NotImplementedError", "min_run_count": 2, "name": "strings.Methods.time_title", "number": 0, "param_names": ["dtype"], "params": [["'str'", "'string[python]'", "'string[pyarrow]'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "746545238996ae5a89a73e0a9518aec94a6fd8b8bdf5aeee8502652a5fc904df", "warmup_time": -1}, "strings.Methods.time_translate": {"code": "class Methods:\n    def time_translate(self, dtype):\n        self.s.str.translate({\"A\": \"\\x01\\x01\"})\n\nclass Dtypes:\n    def setup(self, dtype):\n        try:\n            self.s = Series(tm.makeStringIndex(10**5), dtype=dtype)\n        except ImportError:\n            raise NotImplementedError", "min_run_count": 2, "name": "strings.Methods.time_translate", "number": 0, "param_names": ["dtype"], "params": [["'str'", "'string[python]'", "'string[pyarrow]'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "c1567606c2b8764743ffa66775c6c07eb5f2fe7f3a53bb37cf7cb43d893cd1e3", "warmup_time": -1}, "strings.Methods.time_upper": {"code": "class Methods:\n    def time_upper(self, dtype):\n        self.s.str.upper()\n\nclass Dtypes:\n    def setup(self, dtype):\n        try:\n            self.s = Series(tm.makeStringIndex(10**5), dtype=dtype)\n        except ImportError:\n            raise NotImplementedError", "min_run_count": 2, "name": "strings.Methods.time_upper", "number": 0, "param_names": ["dtype"], "params": [["'str'", "'string[python]'", "'string[pyarrow]'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "a604d50b0183e3c67d95daf50aeac4764402741eedbe074255da92c652f0c5c0", "warmup_time": -1}, "strings.Methods.time_wrap": {"code": "class Methods:\n    def time_wrap(self, dtype):\n        self.s.str.wrap(10)\n\nclass Dtypes:\n    def setup(self, dtype):\n        try:\n            self.s = Series(tm.makeStringIndex(10**5), dtype=dtype)\n        except ImportError:\n            raise NotImplementedError", "min_run_count": 2, "name": "strings.Methods.time_wrap", "number": 0, "param_names": ["dtype"], "params": [["'str'", "'string[python]'", "'string[pyarrow]'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "e4e044dc3427ab8e7c65fe52d8a7309f0fe27f8d7ac4c787271e245cdeabc8be", "warmup_time": -1}, "strings.Methods.time_zfill": {"code": "class Methods:\n    def time_zfill(self, dtype):\n        self.s.str.zfill(10)\n\nclass Dtypes:\n    def setup(self, dtype):\n        try:\n            self.s = Series(tm.makeStringIndex(10**5), dtype=dtype)\n        except ImportError:\n            raise NotImplementedError", "min_run_count": 2, "name": "strings.Methods.time_zfill", "number": 0, "param_names": ["dtype"], "params": [["'str'", "'string[python]'", "'string[pyarrow]'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "a6e2f76821105dfbeefb78124309104ee5bede3683ddc125aada94d40da50c0e", "warmup_time": -1}, "strings.Repeat.time_repeat": {"code": "class Repeat:\n    def time_repeat(self, repeats):\n        self.s.str.repeat(self.values)\n\n    def setup(self, repeats):\n        N = 10**5\n        self.s = Series(tm.makeStringIndex(N))\n        repeat = {\"int\": 1, \"array\": np.random.randint(1, 3, N)}\n        self.values = repeat[repeats]", "min_run_count": 2, "name": "strings.Repeat.time_repeat", "number": 0, "param_names": ["repeats"], "params": [["'int'", "'array'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "474412f6c3806d44cf029dfe51131f441292399f227c90cfac65e7520b49efa8", "warmup_time": -1}, "strings.Slice.time_vector_slice": {"code": "class Slice:\n    def time_vector_slice(self):\n        # GH 2602\n        self.s.str[:5]\n\n    def setup(self):\n        self.s = Series([\"abcdefg\", np.nan] * 500000)", "min_run_count": 2, "name": "strings.Slice.time_vector_slice", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "aaf1ec9c90cc2539c76cae9af1c26b6b5ffb1d0311ec7d6dafe7d228d106ef86", "warmup_time": -1}, "strings.Split.time_rsplit": {"code": "class Split:\n    def time_rsplit(self, dtype, expand):\n        self.s.str.rsplit(\"--\", expand=expand)\n\n    def setup(self, dtype, expand):\n        super().setup(dtype)\n        self.s = self.s.str.join(\"--\")", "min_run_count": 2, "name": "strings.Split.time_rsplit", "number": 0, "param_names": ["dtype", "expand"], "params": [["'str'", "'string[python]'", "'string[pyarrow]'"], ["True", "False"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "c748bf724293b4083adf3d91ce7a5255043bddcd7ecaba38777cac47767ad1f0", "warmup_time": -1}, "strings.Split.time_split": {"code": "class Split:\n    def time_split(self, dtype, expand):\n        self.s.str.split(\"--\", expand=expand)\n\n    def setup(self, dtype, expand):\n        super().setup(dtype)\n        self.s = self.s.str.join(\"--\")", "min_run_count": 2, "name": "strings.Split.time_split", "number": 0, "param_names": ["dtype", "expand"], "params": [["'str'", "'string[python]'", "'string[pyarrow]'"], ["True", "False"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "abecb3cbc4195a6fedc3bc41353ecd447d36060b1cd5e43944cda06edfa8a2e6", "warmup_time": -1}, "strings.StringArrayConstruction.peakmem_stringarray_construction": {"code": "class StringArrayConstruction:\n    def peakmem_stringarray_construction(self):\n        StringArray(self.series_arr)\n\n    def setup(self):\n        self.series_arr = tm.rands_array(nchars=10, size=10**5)\n        self.series_arr_nan = np.concatenate([self.series_arr, np.array([NA] * 1000)])", "name": "strings.StringArrayConstruction.peakmem_stringarray_construction", "param_names": [], "params": [], "timeout": 60.0, "type": "peakmemory", "unit": "bytes", "version": "4a99ea4e68d17611db32d7ce855cf337a8cef4f943a70850cba41c40920b80a7"}, "strings.StringArrayConstruction.time_string_array_construction": {"code": "class StringArrayConstruction:\n    def time_string_array_construction(self):\n        StringArray(self.series_arr)\n\n    def setup(self):\n        self.series_arr = tm.rands_array(nchars=10, size=10**5)\n        self.series_arr_nan = np.concatenate([self.series_arr, np.array([NA] * 1000)])", "min_run_count": 2, "name": "strings.StringArrayConstruction.time_string_array_construction", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "ab831a5f04580cb8c7c669b6145dd5d989d928025617948862888659e2e97723", "warmup_time": -1}, "strings.StringArrayConstruction.time_string_array_with_nan_construction": {"code": "class StringArrayConstruction:\n    def time_string_array_with_nan_construction(self):\n        StringArray(self.series_arr_nan)\n\n    def setup(self):\n        self.series_arr = tm.rands_array(nchars=10, size=10**5)\n        self.series_arr_nan = np.concatenate([self.series_arr, np.array([NA] * 1000)])", "min_run_count": 2, "name": "strings.StringArrayConstruction.time_string_array_with_nan_construction", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "d22b3eb80cb1feeb930bf30db57e5c8a386ddb61e9823b607ee51477d4a0a96a", "warmup_time": -1}, "timedelta.DatetimeAccessor.time_dt_accessor": {"code": "class DatetimeAccessor:\n    def time_dt_accessor(self, series):\n        series.dt\n\n    def setup_cache(self):\n        N = 100000\n        series = Series(timedelta_range(\"1 days\", periods=N, freq=\"h\"))\n        return series", "min_run_count": 2, "name": "timedelta.DatetimeAccessor.time_dt_accessor", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "setup_cache_key": "timedelta:14", "timeout": 60.0, "type": "time", "unit": "seconds", "version": "56ad9655f66a0485943ce9ca9547af9c97e48f5b12779c60896c3147c5422526", "warmup_time": -1}, "timedelta.DatetimeAccessor.time_timedelta_days": {"code": "class DatetimeAccessor:\n    def time_timedelta_days(self, series):\n        series.dt.days\n\n    def setup_cache(self):\n        N = 100000\n        series = Series(timedelta_range(\"1 days\", periods=N, freq=\"h\"))\n        return series", "min_run_count": 2, "name": "timedelta.DatetimeAccessor.time_timedelta_days", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "setup_cache_key": "timedelta:14", "timeout": 60.0, "type": "time", "unit": "seconds", "version": "06c603c515e826893772c4d64fe4de8ff76367d3c422060262604d4917fbec03", "warmup_time": -1}, "timedelta.DatetimeAccessor.time_timedelta_microseconds": {"code": "class DatetimeAccessor:\n    def time_timedelta_microseconds(self, series):\n        series.dt.microseconds\n\n    def setup_cache(self):\n        N = 100000\n        series = Series(timedelta_range(\"1 days\", periods=N, freq=\"h\"))\n        return series", "min_run_count": 2, "name": "timedelta.DatetimeAccessor.time_timedelta_microseconds", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "setup_cache_key": "timedelta:14", "timeout": 60.0, "type": "time", "unit": "seconds", "version": "6504e61d63ba227783a76d2cab32c1d791b1af813406a8c384fc386ca60b1898", "warmup_time": -1}, "timedelta.DatetimeAccessor.time_timedelta_nanoseconds": {"code": "class DatetimeAccessor:\n    def time_timedelta_nanoseconds(self, series):\n        series.dt.nanoseconds\n\n    def setup_cache(self):\n        N = 100000\n        series = Series(timedelta_range(\"1 days\", periods=N, freq=\"h\"))\n        return series", "min_run_count": 2, "name": "timedelta.DatetimeAccessor.time_timedelta_nanoseconds", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "setup_cache_key": "timedelta:14", "timeout": 60.0, "type": "time", "unit": "seconds", "version": "c1cc39aec7c93cb50ced4bf81ec26506de8bfddaaee6968142c0c018f91e296a", "warmup_time": -1}, "timedelta.DatetimeAccessor.time_timedelta_seconds": {"code": "class DatetimeAccessor:\n    def time_timedelta_seconds(self, series):\n        series.dt.seconds\n\n    def setup_cache(self):\n        N = 100000\n        series = Series(timedelta_range(\"1 days\", periods=N, freq=\"h\"))\n        return series", "min_run_count": 2, "name": "timedelta.DatetimeAccessor.time_timedelta_seconds", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "setup_cache_key": "timedelta:14", "timeout": 60.0, "type": "time", "unit": "seconds", "version": "0514e9978f000e47c609125255de6d9536aed804334d426a9222e1347183702d", "warmup_time": -1}, "timedelta.TimedeltaIndexing.time_align": {"code": "class TimedeltaIndexing:\n    def time_align(self):\n        DataFrame({\"a\": self.series, \"b\": self.series[:500]})\n\n    def setup(self):\n        self.index = timedelta_range(start=\"1985\", periods=1000, freq=\"D\")\n        self.index2 = timedelta_range(start=\"1986\", periods=1000, freq=\"D\")\n        self.series = Series(range(1000), index=self.index)\n        self.timedelta = self.index[500]", "min_run_count": 2, "name": "timedelta.TimedeltaIndexing.time_align", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "f5833d39497fb06bb05cac21fd9feeebace738d8e1cb626bea9fb0bbd86049ce", "warmup_time": -1}, "timedelta.TimedeltaIndexing.time_get_loc": {"code": "class TimedeltaIndexing:\n    def time_get_loc(self):\n        self.index.get_loc(self.timedelta)\n\n    def setup(self):\n        self.index = timedelta_range(start=\"1985\", periods=1000, freq=\"D\")\n        self.index2 = timedelta_range(start=\"1986\", periods=1000, freq=\"D\")\n        self.series = Series(range(1000), index=self.index)\n        self.timedelta = self.index[500]", "min_run_count": 2, "name": "timedelta.TimedeltaIndexing.time_get_loc", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "25e9df433acdb6dcf3c1df99f789a41f9c774fba04d175a24c5b8688dad9a7f3", "warmup_time": -1}, "timedelta.TimedeltaIndexing.time_intersection": {"code": "class TimedeltaIndexing:\n    def time_intersection(self):\n        self.index.intersection(self.index2)\n\n    def setup(self):\n        self.index = timedelta_range(start=\"1985\", periods=1000, freq=\"D\")\n        self.index2 = timedelta_range(start=\"1986\", periods=1000, freq=\"D\")\n        self.series = Series(range(1000), index=self.index)\n        self.timedelta = self.index[500]", "min_run_count": 2, "name": "timedelta.TimedeltaIndexing.time_intersection", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "c3f027dc76eb6a9ef0eff1bc06dd59ee562b54fbdb029d2a6a6c4865601424c1", "warmup_time": -1}, "timedelta.TimedeltaIndexing.time_series_loc": {"code": "class TimedeltaIndexing:\n    def time_series_loc(self):\n        self.series.loc[self.timedelta]\n\n    def setup(self):\n        self.index = timedelta_range(start=\"1985\", periods=1000, freq=\"D\")\n        self.index2 = timedelta_range(start=\"1986\", periods=1000, freq=\"D\")\n        self.series = Series(range(1000), index=self.index)\n        self.timedelta = self.index[500]", "min_run_count": 2, "name": "timedelta.TimedeltaIndexing.time_series_loc", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "5902b5b4b32fc27d85bee9808b6014b1f9664e7f28f444e498a7d04083c92e05", "warmup_time": -1}, "timedelta.TimedeltaIndexing.time_shallow_copy": {"code": "class TimedeltaIndexing:\n    def time_shallow_copy(self):\n        self.index._view()\n\n    def setup(self):\n        self.index = timedelta_range(start=\"1985\", periods=1000, freq=\"D\")\n        self.index2 = timedelta_range(start=\"1986\", periods=1000, freq=\"D\")\n        self.series = Series(range(1000), index=self.index)\n        self.timedelta = self.index[500]", "min_run_count": 2, "name": "timedelta.TimedeltaIndexing.time_shallow_copy", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "fae422a896cb1cff9173dd94eb799be107e0957d5845004660eed3d30e0540ba", "warmup_time": -1}, "timedelta.TimedeltaIndexing.time_union": {"code": "class TimedeltaIndexing:\n    def time_union(self):\n        self.index.union(self.index2)\n\n    def setup(self):\n        self.index = timedelta_range(start=\"1985\", periods=1000, freq=\"D\")\n        self.index2 = timedelta_range(start=\"1986\", periods=1000, freq=\"D\")\n        self.series = Series(range(1000), index=self.index)\n        self.timedelta = self.index[500]", "min_run_count": 2, "name": "timedelta.TimedeltaIndexing.time_union", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "266034126c423f3e411bf2195dc68cd983b6a181466b383df54ba9341232ad71", "warmup_time": -1}, "timedelta.TimedeltaIndexing.time_unique": {"code": "class TimedeltaIndexing:\n    def time_unique(self):\n        self.index.unique()\n\n    def setup(self):\n        self.index = timedelta_range(start=\"1985\", periods=1000, freq=\"D\")\n        self.index2 = timedelta_range(start=\"1986\", periods=1000, freq=\"D\")\n        self.series = Series(range(1000), index=self.index)\n        self.timedelta = self.index[500]", "min_run_count": 2, "name": "timedelta.TimedeltaIndexing.time_unique", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "17ea4667001a64a4f9df8c9594ca120a6491a18edd28102cd5712c88535ac416", "warmup_time": -1}, "timeseries.AsOf.time_asof": {"code": "class AsOf:\n    def time_asof(self, constructor):\n        self.ts.asof(self.dates)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass AsOf:\n    def setup(self, constructor):\n        N = 10000\n        M = 10\n        rng = date_range(start=\"1/1/1990\", periods=N, freq=\"53s\")\n        data = {\n            \"DataFrame\": DataFrame(np.random.randn(N, M)),\n            \"Series\": Series(np.random.randn(N)),\n        }\n        self.ts = data[constructor]\n        self.ts.index = rng\n        self.ts2 = self.ts.copy()\n        self.ts2.iloc[250:5000] = np.nan\n        self.ts3 = self.ts.copy()\n        self.ts3.iloc[-5000:] = np.nan\n        self.dates = date_range(start=\"1/1/1990\", periods=N * 10, freq=\"5s\")\n        self.date = self.dates[0]\n        self.date_last = self.dates[-1]\n        self.date_early = self.date - timedelta(10)", "min_run_count": 2, "name": "timeseries.AsOf.time_asof", "number": 0, "param_names": ["constructor"], "params": [["'DataFrame'", "'Series'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "37bd4ce5386fd0b7c34272d255acd943468380376dc1ee5dd9dea070fb806805", "warmup_time": -1}, "timeseries.AsOf.time_asof_nan": {"code": "class AsOf:\n    def time_asof_nan(self, constructor):\n        self.ts2.asof(self.dates)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass AsOf:\n    def setup(self, constructor):\n        N = 10000\n        M = 10\n        rng = date_range(start=\"1/1/1990\", periods=N, freq=\"53s\")\n        data = {\n            \"DataFrame\": DataFrame(np.random.randn(N, M)),\n            \"Series\": Series(np.random.randn(N)),\n        }\n        self.ts = data[constructor]\n        self.ts.index = rng\n        self.ts2 = self.ts.copy()\n        self.ts2.iloc[250:5000] = np.nan\n        self.ts3 = self.ts.copy()\n        self.ts3.iloc[-5000:] = np.nan\n        self.dates = date_range(start=\"1/1/1990\", periods=N * 10, freq=\"5s\")\n        self.date = self.dates[0]\n        self.date_last = self.dates[-1]\n        self.date_early = self.date - timedelta(10)", "min_run_count": 2, "name": "timeseries.AsOf.time_asof_nan", "number": 0, "param_names": ["constructor"], "params": [["'DataFrame'", "'Series'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "501dd990a898123eb091528ad6846c32abada27e5834f83a86729b32c4a0bcde", "warmup_time": -1}, "timeseries.AsOf.time_asof_nan_single": {"code": "class AsOf:\n    def time_asof_nan_single(self, constructor):\n        self.ts3.asof(self.date_last)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass AsOf:\n    def setup(self, constructor):\n        N = 10000\n        M = 10\n        rng = date_range(start=\"1/1/1990\", periods=N, freq=\"53s\")\n        data = {\n            \"DataFrame\": DataFrame(np.random.randn(N, M)),\n            \"Series\": Series(np.random.randn(N)),\n        }\n        self.ts = data[constructor]\n        self.ts.index = rng\n        self.ts2 = self.ts.copy()\n        self.ts2.iloc[250:5000] = np.nan\n        self.ts3 = self.ts.copy()\n        self.ts3.iloc[-5000:] = np.nan\n        self.dates = date_range(start=\"1/1/1990\", periods=N * 10, freq=\"5s\")\n        self.date = self.dates[0]\n        self.date_last = self.dates[-1]\n        self.date_early = self.date - timedelta(10)", "min_run_count": 2, "name": "timeseries.AsOf.time_asof_nan_single", "number": 0, "param_names": ["constructor"], "params": [["'DataFrame'", "'Series'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "5607d6a56f2adf8c34116da998623d2111a97c21c45c0d1287f625a3ecda0055", "warmup_time": -1}, "timeseries.AsOf.time_asof_single": {"code": "class AsOf:\n    def time_asof_single(self, constructor):\n        self.ts.asof(self.date)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass AsOf:\n    def setup(self, constructor):\n        N = 10000\n        M = 10\n        rng = date_range(start=\"1/1/1990\", periods=N, freq=\"53s\")\n        data = {\n            \"DataFrame\": DataFrame(np.random.randn(N, M)),\n            \"Series\": Series(np.random.randn(N)),\n        }\n        self.ts = data[constructor]\n        self.ts.index = rng\n        self.ts2 = self.ts.copy()\n        self.ts2.iloc[250:5000] = np.nan\n        self.ts3 = self.ts.copy()\n        self.ts3.iloc[-5000:] = np.nan\n        self.dates = date_range(start=\"1/1/1990\", periods=N * 10, freq=\"5s\")\n        self.date = self.dates[0]\n        self.date_last = self.dates[-1]\n        self.date_early = self.date - timedelta(10)", "min_run_count": 2, "name": "timeseries.AsOf.time_asof_single", "number": 0, "param_names": ["constructor"], "params": [["'DataFrame'", "'Series'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "afe0b338280acc8cfed3251b3ee2abf5e165c63fe746d8032f062675bf9021ac", "warmup_time": -1}, "timeseries.AsOf.time_asof_single_early": {"code": "class AsOf:\n    def time_asof_single_early(self, constructor):\n        self.ts.asof(self.date_early)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass AsOf:\n    def setup(self, constructor):\n        N = 10000\n        M = 10\n        rng = date_range(start=\"1/1/1990\", periods=N, freq=\"53s\")\n        data = {\n            \"DataFrame\": DataFrame(np.random.randn(N, M)),\n            \"Series\": Series(np.random.randn(N)),\n        }\n        self.ts = data[constructor]\n        self.ts.index = rng\n        self.ts2 = self.ts.copy()\n        self.ts2.iloc[250:5000] = np.nan\n        self.ts3 = self.ts.copy()\n        self.ts3.iloc[-5000:] = np.nan\n        self.dates = date_range(start=\"1/1/1990\", periods=N * 10, freq=\"5s\")\n        self.date = self.dates[0]\n        self.date_last = self.dates[-1]\n        self.date_early = self.date - timedelta(10)", "min_run_count": 2, "name": "timeseries.AsOf.time_asof_single_early", "number": 0, "param_names": ["constructor"], "params": [["'DataFrame'", "'Series'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "2ce4002d656f7b5513c14e1e36605c59ff9c7a0c53ce76a87dc70c83c7052b1c", "warmup_time": -1}, "timeseries.DatetimeAccessor.time_dt_accessor": {"code": "class DatetimeAccessor:\n    def time_dt_accessor(self, tz):\n        self.series.dt\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass DatetimeAccessor:\n    def setup(self, tz):\n        N = 100000\n        self.series = Series(date_range(start=\"1/1/2000\", periods=N, freq=\"T\", tz=tz))", "min_run_count": 2, "name": "timeseries.DatetimeAccessor.time_dt_accessor", "number": 0, "param_names": ["t"], "params": [["None", "'US/Eastern'", "'UTC'", "tzutc()"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "9eda40bf3e2cda858467b080b0b610f6d285e3631568ecdc25e1f9f1161f31ef", "warmup_time": -1}, "timeseries.DatetimeAccessor.time_dt_accessor_date": {"code": "class DatetimeAccessor:\n    def time_dt_accessor_date(self, tz):\n        self.series.dt.date\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass DatetimeAccessor:\n    def setup(self, tz):\n        N = 100000\n        self.series = Series(date_range(start=\"1/1/2000\", periods=N, freq=\"T\", tz=tz))", "min_run_count": 2, "name": "timeseries.DatetimeAccessor.time_dt_accessor_date", "number": 0, "param_names": ["t"], "params": [["None", "'US/Eastern'", "'UTC'", "tzutc()"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "021d8e2410da291a6ddb4c986c398ec7a1aaf57698cdbc2991383c1355ae220a", "warmup_time": -1}, "timeseries.DatetimeAccessor.time_dt_accessor_day_name": {"code": "class DatetimeAccessor:\n    def time_dt_accessor_day_name(self, tz):\n        self.series.dt.day_name()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass DatetimeAccessor:\n    def setup(self, tz):\n        N = 100000\n        self.series = Series(date_range(start=\"1/1/2000\", periods=N, freq=\"T\", tz=tz))", "min_run_count": 2, "name": "timeseries.DatetimeAccessor.time_dt_accessor_day_name", "number": 0, "param_names": ["t"], "params": [["None", "'US/Eastern'", "'UTC'", "tzutc()"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "0f5f97dd470f31efc26c498329b7f4601d6f799e98aebbe018ec372da49ff2f4", "warmup_time": -1}, "timeseries.DatetimeAccessor.time_dt_accessor_month_name": {"code": "class DatetimeAccessor:\n    def time_dt_accessor_month_name(self, tz):\n        self.series.dt.month_name()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass DatetimeAccessor:\n    def setup(self, tz):\n        N = 100000\n        self.series = Series(date_range(start=\"1/1/2000\", periods=N, freq=\"T\", tz=tz))", "min_run_count": 2, "name": "timeseries.DatetimeAccessor.time_dt_accessor_month_name", "number": 0, "param_names": ["t"], "params": [["None", "'US/Eastern'", "'UTC'", "tzutc()"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "a4c4b7dfb99541ee2947bfb3ace2049b3da113f054a4ff987286af80dc59fe9a", "warmup_time": -1}, "timeseries.DatetimeAccessor.time_dt_accessor_normalize": {"code": "class DatetimeAccessor:\n    def time_dt_accessor_normalize(self, tz):\n        self.series.dt.normalize()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass DatetimeAccessor:\n    def setup(self, tz):\n        N = 100000\n        self.series = Series(date_range(start=\"1/1/2000\", periods=N, freq=\"T\", tz=tz))", "min_run_count": 2, "name": "timeseries.DatetimeAccessor.time_dt_accessor_normalize", "number": 0, "param_names": ["t"], "params": [["None", "'US/Eastern'", "'UTC'", "tzutc()"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "ddee7a0133857e8e1e729ffad6e564f65ff9384c97556f810d8ec03339aaf569", "warmup_time": -1}, "timeseries.DatetimeAccessor.time_dt_accessor_time": {"code": "class DatetimeAccessor:\n    def time_dt_accessor_time(self, tz):\n        self.series.dt.time\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass DatetimeAccessor:\n    def setup(self, tz):\n        N = 100000\n        self.series = Series(date_range(start=\"1/1/2000\", periods=N, freq=\"T\", tz=tz))", "min_run_count": 2, "name": "timeseries.DatetimeAccessor.time_dt_accessor_time", "number": 0, "param_names": ["t"], "params": [["None", "'US/Eastern'", "'UTC'", "tzutc()"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "115f61c5815f17b447493bbedc760db0e3ea862c2744122a5a3c92da010a1c42", "warmup_time": -1}, "timeseries.DatetimeAccessor.time_dt_accessor_year": {"code": "class DatetimeAccessor:\n    def time_dt_accessor_year(self, tz):\n        self.series.dt.year\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass DatetimeAccessor:\n    def setup(self, tz):\n        N = 100000\n        self.series = Series(date_range(start=\"1/1/2000\", periods=N, freq=\"T\", tz=tz))", "min_run_count": 2, "name": "timeseries.DatetimeAccessor.time_dt_accessor_year", "number": 0, "param_names": ["t"], "params": [["None", "'US/Eastern'", "'UTC'", "tzutc()"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "e7bb661cf32509918fc15c5b1e271eb8fe3eda146c2c9eb620f79e77d91127cd", "warmup_time": -1}, "timeseries.DatetimeIndex.time_add_timedelta": {"code": "class DatetimeIndex:\n    def time_add_timedelta(self, index_type):\n        self.index + timedelta(minutes=2)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass DatetimeIndex:\n    def setup(self, index_type):\n        N = 100000\n        dtidxes = {\n            \"dst\": date_range(\n                start=\"10/29/2000 1:00:00\", end=\"10/29/2000 1:59:59\", freq=\"S\"\n            ),\n            \"repeated\": date_range(start=\"2000\", periods=N / 10, freq=\"s\").repeat(10),\n            \"tz_aware\": date_range(start=\"2000\", periods=N, freq=\"s\", tz=\"US/Eastern\"),\n            \"tz_local\": date_range(\n                start=\"2000\", periods=N, freq=\"s\", tz=dateutil.tz.tzlocal()\n            ),\n            \"tz_naive\": date_range(start=\"2000\", periods=N, freq=\"s\"),\n        }\n        self.index = dtidxes[index_type]", "min_run_count": 2, "name": "timeseries.DatetimeIndex.time_add_timedelta", "number": 0, "param_names": ["index_type"], "params": [["'dst'", "'repeated'", "'tz_aware'", "'tz_local'", "'tz_naive'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "c2cc7bb231f62b1af6082eb786e15ab49f3b6a3383124906fb7f51a6f9f3b3f8", "warmup_time": -1}, "timeseries.DatetimeIndex.time_get": {"code": "class DatetimeIndex:\n    def time_get(self, index_type):\n        self.index[0]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass DatetimeIndex:\n    def setup(self, index_type):\n        N = 100000\n        dtidxes = {\n            \"dst\": date_range(\n                start=\"10/29/2000 1:00:00\", end=\"10/29/2000 1:59:59\", freq=\"S\"\n            ),\n            \"repeated\": date_range(start=\"2000\", periods=N / 10, freq=\"s\").repeat(10),\n            \"tz_aware\": date_range(start=\"2000\", periods=N, freq=\"s\", tz=\"US/Eastern\"),\n            \"tz_local\": date_range(\n                start=\"2000\", periods=N, freq=\"s\", tz=dateutil.tz.tzlocal()\n            ),\n            \"tz_naive\": date_range(start=\"2000\", periods=N, freq=\"s\"),\n        }\n        self.index = dtidxes[index_type]", "min_run_count": 2, "name": "timeseries.DatetimeIndex.time_get", "number": 0, "param_names": ["index_type"], "params": [["'dst'", "'repeated'", "'tz_aware'", "'tz_local'", "'tz_naive'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "d028d87ac258389493458452a57d6ff0de335941a2f81a7e8fced5b779c82e1f", "warmup_time": -1}, "timeseries.DatetimeIndex.time_is_dates_only": {"code": "class DatetimeIndex:\n    def time_is_dates_only(self, index_type):\n        self.index._is_dates_only\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass DatetimeIndex:\n    def setup(self, index_type):\n        N = 100000\n        dtidxes = {\n            \"dst\": date_range(\n                start=\"10/29/2000 1:00:00\", end=\"10/29/2000 1:59:59\", freq=\"S\"\n            ),\n            \"repeated\": date_range(start=\"2000\", periods=N / 10, freq=\"s\").repeat(10),\n            \"tz_aware\": date_range(start=\"2000\", periods=N, freq=\"s\", tz=\"US/Eastern\"),\n            \"tz_local\": date_range(\n                start=\"2000\", periods=N, freq=\"s\", tz=dateutil.tz.tzlocal()\n            ),\n            \"tz_naive\": date_range(start=\"2000\", periods=N, freq=\"s\"),\n        }\n        self.index = dtidxes[index_type]", "min_run_count": 2, "name": "timeseries.DatetimeIndex.time_is_dates_only", "number": 0, "param_names": ["index_type"], "params": [["'dst'", "'repeated'", "'tz_aware'", "'tz_local'", "'tz_naive'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "4264adc13db2d02dd5bd0c8c6648da44ec1c6a10f4e585bf9d71e6fc9805d1fb", "warmup_time": -1}, "timeseries.DatetimeIndex.time_normalize": {"code": "class DatetimeIndex:\n    def time_normalize(self, index_type):\n        self.index.normalize()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass DatetimeIndex:\n    def setup(self, index_type):\n        N = 100000\n        dtidxes = {\n            \"dst\": date_range(\n                start=\"10/29/2000 1:00:00\", end=\"10/29/2000 1:59:59\", freq=\"S\"\n            ),\n            \"repeated\": date_range(start=\"2000\", periods=N / 10, freq=\"s\").repeat(10),\n            \"tz_aware\": date_range(start=\"2000\", periods=N, freq=\"s\", tz=\"US/Eastern\"),\n            \"tz_local\": date_range(\n                start=\"2000\", periods=N, freq=\"s\", tz=dateutil.tz.tzlocal()\n            ),\n            \"tz_naive\": date_range(start=\"2000\", periods=N, freq=\"s\"),\n        }\n        self.index = dtidxes[index_type]", "min_run_count": 2, "name": "timeseries.DatetimeIndex.time_normalize", "number": 0, "param_names": ["index_type"], "params": [["'dst'", "'repeated'", "'tz_aware'", "'tz_local'", "'tz_naive'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "ba785e6016a90bf14d5bcc2e673f72889453cb6980b898364941febe2a69cec3", "warmup_time": -1}, "timeseries.DatetimeIndex.time_timeseries_is_month_start": {"code": "class DatetimeIndex:\n    def time_timeseries_is_month_start(self, index_type):\n        self.index.is_month_start\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass DatetimeIndex:\n    def setup(self, index_type):\n        N = 100000\n        dtidxes = {\n            \"dst\": date_range(\n                start=\"10/29/2000 1:00:00\", end=\"10/29/2000 1:59:59\", freq=\"S\"\n            ),\n            \"repeated\": date_range(start=\"2000\", periods=N / 10, freq=\"s\").repeat(10),\n            \"tz_aware\": date_range(start=\"2000\", periods=N, freq=\"s\", tz=\"US/Eastern\"),\n            \"tz_local\": date_range(\n                start=\"2000\", periods=N, freq=\"s\", tz=dateutil.tz.tzlocal()\n            ),\n            \"tz_naive\": date_range(start=\"2000\", periods=N, freq=\"s\"),\n        }\n        self.index = dtidxes[index_type]", "min_run_count": 2, "name": "timeseries.DatetimeIndex.time_timeseries_is_month_start", "number": 0, "param_names": ["index_type"], "params": [["'dst'", "'repeated'", "'tz_aware'", "'tz_local'", "'tz_naive'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "b20aef0d8246571897ac2e0e2e624272f493457afb96781e33da7ed766e2e996", "warmup_time": -1}, "timeseries.DatetimeIndex.time_to_date": {"code": "class DatetimeIndex:\n    def time_to_date(self, index_type):\n        self.index.date\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass DatetimeIndex:\n    def setup(self, index_type):\n        N = 100000\n        dtidxes = {\n            \"dst\": date_range(\n                start=\"10/29/2000 1:00:00\", end=\"10/29/2000 1:59:59\", freq=\"S\"\n            ),\n            \"repeated\": date_range(start=\"2000\", periods=N / 10, freq=\"s\").repeat(10),\n            \"tz_aware\": date_range(start=\"2000\", periods=N, freq=\"s\", tz=\"US/Eastern\"),\n            \"tz_local\": date_range(\n                start=\"2000\", periods=N, freq=\"s\", tz=dateutil.tz.tzlocal()\n            ),\n            \"tz_naive\": date_range(start=\"2000\", periods=N, freq=\"s\"),\n        }\n        self.index = dtidxes[index_type]", "min_run_count": 2, "name": "timeseries.DatetimeIndex.time_to_date", "number": 0, "param_names": ["index_type"], "params": [["'dst'", "'repeated'", "'tz_aware'", "'tz_local'", "'tz_naive'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "1ba2f305f5a3ae0f0458f5a33f937418f80a851bac7e9923999b3aeb8c00174d", "warmup_time": -1}, "timeseries.DatetimeIndex.time_to_pydatetime": {"code": "class DatetimeIndex:\n    def time_to_pydatetime(self, index_type):\n        self.index.to_pydatetime()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass DatetimeIndex:\n    def setup(self, index_type):\n        N = 100000\n        dtidxes = {\n            \"dst\": date_range(\n                start=\"10/29/2000 1:00:00\", end=\"10/29/2000 1:59:59\", freq=\"S\"\n            ),\n            \"repeated\": date_range(start=\"2000\", periods=N / 10, freq=\"s\").repeat(10),\n            \"tz_aware\": date_range(start=\"2000\", periods=N, freq=\"s\", tz=\"US/Eastern\"),\n            \"tz_local\": date_range(\n                start=\"2000\", periods=N, freq=\"s\", tz=dateutil.tz.tzlocal()\n            ),\n            \"tz_naive\": date_range(start=\"2000\", periods=N, freq=\"s\"),\n        }\n        self.index = dtidxes[index_type]", "min_run_count": 2, "name": "timeseries.DatetimeIndex.time_to_pydatetime", "number": 0, "param_names": ["index_type"], "params": [["'dst'", "'repeated'", "'tz_aware'", "'tz_local'", "'tz_naive'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "d62c041b2c720442d04ce8c5c6f855c4cd181f4bd098c0b90d587105a355a9d7", "warmup_time": -1}, "timeseries.DatetimeIndex.time_to_time": {"code": "class DatetimeIndex:\n    def time_to_time(self, index_type):\n        self.index.time\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass DatetimeIndex:\n    def setup(self, index_type):\n        N = 100000\n        dtidxes = {\n            \"dst\": date_range(\n                start=\"10/29/2000 1:00:00\", end=\"10/29/2000 1:59:59\", freq=\"S\"\n            ),\n            \"repeated\": date_range(start=\"2000\", periods=N / 10, freq=\"s\").repeat(10),\n            \"tz_aware\": date_range(start=\"2000\", periods=N, freq=\"s\", tz=\"US/Eastern\"),\n            \"tz_local\": date_range(\n                start=\"2000\", periods=N, freq=\"s\", tz=dateutil.tz.tzlocal()\n            ),\n            \"tz_naive\": date_range(start=\"2000\", periods=N, freq=\"s\"),\n        }\n        self.index = dtidxes[index_type]", "min_run_count": 2, "name": "timeseries.DatetimeIndex.time_to_time", "number": 0, "param_names": ["index_type"], "params": [["'dst'", "'repeated'", "'tz_aware'", "'tz_local'", "'tz_naive'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "2bf107f2a7faf94da14c2de8548f07d139c53d011f564729cff6ba2b64f2dd93", "warmup_time": -1}, "timeseries.DatetimeIndex.time_unique": {"code": "class DatetimeIndex:\n    def time_unique(self, index_type):\n        self.index.unique()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass DatetimeIndex:\n    def setup(self, index_type):\n        N = 100000\n        dtidxes = {\n            \"dst\": date_range(\n                start=\"10/29/2000 1:00:00\", end=\"10/29/2000 1:59:59\", freq=\"S\"\n            ),\n            \"repeated\": date_range(start=\"2000\", periods=N / 10, freq=\"s\").repeat(10),\n            \"tz_aware\": date_range(start=\"2000\", periods=N, freq=\"s\", tz=\"US/Eastern\"),\n            \"tz_local\": date_range(\n                start=\"2000\", periods=N, freq=\"s\", tz=dateutil.tz.tzlocal()\n            ),\n            \"tz_naive\": date_range(start=\"2000\", periods=N, freq=\"s\"),\n        }\n        self.index = dtidxes[index_type]", "min_run_count": 2, "name": "timeseries.DatetimeIndex.time_unique", "number": 0, "param_names": ["index_type"], "params": [["'dst'", "'repeated'", "'tz_aware'", "'tz_local'", "'tz_naive'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "9f2f012235902e7df7a11bc6e21c6114209a9f94166ca322aae16d855884b425", "warmup_time": -1}, "timeseries.InferFreq.time_infer_freq": {"code": "class InferFreq:\n    def time_infer_freq(self, freq):\n        infer_freq(self.idx)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass InferFreq:\n    def setup(self, freq):\n        if freq is None:\n            self.idx = date_range(start=\"1/1/1700\", freq=\"D\", periods=10000)\n            self.idx._data._freq = None\n        else:\n            self.idx = date_range(start=\"1/1/1700\", freq=freq, periods=10000)", "min_run_count": 2, "name": "timeseries.InferFreq.time_infer_freq", "number": 0, "param_names": ["freq"], "params": [["None", "'D'", "'B'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "52f02044de50a1a68041e7526ab41b12d85500472c7652ce485fa54cfe87ecc0", "warmup_time": -1}, "timeseries.Iteration.time_iter": {"code": "class Iteration:\n    def time_iter(self, time_index):\n        for _ in self.idx:\n            pass\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Iteration:\n    def setup(self, time_index):\n        N = 10**6\n        if time_index is timedelta_range:\n            self.idx = time_index(start=0, freq=\"T\", periods=N)\n        else:\n            self.idx = time_index(start=\"20140101\", freq=\"T\", periods=N)\n        self.exit = 10000", "min_run_count": 2, "name": "timeseries.Iteration.time_iter", "number": 0, "param_names": ["time_index"], "params": [["<function date_range>", "<function period_range>", "<function timedelta_range>"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "9457d32e113d263ddf19fbd0b54840e4e1c7d9b6cb2def18d5f589f98511d206", "warmup_time": -1}, "timeseries.Iteration.time_iter_preexit": {"code": "class Iteration:\n    def time_iter_preexit(self, time_index):\n        for i, _ in enumerate(self.idx):\n            if i > self.exit:\n                break\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Iteration:\n    def setup(self, time_index):\n        N = 10**6\n        if time_index is timedelta_range:\n            self.idx = time_index(start=0, freq=\"T\", periods=N)\n        else:\n            self.idx = time_index(start=\"20140101\", freq=\"T\", periods=N)\n        self.exit = 10000", "min_run_count": 2, "name": "timeseries.Iteration.time_iter_preexit", "number": 0, "param_names": ["time_index"], "params": [["<function date_range>", "<function period_range>", "<function timedelta_range>"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "f0380cca021be69610d28b266c14816d24293cdcfe85a67101978fdf69ccdd59", "warmup_time": -1}, "timeseries.Lookup.time_lookup_and_cleanup": {"code": "class Lookup:\n    def time_lookup_and_cleanup(self):\n        self.ts[self.lookup_val]\n        self.ts.index._cleanup()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Lookup:\n    def setup(self):\n        N = 1500000\n        rng = date_range(start=\"1/1/2000\", periods=N, freq=\"S\")\n        self.ts = Series(1, index=rng)\n        self.lookup_val = rng[N // 2]", "min_run_count": 2, "name": "timeseries.Lookup.time_lookup_and_cleanup", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "4b60327696855c221b7a2493d4f99390b0834ebd26bcb40c0e4c4464486e0962", "warmup_time": -1}, "timeseries.ResampleDataFrame.time_method": {"code": "class ResampleDataFrame:\n    def time_method(self, method):\n        self.resample()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ResampleDataFrame:\n    def setup(self, method):\n        rng = date_range(start=\"20130101\", periods=100000, freq=\"50L\")\n        df = DataFrame(np.random.randn(100000, 2), index=rng)\n        self.resample = getattr(df.resample(\"1s\"), method)", "min_run_count": 2, "name": "timeseries.ResampleDataFrame.time_method", "number": 0, "param_names": ["method"], "params": [["'max'", "'mean'", "'min'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "b77feaa009ecc95f6bce04575055d274a9030f79685fe8ee8be8a935f84314ad", "warmup_time": -1}, "timeseries.ResampleDatetetime64.time_resample": {"code": "class ResampleDatetetime64:\n    def time_resample(self):\n        self.dt_ts.resample(\"1S\").last()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ResampleDatetetime64:\n    def setup(self):\n        rng3 = date_range(\n            start=\"2000-01-01 00:00:00\", end=\"2000-01-01 10:00:00\", freq=\"555000U\"\n        )\n        self.dt_ts = Series(5, rng3, dtype=\"datetime64[ns]\")", "min_run_count": 2, "name": "timeseries.ResampleDatetetime64.time_resample", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "1fdc7e2f0bf233502eef6c6f2e93421664936d5e8e9d77f64bae068f87283caa", "warmup_time": -1}, "timeseries.ResampleSeries.time_resample": {"code": "class ResampleSeries:\n    def time_resample(self, index, freq, method):\n        self.resample()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ResampleSeries:\n    def setup(self, index, freq, method):\n        indexes = {\n            \"period\": period_range(start=\"1/1/2000\", end=\"1/1/2001\", freq=\"T\"),\n            \"datetime\": date_range(start=\"1/1/2000\", end=\"1/1/2001\", freq=\"T\"),\n        }\n        idx = indexes[index]\n        ts = Series(np.random.randn(len(idx)), index=idx)\n        self.resample = getattr(ts.resample(freq), method)", "min_run_count": 2, "name": "timeseries.ResampleSeries.time_resample", "number": 0, "param_names": ["index", "freq", "method"], "params": [["'period'", "'datetime'"], ["'5min'", "'1D'"], ["'mean'", "'ohlc'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "cee7e74cfbe0838abaa9106ad441f336a5bf93883a4e58bab6e45f9184c501d7", "warmup_time": -1}, "timeseries.ResetIndex.time_reset_datetimeindex": {"code": "class ResetIndex:\n    def time_reset_datetimeindex(self, tz):\n        self.df.reset_index()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ResetIndex:\n    def setup(self, tz):\n        idx = date_range(start=\"1/1/2000\", periods=1000, freq=\"H\", tz=tz)\n        self.df = DataFrame(np.random.randn(1000, 2), index=idx)", "min_run_count": 2, "name": "timeseries.ResetIndex.time_reset_datetimeindex", "number": 0, "param_names": ["t"], "params": [["None", "'US/Eastern'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "fa0f0e85752334f42a01033826f14cbf4e6872765dd7c16f825e7795eaa5dc2a", "warmup_time": -1}, "timeseries.SortIndex.time_get_slice": {"code": "class SortIndex:\n    def time_get_slice(self, monotonic):\n        self.s[:10000]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass SortIndex:\n    def setup(self, monotonic):\n        N = 10**5\n        idx = date_range(start=\"1/1/2000\", periods=N, freq=\"s\")\n        self.s = Series(np.random.randn(N), index=idx)\n        if not monotonic:\n            self.s = self.s.sample(frac=1)", "min_run_count": 2, "name": "timeseries.SortIndex.time_get_slice", "number": 0, "param_names": ["monotonic"], "params": [["True", "False"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "0a9e9e75d9711805af9e2bd23525b886c146db147bda183e7c62c68212a7d2af", "warmup_time": -1}, "timeseries.SortIndex.time_sort_index": {"code": "class SortIndex:\n    def time_sort_index(self, monotonic):\n        self.s.sort_index()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass SortIndex:\n    def setup(self, monotonic):\n        N = 10**5\n        idx = date_range(start=\"1/1/2000\", periods=N, freq=\"s\")\n        self.s = Series(np.random.randn(N), index=idx)\n        if not monotonic:\n            self.s = self.s.sample(frac=1)", "min_run_count": 2, "name": "timeseries.SortIndex.time_sort_index", "number": 0, "param_names": ["monotonic"], "params": [["True", "False"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "4e3d97e97d12382b09d20e93cc00244951e5d85c15eb06dd5e57dc55c553db37", "warmup_time": -1}, "timeseries.TimeDatetimeConverter.time_convert": {"code": "class TimeDatetimeConverter:\n    def time_convert(self):\n        DatetimeConverter.convert(self.rng, None, None)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass TimeDatetimeConverter:\n    def setup(self):\n        N = 100000\n        self.rng = date_range(start=\"1/1/2000\", periods=N, freq=\"T\")", "min_run_count": 2, "name": "timeseries.TimeDatetimeConverter.time_convert", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "37f67d4e4336e8d1ab8b3a815f3668ceb3a58cf9c8e254799cbfbed406fa949b", "warmup_time": -1}, "timeseries.TzLocalize.time_infer_dst": {"code": "class TzLocalize:\n    def time_infer_dst(self, tz):\n        self.index.tz_localize(tz, ambiguous=\"infer\")\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass TzLocalize:\n    def setup(self, tz):\n        dst_rng = date_range(\n            start=\"10/29/2000 1:00:00\", end=\"10/29/2000 1:59:59\", freq=\"S\"\n        )\n        self.index = date_range(start=\"10/29/2000\", end=\"10/29/2000 00:59:59\", freq=\"S\")\n        self.index = self.index.append(dst_rng)\n        self.index = self.index.append(dst_rng)\n        self.index = self.index.append(\n            date_range(start=\"10/29/2000 2:00:00\", end=\"10/29/2000 3:00:00\", freq=\"S\")\n        )", "min_run_count": 2, "name": "timeseries.TzLocalize.time_infer_dst", "number": 0, "param_names": ["t"], "params": [["None", "'US/Eastern'", "'UTC'", "tzutc()"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "867213627bf09b3b2955467bed535d2d2166e059579f56ac7797e6d62ebcd49e", "warmup_time": -1}, "tslibs.fields.TimeGetDateField.time_get_date_field": {"code": "class TimeGetDateField:\n    def time_get_date_field(self, size, field):\n        get_date_field(self.i8data, field)\n\n    def setup(self, size, field):\n        arr = np.random.randint(0, 10, size=size, dtype=\"i8\")\n        self.i8data = arr", "min_run_count": 2, "name": "tslibs.fields.TimeGetDateField.time_get_date_field", "number": 0, "param_names": ["size", "field"], "params": [["0", "1", "100", "10000", "1000000"], ["'Y'", "'M'", "'D'", "'h'", "'m'", "'s'", "'us'", "'ns'", "'doy'", "'dow'", "'woy'", "'q'", "'dim'", "'is_leap_year'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "032d05ffd3cddf25687d384f76ac9d5aeacf2e7476a8aeb4baf025aa07fc3887", "warmup_time": -1}, "tslibs.fields.TimeGetStartEndField.time_get_start_end_field": {"code": "class TimeGetStartEndField:\n    def time_get_start_end_field(self, size, side, period, freqstr, month_kw):\n        get_start_end_field(self.i8data, self.attrname, freqstr, month_kw=month_kw)\n\n    def setup(self, size, side, period, freqstr, month_kw):\n        arr = np.random.randint(0, 10, size=size, dtype=\"i8\")\n        self.i8data = arr\n    \n        self.attrname = f\"is_{period}_{side}\"", "min_run_count": 2, "name": "tslibs.fields.TimeGetStartEndField.time_get_start_end_field", "number": 0, "param_names": ["size", "side", "period", "freqstr", "month_kw"], "params": [["0", "1", "100", "10000", "1000000"], ["'start'", "'end'"], ["'month'", "'quarter'", "'year'"], ["'B'", "None", "'QS'"], ["12", "3", "5"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "3457501ae50d04017ceec6b67dce5e99aa99af7ededd796eddbd0c87b01b8d9a", "warmup_time": -1}, "tslibs.fields.TimeGetTimedeltaField.time_get_timedelta_field": {"code": "class TimeGetTimedeltaField:\n    def time_get_timedelta_field(self, size, field):\n        get_timedelta_field(self.i8data, field)\n\n    def setup(self, size, field):\n        arr = np.random.randint(0, 10, size=size, dtype=\"i8\")\n        self.i8data = arr", "min_run_count": 2, "name": "tslibs.fields.TimeGetTimedeltaField.time_get_timedelta_field", "number": 0, "param_names": ["size", "field"], "params": [["0", "1", "100", "10000", "1000000"], ["'days'", "'seconds'", "'microseconds'", "'nanoseconds'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "83971f7c0e7b0651fbe80cda16bb176f840b200191f86e1207d2de1d30d4a4de", "warmup_time": -1}, "tslibs.normalize.Normalize.time_is_date_array_normalized": {"code": "class Normalize:\n    def time_is_date_array_normalized(self, size, tz):\n        # TODO: cases with different levels of short-circuiting\n        # 10 i.e. NPY_FR_ns\n        is_date_array_normalized(self.i8data, tz, 10)\n\n    def setup(self, size, tz):\n        # use an array that will have is_date_array_normalized give True,\n        #  so we do not short-circuit early.\n        dti = pd.date_range(\"2016-01-01\", periods=10, tz=tz).repeat(size // 10)\n        self.i8data = dti.asi8\n    \n        if size == 10**6 and tz is tzlocal_obj:\n            # tzlocal is cumbersomely slow, so skip to keep runtime in check\n            raise NotImplementedError", "min_run_count": 2, "name": "tslibs.normalize.Normalize.time_is_date_array_normalized", "number": 0, "param_names": ["size", "tz"], "params": [["0", "1", "100", "10000", "1000000"], ["None", "datetime.timezone.utc", "datetime.timezone(datetime.timedelta(seconds=3600))", "<DstTzInfo 'US/Pacific' LMT-1 day, 16:07:00 STD>", "tzfile('/usr/share/zoneinfo/Asia/Tokyo')", "tzlocal()"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "8a0062a64c2f0559eaee437a8eeefbae5c75e27db5faf86541286085b875a6d2", "warmup_time": -1}, "tslibs.normalize.Normalize.time_normalize_i8_timestamps": {"code": "class Normalize:\n    def time_normalize_i8_timestamps(self, size, tz):\n        # 10 i.e. NPY_FR_ns\n        normalize_i8_timestamps(self.i8data, tz, 10)\n\n    def setup(self, size, tz):\n        # use an array that will have is_date_array_normalized give True,\n        #  so we do not short-circuit early.\n        dti = pd.date_range(\"2016-01-01\", periods=10, tz=tz).repeat(size // 10)\n        self.i8data = dti.asi8\n    \n        if size == 10**6 and tz is tzlocal_obj:\n            # tzlocal is cumbersomely slow, so skip to keep runtime in check\n            raise NotImplementedError", "min_run_count": 2, "name": "tslibs.normalize.Normalize.time_normalize_i8_timestamps", "number": 0, "param_names": ["size", "tz"], "params": [["0", "1", "100", "10000", "1000000"], ["None", "datetime.timezone.utc", "datetime.timezone(datetime.timedelta(seconds=3600))", "<DstTzInfo 'US/Pacific' LMT-1 day, 16:07:00 STD>", "tzfile('/usr/share/zoneinfo/Asia/Tokyo')", "tzlocal()"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "90e93c0bf30f84159194f95da549370de993eadd2b9924b3bc6dc1d0ac05889e", "warmup_time": -1}, "tslibs.offsets.OffestDatetimeArithmetic.time_add": {"code": "class OffestDatetimeArithmetic:\n    def time_add(self, offset):\n        self.date + offset\n\n    def setup(self, offset):\n        self.date = datetime(2011, 1, 1)\n        self.dt64 = np.datetime64(\"2011-01-01 09:00Z\")", "min_run_count": 2, "name": "tslibs.offsets.OffestDatetimeArithmetic.time_add", "number": 0, "param_names": ["offset"], "params": [["<Day>", "<BYearEnd: month=12>", "<BYearBegin: month=1>", "<BusinessQuarterEnd: startingMonth=3>", "<BusinessQuarterBegin: startingMonth=3>", "<BusinessMonthEnd>", "<BusinessMonthBegin>", "<CustomBusinessDay> (0)", "<CustomBusinessDay> (1)", "<CustomBusinessMonthBegin>", "<CustomBusinessMonthEnd> (0)", "<CustomBusinessMonthEnd> (1)", "<YearEnd: month=12>", "<YearBegin: month=1>", "<QuarterEnd: startingMonth=3>", "<QuarterBegin: startingMonth=3>", "<MonthEnd>", "<MonthBegin>", "<DateOffset: days=2, months=2>", "<BusinessDay>", "<SemiMonthEnd: day_of_month=15>", "<SemiMonthBegin: day_of_month=15>"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "bfb2ef7f8d94ebf443a43ab768a426b24846a01bcb9e60873cfca5ac9d84acbb", "warmup_time": -1}, "tslibs.offsets.OffestDatetimeArithmetic.time_add_10": {"code": "class OffestDatetimeArithmetic:\n    def time_add_10(self, offset):\n        self.date + (10 * offset)\n\n    def setup(self, offset):\n        self.date = datetime(2011, 1, 1)\n        self.dt64 = np.datetime64(\"2011-01-01 09:00Z\")", "min_run_count": 2, "name": "tslibs.offsets.OffestDatetimeArithmetic.time_add_10", "number": 0, "param_names": ["offset"], "params": [["<Day>", "<BYearEnd: month=12>", "<BYearBegin: month=1>", "<BusinessQuarterEnd: startingMonth=3>", "<BusinessQuarterBegin: startingMonth=3>", "<BusinessMonthEnd>", "<BusinessMonthBegin>", "<CustomBusinessDay> (0)", "<CustomBusinessDay> (1)", "<CustomBusinessMonthBegin>", "<CustomBusinessMonthEnd> (0)", "<CustomBusinessMonthEnd> (1)", "<YearEnd: month=12>", "<YearBegin: month=1>", "<QuarterEnd: startingMonth=3>", "<QuarterBegin: startingMonth=3>", "<MonthEnd>", "<MonthBegin>", "<DateOffset: days=2, months=2>", "<BusinessDay>", "<SemiMonthEnd: day_of_month=15>", "<SemiMonthBegin: day_of_month=15>"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "412f51bfc037b5b10f23387d475123e2c8ebd62a69e6a5692a07f7924f5149ac", "warmup_time": -1}, "tslibs.offsets.OffestDatetimeArithmetic.time_add_np_dt64": {"code": "class OffestDatetimeArithmetic:\n    def time_add_np_dt64(self, offset):\n        offset + self.dt64\n\n    def setup(self, offset):\n        self.date = datetime(2011, 1, 1)\n        self.dt64 = np.datetime64(\"2011-01-01 09:00Z\")", "min_run_count": 2, "name": "tslibs.offsets.OffestDatetimeArithmetic.time_add_np_dt64", "number": 0, "param_names": ["offset"], "params": [["<Day>", "<BYearEnd: month=12>", "<BYearBegin: month=1>", "<BusinessQuarterEnd: startingMonth=3>", "<BusinessQuarterBegin: startingMonth=3>", "<BusinessMonthEnd>", "<BusinessMonthBegin>", "<CustomBusinessDay> (0)", "<CustomBusinessDay> (1)", "<CustomBusinessMonthBegin>", "<CustomBusinessMonthEnd> (0)", "<CustomBusinessMonthEnd> (1)", "<YearEnd: month=12>", "<YearBegin: month=1>", "<QuarterEnd: startingMonth=3>", "<QuarterBegin: startingMonth=3>", "<MonthEnd>", "<MonthBegin>", "<DateOffset: days=2, months=2>", "<BusinessDay>", "<SemiMonthEnd: day_of_month=15>", "<SemiMonthBegin: day_of_month=15>"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "1165522291f90bef9f0aa75d6407828206ad6efc49a2b7023f47fdfd998851fa", "warmup_time": -1}, "tslibs.offsets.OffestDatetimeArithmetic.time_subtract": {"code": "class OffestDatetimeArithmetic:\n    def time_subtract(self, offset):\n        self.date - offset\n\n    def setup(self, offset):\n        self.date = datetime(2011, 1, 1)\n        self.dt64 = np.datetime64(\"2011-01-01 09:00Z\")", "min_run_count": 2, "name": "tslibs.offsets.OffestDatetimeArithmetic.time_subtract", "number": 0, "param_names": ["offset"], "params": [["<Day>", "<BYearEnd: month=12>", "<BYearBegin: month=1>", "<BusinessQuarterEnd: startingMonth=3>", "<BusinessQuarterBegin: startingMonth=3>", "<BusinessMonthEnd>", "<BusinessMonthBegin>", "<CustomBusinessDay> (0)", "<CustomBusinessDay> (1)", "<CustomBusinessMonthBegin>", "<CustomBusinessMonthEnd> (0)", "<CustomBusinessMonthEnd> (1)", "<YearEnd: month=12>", "<YearBegin: month=1>", "<QuarterEnd: startingMonth=3>", "<QuarterBegin: startingMonth=3>", "<MonthEnd>", "<MonthBegin>", "<DateOffset: days=2, months=2>", "<BusinessDay>", "<SemiMonthEnd: day_of_month=15>", "<SemiMonthBegin: day_of_month=15>"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "775bbe2574e947fdebb23ba6451a8510d68d5dfaf0e0813a6967a39209d770fc", "warmup_time": -1}, "tslibs.offsets.OffestDatetimeArithmetic.time_subtract_10": {"code": "class OffestDatetimeArithmetic:\n    def time_subtract_10(self, offset):\n        self.date - (10 * offset)\n\n    def setup(self, offset):\n        self.date = datetime(2011, 1, 1)\n        self.dt64 = np.datetime64(\"2011-01-01 09:00Z\")", "min_run_count": 2, "name": "tslibs.offsets.OffestDatetimeArithmetic.time_subtract_10", "number": 0, "param_names": ["offset"], "params": [["<Day>", "<BYearEnd: month=12>", "<BYearBegin: month=1>", "<BusinessQuarterEnd: startingMonth=3>", "<BusinessQuarterBegin: startingMonth=3>", "<BusinessMonthEnd>", "<BusinessMonthBegin>", "<CustomBusinessDay> (0)", "<CustomBusinessDay> (1)", "<CustomBusinessMonthBegin>", "<CustomBusinessMonthEnd> (0)", "<CustomBusinessMonthEnd> (1)", "<YearEnd: month=12>", "<YearBegin: month=1>", "<QuarterEnd: startingMonth=3>", "<QuarterBegin: startingMonth=3>", "<MonthEnd>", "<MonthBegin>", "<DateOffset: days=2, months=2>", "<BusinessDay>", "<SemiMonthEnd: day_of_month=15>", "<SemiMonthBegin: day_of_month=15>"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "f0a5bf6590a5f4e89c95b4b22ecc27ec52e4cb03e8255cef5009879bb71dbc69", "warmup_time": -1}, "tslibs.offsets.OnOffset.time_on_offset": {"code": "class OnOffset:\n    def time_on_offset(self, offset):\n        for date in self.dates:\n            offset.is_on_offset(date)\n\n    def setup(self, offset):\n        self.dates = [\n            datetime(2016, m, d)\n            for m in [10, 11, 12]\n            for d in [1, 2, 3, 28, 29, 30, 31]\n            if not (m == 11 and d == 31)\n        ]", "min_run_count": 2, "name": "tslibs.offsets.OnOffset.time_on_offset", "number": 0, "param_names": ["offset"], "params": [["<Day>", "<BYearEnd: month=12>", "<BYearBegin: month=1>", "<BusinessQuarterEnd: startingMonth=3>", "<BusinessQuarterBegin: startingMonth=3>", "<BusinessMonthEnd>", "<BusinessMonthBegin>", "<CustomBusinessDay> (0)", "<CustomBusinessDay> (1)", "<CustomBusinessMonthBegin>", "<CustomBusinessMonthEnd> (0)", "<CustomBusinessMonthEnd> (1)", "<YearEnd: month=12>", "<YearBegin: month=1>", "<QuarterEnd: startingMonth=3>", "<QuarterBegin: startingMonth=3>", "<MonthEnd>", "<MonthBegin>", "<DateOffset: days=2, months=2>", "<BusinessDay>", "<SemiMonthEnd: day_of_month=15>", "<SemiMonthBegin: day_of_month=15>"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "ae5cbac53a07afd70222f6a228bac6518d5df75e369f5e8450db66831ba8afa2", "warmup_time": -1}, "tslibs.period.PeriodConstructor.time_period_constructor": {"code": "class PeriodConstructor:\n    def time_period_constructor(self, freq, is_offset):\n        Period(\"2012-06-01\", freq=freq)\n\n    def setup(self, freq, is_offset):\n        if is_offset:\n            self.freq = to_offset(freq)\n        else:\n            self.freq = freq", "min_run_count": 2, "name": "tslibs.period.PeriodConstructor.time_period_constructor", "number": 0, "param_names": ["freq", "is_offset"], "params": [["'D'"], ["True", "False"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "d98fc24ec3bee7645af5de9f3e7af5e28f028c74e4785bda4ceb36f1d46a671d", "warmup_time": -1}, "tslibs.period.PeriodProperties.time_property": {"code": "class PeriodProperties:\n    def time_property(self, freq, attr):\n        getattr(self.per, attr)\n\n    def setup(self, freq, attr):\n        self.per = Period(\"2012-06-01\", freq=freq)", "min_run_count": 2, "name": "tslibs.period.PeriodProperties.time_property", "number": 0, "param_names": ["freq", "attr"], "params": [["'M'", "'min'"], ["'year'", "'month'", "'day'", "'hour'", "'minute'", "'second'", "'is_leap_year'", "'quarter'", "'qyear'", "'week'", "'daysinmonth'", "'dayofweek'", "'dayofyear'", "'start_time'", "'end_time'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "6c0fa44f9b9f197537446c79ae6f7ce95ab1d18e2e68b5acb2a96103c097f4c6", "warmup_time": -1}, "tslibs.period.PeriodUnaryMethods.time_asfreq": {"code": "class PeriodUnaryMethods:\n    def time_asfreq(self, freq):\n        self.per.asfreq(\"A\")\n\n    def setup(self, freq):\n        self.per = Period(\"2012-06-01\", freq=freq)", "min_run_count": 2, "name": "tslibs.period.PeriodUnaryMethods.time_asfreq", "number": 0, "param_names": ["freq"], "params": [["'M'", "'min'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "deedbf5d3c7fd1ba4050791ac771023591ce7ddf98c14082e8627b2b2646cfeb", "warmup_time": -1}, "tslibs.period.PeriodUnaryMethods.time_now": {"code": "class PeriodUnaryMethods:\n    def time_now(self, freq):\n        self.per.now(freq)\n\n    def setup(self, freq):\n        self.per = Period(\"2012-06-01\", freq=freq)", "min_run_count": 2, "name": "tslibs.period.PeriodUnaryMethods.time_now", "number": 0, "param_names": ["freq"], "params": [["'M'", "'min'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "b3c4792b946da369832c7ae6904edf46919fdca2bf03ad4006e36d728c2816bb", "warmup_time": -1}, "tslibs.period.PeriodUnaryMethods.time_to_timestamp": {"code": "class PeriodUnaryMethods:\n    def time_to_timestamp(self, freq):\n        self.per.to_timestamp()\n\n    def setup(self, freq):\n        self.per = Period(\"2012-06-01\", freq=freq)", "min_run_count": 2, "name": "tslibs.period.PeriodUnaryMethods.time_to_timestamp", "number": 0, "param_names": ["freq"], "params": [["'M'", "'min'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "27afe42121b54cb80919887f7d10be0869044b9c877bf53c7bfcd1f5f622e713", "warmup_time": -1}, "tslibs.period.TimeDT64ArrToPeriodArr.time_dt64arr_to_periodarr": {"code": "class TimeDT64ArrToPeriodArr:\n    def time_dt64arr_to_periodarr(self, size, freq, tz):\n        dt64arr_to_periodarr(self.i8values, freq, tz)\n\n    def setup(self, size, freq, tz):\n        if size == 10**6 and tz is tzlocal_obj:\n            # tzlocal is cumbersomely slow, so skip to keep runtime in check\n            raise NotImplementedError\n    \n        arr = np.arange(10, dtype=\"i8\").repeat(size // 10)\n        self.i8values = arr", "min_run_count": 2, "name": "tslibs.period.TimeDT64ArrToPeriodArr.time_dt64arr_to_periodarr", "number": 0, "param_names": ["size", "freq", "tz"], "params": [["0", "1", "100", "10000", "1000000"], ["1000", "1011", "2000", "2011", "3000", "4000", "4006", "5000", "6000", "7000", "8000", "9000", "10000", "11000", "12000"], ["None", "datetime.timezone.utc", "datetime.timezone(datetime.timedelta(seconds=3600))", "<DstTzInfo 'US/Pacific' LMT-1 day, 16:07:00 STD>", "tzfile('/usr/share/zoneinfo/Asia/Tokyo')", "tzlocal()"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "d69932e5796b141be4cbe0df1cc54e17d985cd0d1a2c45707619c95c9ac0df9b", "warmup_time": -1}, "tslibs.period.TimePeriodArrToDT64Arr.time_periodarray_to_dt64arr": {"code": "class TimePeriodArrToDT64Arr:\n    def time_periodarray_to_dt64arr(self, size, freq):\n        periodarr_to_dt64arr(self.i8values, freq)\n\n    def setup(self, size, freq):\n        arr = np.arange(10, dtype=\"i8\").repeat(size // 10)\n        self.i8values = arr", "min_run_count": 2, "name": "tslibs.period.TimePeriodArrToDT64Arr.time_periodarray_to_dt64arr", "number": 0, "param_names": ["size", "freq"], "params": [["0", "1", "100", "10000", "1000000"], ["1000", "1011", "2000", "2011", "3000", "4000", "4006", "5000", "6000", "7000", "8000", "9000", "10000", "11000", "12000"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "780a003a3675ffce34b1163502be5f0eb10d3e9c8e10d3a8f2ce56387e643da2", "warmup_time": -1}, "tslibs.resolution.TimeResolution.time_get_resolution": {"code": "class TimeResolution:\n    def time_get_resolution(self, unit, size, tz):\n        get_resolution(self.i8data, tz)\n\n    def setup(self, unit, size, tz):\n        if size == 10**6 and tz is tzlocal_obj:\n            # tzlocal is cumbersomely slow, so skip to keep runtime in check\n            raise NotImplementedError\n    \n        arr = np.random.randint(0, 10, size=size, dtype=\"i8\")\n        arr = arr.view(f\"M8[{unit}]\").astype(\"M8[ns]\").view(\"i8\")\n        self.i8data = arr", "min_run_count": 2, "name": "tslibs.resolution.TimeResolution.time_get_resolution", "number": 0, "param_names": ["unit", "size", "tz"], "params": [["'D'", "'h'", "'m'", "'s'", "'us'", "'ns'"], ["0", "1", "100", "10000", "1000000"], ["None", "datetime.timezone.utc", "datetime.timezone(datetime.timedelta(seconds=3600))", "<DstTzInfo 'US/Pacific' LMT-1 day, 16:07:00 STD>", "tzfile('/usr/share/zoneinfo/Asia/Tokyo')", "tzlocal()"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "31259509175475d91c89e0d7ed2c1aeb7f584c1ef106af6b79c15883759acb97", "warmup_time": -1}, "tslibs.timedelta.TimedeltaConstructor.time_from_components": {"code": "class TimedeltaConstructor:\n    def time_from_components(self):\n        Timedelta(\n            days=1,\n            hours=2,\n            minutes=3,\n            seconds=4,\n            milliseconds=5,\n            microseconds=6,\n            nanoseconds=7,\n        )\n\n    def setup(self):\n        self.nptimedelta64 = np.timedelta64(3600)\n        self.dttimedelta = datetime.timedelta(seconds=3600)\n        self.td = Timedelta(3600, unit=\"s\")", "min_run_count": 2, "name": "tslibs.timedelta.TimedeltaConstructor.time_from_components", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "976de79734124e410aadd9f6fdb589658515fb75c3456c6c5003df04e31495c8", "warmup_time": -1}, "tslibs.timedelta.TimedeltaConstructor.time_from_datetime_timedelta": {"code": "class TimedeltaConstructor:\n    def time_from_datetime_timedelta(self):\n        Timedelta(self.dttimedelta)\n\n    def setup(self):\n        self.nptimedelta64 = np.timedelta64(3600)\n        self.dttimedelta = datetime.timedelta(seconds=3600)\n        self.td = Timedelta(3600, unit=\"s\")", "min_run_count": 2, "name": "tslibs.timedelta.TimedeltaConstructor.time_from_datetime_timedelta", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "3326b70bfe99c2a6a044540b5db8b882ec1b999993fff273029767c5717f11db", "warmup_time": -1}, "tslibs.timedelta.TimedeltaConstructor.time_from_int": {"code": "class TimedeltaConstructor:\n    def time_from_int(self):\n        Timedelta(123456789)\n\n    def setup(self):\n        self.nptimedelta64 = np.timedelta64(3600)\n        self.dttimedelta = datetime.timedelta(seconds=3600)\n        self.td = Timedelta(3600, unit=\"s\")", "min_run_count": 2, "name": "tslibs.timedelta.TimedeltaConstructor.time_from_int", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "ebc3b0e00ba7cba6a0d3e95134a6f1c56543605b5c4f0337fd76a0b846078e4d", "warmup_time": -1}, "tslibs.timedelta.TimedeltaConstructor.time_from_iso_format": {"code": "class TimedeltaConstructor:\n    def time_from_iso_format(self):\n        Timedelta(\"P4DT12H30M5S\")\n\n    def setup(self):\n        self.nptimedelta64 = np.timedelta64(3600)\n        self.dttimedelta = datetime.timedelta(seconds=3600)\n        self.td = Timedelta(3600, unit=\"s\")", "min_run_count": 2, "name": "tslibs.timedelta.TimedeltaConstructor.time_from_iso_format", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "a16446c3495768b14e84c7b2e947bdfbb1fb7558e73cd969d79d2fddd94f4961", "warmup_time": -1}, "tslibs.timedelta.TimedeltaConstructor.time_from_missing": {"code": "class TimedeltaConstructor:\n    def time_from_missing(self):\n        Timedelta(\"nat\")\n\n    def setup(self):\n        self.nptimedelta64 = np.timedelta64(3600)\n        self.dttimedelta = datetime.timedelta(seconds=3600)\n        self.td = Timedelta(3600, unit=\"s\")", "min_run_count": 2, "name": "tslibs.timedelta.TimedeltaConstructor.time_from_missing", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "ee87e86713ff7adca408473446c87ca651516e45b5a7c43b9142fead580aad84", "warmup_time": -1}, "tslibs.timedelta.TimedeltaConstructor.time_from_np_timedelta": {"code": "class TimedeltaConstructor:\n    def time_from_np_timedelta(self):\n        Timedelta(self.nptimedelta64)\n\n    def setup(self):\n        self.nptimedelta64 = np.timedelta64(3600)\n        self.dttimedelta = datetime.timedelta(seconds=3600)\n        self.td = Timedelta(3600, unit=\"s\")", "min_run_count": 2, "name": "tslibs.timedelta.TimedeltaConstructor.time_from_np_timedelta", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "a8fe79df54c66d13d34089a76ce37bd86f35e6da129e6de26dd0235934789c8c", "warmup_time": -1}, "tslibs.timedelta.TimedeltaConstructor.time_from_pd_timedelta": {"code": "class TimedeltaConstructor:\n    def time_from_pd_timedelta(self):\n        Timedelta(self.td)\n\n    def setup(self):\n        self.nptimedelta64 = np.timedelta64(3600)\n        self.dttimedelta = datetime.timedelta(seconds=3600)\n        self.td = Timedelta(3600, unit=\"s\")", "min_run_count": 2, "name": "tslibs.timedelta.TimedeltaConstructor.time_from_pd_timedelta", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "831bac3969b78367fedc8c945ad8667ac98baab3994380c2c72b8a30c1516c50", "warmup_time": -1}, "tslibs.timedelta.TimedeltaConstructor.time_from_string": {"code": "class TimedeltaConstructor:\n    def time_from_string(self):\n        Timedelta(\"1 days\")\n\n    def setup(self):\n        self.nptimedelta64 = np.timedelta64(3600)\n        self.dttimedelta = datetime.timedelta(seconds=3600)\n        self.td = Timedelta(3600, unit=\"s\")", "min_run_count": 2, "name": "tslibs.timedelta.TimedeltaConstructor.time_from_string", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "8da4af162b193652f720feee641b52568c67cc80c2eef6d146965283fb04bc8d", "warmup_time": -1}, "tslibs.timedelta.TimedeltaConstructor.time_from_unit": {"code": "class TimedeltaConstructor:\n    def time_from_unit(self):\n        Timedelta(1, unit=\"d\")\n\n    def setup(self):\n        self.nptimedelta64 = np.timedelta64(3600)\n        self.dttimedelta = datetime.timedelta(seconds=3600)\n        self.td = Timedelta(3600, unit=\"s\")", "min_run_count": 2, "name": "tslibs.timedelta.TimedeltaConstructor.time_from_unit", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "3ca91b1679620f3ab96408d006de6a0f62611d7e87e32ad104ff37e9f2538c2d", "warmup_time": -1}, "tslibs.timedelta.TimedeltaProperties.time_timedelta_days": {"code": "class TimedeltaProperties:\n    def time_timedelta_days(self, td):\n        td.days\n\n    def setup_cache(self):\n        td = Timedelta(days=365, minutes=35, seconds=25, milliseconds=35)\n        return td", "min_run_count": 2, "name": "tslibs.timedelta.TimedeltaProperties.time_timedelta_days", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "setup_cache_key": "tslibs.timedelta:55", "timeout": 60.0, "type": "time", "unit": "seconds", "version": "027721dc928a0aac947e4eb804535d4414cc57804449f21a50097455e1eb34cc", "warmup_time": -1}, "tslibs.timedelta.TimedeltaProperties.time_timedelta_microseconds": {"code": "class TimedeltaProperties:\n    def time_timedelta_microseconds(self, td):\n        td.microseconds\n\n    def setup_cache(self):\n        td = Timedelta(days=365, minutes=35, seconds=25, milliseconds=35)\n        return td", "min_run_count": 2, "name": "tslibs.timedelta.TimedeltaProperties.time_timedelta_microseconds", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "setup_cache_key": "tslibs.timedelta:55", "timeout": 60.0, "type": "time", "unit": "seconds", "version": "1c88f64d84fd4aa67383bda6396ed221e9b5a7fb816a7ff3ab0788a108b0c6c8", "warmup_time": -1}, "tslibs.timedelta.TimedeltaProperties.time_timedelta_nanoseconds": {"code": "class TimedeltaProperties:\n    def time_timedelta_nanoseconds(self, td):\n        td.nanoseconds\n\n    def setup_cache(self):\n        td = Timedelta(days=365, minutes=35, seconds=25, milliseconds=35)\n        return td", "min_run_count": 2, "name": "tslibs.timedelta.TimedeltaProperties.time_timedelta_nanoseconds", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "setup_cache_key": "tslibs.timedelta:55", "timeout": 60.0, "type": "time", "unit": "seconds", "version": "458eb6a15687e81995044a9cf3b9938fdf6724c379b347d74c6fcb101204008b", "warmup_time": -1}, "tslibs.timedelta.TimedeltaProperties.time_timedelta_seconds": {"code": "class TimedeltaProperties:\n    def time_timedelta_seconds(self, td):\n        td.seconds\n\n    def setup_cache(self):\n        td = Timedelta(days=365, minutes=35, seconds=25, milliseconds=35)\n        return td", "min_run_count": 2, "name": "tslibs.timedelta.TimedeltaProperties.time_timedelta_seconds", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "setup_cache_key": "tslibs.timedelta:55", "timeout": 60.0, "type": "time", "unit": "seconds", "version": "16d230d4bbe759fe887153a89399d0eb5eebbf999155cbe9ec2fdfef09305b0c", "warmup_time": -1}, "tslibs.timestamp.TimestampAcrossDst.time_replace_across_dst": {"code": "class TimestampAcrossDst:\n    def time_replace_across_dst(self):\n        self.ts2.replace(tzinfo=self.tzinfo)\n\n    def setup(self):\n        dt = datetime(2016, 3, 27, 1)\n        self.tzinfo = pytz.timezone(\"CET\").localize(dt, is_dst=False).tzinfo\n        self.ts2 = Timestamp(dt)", "min_run_count": 2, "name": "tslibs.timestamp.TimestampAcrossDst.time_replace_across_dst", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "4eeaaed494bd6b769b9c4efa262f1f90020591c46849984ea9edfa1d194b3a93", "warmup_time": -1}, "tslibs.timestamp.TimestampConstruction.time_from_datetime_aware": {"code": "class TimestampConstruction:\n    def time_from_datetime_aware(self):\n        Timestamp(self.dttime_aware)\n\n    def setup(self):\n        self.npdatetime64 = np.datetime64(\"2020-01-01 00:00:00\")\n        self.dttime_unaware = datetime(2020, 1, 1, 0, 0, 0)\n        self.dttime_aware = datetime(2020, 1, 1, 0, 0, 0, 0, pytz.UTC)\n        self.ts = Timestamp(\"2020-01-01 00:00:00\")", "min_run_count": 2, "name": "tslibs.timestamp.TimestampConstruction.time_from_datetime_aware", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "f14b2ba4c97e828628dc7b144124678a24812e53ec495a6f6f7f035d7e76716c", "warmup_time": -1}, "tslibs.timestamp.TimestampConstruction.time_from_datetime_unaware": {"code": "class TimestampConstruction:\n    def time_from_datetime_unaware(self):\n        Timestamp(self.dttime_unaware)\n\n    def setup(self):\n        self.npdatetime64 = np.datetime64(\"2020-01-01 00:00:00\")\n        self.dttime_unaware = datetime(2020, 1, 1, 0, 0, 0)\n        self.dttime_aware = datetime(2020, 1, 1, 0, 0, 0, 0, pytz.UTC)\n        self.ts = Timestamp(\"2020-01-01 00:00:00\")", "min_run_count": 2, "name": "tslibs.timestamp.TimestampConstruction.time_from_datetime_unaware", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "deda24fb69c398141fba8624b556966cc947474462ca0932939fad017e750985", "warmup_time": -1}, "tslibs.timestamp.TimestampConstruction.time_from_npdatetime64": {"code": "class TimestampConstruction:\n    def time_from_npdatetime64(self):\n        Timestamp(self.npdatetime64)\n\n    def setup(self):\n        self.npdatetime64 = np.datetime64(\"2020-01-01 00:00:00\")\n        self.dttime_unaware = datetime(2020, 1, 1, 0, 0, 0)\n        self.dttime_aware = datetime(2020, 1, 1, 0, 0, 0, 0, pytz.UTC)\n        self.ts = Timestamp(\"2020-01-01 00:00:00\")", "min_run_count": 2, "name": "tslibs.timestamp.TimestampConstruction.time_from_npdatetime64", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "e8deeb3f6693261772dcbea71d4d1e8cf5dc268d0ed889ebc2bd1159359fb79b", "warmup_time": -1}, "tslibs.timestamp.TimestampConstruction.time_from_pd_timestamp": {"code": "class TimestampConstruction:\n    def time_from_pd_timestamp(self):\n        Timestamp(self.ts)\n\n    def setup(self):\n        self.npdatetime64 = np.datetime64(\"2020-01-01 00:00:00\")\n        self.dttime_unaware = datetime(2020, 1, 1, 0, 0, 0)\n        self.dttime_aware = datetime(2020, 1, 1, 0, 0, 0, 0, pytz.UTC)\n        self.ts = Timestamp(\"2020-01-01 00:00:00\")", "min_run_count": 2, "name": "tslibs.timestamp.TimestampConstruction.time_from_pd_timestamp", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "aa508132de1d66508c66cf0477a1ef90bb0d697088197dbff1e6c1cf83db1d9b", "warmup_time": -1}, "tslibs.timestamp.TimestampConstruction.time_fromordinal": {"code": "class TimestampConstruction:\n    def time_fromordinal(self):\n        Timestamp.fromordinal(730120)\n\n    def setup(self):\n        self.npdatetime64 = np.datetime64(\"2020-01-01 00:00:00\")\n        self.dttime_unaware = datetime(2020, 1, 1, 0, 0, 0)\n        self.dttime_aware = datetime(2020, 1, 1, 0, 0, 0, 0, pytz.UTC)\n        self.ts = Timestamp(\"2020-01-01 00:00:00\")", "min_run_count": 2, "name": "tslibs.timestamp.TimestampConstruction.time_fromordinal", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "0d2c91d7caeb1e9f18e97e3b3e49b40506419ccf6a747aba57cec220392b56a6", "warmup_time": -1}, "tslibs.timestamp.TimestampConstruction.time_fromtimestamp": {"code": "class TimestampConstruction:\n    def time_fromtimestamp(self):\n        Timestamp.fromtimestamp(1515448538)\n\n    def setup(self):\n        self.npdatetime64 = np.datetime64(\"2020-01-01 00:00:00\")\n        self.dttime_unaware = datetime(2020, 1, 1, 0, 0, 0)\n        self.dttime_aware = datetime(2020, 1, 1, 0, 0, 0, 0, pytz.UTC)\n        self.ts = Timestamp(\"2020-01-01 00:00:00\")", "min_run_count": 2, "name": "tslibs.timestamp.TimestampConstruction.time_fromtimestamp", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "93f47b86a2ac5472723d056641e6cfea7e3fe451f6a8f80aaaa33d9639ffbcd6", "warmup_time": -1}, "tslibs.timestamp.TimestampConstruction.time_parse_dateutil": {"code": "class TimestampConstruction:\n    def time_parse_dateutil(self):\n        Timestamp(\"2017/08/25 08:16:14 AM\")\n\n    def setup(self):\n        self.npdatetime64 = np.datetime64(\"2020-01-01 00:00:00\")\n        self.dttime_unaware = datetime(2020, 1, 1, 0, 0, 0)\n        self.dttime_aware = datetime(2020, 1, 1, 0, 0, 0, 0, pytz.UTC)\n        self.ts = Timestamp(\"2020-01-01 00:00:00\")", "min_run_count": 2, "name": "tslibs.timestamp.TimestampConstruction.time_parse_dateutil", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "c0309203dabb15ebb9716def5049f52ea3e32116f035e7f28935eecb6eac953e", "warmup_time": -1}, "tslibs.timestamp.TimestampConstruction.time_parse_iso8601_no_tz": {"code": "class TimestampConstruction:\n    def time_parse_iso8601_no_tz(self):\n        Timestamp(\"2017-08-25 08:16:14\")\n\n    def setup(self):\n        self.npdatetime64 = np.datetime64(\"2020-01-01 00:00:00\")\n        self.dttime_unaware = datetime(2020, 1, 1, 0, 0, 0)\n        self.dttime_aware = datetime(2020, 1, 1, 0, 0, 0, 0, pytz.UTC)\n        self.ts = Timestamp(\"2020-01-01 00:00:00\")", "min_run_count": 2, "name": "tslibs.timestamp.TimestampConstruction.time_parse_iso8601_no_tz", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "edb87028a17ef2fe442cb82487dbdad5fc4264ab0c37256a5f0f9940a89ec02f", "warmup_time": -1}, "tslibs.timestamp.TimestampConstruction.time_parse_iso8601_tz": {"code": "class TimestampConstruction:\n    def time_parse_iso8601_tz(self):\n        Timestamp(\"2017-08-25 08:16:14-0500\")\n\n    def setup(self):\n        self.npdatetime64 = np.datetime64(\"2020-01-01 00:00:00\")\n        self.dttime_unaware = datetime(2020, 1, 1, 0, 0, 0)\n        self.dttime_aware = datetime(2020, 1, 1, 0, 0, 0, 0, pytz.UTC)\n        self.ts = Timestamp(\"2020-01-01 00:00:00\")", "min_run_count": 2, "name": "tslibs.timestamp.TimestampConstruction.time_parse_iso8601_tz", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "48fd2b6c0dfc61e556481168eb66875e3bdcabca2d9e2c6d79908f3b16e7a15d", "warmup_time": -1}, "tslibs.timestamp.TimestampConstruction.time_parse_now": {"code": "class TimestampConstruction:\n    def time_parse_now(self):\n        Timestamp(\"now\")\n\n    def setup(self):\n        self.npdatetime64 = np.datetime64(\"2020-01-01 00:00:00\")\n        self.dttime_unaware = datetime(2020, 1, 1, 0, 0, 0)\n        self.dttime_aware = datetime(2020, 1, 1, 0, 0, 0, 0, pytz.UTC)\n        self.ts = Timestamp(\"2020-01-01 00:00:00\")", "min_run_count": 2, "name": "tslibs.timestamp.TimestampConstruction.time_parse_now", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "4ae560aa20eee0beb52506ca024df933003e399825874b0aa280771feaef7ab9", "warmup_time": -1}, "tslibs.timestamp.TimestampConstruction.time_parse_today": {"code": "class TimestampConstruction:\n    def time_parse_today(self):\n        Timestamp(\"today\")\n\n    def setup(self):\n        self.npdatetime64 = np.datetime64(\"2020-01-01 00:00:00\")\n        self.dttime_unaware = datetime(2020, 1, 1, 0, 0, 0)\n        self.dttime_aware = datetime(2020, 1, 1, 0, 0, 0, 0, pytz.UTC)\n        self.ts = Timestamp(\"2020-01-01 00:00:00\")", "min_run_count": 2, "name": "tslibs.timestamp.TimestampConstruction.time_parse_today", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "92ca8839a0be3afb03e222c0647cc70fb3ed56ce204455637cfde1baeea43845", "warmup_time": -1}, "tslibs.timestamp.TimestampOps.time_ceil": {"code": "class TimestampOps:\n    def time_ceil(self, tz):\n        self.ts.ceil(\"5T\")\n\n    def setup(self, tz):\n        self.ts = Timestamp(\"2017-08-25 08:16:14\", tz=tz)", "min_run_count": 2, "name": "tslibs.timestamp.TimestampOps.time_ceil", "number": 0, "param_names": ["tz"], "params": [["None", "datetime.timezone.utc", "datetime.timezone(datetime.timedelta(seconds=3600))", "<DstTzInfo 'US/Pacific' LMT-1 day, 16:07:00 STD>", "tzfile('/usr/share/zoneinfo/Asia/Tokyo')", "tzlocal()"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "1428582cbad6d3d555950451594e390024aad454751ca9d18540ddf7f7548c4a", "warmup_time": -1}, "tslibs.timestamp.TimestampOps.time_floor": {"code": "class TimestampOps:\n    def time_floor(self, tz):\n        self.ts.floor(\"5T\")\n\n    def setup(self, tz):\n        self.ts = Timestamp(\"2017-08-25 08:16:14\", tz=tz)", "min_run_count": 2, "name": "tslibs.timestamp.TimestampOps.time_floor", "number": 0, "param_names": ["tz"], "params": [["None", "datetime.timezone.utc", "datetime.timezone(datetime.timedelta(seconds=3600))", "<DstTzInfo 'US/Pacific' LMT-1 day, 16:07:00 STD>", "tzfile('/usr/share/zoneinfo/Asia/Tokyo')", "tzlocal()"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "29681cac2448139b28d8817e024d6d3c08bcd7fe4594fb26564ed03e81c94f31", "warmup_time": -1}, "tslibs.timestamp.TimestampOps.time_normalize": {"code": "class TimestampOps:\n    def time_normalize(self, tz):\n        self.ts.normalize()\n\n    def setup(self, tz):\n        self.ts = Timestamp(\"2017-08-25 08:16:14\", tz=tz)", "min_run_count": 2, "name": "tslibs.timestamp.TimestampOps.time_normalize", "number": 0, "param_names": ["tz"], "params": [["None", "datetime.timezone.utc", "datetime.timezone(datetime.timedelta(seconds=3600))", "<DstTzInfo 'US/Pacific' LMT-1 day, 16:07:00 STD>", "tzfile('/usr/share/zoneinfo/Asia/Tokyo')", "tzlocal()"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "f7688ade61af780f34bdb840481260073c8bfb88a7504a06758c91f033fb951d", "warmup_time": -1}, "tslibs.timestamp.TimestampOps.time_replace_None": {"code": "class TimestampOps:\n    def time_replace_None(self, tz):\n        self.ts.replace(tzinfo=None)\n\n    def setup(self, tz):\n        self.ts = Timestamp(\"2017-08-25 08:16:14\", tz=tz)", "min_run_count": 2, "name": "tslibs.timestamp.TimestampOps.time_replace_None", "number": 0, "param_names": ["tz"], "params": [["None", "datetime.timezone.utc", "datetime.timezone(datetime.timedelta(seconds=3600))", "<DstTzInfo 'US/Pacific' LMT-1 day, 16:07:00 STD>", "tzfile('/usr/share/zoneinfo/Asia/Tokyo')", "tzlocal()"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "395164d585e187bf1f2ecd1f965a26fe6f63a204fb26eb6daf8c2544e7895f5f", "warmup_time": -1}, "tslibs.timestamp.TimestampOps.time_replace_tz": {"code": "class TimestampOps:\n    def time_replace_tz(self, tz):\n        self.ts.replace(tzinfo=pytz.timezone(\"US/Eastern\"))\n\n    def setup(self, tz):\n        self.ts = Timestamp(\"2017-08-25 08:16:14\", tz=tz)", "min_run_count": 2, "name": "tslibs.timestamp.TimestampOps.time_replace_tz", "number": 0, "param_names": ["tz"], "params": [["None", "datetime.timezone.utc", "datetime.timezone(datetime.timedelta(seconds=3600))", "<DstTzInfo 'US/Pacific' LMT-1 day, 16:07:00 STD>", "tzfile('/usr/share/zoneinfo/Asia/Tokyo')", "tzlocal()"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "4364c2bc5207c0340c1149b8fb230b76c97f7646891613c57bd11cf528e78d77", "warmup_time": -1}, "tslibs.timestamp.TimestampOps.time_to_julian_date": {"code": "class TimestampOps:\n    def time_to_julian_date(self, tz):\n        self.ts.to_julian_date()\n\n    def setup(self, tz):\n        self.ts = Timestamp(\"2017-08-25 08:16:14\", tz=tz)", "min_run_count": 2, "name": "tslibs.timestamp.TimestampOps.time_to_julian_date", "number": 0, "param_names": ["tz"], "params": [["None", "datetime.timezone.utc", "datetime.timezone(datetime.timedelta(seconds=3600))", "<DstTzInfo 'US/Pacific' LMT-1 day, 16:07:00 STD>", "tzfile('/usr/share/zoneinfo/Asia/Tokyo')", "tzlocal()"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "b986ab53361d72e7f0d0ea59b3584f48d6d6fc4994e87be9157f503231f22e70", "warmup_time": -1}, "tslibs.timestamp.TimestampOps.time_to_pydatetime": {"code": "class TimestampOps:\n    def time_to_pydatetime(self, tz):\n        self.ts.to_pydatetime()\n\n    def setup(self, tz):\n        self.ts = Timestamp(\"2017-08-25 08:16:14\", tz=tz)", "min_run_count": 2, "name": "tslibs.timestamp.TimestampOps.time_to_pydatetime", "number": 0, "param_names": ["tz"], "params": [["None", "datetime.timezone.utc", "datetime.timezone(datetime.timedelta(seconds=3600))", "<DstTzInfo 'US/Pacific' LMT-1 day, 16:07:00 STD>", "tzfile('/usr/share/zoneinfo/Asia/Tokyo')", "tzlocal()"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "1db879395196c84d3fd8f358a23b86aaef86f45475d0f83716f8a546e489a627", "warmup_time": -1}, "tslibs.timestamp.TimestampOps.time_tz_convert": {"code": "class TimestampOps:\n    def time_tz_convert(self, tz):\n        if self.ts.tz is not None:\n            self.ts.tz_convert(tz)\n\n    def setup(self, tz):\n        self.ts = Timestamp(\"2017-08-25 08:16:14\", tz=tz)", "min_run_count": 2, "name": "tslibs.timestamp.TimestampOps.time_tz_convert", "number": 0, "param_names": ["tz"], "params": [["None", "datetime.timezone.utc", "datetime.timezone(datetime.timedelta(seconds=3600))", "<DstTzInfo 'US/Pacific' LMT-1 day, 16:07:00 STD>", "tzfile('/usr/share/zoneinfo/Asia/Tokyo')", "tzlocal()"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "43ec3d5f390c7c62a00c06c942395078df2cc729fd8f92a4b0276815f342896d", "warmup_time": -1}, "tslibs.timestamp.TimestampOps.time_tz_localize": {"code": "class TimestampOps:\n    def time_tz_localize(self, tz):\n        if self.ts.tz is None:\n            self.ts.tz_localize(tz)\n\n    def setup(self, tz):\n        self.ts = Timestamp(\"2017-08-25 08:16:14\", tz=tz)", "min_run_count": 2, "name": "tslibs.timestamp.TimestampOps.time_tz_localize", "number": 0, "param_names": ["tz"], "params": [["None", "datetime.timezone.utc", "datetime.timezone(datetime.timedelta(seconds=3600))", "<DstTzInfo 'US/Pacific' LMT-1 day, 16:07:00 STD>", "tzfile('/usr/share/zoneinfo/Asia/Tokyo')", "tzlocal()"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "0ed9c18cc2666c8a010ac46b26f73181d886d5bad76c5a2e012111741777d94c", "warmup_time": -1}, "tslibs.timestamp.TimestampProperties.time_dayofweek": {"code": "class TimestampProperties:\n    def time_dayofweek(self, tz):\n        self.ts.dayofweek\n\n    def setup(self, tz):\n        self.ts = Timestamp(\"2017-08-25 08:16:14\", tzinfo=tz)", "min_run_count": 2, "name": "tslibs.timestamp.TimestampProperties.time_dayofweek", "number": 0, "param_names": ["tz"], "params": [["None", "datetime.timezone.utc", "datetime.timezone(datetime.timedelta(seconds=3600))", "<DstTzInfo 'US/Pacific' LMT-1 day, 16:07:00 STD>", "tzfile('/usr/share/zoneinfo/Asia/Tokyo')", "tzlocal()"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "e29f2f9d5602cdd3653692a09582476ebfd93e83ef6498019842c6cf6b8ec80a", "warmup_time": -1}, "tslibs.timestamp.TimestampProperties.time_dayofyear": {"code": "class TimestampProperties:\n    def time_dayofyear(self, tz):\n        self.ts.dayofyear\n\n    def setup(self, tz):\n        self.ts = Timestamp(\"2017-08-25 08:16:14\", tzinfo=tz)", "min_run_count": 2, "name": "tslibs.timestamp.TimestampProperties.time_dayofyear", "number": 0, "param_names": ["tz"], "params": [["None", "datetime.timezone.utc", "datetime.timezone(datetime.timedelta(seconds=3600))", "<DstTzInfo 'US/Pacific' LMT-1 day, 16:07:00 STD>", "tzfile('/usr/share/zoneinfo/Asia/Tokyo')", "tzlocal()"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "ee2f40845ecc6394591ee911396fc80479a217eeabf14738f0a9b516b7709a70", "warmup_time": -1}, "tslibs.timestamp.TimestampProperties.time_days_in_month": {"code": "class TimestampProperties:\n    def time_days_in_month(self, tz):\n        self.ts.days_in_month\n\n    def setup(self, tz):\n        self.ts = Timestamp(\"2017-08-25 08:16:14\", tzinfo=tz)", "min_run_count": 2, "name": "tslibs.timestamp.TimestampProperties.time_days_in_month", "number": 0, "param_names": ["tz"], "params": [["None", "datetime.timezone.utc", "datetime.timezone(datetime.timedelta(seconds=3600))", "<DstTzInfo 'US/Pacific' LMT-1 day, 16:07:00 STD>", "tzfile('/usr/share/zoneinfo/Asia/Tokyo')", "tzlocal()"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "17752b2964de1c685127ffa838ee3c5e3b0e2a8a63461dff3cba393207ee472e", "warmup_time": -1}, "tslibs.timestamp.TimestampProperties.time_is_leap_year": {"code": "class TimestampProperties:\n    def time_is_leap_year(self, tz):\n        self.ts.is_leap_year\n\n    def setup(self, tz):\n        self.ts = Timestamp(\"2017-08-25 08:16:14\", tzinfo=tz)", "min_run_count": 2, "name": "tslibs.timestamp.TimestampProperties.time_is_leap_year", "number": 0, "param_names": ["tz"], "params": [["None", "datetime.timezone.utc", "datetime.timezone(datetime.timedelta(seconds=3600))", "<DstTzInfo 'US/Pacific' LMT-1 day, 16:07:00 STD>", "tzfile('/usr/share/zoneinfo/Asia/Tokyo')", "tzlocal()"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "e38d3b3704a4721bdc9af6bde865107faa0b6a19cceb1afc4db2be6abebcd5ef", "warmup_time": -1}, "tslibs.timestamp.TimestampProperties.time_is_month_end": {"code": "class TimestampProperties:\n    def time_is_month_end(self, tz):\n        self.ts.is_month_end\n\n    def setup(self, tz):\n        self.ts = Timestamp(\"2017-08-25 08:16:14\", tzinfo=tz)", "min_run_count": 2, "name": "tslibs.timestamp.TimestampProperties.time_is_month_end", "number": 0, "param_names": ["tz"], "params": [["None", "datetime.timezone.utc", "datetime.timezone(datetime.timedelta(seconds=3600))", "<DstTzInfo 'US/Pacific' LMT-1 day, 16:07:00 STD>", "tzfile('/usr/share/zoneinfo/Asia/Tokyo')", "tzlocal()"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "30c8d2e4ef76effa485342decbfb5349b1b96926523713ba746a85a9b4fc0819", "warmup_time": -1}, "tslibs.timestamp.TimestampProperties.time_is_month_start": {"code": "class TimestampProperties:\n    def time_is_month_start(self, tz):\n        self.ts.is_month_start\n\n    def setup(self, tz):\n        self.ts = Timestamp(\"2017-08-25 08:16:14\", tzinfo=tz)", "min_run_count": 2, "name": "tslibs.timestamp.TimestampProperties.time_is_month_start", "number": 0, "param_names": ["tz"], "params": [["None", "datetime.timezone.utc", "datetime.timezone(datetime.timedelta(seconds=3600))", "<DstTzInfo 'US/Pacific' LMT-1 day, 16:07:00 STD>", "tzfile('/usr/share/zoneinfo/Asia/Tokyo')", "tzlocal()"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "0c562c955215c96790f0242b5ba277157e69be2c739e9e95472aa6dd0416d299", "warmup_time": -1}, "tslibs.timestamp.TimestampProperties.time_is_quarter_end": {"code": "class TimestampProperties:\n    def time_is_quarter_end(self, tz):\n        self.ts.is_quarter_end\n\n    def setup(self, tz):\n        self.ts = Timestamp(\"2017-08-25 08:16:14\", tzinfo=tz)", "min_run_count": 2, "name": "tslibs.timestamp.TimestampProperties.time_is_quarter_end", "number": 0, "param_names": ["tz"], "params": [["None", "datetime.timezone.utc", "datetime.timezone(datetime.timedelta(seconds=3600))", "<DstTzInfo 'US/Pacific' LMT-1 day, 16:07:00 STD>", "tzfile('/usr/share/zoneinfo/Asia/Tokyo')", "tzlocal()"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "03313e5f8997f2a2420815b1bcafdef5fcda6334d1bd7ef80f122b59e7403ebe", "warmup_time": -1}, "tslibs.timestamp.TimestampProperties.time_is_quarter_start": {"code": "class TimestampProperties:\n    def time_is_quarter_start(self, tz):\n        self.ts.is_quarter_start\n\n    def setup(self, tz):\n        self.ts = Timestamp(\"2017-08-25 08:16:14\", tzinfo=tz)", "min_run_count": 2, "name": "tslibs.timestamp.TimestampProperties.time_is_quarter_start", "number": 0, "param_names": ["tz"], "params": [["None", "datetime.timezone.utc", "datetime.timezone(datetime.timedelta(seconds=3600))", "<DstTzInfo 'US/Pacific' LMT-1 day, 16:07:00 STD>", "tzfile('/usr/share/zoneinfo/Asia/Tokyo')", "tzlocal()"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "280e8892418c358b39acbba39be3acbd1c294f244e50db4c4ebb0c364fadad1d", "warmup_time": -1}, "tslibs.timestamp.TimestampProperties.time_is_year_end": {"code": "class TimestampProperties:\n    def time_is_year_end(self, tz):\n        self.ts.is_year_end\n\n    def setup(self, tz):\n        self.ts = Timestamp(\"2017-08-25 08:16:14\", tzinfo=tz)", "min_run_count": 2, "name": "tslibs.timestamp.TimestampProperties.time_is_year_end", "number": 0, "param_names": ["tz"], "params": [["None", "datetime.timezone.utc", "datetime.timezone(datetime.timedelta(seconds=3600))", "<DstTzInfo 'US/Pacific' LMT-1 day, 16:07:00 STD>", "tzfile('/usr/share/zoneinfo/Asia/Tokyo')", "tzlocal()"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "eb42a1cc4fe4177b738115226d04b4e2536031f7159767c9709bbb7556c64831", "warmup_time": -1}, "tslibs.timestamp.TimestampProperties.time_is_year_start": {"code": "class TimestampProperties:\n    def time_is_year_start(self, tz):\n        self.ts.is_year_start\n\n    def setup(self, tz):\n        self.ts = Timestamp(\"2017-08-25 08:16:14\", tzinfo=tz)", "min_run_count": 2, "name": "tslibs.timestamp.TimestampProperties.time_is_year_start", "number": 0, "param_names": ["tz"], "params": [["None", "datetime.timezone.utc", "datetime.timezone(datetime.timedelta(seconds=3600))", "<DstTzInfo 'US/Pacific' LMT-1 day, 16:07:00 STD>", "tzfile('/usr/share/zoneinfo/Asia/Tokyo')", "tzlocal()"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "5db3d7d1a89f3a35fe2a867c9046efedb39a0d8d9295b0880d0182689cb78a94", "warmup_time": -1}, "tslibs.timestamp.TimestampProperties.time_microsecond": {"code": "class TimestampProperties:\n    def time_microsecond(self, tz):\n        self.ts.microsecond\n\n    def setup(self, tz):\n        self.ts = Timestamp(\"2017-08-25 08:16:14\", tzinfo=tz)", "min_run_count": 2, "name": "tslibs.timestamp.TimestampProperties.time_microsecond", "number": 0, "param_names": ["tz"], "params": [["None", "datetime.timezone.utc", "datetime.timezone(datetime.timedelta(seconds=3600))", "<DstTzInfo 'US/Pacific' LMT-1 day, 16:07:00 STD>", "tzfile('/usr/share/zoneinfo/Asia/Tokyo')", "tzlocal()"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "657d803a947bd2ee87ff6e4f5fb74034cac717ea6c7234a95be94a19f3a9d926", "warmup_time": -1}, "tslibs.timestamp.TimestampProperties.time_month_name": {"code": "class TimestampProperties:\n    def time_month_name(self, tz):\n        self.ts.month_name()\n\n    def setup(self, tz):\n        self.ts = Timestamp(\"2017-08-25 08:16:14\", tzinfo=tz)", "min_run_count": 2, "name": "tslibs.timestamp.TimestampProperties.time_month_name", "number": 0, "param_names": ["tz"], "params": [["None", "datetime.timezone.utc", "datetime.timezone(datetime.timedelta(seconds=3600))", "<DstTzInfo 'US/Pacific' LMT-1 day, 16:07:00 STD>", "tzfile('/usr/share/zoneinfo/Asia/Tokyo')", "tzlocal()"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "601bf8fc4cd6762f48b99ed3cf7cc263fd851d65febdfa88735ffb31ed02e55d", "warmup_time": -1}, "tslibs.timestamp.TimestampProperties.time_quarter": {"code": "class TimestampProperties:\n    def time_quarter(self, tz):\n        self.ts.quarter\n\n    def setup(self, tz):\n        self.ts = Timestamp(\"2017-08-25 08:16:14\", tzinfo=tz)", "min_run_count": 2, "name": "tslibs.timestamp.TimestampProperties.time_quarter", "number": 0, "param_names": ["tz"], "params": [["None", "datetime.timezone.utc", "datetime.timezone(datetime.timedelta(seconds=3600))", "<DstTzInfo 'US/Pacific' LMT-1 day, 16:07:00 STD>", "tzfile('/usr/share/zoneinfo/Asia/Tokyo')", "tzlocal()"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "f822d240b6aab8f16f5cb4b0b15eb282a11540a85c12eb391cbf3adcd0dea0dd", "warmup_time": -1}, "tslibs.timestamp.TimestampProperties.time_tz": {"code": "class TimestampProperties:\n    def time_tz(self, tz):\n        self.ts.tz\n\n    def setup(self, tz):\n        self.ts = Timestamp(\"2017-08-25 08:16:14\", tzinfo=tz)", "min_run_count": 2, "name": "tslibs.timestamp.TimestampProperties.time_tz", "number": 0, "param_names": ["tz"], "params": [["None", "datetime.timezone.utc", "datetime.timezone(datetime.timedelta(seconds=3600))", "<DstTzInfo 'US/Pacific' LMT-1 day, 16:07:00 STD>", "tzfile('/usr/share/zoneinfo/Asia/Tokyo')", "tzlocal()"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "c7f2fb57fa5899b99e67eed5aed5efb470cddf82e1f2a8f1c6472ba40e5ea021", "warmup_time": -1}, "tslibs.timestamp.TimestampProperties.time_week": {"code": "class TimestampProperties:\n    def time_week(self, tz):\n        self.ts.week\n\n    def setup(self, tz):\n        self.ts = Timestamp(\"2017-08-25 08:16:14\", tzinfo=tz)", "min_run_count": 2, "name": "tslibs.timestamp.TimestampProperties.time_week", "number": 0, "param_names": ["tz"], "params": [["None", "datetime.timezone.utc", "datetime.timezone(datetime.timedelta(seconds=3600))", "<DstTzInfo 'US/Pacific' LMT-1 day, 16:07:00 STD>", "tzfile('/usr/share/zoneinfo/Asia/Tokyo')", "tzlocal()"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "cf7c5eef5480fb665a78f4c97bb9d21ac5d4a0141c4b107f915bcef238c4ceca", "warmup_time": -1}, "tslibs.timestamp.TimestampProperties.time_weekday_name": {"code": "class TimestampProperties:\n    def time_weekday_name(self, tz):\n        self.ts.day_name()\n\n    def setup(self, tz):\n        self.ts = Timestamp(\"2017-08-25 08:16:14\", tzinfo=tz)", "min_run_count": 2, "name": "tslibs.timestamp.TimestampProperties.time_weekday_name", "number": 0, "param_names": ["tz"], "params": [["None", "datetime.timezone.utc", "datetime.timezone(datetime.timedelta(seconds=3600))", "<DstTzInfo 'US/Pacific' LMT-1 day, 16:07:00 STD>", "tzfile('/usr/share/zoneinfo/Asia/Tokyo')", "tzlocal()"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "72364a32ce479df795dde42a507109f4f6ff8450ba4212e2469d7c7c09785e31", "warmup_time": -1}, "tslibs.tslib.TimeIntsToPydatetime.time_ints_to_pydatetime": {"code": "class TimeIntsToPydatetime:\n    def time_ints_to_pydatetime(self, box, size, tz):\n        ints_to_pydatetime(self.i8data, tz, box=box)\n\n    def setup(self, box, size, tz):\n        if box == \"date\" and tz is not None:\n            # tz is ignored, so avoid running redundant benchmarks\n            raise NotImplementedError  # skip benchmark\n        if size == 10**6 and tz is _tzs[-1]:\n            # This is cumbersomely-slow, so skip to trim runtime\n            raise NotImplementedError  # skip benchmark\n    \n        arr = np.random.randint(0, 10, size=size, dtype=\"i8\")\n        self.i8data = arr", "min_run_count": 2, "name": "tslibs.tslib.TimeIntsToPydatetime.time_ints_to_pydatetime", "number": 0, "param_names": ["box", "size", "tz"], "params": [["'time'", "'date'", "'datetime'", "'timestamp'"], ["0", "1", "100", "10000", "1000000"], ["None", "datetime.timezone.utc", "datetime.timezone(datetime.timedelta(seconds=3600))", "<DstTzInfo 'US/Pacific' LMT-1 day, 16:07:00 STD>", "tzfile('/usr/share/zoneinfo/Asia/Tokyo')", "tzlocal()"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "cc992ad9ce5601940faa38dd855be6b5df8a12c763443caf43906b262537aa5b", "warmup_time": -1}, "tslibs.tz_convert.TimeTZConvert.time_tz_convert_from_utc": {"code": "class TimeTZConvert:\n    def time_tz_convert_from_utc(self, size, tz):\n        # effectively:\n        #  dti = DatetimeIndex(self.i8data, tz=tz)\n        #  dti.tz_localize(None)\n        if old_sig:\n            tz_convert_from_utc(self.i8data, UTC, tz)\n        else:\n            tz_convert_from_utc(self.i8data, tz)\n\n    def setup(self, size, tz):\n        if size == 10**6 and tz is tzlocal_obj:\n            # tzlocal is cumbersomely slow, so skip to keep runtime in check\n            raise NotImplementedError\n    \n        arr = np.random.randint(0, 10, size=size, dtype=\"i8\")\n        self.i8data = arr", "min_run_count": 2, "name": "tslibs.tz_convert.TimeTZConvert.time_tz_convert_from_utc", "number": 0, "param_names": ["size", "tz"], "params": [["0", "1", "100", "10000", "1000000"], ["datetime.timezone.utc", "datetime.timezone(datetime.timedelta(seconds=3600))", "<DstTzInfo 'US/Pacific' LMT-1 day, 16:07:00 STD>", "tzfile('/usr/share/zoneinfo/Asia/Tokyo')", "tzlocal()"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "f36d5a11290654921892d1874be3d844db07e8633878642a38777b1b3439bfdd", "warmup_time": -1}, "tslibs.tz_convert.TimeTZConvert.time_tz_localize_to_utc": {"code": "class TimeTZConvert:\n    def time_tz_localize_to_utc(self, size, tz):\n        # effectively:\n        #  dti = DatetimeIndex(self.i8data)\n        #  dti.tz_localize(tz, ambiguous=\"NaT\", nonexistent=\"NaT\")\n        tz_localize_to_utc(self.i8data, tz, ambiguous=\"NaT\", nonexistent=\"NaT\")\n\n    def setup(self, size, tz):\n        if size == 10**6 and tz is tzlocal_obj:\n            # tzlocal is cumbersomely slow, so skip to keep runtime in check\n            raise NotImplementedError\n    \n        arr = np.random.randint(0, 10, size=size, dtype=\"i8\")\n        self.i8data = arr", "min_run_count": 2, "name": "tslibs.tz_convert.TimeTZConvert.time_tz_localize_to_utc", "number": 0, "param_names": ["size", "tz"], "params": [["0", "1", "100", "10000", "1000000"], ["datetime.timezone.utc", "datetime.timezone(datetime.timedelta(seconds=3600))", "<DstTzInfo 'US/Pacific' LMT-1 day, 16:07:00 STD>", "tzfile('/usr/share/zoneinfo/Asia/Tokyo')", "tzlocal()"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "3bcf7f94df95f8ab82da03b954dc9d477df030167d67f9ead7d5549deb4025d2", "warmup_time": -1}}, "machines": {"asv-runner": {"arch": "x86_64", "cpu": "Intel(R) Core(TM) i7-4980HQ CPU @ 2.80GHz", "machine": "asv-runner", "os": "Linux 3.13.0-116-generic", "ram": "501692", "version": 1}}, "tags": {"0.3.0": 288, "debian/0.4.0-1": 874, "debian/0.4.1-1": 933, "debian/0.4.3-1": 1084, "debian/0.5.0+git7-gcf32be2-1": 1194, "debian/0.6.1-1": 1632, "debian/0.7.0-1": 2077, "debian/0.7.1+git1-ga2e86c2-1": 2247, "debian/0.7.3-1": 2555, "debian/0.8.0-1": 3418, "debian/0.8.0-2": 3494, "debian/0.8.0_b2+git68-g7240b87-1": 3344, "debian/0.8.0_b2-1": 3266, "debian/0.8.0_rc2+git26-g76c6351-1": 3393, "debian/0.8.1-1": 3557, "v0.10.0": 4816, "v0.10.0b1": 4723, "v0.10.1": 5022, "v0.11.0": 5863, "v0.11.0rc1": 5767, "v0.12.0": 6794, "v0.12.0rc1": 6664, "v0.13.0": 8139, "v0.13.0_ahl1": 8234, "v0.13.0_ahl2": 8327, "v0.13.0rc1": 7983, "v0.13.1": 8680, "v0.14.0": 9713, "v0.14.0rc1": 9617, "v0.14.1": 10140, "v0.15.0": 10853, "v0.15.0rc1": 10793, "v0.15.1": 10956, "v0.15.2": 11188, "v0.15.2pre": 11042, "v0.15pre": 10501, "v0.16.0": 11564, "v0.16.0rc1": 11528, "v0.16.1": 11906, "v0.16.2": 12077, "v0.16.3": 12091, "v0.17.0": 12889, "v0.17.0rc1": 12722, "v0.17.0rc2": 12860, "v0.17.1": 13158, "v0.18.0": 13626, "v0.18.0rc1": 13524, "v0.18.0rc2": 13615, "v0.18.1": 13836, "v0.19.0": 14330, "v0.19.0rc1": 14282, "v0.19.1": 14435, "v0.19.2": 14706, "v0.20.0": 15365, "v0.20.0rc1": 15300, "v0.20.0rc2": 15357, "v0.20.1": 15371, "v0.20.2": 15574, "v0.20.3": 15686, "v0.21.0": 16141, "v0.21.0.dev": 15372, "v0.21.0rc1": 16095, "v0.21.1": 16592, "v0.22.0": 16721, "v0.22.0.dev0": 16142, "v0.23.0": 17589, "v0.23.0.dev0": 16694, "v0.23.0rc1": 17530, "v0.23.0rc2": 17532, "v0.23.1": 17746, "v0.23.2": 17916, "v0.23.3": 17943, "v0.23.4": 18118, "v0.24.0": 19354, "v0.24.0.dev0": 17590, "v0.24.0rc1": 19274, "v0.24.1": 19436, "v0.24.2": 19671, "v0.25.0": 20423, "v0.25.0.dev0": 19355, "v0.25.0rc0": 20330, "v0.25.1": 20697, "v0.25.2": 21096, "v0.25.3": 21232, "v0.26.0.dev0": 20424, "v0.4.0": 862, "v0.4.1": 926, "v0.4.2": 981, "v0.4.3": 1029, "v0.5.0": 1185, "v0.6.0": 1342, "v0.6.1": 1440, "v0.7.0": 2072, "v0.7.0rc1": 1812, "v0.7.1": 2196, "v0.7.2": 2358, "v0.7.3": 2539, "v0.8.0": 3412, "v0.8.0b1": 3074, "v0.8.0b2": 3262, "v0.8.0rc1": 3360, "v0.8.0rc2": 3361, "v0.8.1": 3551, "v0.9.0": 4026, "v0.9.0rc1": 3912, "v0.9.0rc2": 3955, "v0.9.1": 4289, "v0.9.1rc1": 4249, "v1.0.0": 22538, "v1.0.0rc0": 22237, "v1.0.1": 22700, "v1.0.2": 23185, "v1.0.3": 23272, "v1.0.4": 24131, "v1.0.5": 24338, "v1.1.0": 24603, "v1.1.0.dev0": 22238, "v1.1.0rc0": 24593, "v1.1.1": 24770, "v1.1.2": 24989, "v1.1.3": 25339, "v1.1.4": 25725, "v1.1.5": 26258, "v1.2.0": 26509, "v1.2.0.dev0": 24604, "v1.2.0rc0": 26276, "v1.2.1": 26847, "v1.2.2": 27078, "v1.2.3": 27326, "v1.2.4": 27737, "v1.2.5": 28492, "v1.3.0": 28584, "v1.3.0.dev0": 26277, "v1.3.0rc0": 28350, "v1.3.0rc1": 28359, "v1.3.1": 28769, "v1.3.2": 28954, "v1.3.3": 29206, "v1.3.4": 29489, "v1.3.5": 29970, "v1.4.0": 30391, "v1.4.0.dev0": 28351, "v1.4.0rc0": 30182, "v1.4.1": 30639, "v1.4.2": 30963, "v1.4.3": 31386, "v1.4.4": 31829, "v1.5.0": 31988, "v1.5.0.dev0": 30183, "v1.5.0rc0": 31776, "v1.5.1": 32263, "v1.5.2": 32634, "v1.5.3": 33231, "v1.6.0.dev0": 31777, "v2.0.0.dev0": 31777, "v2.0.0rc0": 33598, "v2.1.0.dev0": 33599}, "pages": [["", "Grid view", "Display as a agrid"], ["summarylist", "List view", "Display as a list"], ["regressions", "Show regressions", "Display information about recent regressions"]]}