{"project": "pandas", "project_url": "https://pandas.pydata.org/", "show_commit_url": "https://github.com/pandas-dev/pandas/commit/", "hash_length": 8, "revision_to_hash": {"288": "4906ee79d730f77be02ec586ec7f66c95a0433da", "862": "9e406c50b77949433ed8f7fd094fd30b5421a35e", "874": "645d61131ad5acf768fff906a25e9e34b53efb92", "926": "cdc607c8ebd05419c0c446298a89814eac817459", "933": "ba1ff88c95b081741eb28c8630aaa6b0423900e0", "981": "35c6b68facf00788e9092d1fcedd53acbf99be89", "1029": "a8b14798fe18050e486845b26370d4899f46a8b3", "1084": "a0aa6a96d8a2456523d9f407d3f9f936f24dd7c8", "1185": "8f79f7c6e01874bbf7f3b9bc38af01551c90121e", "1194": "da3e95da95e1e07acc535b8e734b9b80a0972609", "1342": "010a620da89e5babc137b924dd1f632b4f6e6fee", "1440": "d5fbdcc26520d1c92b5dd73bb6e9a9902756ad16", "1632": "2ca93a17ed4609960f0ee3b8704b8b2edca1db5b", "1812": "06f608182ecd516abcd140531c65e07b30293eb0", "2072": "13f5db0ac0ba5a30d64866cdbd02b9985efa6303", "2077": "abc59ab02622560f226dd32bd068857053bc96d0", "2196": "776d80c2145ce4a4df1cf5c9ad21140b09df671d", "2247": "483ca398bd20ae42dd1a9d12f972634b384d560b", "2358": "4117b4fde3ffbc74a48b01f3a28f1f76b2db05fd", "2539": "9d0949396a8533d9fb9b0a6d0fb90a9f0ac16b23", "2555": "dfd7447e47562a941bb355af51c475823520f9e3", "3074": "5b98fdfeae2ef42d78242c4cca1e0959b9c710db", "3262": "fde270b20861fbf36d3063d504fb299d0b58695b", "3266": "a1d768829015796d16486cbc1e99020348901e25", "3344": "1c08383fc3cf24d503ae221c5d31b93899da6473", "3360": "5f5df2aa34f027d3fc83abb19cf7840ababd4557", "3361": "5d90f7d0e7e9bb53e55fdb7b70f972aa502004ed", "3393": "c91f6d1f62d02a65af78651f61f8db9a62c58b1b", "3412": "a901af2cdfe411d6aa9f9b1f6fa3223738f3e514", "3418": "f5a1bc9cda068f724d2de2ddc0da8ac2c518095b", "3494": "1c24700c3ba74419988e74319fd46e1f937c1f4d", "3551": "4e95b311bbf320d7b88edd6f8ce17194e48b8145", "3557": "23fa6f8b3d1f823dbafb64dc52e5a96fefe9236c", "3912": "e1b6e44bed02f47f59bf2d71c836f42f6e130dea", "3955": "6d9bd5a6374f1d6b4c18d3d53fc0413c82a16b49", "4026": "b5956fdc123b0208cf36fafc1b80a9671c66efbb", "4249": "2d576ee9b9337210a8c85f11e48177db42ecd57f", "4289": "9867f8af6e20cd2248626548f9b3f9a66b57789c", "4723": "78ce0ce8baef9c66bbee77083c0d12a47d5e294f", "4816": "1751bae723d336904bca81945097b3b700b11801", "5022": "31ecaa9d06f71b5d652d15441cf6b2dcc6f7e640", "5767": "258c7e3c5ec5dca7bec32308925b94267fbcff61", "5863": "f9eea308611152f1f7bb89981380fa5d85685f48", "6664": "b96ab6bddd5f2e84bd88a0659c4d98154819cffc", "6794": "8c0a34f15f8a87def3f7ad6ebdac052de44669f2", "7983": "16052e501adc3dedec3bf8cf65a7ea24300de1b1", "8139": "a5410ed841759badae2c3fe4cc71335c9dd6ad92", "8234": "db18d443dc0eac6454b864e179579619493899dc", "8327": "48c005ea761adcaf6b76a84aa94da0d35db8c6d6", "8680": "d10a658673b7d2c2e7a346461c9a4bfc5233d7e1", "9617": "76f6cf0050025ec5a6187e17957ea9a158cc2d56", "9713": "da0f7ae362bb0ee747c3c5c141327d1d8ba161bc", "10140": "d839555f5e080a981ce5faf89b4df7dfe0924541", "10501": "12248ffc942acf3a224922495102462c6999c804", "10793": "8dfbe09c1443334fc3036465712195a36c773f4b", "10853": "017adeaa4b70d63fe6c788db457dc9d31562f4d6", "10956": "d8ab3415373ea42713c096a97c3d9ed5c9cb82ee", "11042": "f1b270fcf5d505eebe4bf964f0541d6a43c3560e", "11188": "18ea1d856d45c87fe18a41d1a267ede46e10880e", "11528": "9e859f40c1651b38f9528aaccd211b1706cf317e", "11564": "c91bdbadfdbf9f60879ead8dd86bd1e72ca18ccf", "11906": "ca9eefc3c4733f368c054e33537ff18384114b43", "12077": "06832891870119984c6a5404bc7f7a471f43b99c", "12091": "6b1055c765c488e6fb411eed452abf75ff8df4bb", "12722": "9687145e06aed545c14630460d24a9693c9a0b39", "12860": "071cffd63e4b99362c68a5e2d472b629618c50a1", "12889": "fe48704835323c140846d1bde5e1387aa0cac3d4", "13158": "6c30cbecf8e5ae610f2a37ba821116bd9f77044d", "13524": "9259a56c600f6ea247a9c58c00af017790fe5e21", "13615": "e5ed87b33ab6cd9dade10df945bc5d7452310b7d", "13626": "e462ece64b7cb12fe7cad6e085f62f3bfe9785c6", "13836": "87b0f4dc1e91571cc4dd933b7cb181b99606ad20", "14282": "497a3bcbf6a1f97a9596278f78b9883b50a4c66f", "14330": "b97dbd01e49f54ae6fa8df382d6f6e4c771d2bc0", "14435": "27b783986230a3d044d045604b72a51acd13b7be", "14706": "825876ca7ee8ac7bea463925399c083d5f190b3e", "15300": "19fc8dac68e088126ffd132dc322dbf8a163ec69", "15357": "2002da33b0a755fcf7ef64b2c87ca4252f0e7df0", "15365": "a31c96d34d00dc757908b564dc93991e867d83e2", "15371": "e346c663cf76186c22f4d3b703461b1b60db280f", "15372": "e5134306bd47db9f6d0f125d2cafd0b8a789e065", "15574": "2814061730893bc8122caa4e01197c699da352e6", "15686": "3a7f956c30528736beaae5784f509a76d892e229", "16095": "c277cd76416d4e930b1f05da873b9eaf101139da", "16141": "81372093f1fdc0c07e4b45ba0f47b0360fabd405", "16142": "fc1e50733ea4c372f4c9eb3a53bf35e102d5d215", "16592": "7bb204a05fee20c3c825e7da39ccaf39fbeb8ca5", "16694": "fae79204e2b60ac1ff2b2309352ffb5d9382a017", "16721": "a00154dcfe5057cb3fd86653172e74b6893e337d", "17530": "44ccca1f3c27795322b979cf6e5dbd49422b5173", "17532": "b02c69ac7309ccf63a17471b25475bf0c0ebe3c3", "17589": "3147a86e1b20571766b488a8444c74cef29729ad", "17590": "2eb5a67999552d60f7a2a9e1922549d5417d714f", "17746": "1a23779f09abc6ebf908d66ee88b973b767e2e3c", "17916": "9b0f560a73d11b2fa72c48d7fd16126b5137f349", "17943": "edb71fda022c6a155717e7a25679040ee0476639", "18118": "0409521665bd436a10aea7e06336066bf07ff057", "19274": "fdc4db25a9988a7b595a3756760d05a6c177123d", "19354": "83eb2428ceb6257042173582f3f436c2c887aa69", "19355": "0c4113fa0906273007cc12a4bcadff85d943dc84", "19436": "1700680381bdbfbc1abe9774f96881801b24d6ca", "19671": "cb00deb94500205fcb27a33cc1d0df79a9727f8b", "20330": "2efb60717bda9fc64344c5f6647d58564930808e", "20423": "d1accd032b648c9affd6dce1f81feb9c99422483", "20424": "d48306e77c0a708e0ee33a2aa1da7e267df52ef6", "20697": "171c71611886aab8549a8620c5b0071a129ad685", "21096": "0efc71b53f019c6c5a8da7a38e08646ca75c17d9", "21232": "62a87bf4a2af02a8d3bc271ad26e5994292b8e6a", "22237": "d3f08566a80239a18a813ebda9a2ebb0368b1dc5", "22238": "b7fcb545a1a298817cd7d9f8940f19992d1202d2", "22538": "fd9ceb9dce3d62d8a9caa6ba7c127b512939452e", "22700": "29d6b0232aab9576afa896ff5bab0b994760495a", "23185": "7485dbe6fcdab3fe2e5a23534ba00767d50374d8", "23272": "3adf3340453d6704d4a2cb47058214cc697a7d29", "24131": "1ce1c3c1ef9894bf1ba79805f37514291f52a9da", "24338": "b687cd4d9e520666a956a60849568a98dd00c672", "24593": "bfac13628394ac7317bb94833319bd6bf87603af", "24603": "d9fff2792bf16178d4e450fe7384244e50635733", "24604": "d1b1faa3f68dad6163000784c34a66b8f6c227e1", "24770": "f2ca0a2665b2d169c97de87b8e778dbed86aea07", "24989": "2a7d3326dee660824a8433ffd01065f8ac37f7d6", "25339": "db08276bc116c438d3fdee492026f8223584c477", "25725": "67a3d4241ab84419856b84fc3ebc9abcbe66c6b3", "26258": "b5958ee1999e9aead1938c0bba2b674378807b3d", "26276": "7688d3cfebb7227c978cb386145c0d4924209efc", "26277": "0f587028e42d5444e2f0edbc0b4c889af16eae26", "26509": "3e89b4c4b1580aa890023fc550774e63d499da25", "26847": "9d598a5e1eee26df95b3910e3f2934890d062caa", "27078": "7d32926db8f7541c356066dcadabf854487738de", "27326": "f2c8480af2f25efdbd803218b9d87980f416563e", "27737": "2cb96529396d93b46abab7bbc73a208e708c642e", "28350": "3765b2099e6e2cb4d180edbb354045ae09a40269", "28351": "cff206be208c61146c0aead51ffacb5a15b4e31d", "28359": "2dd9e9ba9009a40191c0c0b96262fa3939d609f0", "28492": "7c48ff4409c622c582c56a5702373f726de08e96", "28584": "f00ed8f47020034e752baf0250483053340971b0", "28769": "c7f7443c1bad8262358114d5e88cd9c8a308e8aa", "28954": "5f648bf1706dd75a9ca0d29f26eadfbb595fe52b", "29206": "73c68257545b5f8530b7044f56647bd2db92e2ba", "29489": "945c9ed766a61c7d2c0a7cbb251b6edebf9cb7d5", "29970": "66e3805b8cabe977f40c05259cc3fcf7ead5687d", "30182": "d023ba755322e09b95fd954bbdc43f5be224688e", "30183": "7a4a85a0f76c81f8d03d5603baf626a9a068a655", "30391": "bb1f651536508cdfef8550f93ace7849b00046ee", "30639": "06d230151e6f18fdb8139d09abf539867a8cd481", "30963": "4bfe3d07b4858144c219b9346329027024102ab6", "31386": "e8093ba372f9adfe79439d90fe74b0b5b6dea9d6", "31689": "e754faebe0818f87ecad04894299aec7372f338a", "31690": "315bcd05f2319c0311e6495d2cc9afa39d53d0a3", "31691": "e0cadc567013beefea0db87f038bb665b8f68cd4", "31692": "d9e2fb5e4be0b0dea5725bfdf86675e803b46ae1", "31693": "06dd5dab93ff4a55377309c0315aa767fdf9937e", "31694": "c70f9b9b57094674df9b5682ff2d0073363bdd22", "31695": "152c4dac7420bff9708b02d7c7f9d3428ec464f6", "31696": "50c2af1a6322375359a8bacfd79056ca4ab02df2", "31697": "8b72297c8799725e98cb2c6aee664325b752194f", "31703": "9dfbd9f45d9afb6975884f6a55e246f423519b9f", "31704": "c7b470c3e13f99ce990e23b2a311d3a2c633499c", "31705": "9f81aa65a416510b0ad7cb1d473600f261169813", "31706": "e5bfbdc239ee4c55dd3d731a7119d0cf191ebb5f", "31707": "aa9a1b3c5f0d56dacfa9e2ebfb99683827bf7f2e", "31712": "89d024e788f3687fe2b2f4d3a50675503f792971", "31713": "57edc45ef1cb91cf000164b7e12acf8f745c7a69", "31714": "d906b3316380d376ed765eed980a77ed514d1cc9", "31715": "3512e2408429ed0f058480e5df4d54e0f9bdc25c", "31716": "a6aaeb6baf679fe133e968e0f65199fc56d177b2", "31717": "5ad44e71a12ea2c77449a229b86cc1a31b33f2f6", "31718": "9de1f0b32de55ec6d892cea31449cfaf1996ccbe", "31719": "e94faa23e24c0abf9db74d79cfebe06676577867", "31720": "b3f8ab4f645ba8e1f609f4d48577d76c4b522974", "31721": "655d9f4fe7d9fed1aea7baaa0886be6017e08878", "31727": "157a65ed58f333f9d0a5b03cb7ded740359c7c4f", "31728": "c19a4ad6e15ea37af0eec40aeed2d961e7f8bfec", "31729": "065b51c1a17c6ee472af0273c0a16dfc55e26fb5", "31748": "7b7beb903b1d1d80ea5c2dd434bfbeacb3c2fbd7", "31749": "5cbbc2c0afc74b57d5d6d0774ac71eb55d5bc19f", "31750": "cf88cc14787bd4d1c769e269ec5f0469b2eea820", "31751": "30efa5fbda46b1d71779cb7f7ce0e5b81fa5474f", "31752": "ae47909f030f1ff900888a64b8d12d81a763e14d", "31754": "221f6362bc25833da87f00015d4d5418ee316eff", "31759": "901b02f67c426872d75b5ba3e2eb5e42732a6c67", "31760": "af146315a5df2d821c54df137495013064edd061", "31761": "e65a30e3ebdb7572a943d097882c241789569669", "31764": "2856ce13aa19ec07d2f6c9165b6f18f0146a3dd5", "31765": "606dd3c40ce48dbf5616901b0d179e4aea7e6e55", "31775": "3b901a4143d2263bbc7fc5076f040eb70166ff92", "31776": "224458ee25d92ccdf289d1ae2741d178df4f323e", "31777": "573e7eaffd801ee5bd1f7685697b51eef5b8ed85", "31778": "0402367c8342564538999a559e057e6af074e5e4", "31779": "378fcefcb203907ba651b9ebd570982ffe020bc8", "31782": "1f41ff07d1f86113c1e7c128ee612dca8bd65ac8", "31783": "2e9619368c7aec7bee20471c6eec368c27d055bb", "31785": "6df6691438dde3aa9c6fdfa359d39b730e29e331", "31789": "a294a15f95b96c4bb43a2b79f43661d6e841d869", "31790": "b01bd9004951330a86d917547c96c8d3d3228730", "31791": "ed03e396ea33dedc1b61868a07d34dd367a79518", "31794": "e0cf2645095a5164ea7a7b143097bf0051f11481", "31795": "a203a307da58819c9e0e994867a5a0dc4ddad7b3", "31802": "64e7859deb5656cf5c6aab2742ad8cbaf831e0c8", "31803": "1b2cc268e485158ca57d1630f558107b2bca725f", "31804": "c08c925b7b35ff1deb9013305236cbf5c735f73a", "31805": "e97b0824097182a735995f67dfd42b4484eb62a1", "31806": "9757d1f93faaa517161fd719e884be7344c18b62", "31807": "03d8cd27d5aa18a06a67e8aefe2fa8a49f557292", "31808": "b8dcd27b74ed09130e283a557bb85ee0eafefead", "31809": "7650e4e66dfc3d441df790cb4662348d30bbb7ad", "31810": "8955276b7079e85251b1b89962cc531fae0c5b80", "31811": "87e59820865e1da2f39109c41925ed9cc9583e79", "31812": "6559eda304d9a8b23e52043c6b540b0302d9ca20", "31814": "707039adf0aefcb32f4f2b4db14c528773d6b605", "31817": "642bd3de5461f4083649281c9deda432e229fd86", "31818": "1843cf23c7aa74248d956ae28a30abfc2c0af8e8", "31823": "b1e6c1fd108a2be6a64973eb66e9da7cab006f94", "31824": "654c4c05447897cb0678d5cc189a89fa4071e382", "31827": "3a3ed661c0a62b97f6fffc05bbf1fe6769b908cc", "31828": "f0814bcca41a116794ff926b571ec6c2d15685d7", "31829": "ca60aab7340d9989d9428e11a51467658190bb6b", "31833": "3f9c04275e87e806dc8f5082aa3f3fc987c41a51", "31834": "baf1d2c80f41c51454a07917a28e6d0535880a0a", "31835": "e7414aa17f67d05b6ae5a7a66881178936c8b2ac", "31836": "b3e8bbe4e5af934b3103b533de9349291e4caf4b", "31837": "bfdb524f5807892adde0e5d3d754351459cd1614", "31838": "d0268e719f899789f9606beb4592a17d27086b4c", "31839": "6165b6495f364155b221e5f8099acbd729b49a17", "31840": "96ad686a0f5eba9524b6b2e672af9c4600ec4e7e", "31841": "126f48784042e84f26ce41c827354d2a258b69eb", "31843": "10855f6b55dfb05b1e9a0186b8203bcf4bea7df6", "31845": "ddc52f203c3f1e6a8e1738da34225dfd56375591", "31846": "b1c3da6ca3b2e32b4c463a418eb62298252d31e4", "31847": "ee1c4c15de86dcb075af3bae07d5d647ace1e6c7", "31848": "003f1253dddff5b4bf1fcbcd74c66904a0ba0b04", "31849": "a1e49873ca61286deaf7b81548ec95ed7fc53561", "31850": "298dac384f92726b6da9a6319695cb0269e6eeb8", "31853": "82c39f008f2724f30439583454d8a070b4cec72c", "31854": "d8ddfcac96c1acd8792d81bc522dc57b8da5d1bb", "31855": "fee9b5d3a459eaf24398ec7cf2717e935af5549a", "31856": "854987f2deaa39effababc6e8f2cfc5c5534f6cc", "31857": "9c509e2812dbb27735288095f3305a08722594bc", "31859": "f0fff8cfbf76fca9e228dafa882e3a51339161b0", "31860": "a72340acee1f9a613a304f639e75b255181bf42d", "31861": "64c8a05a3c1a9aac3ffb78884fe3a00fe9f8ea08", "31862": "4b645ae5a0c77aff7828515de02ea567e52ed1cb", "31863": "ddf2541df866e89150210d41c22e45eb2cf83e91", "31864": "fa211d47604f5de7667440a842f7fbbb463de31d", "31866": "480d6be456ee3813b9ac1a14daa8c07672b99730", "31867": "6787b8b73f4c54a0cf742a90433e6fb6c7edb231", "31868": "2d8d31355f10da9d90d7db1c59dc4b9793910cf6", "31869": "82ce975b16195b66ce2bdb00b9040d843412cc33", "31870": "a9138a974fe7464c84a7110488555faa563b8385", "31875": "d1d9b7f8d61e22fb62ba40611d8d02c1fba49568", "31876": "6f8ab49ce31245f2c935d7c0364bc81753ed7105", "31877": "1196bb0ccdd48612d31067c6932b3ce8afb45169", "31878": "edf0fce742bf9443e38c035deffa10f6a18591bd", "31879": "50c119dce9005cb3e49c0cfb89f396aeecab94f1", "31882": "58c124feb4dffe46a73a43fbe995421ea361dfee", "31885": "ce143a2fb0a41e78c85d5311d0e159552d651b00", "31886": "b8ae9bbab3c3384ad90e6145fda13a338767ea21", "31887": "6dc589b957e494750351e8572b45b8fa12c27d01", "31888": "7ee5d600d84ab42c3e8ae0ce1c747ca1bc3b863d", "31889": "266dbd5c5efc5770f0fd1785415237ee1cb2437b", "31890": "78a5f7193cfc05640f83818cff0ee586a61ff3be", "31892": "0b1d400080508d205bcbb9050ea7e83be493fd98", "31896": "28331e0cc7aa0729968565bbd1278b3b6239c823", "31898": "c30456f9e465edb4bfc66a44eaee7a781ae0037f", "31899": "ae6dc976d334e791b3e215cf6e63a267675cccbe", "31900": "54347fe684e0f7844bf407b1fb958a5269646825", "31902": "f3b4490c3aa0f0ea55603dd139078fcbe5e7b42f", "31903": "5bcf4d532bbd40337e5fc4ad0f126266caf1e01a", "31904": "047c11d7801ffd0cf679d606293af510e34d7b92", "31908": "1b2646a7b6e728b51bce04a2263f3f3dec00938a", "31911": "8fef0185fea9d5a4da71fd92a7074f92b02df87e", "31912": "769c2422fcaf9f5888e77be9d580a755d6decb07", "31913": "cc920b4ff17d7903aa565bf57a1b2a20658fce3c", "31914": "4aaef2d507addb7ccdec3dd0e439e3e102bc6496", "31915": "191557db8e6de0772d8df987a630dc397928bcd6", "31917": "4e72340d9161c0f89c2e9d96253f75d7b7991cae", "31918": "7b89f3e41fac8d5f6dd2d898d6ed8728cae85a3a", "31919": "fe9e5d023e20304ad1bdfa1da53f3af452c72a00", "31921": "28bf7f28300adf592f24634a50f39d18342bd587", "31922": "122cd0745657687efe04cefe9471938cf0609f3a", "31923": "bed6b613bb81be208ae66fb00b992852659f345a", "31930": "9f9d80ff115d0d6fc2afd9ada83ddbb24eeeaa16", "31931": "ef32d4cf7ba8daaffdaf9a972230321963460907", "31933": "12dce19a74b7cd5badad0f61ca079b873c1b6089", "31934": "8f21b977a4b346aa92f61e40402776a2704e6f78", "31935": "94044c85326250717819bb33fb52848b1191af82", "31936": "5514aa3713b66f531f3abfc9cfe726a1dac638ff", "31937": "3e1d1752bf36b7988693d5817153a07e3a01933e", "31938": "86967da0ad0af2cc6bf4d6ea150bc98ee43950df", "31939": "6b396cf85d5cf390935e82789b09b5d197492274", "31940": "68d6b475283264f198fbe6449ea054f1350bd770", "31942": "aea824f9aa9d86bb9f25c9b3db6f7a585025fc22", "31944": "65af4ef2043a5f879dc42e009de1323fdcea225b", "31946": "f79ee8a7d7611e755b3f9fc11f4d7ae497e1a8ac", "31947": "2b2720aae01c416f8ebdbcca5a46cc938581f751", "31948": "23603171fab52bff4521888f05b68cbf520e687a", "31949": "6e853d6dd0c0cf74528fb89faf1da5bac294b629", "31950": "5e2e92ef3cf1caa56d8a1a5961f58f2dfe180d82", "31952": "4fb83b00137256e4ab0c4f2a7bd33cc2bdc5cd91", "31953": "a551f1b7b0aeace5d3c6a1c629dce5442fcee85b", "31954": "5f5a38261cd1a74898258eddd8553174f76eb748", "31957": "752fda842f90b98c6c9be8c0267a412c6a63b99e", "31958": "faa81145cd80e73a2db4965511d9ecbeb427bc70", "31960": "c01532ed75ca5cab3a8017d1a555866bbdab477d", "31961": "b99f0735bdb16d34a9acb01b1e0da70ebefdfd1d", "31964": "d5c0f57d39c27b139c765350b96e3f8e00b1aa1d", "31965": "e024cba59f8785b27596900d013086aea161ef08", "31966": "5d7b54b4d8179cd19361e187e283b873845217a8", "31967": "bbf17ea692e437cec908eae6759ffff8092fb42e", "31971": "ac648eeaf5c27ab957e8cd284eb7e49a45232f00", "31972": "b934b0e529fc245460fd81481eee97237fba9c04", "31973": "23056954673754a85fb50959b1701f0ed8111bba", "31974": "b5632fb310c26292ac37c64b6a514f50eff1d77d", "31978": "a712c5019dc0cfb58652ddcdf06361244f38ad9f", "31980": "85246fe460e93d2b891a1c116bcef3cb1a698664", "31982": "f088f6125da0ac296d64fe742cd1947b99846319", "31984": "64e042e6f988908c25a45ddf2760584618106b8d", "31985": "bf856a85a3b769821809ff456e288542af16310c", "31988": "87cfe4e38bafe7300a6003a1d18bd80f3f77c763", "31989": "2e151072345791eba2ce9982c7d67b6d5f1d8a32", "32001": "3038c6e8a1c7f8f016bafa037848fab2722d09e0", "32002": "81b5f1d390e1c57de833a56dc90afa7fd47f0b3f", "32003": "1273bc98f6af779af4779985c2faec66a3308026", "32004": "f19aeaf4976228ed936e9cc85b6f430ab72c1793", "32005": "5de24481d817339829911e61bd62170a8d0b2734", "32006": "c68a96f6994a1c4a3e684669b293b5ae37634f2c", "32008": "9ca7729118ab8c5227c8a2246a3606652bca754e", "32009": "9a607e2afa549a9295db09ad05df6572c1a85542", "32014": "7007ad8f39f1d1e8952d0b961b6c7d9f18840f27", "32015": "658b2b86f351ca5f03514ce82ea268b98f1cebc1", "32016": "3937fbe1106c5b30b9072243920a8521d36dc301", "32017": "744b846557540a86286f3bdc534a6a70639dd902", "32018": "73d15a7632e1b555defcc7942e5f629161626a4c", "32019": "e493323d93e6a3447f0adfded493b80a42f4fec4", "32020": "06e197830a625f132f54be8ef56c5358fb4d8d79", "32021": "c52ab6d8aafd49275dd325c9513f8288dbff5f5c", "32023": "e8a4ce2dd2de124fae5d51eb66d84e4c5816dc91", "32025": "fc8be37ceb05848e0fa11271606ba8ab7d58e96c", "32026": "9b5c5d169592a3921363a94ccb5de979c234d40e", "32027": "709f274245dc2f3fe2d91ad53a4cfa57f9d41d59", "32028": "71fc89cd515c3c19230fbab64e979118858b808a", "32030": "a375061d9518de447ef05b6490eeb264490a3952", "32031": "1c51e6004c09e6ccbbb8841dcb327ac0b5c9c80d", "32032": "aec51a1842c2281164e262bf0b158abab54bbf99", "32034": "6b9d0f7850f03a51a96d164e4a3e06aec2a2da39", "32035": "26d1cecbc9add6956220a4642b90b9ad8ad909bf", "32036": "36a67f6c99becaf8fd48678cd5733c54fd81c2f5", "32037": "cda0f6bee2a6520729247f92eef9f722ad2487ec", "32040": "7d852a9b15f92e57327f6e210157b67decda4fd3", "32041": "c2fade19bbf275f1fe5022f1c9ded387e52a3921", "32042": "9ad36f23a58b712c09a8a29c60b539ec50e65fcf", "32045": "2fbdd1eb4ef73a470f3db60cbf38a7d9f6c3ffe1", "32046": "04b338328d09000f428c902b71b3851bacd91038", "32047": "fc9b62aa75cf5a08174549419d2e83437cf0ed98", "32048": "12091609eb7c6a77d3921bc935f465d0c265aa34", "32049": "44a4f1619ff5031e59a970a61fac94c3745e4433", "32053": "6745e4463180e5808d87a48717728509efaff3bf", "32055": "576302378541230f63a0ad782ed8df399f488a00", "32057": "6b93a0c6687ad1362ec58715b1751912783be411", "32058": "e0608cb42e98f165fd99b595b2c9d0bfeb208b8f", "32059": "0eb6d33d7c27ea20f24744ecdae8238f650a37ad", "32060": "6c7507fb7d4b624b9710d7c6be6d4b74395c8094", "32061": "4baeede019754603c64f700821f43f35469e9a45", "32065": "3622f15b5056b8f038d3b7adeb82eecfe980beca", "32066": "e853e039f0191b1a0db6d30c7e7db826a150722a", "32067": "2dd2ee16af58ee52cabba7407073b5c7ecc8f51e", "32069": "2a6c6a2d131e49aa1b0272d5d5bef94c9810f67f", "32070": "b3552c54be2d49d52e6c0ae90db23ccb13bbfe0d", "32072": "49d4c075e015b5cec0c334554d9d980ae6bf0224", "32074": "43a54b5b9460ee4c768c1a9c792794925e6e0e37", "32077": "235d9009b571c21b353ab215e1e675b1924ae55c", "32078": "dd846e93a06740ce1ab536b92d70fdb7e0e213f0", "32079": "0e93cafb394131c64c4c4cc95c8c43967f09a0c2", "32080": "8b0ad717d1ec54dd40136817a326b41817ffcb86", "32082": "070e1fe860495e408c049155d1928f8f7b970408", "32084": "73c7dc9acb3af777aa25a9a463dec13af2b9e921", "32086": "07023aa0c3bdae40e38567789ae96a2a1727106e", "32087": "0dadc71dd4653e5b858d7b4153df1d7aded4ba46", "32088": "979c1c6d62efb01b7423a23e2a2fae5622f43b2d", "32089": "c68d053364e79df52a11425ec6dae454d37579e5", "32090": "d719840e5a2639babab3b4646b11a111547c518f", "32091": "336896907748389e2cd0d57504508475d425348e", "32092": "953921f2782062a67aa3886837fac563892d7ec6", "32093": "5c0ef1b5d84ce2619cc1a66965470c2448ae8a17", "32094": "80271b0b34dc280452367758bf7fe99ef1bda4eb", "32104": "5a9de8baca5f97811ad6579e3e569b8f385c7b08", "32105": "f1ed6def2ad4f0d347a8a877dfd5628e8bef871a", "32106": "0dfe909aa44c174aae13b1caf8fdb5b7a8997869", "32107": "5516d8fb996708d46050a8fdd8df3ac4a5b54826", "32108": "5e503b4bdb6c21a4813a210a1078bca9a251ff7b", "32112": "050b3b815604652bc445d2487f6e1fc83eaa8d1f", "32113": "9ec687ee0a00bb4022c2d7efba7d6913bd314c84", "32116": "58f3afc5dd8a071f5222fdb4a7149db64ae1caef", "32118": "1dee9344a4e9a3a00935d3b91587254b5fb0b4f0", "32119": "d76b9f2cd045ea0c6e32bedfeaea0410c569f56e", "32122": "dc796005742fcec18793415c6c81f171e7713d30", "32123": "b0237ed682fd226e6c76327e6524b54ea7ace9a3", "32124": "cfeed03306ec1e939c9dcde2cf953af666bb465b", "32125": "e43d75e7adc1bb7d5b72e5268b462be4499d0d49", "32126": "6e95d7ab11ca4d6c23d7dd0b7ca293e05d161259", "32127": "5344107b8c53d1f176717a257e4df9644364a7d5", "32128": "b116c10301cbf73f092f6784af5456d360862d48", "32129": "e6024c12f0061602b67f64adcaf8ab5cb77d5418", "32130": "fba672389b74ca4afece56040ae079a1f2b71544", "32131": "053305fbf19e57724d1b344c723190371a4fb74b", "32132": "00b5cc54e215b2cf828ae25033da79186451b9e8", "32133": "2ef8d147c51afa9dfb5d184c2407227cf9e661db", "32135": "9f9448073f49e6ae3ee3b8fbfcbe0b76d7f0b574", "32136": "39fc318920ce65cfd181b1f67595ce65abfdf199", "32137": "ca191f187d906d3c4474bcb41fa6443baa46e10d", "32138": "21ad93bd5f93ed45d06af437751406e021b66da2", "32139": "8c3c9e3bdc6e6870036428bd192c8fa92b93c295", "32140": "8bcc1ebb8babdfc95afe89219dabcaa98614caea", "32141": "ff9a1dcda9580f5b7a1480b67044e11374bf3187", "32142": "e25aa9d313dc372c70d826e3c57c65b6724190e5", "32144": "c855be85bdb08dfb8d503f9f1ce5daf6e037a59d", "32145": "d8e76517ee98f957d461309de26022acde5714d8", "32146": "98cb9a5b9341ba2b837f18e5fcac19dceb2e8e37", "32147": "bf9926519acdcc9e52845af1d10b9087d1673ba5", "32150": "0c3dd0643061a14e5576eb22174c810550e96333", "32151": "ca2d5ad6ad34ca2d3d9b82e89268b6a4f87fc68d", "32152": "855ed4ed1383fd5a571c39699404feb28d134f0b", "32153": "29f67d38c6292b7cd2994abaabd42d10ecb7d2f4", "32154": "f47d82baf2f69da84b808fa537b72c3aee5657e7", "32156": "c34da509497717308c97c4a211ad3ff9bab92d87", "32157": "814fd82beadf7155f8429c58c27425edd241922c", "32158": "32474d919eb4b048464e0250c1384d244f9909e7", "32159": "159a91754159545df743ff89fc51e83d5421993b", "32160": "b5d6ae32e5d0736cad4eb9be21330e74e3eca65f", "32161": "e4dd35fb10349f804bc51bafeec14ec3e33a10e6", "32162": "ee352b14cc5704245b7f05688edb1fc5991a8b70", "32163": "c0e6baf3e5cea44d105c0e9ebb3bafbc9fb5fd27", "32164": "c0c65371be1af0d5d5e480fdba6ae15071afe371", "32165": "3d6b36557582279a8a3bc45a49aa15c5cf44bdd9", "32167": "7f24bff9b599a822384e8640dba7481b00c61664", "32168": "295bc764b3850146f0cf041ae5867b68aee6639c", "32169": "9fb69e6359ee9b1fae0ca9d3a795574dcedfe3aa", "32170": "4ceb5d96ab8bf4721fffba5b8c02517ca02437d5", "32171": "5620f0e3dfcb4e9d612bc72ee7998188e34102c2", "32173": "77d4c3eee7c68700c3027e7e3b126b329f15d990", "32174": "ac05d29cf8cae186e96c83a03e2e80542ce2ad38", "32175": "55dc32437ea43a238975439ddb6c9dda81b33020", "32177": "5f0ac04bad108e037018ecd6577ad03091adf067", "32178": "464c10993c6ec76636a1335903f21baf8622c1e0", "32179": "712c2b197c3b3a7a68e9da3eac965525a9eb53d6", "32180": "f3f675c2f24346b547d6d01edcd9351dc1aaedad", "32181": "582377f7d8a68437e5b0af4e17743095262a9839", "32183": "fd8e3e773887c0ba9721406b3034494fff2c2567", "32184": "3f310c450d879cc4b85825e235616bf5076f0584", "32185": "cdb905a8b7e25433a3268951fc3ec68aa03914aa", "32186": "b48a73ff53a2c3414e38f5adf11f661dd7883cd1", "32187": "bfdf223133541da7e0002543e36bf71ba59af481", "32188": "bada58a00e873a66cdb3d23762ccc95216251643", "32189": "28da588f75e5ea094a2eba58b714b232b14230bb", "32190": "feea3261b2c95e8f555c8ed1eff8ac6395f16cdc", "32191": "c9fb01823bfc987581711bda8bf9625a8ed7fccf", "32192": "3ba6bccc3b13a1a5db1f4f737daccd94c685100c", "32194": "04db72145624ef8fb1405bf7dea6d9ae6bdbca9a", "32195": "8974a95ab30439a600639e94e38d219ecc7e89d3", "32196": "f2a91a0ed8c2f9198b39860c987a59cbdbcd9999", "32197": "060536de9f1e54bf6b41b7fa232cd5595eb171b5", "32198": "c6cf37af547d257eaf6a5f6e0766b1ce2112bbc4", "32199": "20bbd124170bc16f318c2040465c9b4528c242aa", "32200": "98323eec0e94ea103412a1a20a1e6b4c6fa0599b", "32201": "a97396b8e47620eab938a8e3d090535944b4fd04", "32202": "56d82a9bd654e91d14596e82e4d9c82215fa5bc8", "32203": "67d75f3715ed8bfb19edc6d99d16f39daba6e461", "32205": "834fe47d1f5488c2aae35e147a844b39413e93ff", "32206": "243a5e149b56ed197d650eef0f97887eb19c4eca", "32208": "c671f6ca3dba3f4e6f3077c00c1ff773d1ef7f45", "32210": "afbde4d71e36177c2dc3e3b24099b58481e13443", "32211": "51a869c14493c430d27d1a5d6f5ef4468bc02285", "32212": "7aa391ead0f8761219add833045f77a40a25effe", "32213": "0106c26529900bad0561efb9c9180f7f016365b0", "32215": "4b124de966496f7dfa73162cc597ac805be3a3d4", "32216": "e3d0126e8af9f0a23dd6609a23817f858825e089", "32218": "42a43e3b74665701abbbe31dc461ef38419274bf", "32219": "ac3e26fe7747da75dfcf4d5de1f41a018a3dbf72", "32220": "7751108ac5cb40e9dee257fcb88002663d7089a9", "32221": "b44520131aad12083863e483853c2aab24b6b2ac", "32222": "599f94f41f0847a478959d2b7df41df0280a980c", "32228": "a50ea1c6353b5f13c65e7dbaeee68aa7c542b49a", "32229": "7a910defc75ac8f8362bdfa5b547300a5a021b42", "32230": "a0156317ebb8d65027e6610dbb76558470b547d6", "32231": "cf0056d8f8936f7a4b930690ca10448b52516b5a", "32232": "fb19ddbf1f327d683bb4a42401cbb652cc149606", "32233": "90b4add77859d1349530fff3c8cadeef95f36f39", "32235": "6a52634efbf0d66aedd07991ef546dc9210dbc87", "32236": "4715d67eb6f7e30929f2d5c6c199c264c9e07b92", "32237": "1ef45fdf4e8b0d4349caf81da553122400bfe77c", "32238": "307c69a37b7f652450e2a3ba7578fdaa7b8d427d", "32239": "2f7dce4e6e5efcc8e4defd2edb5a0e7461469ab7", "32240": "822074bc5d4cca74cb2a26f0c476fe430e3d9400", "32241": "8608ac919fbad7fb656d6b9bc5ddf7f09ae7a430", "32243": "b07e31cfceed3df886f2674a6bb2df70bdce2dff", "32244": "7ebc3e809491cdec3ffe4dc8917ad9729f55b713", "32245": "9415ce2fa50232cb5104cd8db656bb83a218ee99", "32246": "523bf3414de1ad888669df8a53d423be719388f5", "32247": "856e1e2f3220ca51b2720592f9e233f48f3ad3e1", "32248": "e7e5df5167be28dfc00c900d24bb13c9827524d0", "32249": "0914e94584e6bd799088115797e03395994ddd1c", "32254": "f5a86fef41323a23e08f7452e7c2343f253bb19e", "32255": "48368ad6f9087e2e4e4c5236d5492a412ce9d826", "32256": "94e398730016f21ae3a6a6ea1a3d0bc6af0e7b62", "32257": "5a4339f686225ed5eadc5c4b7d2508c0765ef577", "32258": "4583a045e7123032dbf7856429ef411713a6937b", "32259": "4ba431f0b4e82319248663d9366c0fbfbd35ff1a", "32261": "a75ea75a0d4efaf273ac70b6269adbfa400d0844", "32262": "2e7f5a30abdfed4f34902ab1effee65e9fc48b4e", "32263": "91111fd99898d9dcaa6bf6bedb662db4108da6e6", "32264": "62e05f58b723d6d506574cc6752d33e494b77f61", "32265": "fbff58f5ef0450f5f5e7d2a4cdf14094d6a8f3d5", "32266": "eb2ff31a7e21efbcc1a0c6107ae45eedf56f3570", "32267": "4d41ccc2431f36a72c1701dd31be7139582baf71", "32268": "8b503a8ca06c6370fc3fbd972fc6b0a621df9531", "32269": "bbb1cdf13a1e9240b43d691aa0ec3ca1b37afee4", "32270": "75429df91ecafff0748816c414aea0a00eeb25b0", "32271": "b94f1a18d35ae516587ce9161eaaa5f9a16f505c", "32272": "145e527d717ada8d4648ac3d4b22a07d07143a31", "32273": "a17bd64a6ca0c4d71662d467536c49bde8df3d09", "32274": "a9acc52632219e09bdcd41fc6fe130da7c04e124", "32276": "91de4cca64a59f8905ed62aa5c40f428cf73e14a", "32277": "a04754e99f3203675847194304c12ee85c8cad69", "32281": "14b2b61b14b64bf3df98c5769581d92775366b79", "32282": "0ecd0ec25d77797674f1b41dee6075d6107b2a22", "32283": "c110f27decb686ae05f4ce0b5ca601ba76447531", "32284": "b4ff385bbbdaee684ee0d26b81a652aa1b2bc3de", "32285": "753ea2e53b4d3b23b8a9f43268c01132072e1c79", "32294": "8b75fda1bbfaaedae4df05acc6aef8a73443319d", "32297": "7a8d1654f04049ab20555c4fc2556c29082acd21", "32298": "61c671893219a5fea4bfa6756b065db8e66071af", "32299": "66ad6205574692ccf8189cc78d12eb2c426ba6b5", "32300": "890d09753492242bd30cc43c7ebd4e819ad89bf1", "32301": "1ceaee3333f427a97570eb87066ebba01448c770", "32302": "2be9661853f4e425e00e3a32d265fe889b242f44", "32303": "ca1b60715b69410897176ccac9e579a74c962be5", "32304": "93bd1a8ece37657e887808b1492d3715e25e8bd3", "32305": "4a2b06862c9e8aeab488098529eef69211ab00de", "32307": "0cf87d2ff2e686d24c376099cb6ef151812fc913", "32308": "84593e3749cd3411d022c065db1f2a9f2572f34e", "32315": "bb858daf707d5aa5f6371a2192c0151b9656041e", "32316": "ba5031e0131e13c6a0d34a5938c3fcc615179a5f", "32317": "0dce2853ee6395f37deb38ea532587386f294a8c", "32318": "c667fc41c1c8ab82ddc9df4a9c9735c5e748432a", "32319": "6c46013c549de053effc770faf210695f4312757", "32320": "edbac360fc97e639590fe6031aed165e7b8790af", "32321": "a19b98167ad5c68f36c1b0ef62c77cec996a5fa7", "32322": "d00928e80e7ed3fd40fec824f1c386670c51d4f0", "32323": "d0326528144600ad22e46816c54125e31559e446", "32324": "f11fac3b87335f5c80fdaaf81e4d549346225d9a", "32325": "5c51bc161db0f59dc3d02c738b7f381fd11152ca", "32326": "f8f9961527c7ea279351481cbbd8f3e068e65061", "32327": "3f4854f810b8a0ebf2c372c9e2bb7f20d7982c65", "32328": "a6e61fee393a612736b51af338cd738538694226", "32329": "886f841d0653020d418fe78dc4fd8e045e7448f1", "32330": "1294b193f0d00d53e160398803977287211ed180", "32339": "b44f1cd1a23463295b45cb6f8d5b9412e06f55fc", "32340": "57538192767547bd138020c9001a2fc6bb1ed004", "32341": "fd97a078531c8fc5c9e4fd2d5f49da5fa5ea16ad", "32342": "dbe0c10ce8d7d8682d13ca7fd46add489065ea9a", "32343": "0bd52be9f70209ec0bb5e04267ef3fdc3c955da3", "32344": "22e591f2d142b20ba294c40236954d377c7b22ed", "32345": "8427060d60d857f00c63b7de8672ae9f96e84bac", "32346": "8715d63141d093d48e67a7fecd44d8203b542331", "32347": "c368c320fcde19a6fb48a22ddaac4b7e19d41c4e", "32351": "6a1ae42bca296f8f1cf649e466dc8e11536a079f", "32352": "74c4cd1f25b81bb0e5afc70d063c785565fde7fd", "32353": "a7341b37a53f121262c07f373c4552b69673d25b", "32354": "0d95478c738afe96e78b66966edde490362ecf49", "32355": "bca35ff73f101b29106111703021fccc8781be7a", "32356": "eef20d32724e90d3a02b39798737f487913f1669", "32357": "62757c43ba506c62edeed300def524d6071dd79b", "32358": "5d9090b1a09dfae767dd41a4e8ba020cc9e07418", "32359": "c0b180014bcd6b51891057e4711b18351509ca3d", "32360": "1e5fee83f914db3775d931cbe289bcb2288531d0", "32369": "032316f631b4c29a3b1ddc266ea667dfa39aadcd", "32370": "7fddb30c82d70ef72fce6634bc26d1ab71312356", "32371": "2317bf08ed172048a66a0533645ebc1886939417", "32372": "9c9789c515f79d1a065ca6891464865d3cd16468", "32373": "2c775676b7f9facbd27fe6495599b7ef60f98c04", "32374": "201cac4c6a43496a31cb1156cad9bfea47eaeb60", "32375": "db1b45816d0871f75d90f9449757176573cbfec9", "32376": "b48735a6b025f99f4b03713e894003080df595bb", "32377": "05fb08ecca8850b71f659788183b48db9bc4e391", "32378": "bcb8346e8106be4267ec77dfc603d0d77a3fda81", "32379": "6b4fa02e10480c4ddae0714e36b7fe765fa42eac", "32380": "b74bf147f00dccda2165f0c36506ac946b2e6948", "32381": "30589f72a2c8cfbe4cd4e4d78161c18adca46212", "32382": "8564b701454c0cdd443b0a786f291e04b4f05359", "32383": "a393c98f0cc1f7985ed89229bfa107ebbc723157", "32384": "cb42e052416d0d0f33ff8ba9bdbaf8bfa383c15b", "32387": "0a5cb8f47712fec6009d0f0e3eaf5ef924b5fc57", "32388": "f1bb3b2a3ca65779baa732a86853227936b4404e", "32389": "1506ed559e14f7c8ddb24e623e27b07c97b2a197", "32390": "17e0e0642294acecef2d2909801758e1785bd701", "32391": "f9ff3796329e4bedb4a5477739f5eb8d2e40761d", "32392": "8ea52bb32a5a0956467b3532e6c2ac704c8b90e2", "32393": "ab6562a20bd894d02fb28675809698d5be0436f9", "32394": "8d615a34f2d462cb21714a0cc577849960fc83b7", "32395": "2c86d9f472f61226df429cb6f80495771aaa789d", "32396": "d97e7bed65b1389ad669f7b8d028f603e8760f2a", "32397": "7b393290f814e60a5fbecf4fce5e1ca2bd862201", "32398": "4b98e0b99ad3064463f9dc777e46d0b2f249e248", "32399": "3370c8179de16b3f0556891a1ff06131e186dfd1", "32400": "3872572512b4ea5af50618203331d9c7cc5d5fd8", "32401": "c45bc9a7b8b76324499ac52c957f3ee59c983342", "32402": "d2f376bc99cf1bad9308fbe0dcdf78df071bc55c", "32409": "278c69bca0b0480b9d33d6b9849106aad33daf3c", "32410": "cb57af0efaa87fe9198d0cf5ec3e0010140cd398", "32411": "ead5c756da231d971cde0627e88acb4b51588568", "32413": "60013a26634b581e34d967f76907de460b9adb93", "32414": "eb69d8943fdc2b551f083435a184b7899ad13548", "32415": "73483be93ffdd2d826e18e782dbed386cdb2d9c7", "32416": "46cb18c4a021f5058f9018aa9c3106cfc7914aa7", "32418": "c9fc7fc662a4f2d821f7f9abfa2cf5c1429a85f9", "32419": "eec47a1ebe57a31480125e2328b33f12be865d0b", "32420": "e6ce78dae8e1e60ed025c0700f501471378b972c", "32421": "76923d7b58d8f25329e779a40b87e2b6959f9cea", "32424": "6122c7de128fce3a84d91ef91b9dc3a914531745", "32431": "c0445543a10ae6c6abe5a3efc519fd9edcd2d276", "32433": "cb43a819d8e34f61ecb4121d154b1f9a9357eaea", "32434": "fb9b3451c4f70818604bd7afb7bbdd4c04d12667", "32435": "4e7ade7d3e50e2b04d2f9150b59cf6f2d1fefd6d", "32436": "a793802ca08ba159558e36db95f8242fb0f44156", "32449": "75d093dae92a68e6f979815ce131036055492d39", "32450": "53430f2299291ec7cd0c9b79bc68b2c9f3730598", "32451": "cdc8db6e0d3394e0aabbaf0740ab06e34bf67aa8", "32452": "e5961e2dcb9b8b84853c32ad4d1f6fb7d6f84454", "32453": "9820edc174730e11cb423d7869650c13100eb314", "32454": "6526e938a0405877e57a6bf57c36d7fc77449081", "32455": "7ccac683c074aaf5abaedd64f8aa5da4d9fe08ee", "32456": "e02133c6323ddfd886784d6a9d3a4e5c07c99557", "32457": "a215264d472e79c48433fa3a04fa492abc41e38d", "32466": "b77417832c76f0027723cad68ffd5654bbafe2a9", "32467": "aebd2293b9e80893f4bc6fbf5f870be5ae8c7ce0", "32468": "cedd1222e3b2ac60d1006bf09df4c8a4870773c5", "32469": "8188f6c1010fa80bbc15a152bc38e8d4eb50299a", "32470": "cf3043ec449137fca3619da5405590c15a87cccc", "32471": "d49eee36271ca3cd324384b7f8294e833b50ff14", "32472": "7b605f3033117826352e3770ec2bb1a25fcc418b", "32473": "f6204a57ef174d0058744dda1bfa3e6c67b5c639", "32474": "57d8d3a7cc2c4afc8746bf774b5062fa70c0f5fd", "32477": "28115430214ea6d520ab7b2d5243e86f3503c712", "32478": "586cc351b89cd299ecbf8f3ff0ab6dab1b799db0", "32479": "5a11eb5efc2390a3bcc80fb646496095c1da433d", "32480": "01b432c3537dd2fc910e682cd7c03370a67710c4", "32481": "cd38fa369d12e8390189f14fe7fcf6533998f5ce", "32484": "4d7d9217ba190c189f66c66149464dd493cd031b", "32485": "7e9ca6e8af2f97e62a69242d40159994ce1d6178", "32486": "6dc92ad0087984555f4204d2fe00384f5462837f", "32487": "081c06bfb0fc97a38ac1458d5b5154d8a9030e51", "32488": "16645fedb7d9895395488d4d90dc06bd47510057", "32489": "2a2daf787c5bf4015729f6660d189389d3d7dc47", "32490": "16baf871eebeaa604891893a395456c80293a092", "32491": "fa41c52c3dec0597a39910ade667084a16169b28", "32492": "f332143172c6345f28ea2a39f84a9bffef840ca6", "32493": "0b931173c842a3476646b627422cf943d15288f6", "32494": "a7da45d8335507f9a561a5d47e99c4b0de24b7e9", "32495": "85c2cb360741c87abbe4a2c39cb2999c929ab031", "32496": "1d8922e20b3384d56551646dfbae2f4c4e458da0", "32497": "f0d4694bf80fa9499880db34d5d3a13a8d073122", "32498": "72cb5498d7e92a28d1495365d5931d61c515f926", "32499": "ed1d1f9134185848795e78301ce6582df338e1b2", "32500": "9454e1210c57c0cb886a12913b0da349857b2564", "32507": "09b42d2afe679188d7b01ea8b65fe555f530bb87", "32508": "af4a11eb2066202bd79c1d42f96e02b0c184252a", "32509": "0aeac8ab2144f1687c2aa53caee091d78a8fb97a", "32510": "8b6b867f5a7b0a03f254516128c4055e5d234f8a", "32511": "ef23fc75b2adfffd0d82a75f6be8f87fb00a5892", "32512": "7bffe51982fbcaec4d72304ca2068428535ec418", "32513": "ca99c94ad9acaa894742f3d65eb5aea5b713c666", "32514": "bb7dd2c85dff62b7cce2262f6ba6c3ecb1013153", "32515": "67ce770ae4f7248df7384965e5b2cfdc350e3e5f", "32516": "d47e052379826ab6085e145e6ee2c654b0d1c471", "32518": "27138738a22edeaa644a3aff1a2cd98d1f954632", "32519": "25832bc479dd794c588938b5d650126f9d8d9bff", "32520": "5a36b5f5273f1c19fd0c9b6ca13d985a25316649", "32521": "4117f98592c1d1d671684c86e9a01bf48e1c2347", "32522": "d69e63d7b1e14b518a413fdff245e3329b92ceba", "32523": "e7a5c9295f5f3e81570cf2ce68c8071703cc12ef", "32524": "d56f6e2bca75f10bc490aa320c4e1bc295e367bd", "32528": "e8b43b612669e984cf9ba13abe257f068c00dc43", "32529": "7005f8c6f7683c1f022c20ae4143fbc1a37f44e2", "32530": "b8bcf50dc86a5ee2d60fc3b21b82ce9b1b919cf1", "32531": "60209e5d57b44a05044f942533e1c01c99445175", "32532": "61ba5f8ec1f5ce05a8c77a617fce3199e4f4b0ef", "32534": "8f869f3de0048d01fcf2f8198644fca72b926aa9", "32535": "b92267b2307c53b163f79239edb7c6c6e663cdf4", "32536": "b7ea7c6dfd100c40b0bc45aacf6d92c5c22f2e63", "32537": "f2f4d120307c179cd2e186ce54b7eab16d47facc", "32538": "f09d514cf0b09e65baf210a836de04e69b208cef", "32543": "f82b1c6329a1c2de20e453e6bae5fbe0beb69360", "32544": "9c059187893a6a45bf0d5430af5e4fe7f9a3ccb3", "32545": "72e923ed4d3bfd41b64dc763269f48fdf6727227", "32546": "f3c46cd0899d5e11e0602798d9390c90e51e9ba7", "32547": "f81f68720ed9d022c7f2416682d5485e609df9b6", "32549": "16a4a5fc5e20f5e4ff387a593e33df6b6b43662d", "32550": "9fefc8f7a92fe08583466c668e07585b4e421021", "32551": "6ba52161147f2543d6cd4194958b0071fec6d1dc", "32552": "e41b6d7827720df90a51ff05caa689333d7e02af", "32555": "a23eb834eca2c194d70d865e09bd2f57c51e5be8", "32556": "dbb2adc1f353d9b0835901c274cbe0d2f5a5664f", "32557": "9dbb7d747ddfb171d4c3591f24fc4b30288e4e98", "32558": "289f32df5a565848adbc0adc8949fa4066542316", "32560": "e634b345fdd8783ba86d57fa39ec699206fac66e", "32561": "f569301fef3d89d9041ba9a0375af0bb48b94beb", "32562": "6fac28d34e3fc19b97e922dc70faf81a84ad4cc0", "32563": "2f7b42dacd76f126310fc3c28d7bbba1ac4eebc2", "32564": "e7b044c558c7f763055b8ac1be359dcf787712bf", "32565": "2e55bff66d83b916152191935afcbe79a232f3f3", "32566": "9daf62f630a489a09e3f93e35c7d382271ed8fb6", "32567": "1f6e44a2354fa53b724eadb2c52ee84b02300500", "32568": "4dacf5661727a3738711f23df961abc9fa897148", "32569": "c7010a7adec1c47a4642fa068544699fc8e1ea6a", "32570": "b2b61af5c7b87bb5b0ceb31770165c9dc62a258a", "32571": "c96cd9b2a09c5a982d32d3563222402f10407fde", "32572": "97edd8e4ff89b4a3eedebd03bd718048fef339a3", "32573": "12ff4f4801cd60bf8351655abffe8a6c32f8c11f", "32574": "d3e84c5f9efccf439843138005ecee16ce532c17", "32575": "a9707295e87793b137965bb3a0707fc5701238dd", "32576": "86f182829d2cfe2f4c380d7f2ecd6ea27d6e0f1d", "32577": "7adc7d0e331bfa709b65c11f16009fe9c6f932f8", "32578": "b3db4b9844b9003fd7a8b5cf88c9fb82c1a8480d", "32579": "c60135c0749ada8508e315f1c04795d9c01a47dc", "32581": "6228771852092baa0ea05bb0c70f58aaed72afe4", "32582": "e3b0d4d74b1311f6a40ce1ae13c42cc7619178ab", "32584": "bf676a25e7d1170c467dfc2d0266ee08439e5364", "32590": "0a58c03f5dfe643a9ef7ad54bead679a82d2e63b", "32591": "ec5b62eff3d10e813d89750aca5e1778b86f11f2", "32592": "18aca9c0783035360893e8e8852cea04727981c1", "32593": "c04bba47d09f56101932d673db53a7ae37086132", "32594": "f6d3cb292e50e77e7cb624ea33167f943c5a2481", "32598": "96b57806a3779cb63287db5f0e4116020854092e", "32599": "25f89683495979828ec1407e5b5421c492407818", "32600": "b1f1f37e0fc78e80e9392929703cc6f527f3c308", "32601": "4a5d77f03bad3502a6504b03922807165881c630", "32602": "d2630d85d31d35f6d646c1ca10585631263c7d26", "32608": "cca262d35b881d327e26782da699c1fe405c1c24", "32609": "3d8cb79823bbf62a50245e9daccfa1e87c9396dd", "32610": "04c33d3b17e68602c77be0007df0665592a41151", "32611": "68e2c2ae8b714bc9bcbdf9e98793bb681048273a", "32612": "8020bf1b25ef50ae22f8c799df6982804a2bd543", "32613": "6b575b4644bd1808808ce0270413c6e75ff7427c", "32614": "c37dfc164ad880b89113326874a0578e81113b6c", "32615": "a45dcfd59bb33a4a506c55b899f15be1fe2ae752", "32616": "12aca3c80c10438e70f7b9a4eb254b54c77ee745", "32617": "fdb917f52b7063aa0488410b32cc5878fd395558", "32619": "4f3c3810003cf4c4e3700288adb24114ea99a77a", "32620": "a99c1ad4e53713322660c30733952fc9ef16dd2f", "32621": "d4e3963239a36fdba21825b37add4294771b0268", "32622": "b01cc53e82dcfb5022630c74f1581b0e2330f906", "32623": "606499dd4b054d107e3fadd0ab504d5b77898876", "32624": "42bb8fe60999db433d8f9e1d37117cd2011d291b", "32627": "cbade64f8dc66785aae75269a695c6132f0c37a0", "32629": "e660f2cf774c78d0d16b4af153b502a8abe49992", "32630": "a3c58cb275c017d0323a6fafd41f6449a43fcc57", "32631": "8f8b5b3b3f64bffc0a1096026cd45d3d79ae6668", "32632": "be79267e9b290221cb0adb6653f36c2ddef86327", "32634": "8dab54d6573f7186ff0c3b6364d5e4dd635ff3e7", "32636": "450f051a7934c908b7cef972a06a4a9f67b06317", "32637": "9ee33259e470bf32e58c5de1d771100cd54420a1", "32638": "025fbd05a1ae8973d5669bc1a3afac0b6bac602a", "32641": "6a5eb136c736b00a95535c97ee655d3596f9ac87", "32642": "7d7c818de14149d4b11f6a8448a3444ee521d2f7", "32643": "5e1b4b718d2a5eabf71d6371925e42d0f197e58f", "32644": "3e7cd5ea7ea5f26be0e4d88313b3cf812f7c8a35", "32645": "a6d3e13b3a3c0d2b902c6229a7261bc299f36a03", "32646": "22de537361af45a6b769eef8f3391f682b055110", "32647": "556848ef3ab29be24c7a4e493d7b8bd52646cd7c", "32648": "17c4e13a1548afdef3fef4bf459e43277573ae66", "32649": "9f687cbc2f696a652ee5362e18a4c61e57335ff0", "32650": "9691bbac886003ab8a4bc593e38ef0f2b9fadc4a", "32657": "d8cfbd2667d370423f32893cebdf4f998d300d0f", "32658": "b6736b449f3062cf05c224ad738c03cef62e248e", "32659": "c7460e5e8b679d38d7965b35e2ff7dd34adb3ee9", "32660": "beab917b99616d157b4bbd24b7a83f7432c9dc26", "32661": "a94e85213e286befec583555c039d556f22a0faa", "32668": "253daaa1a67918f5d71956282a29a14adf74bae7", "32669": "0a4440d90ee13b3afa294aa7585da1233648bf04", "32670": "3fffb6d49abe20ebc4a3380181f90103fb9ce22e", "32671": "005486fa6c2f065e25df3c244a2bd53abe80ffb3", "32672": "50a866708417dcba2226fb1d11d545727c167441", "32673": "f74f864ac00f24c5cec406d0802435c3aa2932ed", "32674": "d95bf9a04f10590fff41e75de94c321a8743af72", "32675": "8f479824974e3bdc980c721ee5a2bf5b89333b43", "32676": "b7708f00c7b61990521e9a0e03680ed45b59086b", "32677": "22363469b10f132e4cd5452bcfb15a51cb4a9461", "32678": "c6bbda551eaa04d555fbe34ff1c27628b9df1e1c", "32679": "70121c75a0e2a42e31746b6c205c7bb9e4b9b930", "32681": "0168e27843efb96b56202f22fbe5dd720c346368", "32682": "182ba5aa55dc842f8ff73a124e0ecf140fba053d", "32685": "0429b648709de4af526c8a65313b60a8f7419f1d", "32686": "3b09765bc9b141349a2f73edd15aaf4f436928bd", "32687": "adaffe9a9e39f3fd34f0a9bff3fb71487065e85e", "32688": "17c247fbd44520ce5231830a3df09726532edd34", "32689": "3c72d6f1c0b85313aba0902fbadbc735fe01623d", "32690": "0b47d85d016b6533f19285d81d03b2c8f8e10a75", "32691": "16b4e53ea8c6673a077205bc111cd123a65747d5", "32692": "9fe5ea45301e01c69792ecc8a02bd6115a9a4921", "32693": "61e0db25f5982063ba7bab062074d55d5e549586", "32694": "15e6abd81afdcca4a117686c9bf84d6a3b487b18", "32695": "094b2c0a183a96411b7ee2bc26a98e6d82c8cbb9", "32697": "b97316231ad9c1cfbedb671aa37ccd0f5fce50cd", "32698": "494025c2dfb933e6acd11b883891d016ec0633c0", "32699": "56f3aaaccbd941cc56db304a607c15a4b7a4e937", "32700": "3c4b9b945ff06c4aae54a994e2e320a0da3eb708", "32701": "0d2c579c51a8289c660070f80a635ccab15db7a5", "32707": "8b227f39cecc170ab2a14eaa1d6e349ba59528bf", "32708": "14dc069f09634054d2db95681fab96f5b9b30f18", "32709": "a0c3eef599dea71311bd00f709511ff5d4933dc1", "32710": "d52b6b334677aad76334b5246ce26728156c0d70", "32711": "82d271fef81be7063f47ad3f7f128499b0f23f3b", "32712": "c77aad21b8fd4126880fbce9f6a5125b03fc8a0a", "32714": "a7ac7d6a559e6b100484b8ac534c00a3b65b7979", "32715": "dc5e00d91dd515e7aeff1b84967afa0b4d39adca", "32717": "32b4222050c7d5eedfa8fa47d5a45fb1d6c966a5", "32718": "48e7b6ed41eb94a7792ebda8fa7999a8813948ae", "32719": "5422716d04959200b815621a4c100ac657c22f31", "32720": "c3a257c17a1f3558811016c76de1e4cd69f71cb2", "32721": "c872a8bf2392b7d74a1f3c7b57ca8f3219ee23f0", "32722": "7374a0dfec7c0eeeb4c7f54ebd49e3dfdd46d559", "32723": "c09ac01901854994a29c4aba755092cb31f2244a", "32724": "4d0a4365870893e232f639af13fea44c7d3ff9d4", "32725": "13f758c9678d062a404b4aa2210e224b27d9ebac", "32726": "41db57210c1be8f456912ee67c32d6f1b7084a0a", "32727": "284758d5108833852ba656cd1da53071e9356aed", "32728": "4d9145fed2c0d34c2dcc07fe6e7a400435e32ac7", "32729": "d1d8b666abdb03700703a39d6f9b48c5638d4d62", "32730": "e35c0c4d9522f114b2c495b3fecc738367b16434", "32731": "f26d2254ff53461ab919582e75f3f686a94e98e6", "32732": "163b003d400095afc340d7cb811a16de7c256622", "32733": "c65e3d25ff05b922a270117af99989601f655a10", "32734": "2804681c45b5f748d0977e3998bbfc91d4653b10", "32735": "d6918c10736b8c353ca2edddee83bf8a5111ca52", "32736": "176621a320fc858a5d8864115c5ca00fb7d284a1", "32737": "fc91090b824959833cf36fbe51ac7dbef6b22982", "32738": "e5fb655a74c828eb1bef026a54ba9be85de1f3e6", "32739": "2e3ffa60959480e773a6d654742c7a83aece9e15", "32740": "7f47d336b0a6689a9d333e332be7b9663a25f29f", "32742": "9e6bbdebb6f4f4f8da6e635508a15276bea5792e", "32743": "7e5a95cda77d2665d5bec2f4154bf72f041ac36b", "32744": "3d0d197cec32ed5ce30d28b922f329510c03f153", "32745": "5241bd05c229688404c8c23da32f242b5988e4f9", "32746": "3377a6d33d813e3817df0786117eaa08d5dcbf96", "32754": "90757dc6d1672ec9799e664c2094e42073e80eca", "32755": "0bcbdf954feadd7a9d010682d25a34a7a9d44958", "32756": "474a528ea3bcec82830661b7a41503c94fc8b5df", "32757": "ffd8b00e1b9d50d1ab0e4cbfa426da5c5a3b00ca", "32758": "de6a5cc21e59e61733be1b7f8ae7d3d4e15374f2", "32759": "13b6b59604a29dca616bbb7ec45777a0e75ccc4b", "32760": "a85a386b780856842dd81155f7ea066df5ccca6d", "32761": "f05d217066c02049caaf5c14e8859e9668c0286e", "32762": "470fee6f3e869b22bb9ee0a3661efd94dc262fa9", "32763": "5b85b433a9a21302a873c67e9ccb9be728700e50", "32764": "d88e0fb39830e321060111c6534d378ea1d259d2", "32765": "1d5ce5b3b42cebd4b49ef3b06b50b78e09b1d91b", "32766": "74f1e94a3882eb3fc73541875f3e04c37dd5e59e", "32767": "8da8743729118139910b9eeb27e27a1ceceb2c4f", "32768": "4c5db2e435d13c5ca91f98d07edde18a498ae6dd", "32769": "e7ed4cae8897de627c93703daf6a852831731bfc", "32770": "0cebd7508e252aa4aef7be7590537dc3e20a0282", "32771": "2411042dbc085845eeef27f0d3be6db36a356692", "32772": "0ca49fcf1e5d6a870f99624272a7e9332ea27593", "32773": "b2df890b65bc29ad387ebc61e45fbdcb2365e560", "32774": "6b0ac938279d2baec210641bfaf3719872f9a187", "32775": "22d9ffca7fe429554da2b42b170c616b29fcb400", "32776": "f7fad771eb1598b7ad43c1170a91178f49d0a93d", "32777": "dba2080af7647145ce82669c9d67cf2408b2a48a", "32778": "1c71d7db926f4247798a7182f85aba1124fa894f", "32779": "7d2337a34828e3ed645498d0ea37ca9ceb3fa31a", "32780": "1b23a7d779fd18b362c021d9ba58231908150438", "32781": "2d185e1d545157e08def82b202a1e8da67efc5ef", "32782": "d6608313e211be0a44608252a3a31cf5220963f4", "32785": "1fd894d734d2cc466918eba5b2a06837fbd8139d", "32786": "5206bb52c3d0daff00dde93e360920ad02995998", "32787": "7c208c8907f5ab18f807366c0c5e26ae1dbca299", "32788": "078c024981803aa1595349bd602d551f58cadcef", "32789": "bc987e708b9856f5d5c8cf3096e1e2bcf23e1121", "32790": "7c0278e533b8cf19a8b6bd367bcb26a06d08ab9e", "32791": "afca9f844d982b75778fa498e1c3f2feae742a6a", "32792": "e93ee07729afe0bc7661655755df6adad657c23b", "32793": "2d5d2def27fc34bc77d2a3d01de33bda67aaf92c", "32794": "3af7170292e579413b84424448fc98bd13dffd09", "32795": "8d1be809bdaf84e25ff4b66524197a20e54006bd", "32796": "56931c49bdfb22725f42a2323a0a4d4f71faf840", "32797": "03a981ae61e685bb6c35234a6fb78a68373af0c6", "32798": "0ad74d70d5a46bb548ec51ed551d9388ad9c40df", "32799": "e0b111b1d46f550d9c4272bf143dd2ea20a1ecf0", "32800": "e61e58ec7168e4ff8f8d091848ca651cad7ce8c8", "32801": "3ece807d6d85663cb0f9811ccabb8426f506bb5d", "32805": "0119bdc57c41a71ae3cdd5fc47f384e504c19208", "32807": "7d79cc6a8096579e0aef2918ec1889ebd5288022", "32808": "4eb4729fb47bd160a39ec49f6af89dabfc63d3ac", "32809": "14991df5ab3e5eca83adfd8f3fe6eae9a2ca888c", "32810": "49014106977c6425040a3c6ebd4817a925567191", "32811": "b9980b66b86489f0df88e09a93529d98e6371135", "32812": "a047fb6c101f6805de81d25c0062933987c7e832", "32813": "c35eca35d6070ea508a115ef1008ab40f33ed727", "32815": "cab77e3d6c122bc11e13dcbd700cbbfbdba31fa4", "32816": "eedcb5fb46730750140ba8bd10d765e8dbdfb44c", "32817": "5fad2e4e90be46c14e947ac1a7eba3275c4b656d", "32818": "f5323ab05eb7d75b1f2d4f4fa7f36bcc27693427", "32820": "e38daf0b6fe170772cf6518fec666e2872eb32eb", "32821": "5fe95c60c7b1db349a92e36b23816cfd4f2cc515", "32822": "eb2351205c9d63ffc82753df59881b9138349869", "32823": "ba74fee9be5317665379e6a56a5cb645c6061a86", "32824": "de4525b1845e85d21a670f7a1ff8abffb8ff85ba", "32825": "68537e354c0f44197c90535dfc076459e8bfa772", "32826": "a0ee90a22eac704d043ece58f551861c0bdbc071", "32827": "7ef6a71c5c41eadf9ebea514f4be502e83c95a6f", "32828": "16b9c98bfedcfae031df5d570ef68a2d126826b7", "32829": "7b2dd3892c1046ad5fa6354ddfab5a73927ba4c6", "32830": "e3143f6119c4745472d8291f72fc06121e72c699", "32832": "63e50d5f5db00e0018651b4f6b834046a04379b0", "32833": "49f93ed45a6390789551c96d5dc11e63b5ef7e43", "32834": "d27f47b718bf198cc7d322a36c0df8253b5d42dc", "32835": "5ee4dace4334f98147abcb42b5218e6d8f45f7f8", "32841": "18be7579e272f9219633824aea93fb3233825a33", "32842": "e476938e22d80ae924d3bc525cbc7e0e54a2e862", "32843": "43bff73ceca04702a0069c077162a05ed0774995", "32844": "1f836f16b15adc0838afe634df5bda3977b3ad10", "32845": "627d1b6ec79bd5dbd0f65e13df8e9d284b775a6c", "32848": "1d5f05c33c613508727ee7b971ad56723d474446", "32849": "65987973b4299004aa794f84ef187a1b6b58aec1", "32850": "bce995817caf00ab5e82cb4cf1b540f1530cf4ea", "32851": "d05040824e6ab4e1611590a38172880a45dbd92f", "32854": "749d59db6e5935f4b3ddf371e79dacc00fcad1c0", "32856": "e0b93cce7161cb31e6a24b0cffdd2dfbb952e0f2", "32857": "018967465f2b8994041b8e220118078682c08e63", "32858": "113bdb37694e2849a15c390fddd8f28986bf1863", "32859": "e17a7f8612f7f1e1eb180486afdb63fcef517041", "32860": "7b0d4dd2da6a5565e7fffdeec3a58750640c7f2f", "32861": "3029dc74e6dcd65d235f1aeebe0b4c0ef356f4b9", "32862": "bf5ee72d5b81962db91fa12f637b4369d3e30f77", "32863": "a5cbd1e52e9078637c899167f40a29b4bc8901b9", "32864": "00fa270c055383ffc07ce0c8c67f545389075129", "32865": "4846169970f2d184f4376faec2f66b6768e59028", "32867": "a8c2000b6a631017ac411b13fe13c7fd6a56215e", "32868": "f759c33d1bc95f8820cbdb3d3fbab4a8b438e931", "32869": "16405f6584137e69a52dfa98b901f1afb194e52a", "32872": "79b131e775271c79349b7bc412aab21cef6eca12", "32873": "14881577a2bd874ee45dde7230cf334b69f9026e", "32875": "026a83e06447b749385beddd3d03abe97d48e8f5", "32876": "e0cb0b31d666a60823f0b63d88c92399cccbe3f4", "32877": "70eef55e438823697515e834ee4ac350bdb0aaa7", "32878": "060eaac1b6d275fdbb02404ecb0635f0bd9d1377", "32879": "0986922d5cde3eb7c7664cbf37a9d1d2c75fa3f0", "32880": "e1dd15b41e02ec78ca61379dad74a99f5ec16aa0", "32881": "e413b91d601217238d7e3e701f2e92a4c5d215db", "32882": "22491dc041315d40e525b722a92202f656639957", "32883": "2f993c2e8ca76e723f59195edcac9f7476c3a8d8", "32884": "1613f26ff0ec75e30828996fd9ec3f9dd5119ca6", "32885": "12624716f85e7f12c64567ff259bfe632a42e7fc", "32886": "d3e5e058efe8d614fba4c1a8029aaa904e2731f4", "32893": "5f3c29e3e9caac70d6c3c2914b8b8038dcb4c52b", "32894": "cbf80c28916279b756a769aef1b4ac28ba2d8260", "32895": "075947f0a29459d2df04bf08314909390d5031f1", "32896": "8117a55618ade79272fc91edfdfdaed4d460b08e", "32897": "3da778cb04a2f62461f103c1669ff02f430f9171", "32898": "d0dbd9f7210a3c674018a3f4539cf5b5ac134c55", "32899": "cac2e8785f119369c89497647eb0e077ef12854b", "32900": "d80002440df612865e237d47794ff2ddc89081d9", "32901": "3c55eee968e702b340eb3220c132b4b821132c72", "32902": "083d030d473260456dabd7d4fd924830e557d97a", "32903": "608f49a1c7a6999366be459ae954a2ef605ea9f3", "32904": "2fbea3fe245cd2df0ec5758c92906cf5be43a382", "32911": "bf05f35d16afe2bfb8f82cb257ee9a982b95fee1", "32912": "d20c02b3fca0956174b6b1dd0e3a2d24cc700a65", "32913": "6cbd87b38b1d069fb83d3e094866a8192b5cdb63", "32914": "5237be554ac5b4618e22a9dbc48e136395607d13", "32915": "ca3e0c875fe0dd862afa88b905e8aa4a44815231", "32916": "f31da23cac7b06cfa81b0ba27ae103af7bc9da00", "32917": "b002462fb52356da5b493ef6fdf7b36598f7252b", "32918": "738564e6eb0f974a3bdb579e0fb644f909918581", "32919": "ca0434994ea944f81417e304203ca9fc494fd2a5", "32920": "8469f746de31aa40b409c143b3d542f09e2378a0", "32921": "50f19b6ed5f335d2396825ad5ec055f2607a39fa", "32922": "c49733c274cd7007231b77f0765209aaa02c624b", "32923": "280fbf6dd472b868e3849e81998db6f266b96514", "32925": "4bd55a40e082d311e4fcaa97a203c9348ba8df3a", "32926": "4e4be0bfa8f74b9d453aa4163d95660c04ffea0c", "32927": "bf7960d004d2e517d1183a790bab3911792b1ed4", "32928": "fabdd5d26de7adf05da5fdf874d2fa20f2250e94", "32929": "1ce4455424898eb08719295205faacb2f0d9a4b1", "32930": "be2a09e37ab74942378b8297a1ea5c7d6d78e3f3", "32931": "49ceb1b1066a3474684052aff229f7c7931a56e5", "32932": "cc478c4c815a85912c3fa8f4ec400f8b261b97e0", "32933": "7bc699fbb8dd94177d723dd637d7e99fe0eea65a", "32935": "9993ec4059f15758c72bf943ccbc63edfb709f90", "32941": "2e1206e112f126c7c8508cba44b5b7975e24ca91", "32942": "1b653b1c23f7a5f9fbaede993cf9370dba79b1fc", "32943": "9918c84043a340cc0a62625273c842c05f3d71b1", "32944": "4878dfe551da2fa8e2bc33e774b595f099bfa74e", "32945": "0971f55d27680245865eecb4f5d6270fdc45b130", "32946": "c54ce8e9d53433ed7513aa281f19ed4bcb79158f", "32947": "eff6566cdcc99b41234e0577ab92b779348695ac", "32948": "35a7f807ac9f02128333c1b5df0f03c897d13445", "32949": "38b4e966548980fdcd63dfa657bb5a2a0ca40e9f", "32958": "b233faa4d1a538466d122c720524973d417d3ec0", "32959": "029e098431628e409ec565dbcc809652e39dad26", "32960": "b0305f7b8b58c36450ed4b4c285dcf8743c93f42", "32961": "3bc2203b05ffbf3d18e912ce818f94bbf7820474", "32962": "483a4f58b48afdeebe0ed099e0c425d7b0f8cb52", "32963": "dd8b721adda09e09599b66181582417564ae9607", "32964": "5a9142ea2ceb223708999c88b2bc54338a5b8f62", "32965": "b6eecb392c803914a4f25bf08fe2824726945af4", "32966": "4e88c3f0389a1a7ecff8bfd23615c84ed92db951", "32967": "dd8b7186fd0647783e36795cfdcf7709f6029e65", "32973": "fa613b3268f7b6ed6ec2d833f4e96ffe2e8659f1", "32974": "032d112779bfe63af46df7a97e0927eb9f0e7583", "32975": "8d30b6eff4954aa0a8a7d31b275a02c0ef11ff7b", "32976": "2e224c7e57870196e47fc8656713834f3d8afa41", "32977": "af9b72af8816bcb5604b7a6371b2c4039a4de5db", "32978": "ddde1dd2e42b059754ca4686271e9345cfd4e870", "32979": "23c36765d9a884c815d1eef0d6d351d816853ffc", "32980": "17583b37013b21f65107796fb8fc592426f12bf3", "32981": "797f23efcf9c5eeeed06749493aa0a5c5baf5514", "32982": "2899f46f87a1dc254f331e6d6d5138a2a195703a", "32983": "0720b035a8eb947ea442debd2579f2431a2e869e", "32984": "502919e4b18e5d5aca584d4ebb84d663fcefffc9", "32985": "acd2f5f889df788be7c308bff7db282d71c80b3a", "32986": "42b0b7acde4fb34c813d5430dd396dc9fc8a3620", "32987": "d859ecc1b0e386a66a5e0650609a9e3154fa474c", "32988": "a28cadbeb6f21da6c768b84473b3415e6efb3115", "32989": "98efdc8ae551f44f35c497bb643afc1f1db4b40c", "32990": "5718de1a3e9555da03f4a0949c232233ce370318", "32991": "184e16741b8d7b4d67b579a5366c69df8fb2e52d", "32992": "99859e4e3d2d367cb58e9bfbd61731abeaaac790", "32993": "b29db1b5f81ce85e9b9c95e970e75729e62b308f", "32994": "c4a84ab20b5699302e6bfc6854a894a30383ee98", "32995": "f82bc3edcb5d110d92c07106be4b5ac5f45176c4", "32996": "32a261a39d83d8fcf72b09b9b46343e8baa980a4", "32997": "29e287b648027c974b9e5c741913befa3c58c947", "32998": "50973022cce562d1c2c5d80e75d27909d2ea6092", "32999": "179dc14af16c1738df262b1886cf9fb63cb2b849", "33007": "41ab44a4555eb6786dbfb5f6f813807979f53e77", "33008": "2c272e239c9fdaf6d3c59e141961a17cd310cc89", "33009": "d555c1d83b3ff1459e17d6940b594a5f1bbce8c3", "33010": "14c8336379a1c9c40d7538f98e2d31fedb3a2cd9", "33011": "3ea04c383bec5aa82a1f2c57c6d4da81ebd74755", "33012": "548444b3a472eca3b181c5c5b2692d50d96048af", "33013": "02d22f34af090615d382e8609e059a4e88c67408", "33014": "0a4ba64212bf440f37515b242e5746fea943c62d", "33015": "2da7128e3436db520b96ccb07e56811a4bfcc72f", "33016": "45bd6372f24edccf68c2a5d05224295e805bde80", "33025": "8912f96ff397abb359081f1f94b90bdfaef6536a", "33026": "7c4b98e7940a1d31bbdbd0011ab3ec027090abb1", "33027": "30587136e9e6563572eb87fdb9979aaf1310c15d", "33028": "209de2803c5d772a4b297ac696aa85f67582448a", "33030": "18bc585ae6eb6918911243b9486bb2c1a9dec570", "33031": "e16569a0041759e5bbb142636d3cc158dadd761f", "33032": "dab080e9ecc393ab2911440958f26133fe77959c", "33033": "f816fb97ee3b105a1e88a20f799a9128abe7d766", "33035": "3a0db109390ddf9ab331cc86e63449c7445aa8a7", "33036": "3b26841feb584e7d42d95b0b00b20362fd68ca2c", "33037": "1d73a567265c01e2acda0825f995f65bb2ed919e", "33038": "a82f90526c6304ee400323984f89a5a01bd3f412", "33039": "60dc3f544178e83660796133302cecbd8da28b91", "33040": "222e37ddc7cb3ac683666d11a1a1d0e74fbcc402", "33041": "5483590436972268faad830a70fbc46f7d19a053", "33042": "92e458d8037057b73724d10badfe3afd4580a262", "33043": "399a0ba9477a83dd89cdd2de9fbe183a42b2e4cc", "33044": "0ffeb2b5fb20d7b8f8ace55932170801dcbb7d6e", "33045": "fa78ea801392f4f0d37ea7ddbbfe44e9c8c102bd", "33047": "857bf379ce964dc9494e2fecd3468800fd7c295a", "33048": "18c43651b0497b5e93fd02e4f0bf6d254a25c316", "33049": "07822fa3788470d2fe23af301d0db8fbd74fc03e", "33055": "4520f84c9865bc75a63937594fe536cf46368d2b", "33056": "47c9ee7b32d8bde2ff8cf50288a8787b11d512cb", "33057": "37ff082139a0dc67f5cc91b519834db8d54df56b", "33058": "2ef976c4c8dc17fce889e2dc3847ae0b65a0b4a6", "33059": "53c14257926e230ea3bbd885db43a732d715f86c", "33061": "db4d3b09f68bc26704b8294c49ea05a8a6f72796", "33062": "76c39d547c42644f8ce42801d696334cd3e199a2", "33063": "01cbaeaff4eae2ce75477e6d249f6290082025ec", "33064": "1e4e624ea3ed8e6ac97c937a96e451063b412845", "33065": "18865cfa99c37408fb90bf2523d075b007a5dc2b", "33066": "f4136c041594721bd15c729cd1f95315aaee336c", "33067": "296cbda251ce71edd2ccc464b943f69f5c39193c", "33068": "059b2c182eae3d8ea994b388a39ce780e4a345b9", "33069": "f47a8b83ec10c906429bde6d198f563a869ed7ee", "33070": "b513776c20e5de892088e6d7b2c27f90abf9479a", "33071": "e7e3676f97ba443a5be3076b2b412de5c9b31b1a", "33072": "c2b2a49b6c9d7bbb8cef3609a1bdbe01cc183416", "33073": "5b1f72a046c14bf70d324c2f1a1c5dcbdc2aede9", "33082": "65baa5b1451078ee46344d7424fadf1968082809", "33083": "27e74676a6b10378e6b812da3f1a7b0ab6e5f7df", "33084": "d7714cdb15136e6dafda46f33029dc25dac5991f", "33085": "ef0eaa45a999d1ec0e1af0db66998e215f87a2dd", "33086": "5115f0964a47c116e3899156ec6ccfd02c58960e", "33087": "bad377488059aeb898bdf71dad88eb6010caadff", "33088": "59f7baffd4da90f748eed2afda6f816ece16c09b", "33089": "1d634743215b3eba4f15d458267b8f0ba4571e47", "33090": "939d0baa6a59c484b16214bb5e9c6451537accd3", "33091": "5535def388d3e82aa07977a37cd25d6343909e51", "33092": "05e93590e372454dc8ba9d7e198d845b3d93684f", "33093": "db8af0e767cb66a7b747984feec380822012cce9", "33094": "1bcf42e3547982cf04d6d5da0b3d8050f81d1f0c", "33095": "32b33085bf6eb278ac385cf7009140bd6012a51e", "33096": "6da42f3776bfbef245ff04028706f3be82329614", "33097": "9d8e7048affb31aa33bfe6f09b626b3045ee0d33", "33098": "4f42ecbd0569f645a881f15527709e2069c6672d", "33099": "d00b945e10c9edb6658b2f9cc3cc5ca0a0d74ae1", "33100": "aa789eaabe61a8f633cd852db208f503031e4028", "33101": "2797b84836051c6c366d98d1b3cc8acea6f0c7b8", "33102": "710b83bf29c90b0952e442d04c52a9fc1a4bc7fc", "33103": "279138cbc179b287b76d25082805dd47ee55eeb0", "33104": "7cb7592523380133f552e258f272a5694e37957a", "33105": "eddb6f459a6b32112f614a9118659ef763b50db1", "33106": "dc295d625e66e30917ad3f8fcecdc5d2f1602d8f", "33107": "dc7f851135a7200673f879facd3f3a05b3bf9117", "33110": "fdd71632615d1db02fb606667e90b632470fb4dc", "33113": "d67fad54f9656bc902a0838482529c7518dc18fe", "33114": "35ce27a914285a3bb059f245a73375a751cb8ac5", "33116": "bb18847e70cfc07fe0ea0908dd6eda6f18431187", "33123": "5e95673d6f958732132c305e1ed6a6d3918ae439", "33124": "2d6d744f9702b94a616890edc1543ac9bd246e49", "33125": "e27bded18aa8c84832b1cb977531cf0df2df9368", "33126": "8b96ef2b88f68b912c60563b588a01d7ab58c8f5", "33127": "d3995f76d4d366d44f3c29b9db8f33f23254dec6", "33128": "9991d5eb99d93a9d03368490379447ea6156a4c9", "33129": "829ae73243e44221d0b05415cdf45ea9e81a7261", "33130": "62521dac4f5aee007037f424198c525deb27743a", "33131": "954cf55938c50e34ddeced408d04bd04651eb96a", "33137": "627bc4044e21e093dd6245c83af2dcb5cd7f3c3f", "33139": "f15a65cf385c435b2d55daef80bfffda08f1036f", "33140": "01141ab8f3a1d74382890b53cfc2a00259055259", "33141": "7afbdf17f79ab2b4fa20461a0141a7ae3a76408b", "33143": "b37589ad7e33e326823486f6e97bb4971086393d", "33149": "99d367a6a03226a9cc9862b786a4987d255efa83", "33150": "2c994c7b67aa6a5c82df652e2f397f174381b100", "33151": "b173e7ba86aa0066b8ea8bb9c583d39e4284f1b3", "33152": "a38a24e69fd614cdab024f88e6f56bfaa5cb4e80", "33153": "384a603b14735d7673c88c16c77371f181e460e0", "33155": "9116f32d50a89560b064af278c5f96aa31468a19", "33156": "fd2c2315ee1798876f1685e250ea46b3421e9d4d", "33158": "5b6d6eba9ec372baa8c0755b59f72cfb9d4db873", "33159": "575dc38fd816228b391ab4b8a1f4eeebd14ee867", "33160": "d3f0e9a95d220cd349fbc2d9b107ebebc5d7b58a", "33161": "9e8a243c5b77429b662030cc0128a076eea192c8", "33162": "cb83712635b56aa061c4d9a8f3bfd8cd23716529", "33163": "a0071f9c9674b8ae24bbcaad95a9ba70dcdcd423", "33164": "316c8ba41209b460bfd4928a68b2a6c00fb065c2", "33165": "afb7635198b0f6a5516baae3fec2d9181f58f8e2", "33166": "cc1a8062b4e999500b020a2ceb57fe47b1588fa1", "33173": "35586f3b761d59421251e00ffc966516b27ffa0e", "33174": "3ff71e469ce796053311034680274f7314c4ef40", "33175": "89a76f6e9ebcb756cf232bf237ac23e295b19fb0", "33176": "9e5a62f56924e4a24ebffa4d78d2191aaafe5edb", "33177": "579e07093e95f01b454146b3cf9de18bdfb15635", "33178": "b0c0d8a8237f4109d2a97ee2a9719e6b8bcb619a", "33179": "c426dc0d8a6952f7d4689eaa6a5294aceae66e1e", "33180": "9012a9f49cf34b234babb3d166bc4a8fd4f8da62", "33181": "4a794851c3fa8fd8e0edc022c6a14b396937172b", "33183": "86cb9500419da51d4853b00cbe8bfcf1a29855d8", "33184": "affcdf95584ae4da7d605c5a1bcbefba5bb68739", "33185": "8d296f21f1fcee8e8b6438a2162cf0e84abbaa95", "33186": "f63e7b82177e8455d77e23359f3927a01b6ae76b", "33187": "06d074fba8b4690bd0233e81d2cc08acadb6dd36", "33189": "7f8baa0f0eecbbeb3d45b086665286ac406887cc", "33190": "0e0a4472c4403a4049ae345abbe7c7552096b7c5", "33191": "d72e244db5c77833caeebe5f8b38ffea867b1a95", "33193": "fe9810101cee7012a9e4451eae3ae6cd697ea46f", "33194": "9349e61f236d3cc94e05429930ecdd76872b6365", "33199": "96fc51f5ec678394373e2c779ccff37ddb966e75", "33200": "3f0af5e9f5970f723cd81bde47bf2a7ead0b8c80", "33202": "9bf60aa71651accb21850f392fe8ada37a7b2f67", "33203": "afdf0a3e409d02cdfff6c813f512717f1503a4d8", "33204": "a1babdc2f55f804692d6cacf15eb98bef33687d1", "33226": "ac3c010ad76ecdb7e0393116942655cec5e253e7", "33227": "9097263ad5b670dfc79f913d1520a451382aa1e2", "33228": "a063af0e6d443c4b5826eed2102a6d3c988da9a0", "33229": "305c938fabc0d66947b387ce6b8c4f365129bf87", "33230": "254660434b4bc90baa51b09a8e3bd7ce7524ee91", "33231": "2e218d10984e9919f0296931d92ea851c6a6faf5", "33232": "268bccd19d0d6e8d7448cd890b68cf6510246047", "33234": "d58bf120b9cf4149ab8b379ebc7db286115094b2", "33235": "cda7ba411efc5e123dd8381c3d30db4efa426de3", "33236": "0e484edf8ebc50a55f027f4c022815eb8ea28b5e", "33239": "4d0cc6f4a38092c1345f37a2bee732858b2ac982", "33240": "5e4ea2e1cc7adbc064577021e0a6c556a303d5aa", "33241": "ca41a7584545dceeb397d189423ca367d9d305e5", "33242": "0569760e09ea7da36e03b59a4f58f7cf18b5ae98", "33243": "05d12b5eb9ef3ef0ef697dac92e3548371b6dcd1", "33244": "1f1f645fa9216e59c542e3eea21b9073bef4f581", "33245": "3fa869ef9090281b7c6b595355a6795cc366876f", "33246": "86ae81c50e78119d10145d091ade0d1c2c83c141", "33247": "99f98de8af6addf10510b9933f60379988b19cb7", "33255": "da2b086a5f206414bc1ffeb95b70e52d253e8704", "33256": "f69efb6fb7d0ef2f181006ad19ae7de83b9e95d4", "33257": "6ecb52e5332a85fd5d7411486d6ffb8104ab3f90", "33258": "69a8150ee703485363f90ff9fb4a8f47e3ad1a57", "33259": "185c53f50e93e3326cee11fa5ae1e4cfe551f1a6", "33260": "d1b7244e8793c0eb10a5c6b88a2e2ef95739130c", "33261": "56c1b20eccf7cd7ad8b1d286dc08ee0577773646", "33262": "ce9e3d658d6efa3600a4563ca7a00e7a15b80272", "33263": "77afbccc0fe3ce6504898bb88fa418a3aec07a27", "33264": "e5021de3b22f89346c380ec18026fa10473be5f4", "33265": "1c17d94376523887d1113d001fa758d77b7d6eb2", "33266": "ef6c35cd571b833354824f5342ce1a899a3496cc", "33267": "e7f6a841c653f46bb46e72f7df26f14ac36b10e1", "33272": "76561d1c481c24bd31720f320ce75bd66a4eb82a", "33273": "448a023c9182318af8da29a652026defaccc9ef4", "33274": "08a7a9e249094f9f246c03180841210e447c26c4", "33275": "5120720687887687fd33506ca29a0d95d4eff3e3", "33276": "626b65101c875ae8462954c5a46cf43877057787", "33277": "3886ff75e194630ebf3f6bf4092f3648b7c33a9d", "33278": "be260f1482c4695d79725a99c490f3e0a1dae0d1", "33279": "1951b5117b22174abbc944b2e6efc41fe34f0a63", "33280": "5752494fc608bbf28b32a7c5c5a490120542a300", "33281": "73840ef221050af2588b079bd6ba45c8e291bcba", "33282": "2df4522a4ffa0ed62ff26a0b9cf656c9ea5cc317", "33283": "cf536db5b0cc3b7cfe07f5b9c58ccc3c3fd1dec2", "33284": "6d6917daae652ad7a92888f077c2de5a0244a164", "33285": "bf1d0082a3240845f76e697872634c80c8ca6a92", "33286": "859e4eb3e7158750b078dda7bb050bc9342e8821", "33287": "33f4f7b57b46bb295c1b71f3890377a5e541122e", "33288": "d50c3cc7fe728b79d49a82db7d9aec06e0163b41", "33289": "7f2aa8f46a4a36937b1be8ec2498c4ff2dd4cf34", "33290": "74b13fa8996f796cc487ebb12ef97e826386dd4d", "33291": "a82b8e2073ba3a3bdbfaa3c54c46375d6dd09977", "33292": "dba96f97abc96712946067efb63a587e47786caf", "33293": "fd9a9ea7b242093314384d134135ebdd721b5daf", "33294": "8448d39f25413d4d1246356d3843f6920c9aba56", "33295": "b39c78b54c193766c4fe7e7d3b265ed73f54d13e", "33298": "16801a1f4b836e2fbf49d623fe565457a3e375b3", "33299": "7aee076e47f3bc23ad9c1f771b88f7f592a76a75", "33300": "588a74931f7440da00f90a5576b13ed1ec7bf866", "33301": "1269a3ba3567772eab2271b660c064114ddbab18", "33302": "fdba1e67480779f976120f6c66d6f242232f4e6e", "33303": "a5042766a8c56a8d8d803e9654bb67dc6852389e", "33304": "7454934d40affa2f420e3c55c67996594d71df82", "33305": "ee03ed1d216830edf2e0154661097deebe2ed085", "33306": "14eaa428fe77a576dd6368d6d8a4546d11b064fe", "33307": "4ce3757a0295638990a452b11164a8ab46e6a1ea", "33308": "01693d64fe7b4335c327d62c5a5861f07c98f8c9", "33309": "57c6533d4d54326c7719a792aa9118dfc1079555", "33310": "2ddd338c03f9322a163285b6c5d5a3d65017a8da", "33311": "f4d1cd55632287e8d03497ad428fdbe9bfeef5a2", "33312": "22de62caf6780ae420685668857bed11408930d5", "33313": "2096725de083f1997c7e03aaad145be6d03418b2", "33314": "7674874ed3255098f47539c1cd6afddac4f107ac", "33315": "6dcec6ae7f88734cc951c39995f5b1f4319949f5", "33316": "73dfbf45b4f7b1063c7861b468a0210f6d9cd320", "33317": "b3cb116ad409588cbe867349eb915ec0c4380e3a", "33318": "852518eb293897d14c7a89afe4f14dbe0e30c160", "33322": "77e97d2608e533a5b397d2bba4935dfcccf8e540", "33323": "d6afc862a7e2e0f742ccd99a96198b2768091284", "33324": "ae1d9c91a77624515d8c4e4d3531fa0d014cdbf4", "33325": "0d43f683615e0e8eeb98ee5cff92494deb323f90", "33331": "8983b55e1bc5c482809af92308af841dff3459c0", "33332": "8aad1e7a4d5efd4254417cbf628ac9b6ab12927e", "33333": "fd0e2f1147f0e09b061e6d853386c0e3ef009d8e", "33334": "66de372df0b3693e1bc46ad2df58be3d06a5872c", "33335": "e4df678be8286f33fae7fae9a0145135412d6bbd", "33336": "d0221cb4449801dfc31108e019f668661dc56072", "33337": "cc6c9570aa2774038c6247455875186c3765d18a", "33339": "c73736cead833ae265d99c467978708dcc0ae5d7", "33340": "87f069a2f850dab81a4dab648f1d6fe3556df4f9", "33341": "541d0928fe0c785c774d0faef1cd5e6a41e4d5b2", "33346": "39f72da76f0ec5270c06043d0ab957e5f7495615", "33347": "07c3186a601d4b367eb3a5aa4a4b8d1abf446e10", "33348": "40331562064b0e83a0754337669926d002d647eb", "33349": "1d58928c799d7d36a767f01e860d310596b7faa9", "33350": "0d9fdd41ba9149c479fc3dc644fbd0070036cafc", "33351": "3770ddabc99f4edddea12c275dd316790b6a2a92", "33352": "d3f3d5d09011ef23b5c953b451d45223119a18c1", "33353": "01241481d590d2a22ec3e81ec98f5fd60a5269cd", "33355": "a3fbfe3629eeff0d10d12f86237e3738cfb3b190", "33356": "936da9e99731157025f1ed3ba5c2f103c5115600", "33357": "961314dc73382fe5d62e6d55310940971dbd0a3f", "33358": "dbe5927dff43e36a7117712a20dfcfbcb2cd0ea1", "33359": "bec92a43feb0057f06f4f9b9db26c1a09232b1c0", "33367": "337faf309eea63a92b0e662694b0a4d7f48121be", "33368": "3b941193d4dc6e2b6574ef3bcb4a0644756cd1bd", "33369": "80ecde4bfcb90a3fe5245319a0823ccf05a33358", "33370": "6478e70fa3297e6d923405061d85945cbda4809e", "33371": "10c51ba02014d4caefa8dc2d2ed2874759693b14", "33372": "f3015e39439920d3d00a328714c06b6805f7f32b", "33378": "37c9523888e3eec7a0d8a30d6c0bae03072fd2cc", "33379": "dbed1316d10ee699ad6d5c8205a3f4e0b1377e5d", "33380": "785691e474f7b5fc6b2a5f228f3c7b645e879232", "33381": "1acdf4b3bee6d3ad034ffb993968381d2c104f3d", "33382": "755a99b258ee885f1dadd4b6424d4d386e3519ca", "33383": "9277f93d37f207fe50d8318686fc59f637922fdd", "33384": "ac5bc67efca155a1c373dd3c61f64d0a3be37430", "33385": "f06c96a93fb2e21c9f801192d9ed5896c5ce3535", "33386": "fa7639e6757ebd7585c3123c84a7cc5a062e2742", "33387": "b65551c2d79cad75c50237d48bd39ee37a0d72b5", "33388": "8cb638273d7bb9097f4762129e1a5e117dedd59c", "33390": "5645847c042de58d6ea4f4c2fe0e28457f0e1ab0", "33391": "50d288e5804621212399a11fb461812695efee6c", "33392": "92e2379d6296e3e3c57a45b356fabec33d2beb7a", "33393": "1539aed5a47cb6f99065dcb7652f16534f3bd14b", "33394": "edad0368032bd7ba75cf1ad00d8edd0bef51da66", "33397": "385a6679d40a359ac93e9c81aef467bc561c1aef", "33398": "dc1c97c761b382f5b06d6bf40fe89e001d7ade1a", "33399": "d9b56b2142e96144ff0356dee67e2edd0866393d", "33400": "c75f5af033df07762888da522e26c6709571dd88", "33401": "0cedcbf6ec769fbc6075c3be1bed9087d85e2dec", "33402": "6d6cccc52da31284683364dbd4f5fcaed126b27b", "33403": "605d446135b2fdfd0ce68222720989a588af45da", "33404": "5c745bd7affd98b0e1418209bc1c38a337bedd2c", "33405": "ca9878e59f61dfbe402c138bd391c41765cd4b2d", "33406": "b161fa7eb4ef0f179546f6b623509b4f39d17ca6", "33407": "8deae52ff633a3e9f89e5543bd8585aa7bab5026", "33408": "1a48cd94d8f5abcb269237f952bf6a8e4262cd07", "33409": "30cb546447a0a132d2dbcedfdf2b41eefd00d1cf", "33410": "76025a637ddab18867a47c6487f287e588e1792e", "33411": "aebcfdf923d8eeb83e1932c5cc9b775ec0d09295", "33412": "808e56eb2a60685ba167bb2c523e8f844652f46b", "33413": "82ccccd50fa4030f2358e9c9c8a998ad14b87bdc", "33414": "b2a26ecc538cbd04ef256b6e0de78aac700ec286", "33415": "eec200dbc8d3986f00c54a4b0b99541dfcefd5e8", "33418": "af84a085b492533f286c486447c53b9739e27808", "33419": "15e258a8b5011adc3f71cf094768e3320977276c", "33420": "c64cc46a4cdec1b9827be07e2447f820fb9f61e8", "33421": "ad03e49f0cdd5b233eb0a17f705a072ab5f3888a", "33422": "9bd15db77343c90c8d7524af8fecc4f244e1db68", "33423": "1efc2d7464cc8f951b82106031acbe51f6febf69", "33424": "5b6c5d182b1cde1421040a7e2f2fe6e329f156f9", "33425": "8478cf63888d6571a2d27fc8c9dc9cf744d767a0", "33426": "d8a1a0d329205d825582a56eaad87c8702f99c87", "33427": "7f2f465fae88a005f2cb9c91e2b38ce54675ea90", "33428": "11d856f52689998bf8c5427e2f9168452a44f8e9", "33429": "61f09368580205a476f2cd46cf38afde503e4780", "33430": "44c30ac2be26cb86cb7750ccbe21c2c663c59b09", "33431": "6a83d3c943ea7cb5deb4caa572356b16cb6dcc15", "33432": "fcb8b809e91e7df47f3c20c457e9f6cb58c2f067", "33433": "5d17d73be969a7d004a7e1035afbf811a8fbf18a", "33434": "0d842ea2836a6f507bf54bc60f858a2a5c98c18c", "33435": "7e88122a2a829bc982b6471948c21cd1096ed980", "33442": "1bb128edb058815b66da327d4a9f28f3678c0d3f", "33443": "326de11f2bbdb98e0c0becd620af22e6db57d483", "33444": "99ebe28fd2e1cf5fc2fcae929bf88a835e1228ae", "33445": "bd4ece526b30fb30109de4d2f015df2aaed681e4", "33446": "fae47ff19afd4326549fe8c973f18b6c05f92efa", "33448": "409673359972653a2fde437cb2a608a66c5753d1", "33449": "48c99f21f86dd230191c819ddf0468c662406c58", "33450": "2a6d7b73aca3cf1922db59c0bc97def33f083c05", "33451": "b37321c7e02afba37bbef855a9096abe8771f569", "33452": "03088a973d0b5f15fbf41c53c32fdf0eb6320ca2", "33453": "d0fbeb49cb486bd06bca959649ea497f504c90e6", "33454": "13db83ad3f1245107151e6a626537a8ea7f72df1", "33455": "0e8331f85cde8db2841aad92054d8e896e88fcef", "33471": "3e8c3b04a1406652180edfdc291566820c8a75a6", "33472": "4510c6f16a2c70916079ed194b81617f71b9fe9f", "33473": "9bbb1c0cfd5e34b34e66faf847ace4b9dc4f773a", "33474": "c95b9e2019d69c9dcc87ac8dced879a2b97a37c5", "33475": "8661548d12fa6809e89e5771e87562867a5ad3a9", "33476": "ead9ced1ebd7a064bd99a2c6ec157caa0d06bd47", "33477": "f07e98b7e50ca9ecd8ac1a5782289d18825891b2", "33478": "4a168d0d0f8e2971fefbdaa11706df3fdb122699", "33479": "6f58d863056263ec6fad2be3effb931655364759", "33480": "35d76e95d4536e538dd8b950f45e073c8c1f56ef", "33481": "94f9412c85e27976debadf47c20265315abee125", "33482": "7bdf69f45f6ee6fae3d137ea2ab5651082c83c25", "33490": "fe0cc489d54dc089c9032ba002259c606ef43ae7", "33491": "180d81ff85732057e407426faf05020044e23ed6", "33492": "cf2d8f92576e546cc2fb894008503933b7ea0d99", "33493": "783a68e70530c6150acaa0dd396f472ba12733a6", "33494": "02a60884669fe46d0a39eb790c0528d5e20f19d0", "33497": "68305c132c61aca6a12eac7d1c0ba1ed2ed7010c", "33498": "ddceb8eeff8e6c81cef99876d1aef9a91de6b2ce", "33499": "d744bdb670c04bcf21c76e196c21d1fd4b6933e3", "33500": "14fc3ded86b875648b25ce924de0501ec6f924a0", "33501": "341b57984e6a376ba4a869e774e8cb71a49dd12c", "33504": "7986bc2385f9ae94b837123a97bc2e520a15a1e6", "33505": "3ea8389ff6f5e684f02f93881dc02848f1e86c26", "33506": "4b65e2f8ddc1a53c27b3d662bed2ad30ab8f7a42", "33507": "4bf16d2cd72872bf8a29460b8a57f00708d700a9", "33508": "031e9bbc3a9db4ab78be8b477b15d7173a1f625e", "33509": "c4caed6be59fa8f54f13ea7e963107404ad99da4", "33510": "9764f3dbf0173892aba5da4b122851ded43c09bc", "33511": "8cb1f22e5e54cb66f9a85fe7ea06dc3d20d8b2bb", "33512": "2a659f848a87bf077ce73be476e7471d957103c5", "33522": "aee3455b9ca94c5e507ee3c2078fce34f2759f30", "33523": "c7fa61113b4cf09581e8f31f6053f2e64b83a9fc", "33524": "89b510c36f3917d22b95e77315af3c7b6dd43147", "33525": "081167d5922642bf4a1a4d5de3f59e9e4a2da741", "33526": "f3d4113052e3d09f3a2cf288a9f1dcd17ab113a1", "33527": "d1095bcd5a43528e195e2d587e6a8691d5ed005f", "33528": "107c64f340c582cc8547f180555c85438da42e43", "33529": "28780a853971f84509d55d4f4fabf622c9efbdb8", "33530": "7d545f0849b8502974d119684bef744382cb55be", "33531": "ac9a768378d87d052462e137d22050f823a556e9", "33532": "985e89a1b507f91069cdea7a951e734a980cdc78", "33533": "c03ac846b091ef47a96dd04e55b5e98b605591eb", "33534": "8d1b7fc84a1766a44b524b84eb56838c9f77ff0c", "33535": "b196a09de231248b315a1ac2c76281c4c6e0b43d", "33536": "fe85cbfb20f3f360ebba62905b93a6f98bf655c1", "33537": "74d5c1950088c2dc0d7cefea382566ea42128765", "33538": "dd30415b6e569b66051d41172f86cce79244f519", "33539": "e9f90a25c67cddd74f3a53716cfd5e06a0264357", "33540": "0e12bfcd4b4d4e6f5ebe6cc6f99c0a5836df4478", "33542": "0788266d98b3eb467d197c761fa4026dc51f48ba", "33543": "6db4c479d719a400ef39bc59adc831c4f5425ad7", "33544": "fbefd525fff8576af17ef55fbf9ea637cff46f7d", "33545": "6e27efc650058b9d22d487af38278a56e648b8c8", "33546": "019731296e8b322cef68d3d33466ff859f6a6d42", "33552": "cefc6f85e34b14109075111196c511857d4e0eac", "33553": "047acde15fb96c9c543abdf921f05b38e93632ee", "33554": "0fb84aeece9119abf28043a5f3d5b82adea7db69", "33555": "07667f3210a5e4c2c61ea876b32b51e321a677ed", "33556": "0796d9d40d3d4f618081996718a35638f6dd8c3c", "33567": "dba9ddd65b3b3bc30e9081ee2ad93533e23d14f2", "33568": "a108ffae3eaa9d748da993ba37356836a6a0974a", "33569": "31d414124da03cc2f04f4050605ee299b9160ec8", "33570": "6057d7a93e6bb792508339dcf8e70998e7e78e1a", "33571": "7598f71993f442c6420456e1e2c3c8d3bc65c80b", "33572": "f15e31fed31fd64f2c07db6eee065c9b58647de3", "33573": "95a087dd11f5d3194afdb7b25d1ce613b4cffb41", "33574": "a131266c8ab7c83f73331b5be5ea49d9a628f075", "33575": "89bafd26c8f178e6364221710444fb53cbc5989a", "33576": "78cf4d7ffea814ac124bc2fa60485e4409fe96fe", "33577": "56dc87752a54a4f43766d0236684f3222ed202a8", "33578": "6e29dbfd291e5731e68226c3aca1604ce802f9e0", "33579": "a162c40de298f099b41bacb6ac953b71ffb143f0", "33580": "4965c51ef63dd06bcf460165a10bffa688142c46", "33581": "bab4f3051b886272e4bcc28f20664f2baa33fc3d", "33582": "41d937d44c156416881bedb79567600bf31344cd", "33583": "2070bb8daa1d3395f10d5e4748eea30fd8b98b35", "33584": "3fd020c5a7a343deb93a35cd4761a24a7c245354", "33585": "1beec6227711aaf35063787bd8ab7bc96f332a66", "33586": "b836a88f81c575e86a67b47208b1b5a1067b6b40", "33587": "0127d067d85fd30109f9bcaf10c0b1dc9ff3da9a", "33588": "450a1f04b7707ceb983a331768933861c09b3223", "33589": "6b4547671e4659c0856c61bc82c6ea203bbe2cc8", "33590": "592e34fe105afd3bc83c33faf9877e627e59d23c", "33591": "367d2a8627998eb54071f76fad9269f24f01b58a", "33592": "9a7bfe60f1d90804a5d706dab9cb374c1ba65ce5", "33593": "d35646f04b4f4b68b472180b555c665aa28addd0", "33594": "8159be6d2d1ad339aede34678e533920237a179f", "33595": "c133327c00553f966b09025f3846cb1cbec9f72c", "33596": "8275e8840d2fc302848a349b865d19041234567d", "33597": "3b295c9b4891cd995f40b2bf9856b960e957f73f", "33598": "1a2e300170efc08cb509a0b4ff6248f8d55ae777", "33599": "09c6351374ca45ab621f448d0d7d160f0becbd76", "33600": "cbad73ac9d68ca2595bb98e1979892545c7b2c11", "33601": "7f022b3aabda4c7e33335879c4ce8f6730f170d5", "33602": "8ae81738373e4fdb7db54de328c64a01f589d68c", "33603": "9a71cdbd7fdf994deee0b67c2bdccca3c65c6cf8", "33604": "8d2a4e11d136af439de92ef1a970a1ae0edde4dc", "33607": "18dc37d1642a9d0e2c0c02a0e60af1eb098acce3", "33608": "18ef7f1bf00db88d7e2d0f52d7a85e53c31f74b0", "33609": "c82ff3f796b03a3a37e716348ffb7f92c7d12ab4", "33610": "d2dc56ffabd8a669f9d81a91babe3898b84563b4", "33611": "a41fccd2213357688551d7e76cc8c0c24e2c78e7", "33620": "87fd0b5fe115dd14c572e03ba6fd732f9de67973", "33621": "2deba1994b56960b3f2dd8042cb8d40357913ebc", "33622": "dc947a459b094ccd087557db355cfde5ed97b454", "33623": "ec210cc4e26dc39d22fe7597c234f77051397738", "33624": "3e2ec509a85607b37d799c323d6fe3c7e543cf69", "33625": "3f3102b55458959481f4337e699ccd3b90460544", "33626": "a1c6a221790175197d2ffb81f82d364577c946f7", "33627": "fada873232ecb274f86c703770e41866084ae536", "33628": "2cf879d16844cda95cb5751cea78ad020688b80f", "33629": "1b5370a9dc901eeff25f3025c85927912a919ca0", "33630": "4f11580a4e63f1a3fcc99c4d558fffd012729bf9", "33640": "3f2b18aed1468d3643bf638f7859cacf3141c8f4", "33645": "ddae6946de41f000347a978877d653e749d028d6", "33646": "bf29272d6102a3f54657a79a9353165b83beb711", "33648": "b11e0db6089e9f8fca93ef3c1a6e2bdb41dc5882", "33649": "f26bf2726638a524d20a6416904e3fd83091d849", "33650": "d08d4510db5e79b8e65b35174a3bc3a968bb9189", "33653": "dff66e37fcad8f956618966a8153f4278d155f52", "33654": "65bca652cffaac5058dd216e6f905f7dc7cdfc0d", "33656": "fb80674bda32d6f1536057816f6bb3a95bc3cc97", "33657": "887d2c495d88ec403bb9ec4b6c04b44d09ec06e6", "33658": "c9017d95a0f9c5d2508f9015ca8922ab10216b6d", "33666": "c29567beb00fd4f2eb8662576cb971758a3ee194", "33667": "b070d87f118709f7493dfd065a17ed506c93b59a", "33668": "6d2b46d7a62f58a0428bf89f65615db4126f40a4", "33670": "f1acf8b0d6ef186670765fa1b5838e894cbe3dce", "33671": "b69bd0755d654c0dba42042df7b2251918274327", "33673": "f2a41faf9b58bf5f25e07dd3e4d88a1fb58711e9", "33674": "920c025c41be6ee8e1d0e0df7b47c1b10d2eee1a", "33675": "129108fe6cd114fd8a78f2bbe0c24c16f9d55277", "33676": "c239f54fdbab9a2bfc3c91c93a6662cb87e488a6", "33680": "ddb19e28b5370de52719fb6e235e823ff4c8bc9e", "33681": "8974ce628276b5af3f295ba1f701fab3d2406649", "33682": "2a3420a6a33ea32fc1b5efd4a281879caf95fc01", "33686": "e3c2a5e9f813f56ce1ff1f5f35d37ffe21e9d854", "33687": "21b019f275b08d7d5a9cdf8fe040ace91b38c09a", "33689": "efe896c0813a9edce9bb42eeb516c378527f6405", "33690": "f94386498f45de70d743a08ebcc334a3ef7c198d", "33693": "e057427f643f5904b9c2a245fb2d2c90ddce3798", "33694": "37d903f14562f01f25d5d2ba7024340b3936d5f8", "33695": "4088e8a718bcbafb82d9217726e37e71d762b45b", "33696": "a80ffdb19988d175f3e54a9c6e472e4ff6b8cbc0", "33697": "b99e2961e1aa89f80dbc9561d8ed47afbe4bc822", "33701": "4700a6101e6338fec437ed1222b9f827b4f66cd5", "33702": "89f6a1296531d446ac2d2a511968821e0925c347", "33703": "d05c0b92e3a2d7ec41300cd2afac4dff820bba15", "33704": "5de7c76ca9c34dd92461aa7b04fa07b980d9149e", "33706": "0dd39010869c7494006d434866eaff1c6693da88", "33708": "2baaaa60d698cb9fb63ef73f8387a04032b6da43", "33709": "9203f9e90a5548275769b17f85b1fa06ec69e011", "33710": "113036005dfaa4cb3ecc43d110a94eb06955b5bc", "33712": "444bb0dd6fd9360af7de5bb7b8d9146682f1dc67", "33713": "66c53fd0ec0d21b4d02bf35bcd7288d5a8a91e77", "33715": "44e07b25ec419d4de20de00edc54346f81d70011", "33717": "13f38245252382b4a1a5f25ebe9dd27c9fff43fb", "33718": "5dd6efc209f5a47aadc9813def6bb29695a14653", "33721": "29140d44f9e96197fc5c74f460e6b9d87f731ea9", "33722": "1ccad128b412b168224ce2e8d534578d5b6dd0d6", "33723": "ac70f230995aa1bbee97b5db7bfdc28e5c5ed14b", "33724": "aeafdd66e4f224f7dee84c40b211595c582c4509", "33726": "ced983358b06576af1a73c3e936171cc6dc98a6d", "33727": "7e410c166d298ba61d4e33af55968f6f7d25a005", "33728": "132fca0af1d56d4f41b6dbd04a31fd30e116f9e4", "33729": "b02728c19f2ef2cf44258ecc3a77371e70edcd4d", "33730": "3b632d97a1dd2717ed6c4552468e36fdd0bb12ef", "33731": "4179a4409239ceebb42987d245711b5bdc3c0521", "33732": "6bb8f73e75bb5d25ca752f34f54705cdc533da54", "33734": "4d18871d398248c5876035f5aa139292e6a05279", "33735": "cb04202de30f11730fac45f5206df1bf0ace2d28", "33738": "530e460ab67a949dfeb9789cc0ddb74374f71572", "33739": "d89f1622b06ef8f79687e7e1c18337e0ffc820ce", "33740": "02adb3dca764e0a3ec7a70f2455cb6165ba8a6bd", "33741": "ce3260110f8f5e17c604e7e1a67ed7f8fb07f5fc", "33742": "f298507b153a166bdd2a919274e039c45e740c5d", "33743": "f33b3c641b33c51017e2c5694bb5e54650d1caba", "33746": "1151e3b2dd6b2ce849360d5138c75fcf150ec290", "33747": "a344dc904bb3a3918dde1677e210cd970ef66c3a", "33748": "b056c63b2fee3418c872f7144128af8c4087f588", "33749": "d3854657e1c9842b8264b6cc90488ccfed0cd6a2", "33751": "b1dcfd5ce55c65ca08322dbb3a0dc1c39bfafe16", "33752": "005e0eb256fc524949a9e0cd24642e66e549eec8", "33754": "e1a42f36549510fc6b43c66ab40753b104a7767e", "33755": "a3ce35a8a01eec84885465030c8f8b64527b68a0", "33756": "56508fb9a5df3ab9d04057e25be959a00927d357", "33757": "455ffb2a8de132700e86fb6a3577613536003ed3", "33758": "d9ba285ac159d4113f1990ecfd13eeb2dda0ad29", "33759": "7f53afc69ceaabc47b1224e7c0fdd93dfb3faa7d", "33760": "19259187d5f1c381142cb3ab6215e63b7189dbee", "33762": "b39efd9364be19615fd39bfa80150eb6c04ed758", "33763": "3d47fb960892eac1b081fff1772d62131410c405", "33764": "02ab370845c3f41a2164f1e91bb7b0f6878ba667", "33765": "ff187c0ffe9088ae633787da32ea2b9bacae8fed", "33766": "b3913977ee03dbd19be92ec8adbc27a6ba237ee5", "33767": "4af57562b7d96cabd2383acfd80d8b083c7944f3", "33769": "c71645fff865c29e77bb81bd9510dba97d93a67c", "33771": "64da538b21d1c429f1dea585f5551951c10c5d99", "33772": "3b94ec55bfb5fb646855e60150bc044b96af4d66", "33773": "4ab1c76a4a28aca442410da173f91c42caa7c915", "33774": "dfd5d66b9131420b38ce37fef41d61f5f783fecc", "33775": "bb71ac8b9149ecc197581cb827215d6eac02f5fd", "33778": "db11fc0e1874ef7bca23a24fba11bd973113090c", "33779": "b1c6622bcfc0093ee1490d581dad724c431e1ea2", "33780": "75c1b9630aa089f66f24723a5b95a0d388773d6b", "33781": "852aa751fd4f2516a116e5d383dee357bac29d6a", "33782": "fa0187066bf8de71ad43055f59c71c0aff4f7f96", "33783": "d07931f183cdd9836c265222bf420320f9a940c5", "33784": "056edfaa6a4317280d9e10bb72e738ba5049ac37", "33785": "178e504c90ef2cfb6e2dccf5b409c3787e0a3bbe", "33786": "edf1ba13383e2dc296ee18f26206c5484e3ac3e3", "33787": "f9be5d90a6bb72f2d11f47046f483efbcd5a787e", "33788": "7b855c1b07ea05f599a8afb287a24f0cde499d91", "33789": "27f7365e3ea3d8827b7ccd210f2f9a39aa3cf601", "33791": "376f77da131bb45147ea67009b65ffbad59e4945", "33793": "4d102331d0b06d9e11c370da285867d4a1f993fd", "33794": "f7df8bf781b85649792052e778d5a76672011ffe", "33795": "948392b750cb0e557f2a2f2db8422327c48643b2", "33796": "aaa1b90df52295566fd171dd53c040365b8ab9e8", "33797": "161f7622cbf41075fcb1dd9d671359d74c7b05cb", "33798": "add6a4bde394ce5d777589f998a79c9b3a97dc99", "33799": "9312ddee46a04568ef607f28552e4fb557c3670e", "33800": "3e0c1dab6bcbe95ea1349f144e6f4bc606471ae0", "33801": "a07cb65459f24446e82354854ff6658f29414c0a", "33810": "ff9c8f4a56c243d4d7c101ed9d9d1da322eb5c59", "33811": "7389f03a5b274cca087221990b4bdbc4eafb2b9d", "33812": "bdbdab1d6c84b5ecd2f638b79491f652b57782f5", "33813": "6d6dc1a8b4f645e131799e9361541c2ce10e4564", "33816": "c7070353ed51ae7a66e5cdf67cc5400bf2f4f554", "33817": "f7f0df109f84ec70a61718b285b73a7527e65c91", "33818": "7ffb960f6d5a0e7a906ca7436e9136f1f59dd070", "33820": "f4f2d89724a07cff13b82cf4e477538b3b889ce1", "33821": "dd3914045aac8b2c603033367bad6754081d2a5a", "33822": "b3d18af7d7ae2c454b9dcef0f2c0c2ae89bea047", "33823": "a53cf8d479a72b4d0036116ec1df5b3394c75207", "33824": "acf3395aaafbc15ce461f6667f0b1d63bf3766d1", "33826": "5b9f980880776923d65d910935f10c2f4a7e42a3", "33828": "5d04432f2896ee3beeed73feb544e9c9c7086820", "33829": "c293caf2e94ca50d8036d43324d05b516392eb16", "33830": "eb7f903e2fe1cf4890e2407ddd3791d9ee9dae87", "33831": "9de579e3cfe28bcf2b1debfb8290e200c74d76e2", "33832": "78947dd9fb06da2a3945209ec661ca825a746cdf", "33833": "af43bfcddbd761ed8b7329cc1951c7cd4f9e61ca", "33835": "4a4e32dda39ebeb8f6c73dd3618a804ac8f37298", "33837": "d42757a0f95b02fd611802286e28936706b95c09", "33838": "83858b23ce172782a38d4408767615e560cb7a3c", "33841": "e9ea582ccc0c31088921a019770745be05e65d8d", "33842": "251b512ff7eeed4a34ff436c53b139229df8976c", "33843": "52c653b437db67815203872de6179b1f7adeb148", "33844": "3f48f28bde59f3a32977272e335e2d1dab1a9695", "33845": "4d74fbdfbdb8523ed4d73209d8c4c3753da8eb2f", "33846": "dee2bac09767f82531b02994ac29d854173c89e7", "33847": "2c996a620d8af05e84abc36ef1087303abba9ce7", "33848": "6169cba72dbe8c7e9c7f17ab38af15a256f083da", "33849": "b7a6133380cf6d60ba3b799cc6d724584be3b208", "33851": "ecc6ead06b54a6d5ac448f899f6c3136ef766ce9", "33853": "a7b9c5600f43609b29a21f6f2b75c43a0f347872", "33854": "bfa7e9fda1fdf87e60b198c4975ef4a30b2dc02f", "33855": "7888cf47e509bc61871c599ee1b636c0f98c9076", "33856": "ab76540ada429ffb6f10785f1623c47a997b5763", "33857": "26b17c21bf595a7a6f3d692bfcb25e2ece6c6671", "33868": "e316f5d8656cdb3c9f746468e6354a5c8408392d", "33869": "7c84082d54866c83f169683c2fd1712fed7fdfae", "33871": "c9b560c35d1a6f90ab1e9bb97aeaa85bfdfc64b7", "33872": "73dfc3009e13d86acc46509b65e6dffdfcac120a", "33873": "506fe537d7468b5fb853d6e06bfa0d22b84bd02d", "33884": "5053b563e638398b6593531a67ec91cc44f3b969", "33885": "693fb71ac4b9f68da332b94ce234929dd2a5d5e1", "33886": "3135c6206750c2e4dac0afa5a997d50f364e45aa", "33887": "3161e3f3ff76d707ece5a19ba6077db8716eedbd", "33888": "fb754d71db2897b40dd603e880a15e028f64f750", "33889": "0359f1706ebe69df627b58f95c4ae2cee0b5acaf", "33890": "8487b2e25b9d48bf3c204c133b4eec2b7bc392b8", "33891": "c8ea34c6e00b886b11ab961ad1e9d57773d0f23f", "33892": "f8a37a76c5d8f22cc9937e08c0c9555e75f819a4", "33900": "a5a3300276277ab7b2d6f0b7ef456364097d1301", "33901": "d1c43dc96673e02bd6e47e3b1a2730aff9dd9133", "33902": "e9a2eb8e12609bbc9b8b741eaccefb6e11b69a72", "33904": "f08871d1b1b88fb48d534d82c4a235df6dbc3704", "33905": "2a983bb1c2e0c962d828dcd9c828d95c5d82bb5a", "33915": "a083567e78f9c0e21a0d50b97eca443f84c5517b", "33916": "3ce31eb81e743f32bba3e10db141f34a1ed213af", "33918": "48d5061b73a9c1ab7b93313084812efc74855045", "33922": "3fe439b9878aacc11c02746b25cb1fab54120b17", "33923": "74e8c00e9e7f14cf5891faa5ae55d8d9e4738bb9", "33927": "ebfcad17bdebfad05de90a9f70313ed4247524a7", "33929": "6b27de318619ab7524e24976c31adf20e59c25f5", "33930": "c2a7f1ae753737e589617ebaaff673070036d653", "33931": "060b9dae7cd46bfae3fb786abf1f7416ee9e2727", "33932": "12e7e9c625b5a6f03c1f3e9d1450113b7a5947a8", "33933": "d716d801ecaad6b81308a0abcef75a4c0739fb0a", "33934": "a29c206d071bbd9b41a5cea77692e385cc48ca6c", "33936": "4ef638aa0923f59d943f85746964513949fff8a8", "33937": "23c3dc2c379eb325fd4f33be78338730d3f35731", "33938": "88f2df5f65e8ff575ee7bdbf2bfa129893573f62", "33941": "d534007e4cf07b8a8070f0ff9fe8875e5566f2d8", "33954": "0163b410696359e1aac0dfe5c190f2e048842e24", "33955": "017c72c03363b593273e89ae2567c0fb94854b4e", "33956": "be1b41be29a332de433cdf41fcdc39a0e4af9ad5", "33957": "9289f5d3f705f98bda623bc22d8007e325dcfb5a", "33958": "fb282b64331e48741660fbebd2bf948213fb2741", "33959": "1f7a7f20b1a3aeb66527df0d9a3682159e56917e", "33960": "be209b70cd3e951c35402421e81db9ae108a92b5", "33961": "04ec93ef5d532a3a7f88471be0ae0fa73836ada0", "33962": "d8d1a474c7f9480edc18f219cc0f92b63f85906d", "33964": "c73c1c8cc34fded44e4262596f0f82631628e8b1", "33965": "4ab82d055d42313c76604448d27fcebb0a0ae7fb", "33966": "c4c1e2729ce02595afa7950b36b0c419bc84e530", "33967": "8e456d3599541dc1a7fe7ec742274774f768f97d", "33968": "c2ef58e55936668c81b2cc795d1812924236e1a6", "33969": "bcee6d6f958d71395120fa21ea87aed6340596e9", "33971": "b5aec87d301b180a833bfb2860fb34313e1e9190", "33972": "72f06ef290f9a0725b3ef1067557cd2dbe99fc6b", "33973": "65cb7c42c7465b032c7da9ac789803cbc6008fde", "33974": "7b93b0610b79ee8e7201162d5f9fc08d8e8dba84", "33975": "0950b1c8110af3082d92713f2e516e0142b6c47e", "33976": "802322533d9d602aca40f9a58cf14d428353acb6", "33977": "33a3fb18a046f6d178a9031e75a1a9619a85ef4b", "33978": "5f37c4760e1422ce0a1876e8e4206c5b8a48af05", "33980": "532ed6f50ad04829a62a75939586aa9048573898", "33981": "900ffa31abe503b50b5593a3fd01703665eb85d5", "33982": "2171154d827ef1a886eb82b81fc2480c71e4f1a4", "33983": "f2cd62a0263ee51d036f23c76bc9df5c44fb33a9", "33984": "5c155883fdc5059ee7e21b20604a021d3aa92b01", "33985": "7e92ca6ae81a0260a24ba3440be556bb71d30848", "33986": "673f0231f68a696b5d08fed9c8f17b5441c24ba0", "33987": "57c49405f2bd31f797991f2a36dfa0036cb5adfe", "33989": "14affe0808078ee380a868df544701f372b6b02f", "33990": "3083ae932e0b122e963608fb25cf3df06d588b03", "33993": "aff52bfd7621da015ec675e1e4564c214e36654e", "33994": "1c1b158ecf3c7283a4e4806aa52c556a52ab2892", "33995": "540db96b8179c2ed83e427b9d501b04d68ee1804", "33996": "d22d1f2db0bc7846f679b2b0a572216f23fa83cc", "34001": "a21bf9af929c1e561831b9714aee580f047cba22", "34002": "25c1942c394ecbd3281240382728006e50bc28dd", "34004": "805d765c5951f27c9f646388c69dad4ecae8bde4", "34007": "4bf60ac2bab5878c1a0f640ab826df77a77f7e98", "34008": "db313f273229271cdedce61346332ecf6ea16b74", "34009": "4a2ea815f53228efce831088a09886be8b33e88d", "34010": "3c4be2bff160fe3286c3516e12b2f9404d9b0626", "34011": "525f1ef36d8c49ef17f102a8e45be5f054000b13", "34014": "ab76365f70599292e089641e04ead928500714fb", "34015": "e7859983a814b1823cf26e3b491ae2fa3be47c53", "34016": "7b8023f6c5d0d39845c97caf6d7102b3b5e457fe", "34017": "246a9dd832f21ff2ed3501512d71f1b5c1952382", "34019": "b63d35d2c6b6587dfb5c6d79e2e48db82d7f3cf0", "34021": "6c50f70650faf0f8f192725c78c53c86eb40a4a3", "34024": "710052cbd2193c2a21dd28750073806fd6ca1481", "34025": "eae60003c62063bfbc71e0a74a0d7878d3359954", "34026": "6f589922381d30bc789ef7868754c11ca4803233", "34027": "fa3aa5fbd099fe4f1378e7351d3053c565c2e0d0", "34029": "5c4cc4a51c71a2620dedcf033ca9e36fa185974e", "34030": "606e0fe5834b82d94a17ed2614008270ecb93171", "34031": "34ee4faaaa9dd144f5e08708162f9e81f15dbea9", "34032": "e63e2af0b50e2d01068e1742169510e34067d694", "34033": "125e1ea3a7ccdc1c1812251a02dd00187c0d66bf", "34035": "5045a99b5bee3a1d7d651a82f86a189014a3b1da", "34036": "22daf774419051e21a9ea0ae76fd360b51871afe", "34037": "a1c11878c66b0dc837e3bc3144705672a3d1aafd", "34038": "cc659915508e970f40ecc22d6a522f318d2c1efe", "34039": "5269aefa910d5c762bb73f0313657bf0d83a3cfa", "34041": "898ab21300ef095137ecd01145da81876467e558", "34043": "e62961221958ad5466f7e68ea07bbbe1d1608248", "34044": "770468928ce92990d1e75685124f2c18e78ec396", "34045": "a7def3ea68de7ab433bd28d7e757dae3e45c8b2b", "34046": "10000db023208c1db0bba6a7d819bfe87dc49908", "34047": "ac993e710b1c5c1adbff23ff62468ae551e3d0b6", "34049": "d86cdb0c230b311036d154312448de87e59a6c8b", "34050": "cb6d8fd447ff67fabc06c8906ff92647d0e5c3f6", "34051": "2ca9b3cb1d1ad81daa0af1a470c6317b4d92b15c", "34052": "2e0c8a496cc1ac7e9f43c658881486e414a15074", "34053": "1e2d87ba64783ebbaa90fb0829df29a3812014d0", "34055": "8c7b8a4f3eaf4aef90c300baa9a2337323f7a12b", "34057": "81fea58f9a90cde07c0bf66230e98d164a6db4ed", "34058": "a7fec9757af26638280103fb39928d24870c0bdf", "34059": "1f9e8e780853d367319334d3c1ea14d1f506ce3d", "34060": "2736ec83416c0ace552f8d9158c3c009a33f831c", "34061": "beec0e83c492168900c6d2747878be30db4bc5fe", "34065": "d95fc0b17d32b490000277e0f9a10e2de2c63a8d", "34078": "f8de8d962b940d1f5aca1c9831a3f7bae2411208", "34079": "d75e8fd3e1d7f4e62237f6ca94d8a68b0350b860", "34081": "30809bb1cf232b682a76ae4a47ab94bb9cec6bf4", "34083": "e5e6e094e2c0f28410d5d0fdaab787a3c74d84f6", "34084": "32f789fbc5d5a72d9d1ac14935635289eeac9009", "34088": "37e823d25be2a8ec9a3ac2d960e6af11f3c8d65e", "34089": "825b5c3ffb8d0bd5324244c75008f7c4839a6794", "34090": "261d425b88eacadcf67ddf4484976114175b0f50", "34091": "b522e7e4f7e19fd58dbcf1494a58a0e39985c014", "34092": "c016b65ce3628273c9ac4bcf06927667c4fa160d", "34094": "176d2562f952f76d0fe20ebed14359ee90d879e5", "34096": "4a2c06c8a5e4b12f7850b834eb10f1fa1f302f92", "34098": "ceef0da443a7bbb608fb0e251f06ae43a809b472", "34100": "44eb283ae3c00752a0e8648c1957bb6512697bd6", "34101": "6cae820153a7fd4de3864d6866f57d19bb0851d1", "34106": "af513bbf7f3ff31c7ad927fcf3d3c4915716944c", "34107": "fe09ace9dcbbfaee5760dcc474011f40c55a7814", "34108": "233bd83f692f6143e94cb4d455093cbf70630aae", "34109": "c61c7bad3148cbb14ba128b1d2e72420267bfbcc", "34110": "5ea55705aefb66358ce7318f0a8874142f5979d4", "34111": "9ba4ef86325abab6029436dcabbe3fab4a60f6ba", "34113": "1c2ad16b399ce2787212b84d08e96d470bc03d7e", "34114": "6d89d8c900ea27fe6c55f204d6b96961e73aa67f", "34116": "4d1c994da1e9815c87db2cd48a3286b077f2f7fe", "34117": "d69eaae79af408b1a941ec42f6ac52a545bc39c0", "34119": "7ee7453ba3becb0a286f9411532b5f6173efed36", "34120": "d54bd786828dc3c3914cb698751224025dc45289", "34122": "ac79adcffa2734252e6c08d1b61d55356b13be33", "34123": "a09ea5ec04ca35f0802a36a639ee3876b6afa4dc", "34124": "9051aeecd3e375ab55955670772cb1fb670eadb0", "34125": "91c2cb5b4b43bea4a90cb8f4be58b86356ad4b9e", "34126": "0d6787b32a1542f6877da5fd7d0e2b1712ad0356", "34131": "bcc5160b3a5b0fc9c531da194c6bb83619045434", "34133": "1aebbb243ffdbcb7f9c0a5f0b7e06cbcd1b70013", "34135": "478d340667831908b5b4bf09a2787a11a14560c9", "34136": "e61d371e0204d398a62092b5491bdd09becd2376", "34137": "0ba82890fb398a7afc2d6a1b83e31fa3b33fceae", "34140": "66f3f594d52c761773a1771ad93a8bcadcb1611e", "34141": "5555c51029dcc6f5b37ca04a0aabcdecd750b727", "34142": "1209f2780c63db31e728fe0a2e15d6c41eda445f", "34143": "e6da6a6a177597490e1f628b6bbe0c848986bd8f", "34148": "996bd1125f21d10e08e2299a4099755f712a2fbf", "34149": "56e24ff1cdadc47eddcdf36984453e516a557d24", "34150": "d86d842abbf2ff659c527462fa06ec2fead0c2ac", "34151": "64eed4c30d73fe6e5e43f3d6e1e16e05bd1a38f3", "34152": "4c07e0769c3838bba11729e5f37c1ace4a291c84", "34156": "cdde32c45a0b0b71c6ebb7e02fce4bdb06cc580d", "34157": "76670db5bc6afaa453401a9de095703e067feab5", "34158": "74adfd6aed9a72ea408ba598ed252c5a21f75381", "34159": "1b83a4611702259891ca4a6b33dc5e80365a6aad", "34160": "a174f42bd5e79f1aea1fdd6b3af1c55bef3cd18b", "34161": "6d36c458dca6c525479cc96c5bf15645144b7f1e", "34162": "254720a723fde3b8e4eadb0b8567c8b9ec84e045", "34163": "3ce07cb46986ce59427b601c6878c81633e436eb", "34166": "8daf188ef237aa774e9e85b1bc583ac1fc312776", "34167": "b6353699b847def984193296e778d166a5a5e464", "34168": "fdc13d65822e6572ac0e2c99c51c84c32dd72b9d", "34169": "4d64a8a057117a8b63d502e8da934a148af489cd", "34171": "7974ad0ba191e0a6b6bda5e0beb9669d0391b5af", "34173": "e80dc8752932d0bc0e991ca8ea1dee07c78dad2d", "34174": "9c89702b97d8cac26d184dde479f811f719487a2", "34175": "ee6915e4acd948b99a4c8ae352da8c112c92ec88", "34176": "0e857ffebec8f96a8723e7cd09bee2e356d90e26", "34177": "79e3ee6fce8830cc8c1ca8166bf49af8f369095b", "34193": "9722fc9f23d0689130b29873240187498fc7d7ac", "34194": "d5bfd2b88969c1cf0ea0aed7ee080005d02f7370", "34195": "c67fb96d21ca0c832d0a3b7808a9afbe287adc02", "34196": "3879640f6e7cd05274a1a047ba0482156e5ddf9c", "34197": "fe415f553ff28c9e1a4ffca49f89030152e66a73", "34199": "9271d25ca4cfa458deb068ccf14d2654516ff48a", "34200": "8932173cb1b977f2d26b3e4f0adec1d3b415c85b", "34201": "4adc5fa9903bf603055e4b1a5f3c25d1f7d6daec", "34202": "b637ad2a7d75c85d39f4e042e960bb82c76e518a", "34210": "efccff865544ea434f67b77af2486406af4d1003", "34212": "ce7522b4463dd353a17037bb1ecbc78a0e3c7ef7", "34213": "4d6ca9d74722ab6c74f3e8541110342fcc0a1f35", "34214": "efaa11eff5d547a60f6c9c4f7e3a59da7c3fbf12", "34215": "ebe484a69c5dc6f501cce7769bfd28792cba83ba", "34216": "d88f8bff372863a33d3d5b7bc976b52ead107f37", "34217": "e58d1ba1013431f90e081c7ec6dbeee587ed2356", "34218": "3c447454c7daaa8d245b8386d7ba2b2da70f7e73", "34220": "328a620c84179e01cfed5da8cc187817115d0e29", "34221": "e9e034badbd2e36379958b93b611bf666c7ab360", "34222": "4df76efe9abecb0b4717d9991e1b592c1a6460ca", "34224": "8534e13a02fedc39a667fec91ca2943a82d9a226", "34225": "f29ef30e9939468e1b866b6a554ee6b69b8322c5", "34226": "bfa5f9b4f058b2399bf8e74ee383a9c3a00da696", "34227": "8b9600cb231eb746854ae22cc7e7ab2f16d3ac62", "34228": "0cb4d1ba852ca7f8430b1ae52ce2c6b5ed140747", "34241": "dfae6dbb009e0123b42fab8562befa4df0cbc1bd", "34242": "5b66502b7fcff3977443db29841ccb5bfa449b70", "34243": "e3337aa9395892ba7ace4e839ae23bc6565a57b1", "34244": "0e1c237a646e89207f4470e13c480940c5d6abba", "34245": "7187e675002fe88e639b8c9c62a8625a1dd1235b", "34254": "fb92f38ebb4ce4c40bc4c998ac6164405f052918", "34255": "f70638fb4d38aa513331310df221360a801c36c3", "34256": "e6169384dc003c05799e5ff56da3fc611999d8fa", "34257": "658ac5b62745296009ebf9d5414f036b1a3e0dc0", "34260": "656e4fd0a60b2bebaf38f2d060151a68ead0323c", "34261": "7c55534472f4718e0372182070343d5cf514af11", "34263": "5ab10a3af76186f3908dd0816688f33d30cc43fc", "34264": "ebf6c8fb9af741f23908871970926d5551bc9a40", "34265": "471c852b3c7c665e4d45b3109cab2b79582a8f6d", "34267": "e8416dfc2cc36dd4989fb7c13efb845c6c87c1ec", "34272": "9b207595834f27bfc83dae5baaac1019644d9fc7", "34273": "6480090594d8d80392f80fd0a5b140945544ee26", "34274": "8d4cab5a4c24376c6251e93746455f0fb4a96c07", "34275": "0ab323f22b89c828e1380ee0b96668ba14af8c84", "34276": "32ea575a626c797f5caa1fef025fb7390f2a3374", "34280": "a6d5db7c90a9703f2c875d2a24cf7f97be5735f2", "34281": "13073534186fb8148d04f925d15e788ec52ed491", "34283": "81b08a9581a72545bee2d3026d3cf5d030ff2223", "34284": "b0ff10fd258f6ebe4f22c61f97ddff7204c17bdc", "34285": "bc5039efa94e6afb4fea182244ac89651535a99f", "34288": "be170fc28e4a937d233c773c2e420e229c0f533a", "34290": "bd5ed2f6e2ef8713567b5c731a00e74d93caaf64", "34292": "e6e976644eef616b94849411b6282d8922b1883f", "34293": "5799de2a4f828b0083b5f2b8ddcc2fea8adf4f7a", "34294": "249d93e4abc59639983eb3e8fccac8382592d457", "34295": "a80cba4e10a7d3bdb7812c1a97061e49f13c8254", "34296": "80001a05d60f5f14d89130e2b694ce43922568a9", "34297": "eb582981243063e727c8597d2fe0fe364b387ebf", "34298": "f9608250a32a3eddbd3c52741ed5dba250caeaa7", "34299": "5b525b42385eb0182d9002e8f18863449a0800a9", "34301": "8b797e9f0bb1e4fac2bc98151795f49104c67f95", "34302": "ac1552830e17ee7b074343e80dd6e3d9583f86fe", "34303": "b661313cf5c9f5543c393d85339bb82410c18b7b", "34305": "75a79e71c1f3fc3df595c4df260ab5ff4912a0d4", "34306": "aa4a039292f8e4fadc2eb7c96d241d01834e6eb9", "34307": "9eee1073c2d0602569ca445b7509dedf906f4af5", "34308": "436f5eb0b28f7057e9bbf5f6f01100f862fb8cfc", "34309": "59024bd9bcc325f43dd4b758a6bbb4b427a2fa39", "34311": "e7343f7550d2dc7b59c4304ae3d6b72f478f4a35", "34312": "4017e9c71f07793a8b69b0474938a2a10083bb1d", "34313": "34b3e7f92b6fbacac3a5d0ca5f16ea9a6f5e31c0", "34314": "1567d9e817888dd7a7b349312d732f659de52326", "34315": "832bb059ad6a40a8f3b97ef1d87a452f30cc3f94", "34316": "38b56a065303fb481d1db822ecdeb4fbf457deed", "34317": "de0753e4932d1b4951bc8275610ec4b0b9bdc1e1", "34318": "c3e835a0911da6177923e6bb0b086377d5888b94", "34319": "23f74d3f57cba84cdec677e68f4e7b3aa98d9198", "34320": "11d75d8d17d15d315de6511285d79edeed5c0b73", "34321": "ff8e88a05c907bd124bcfcf3c5384e16a7987cc7", "34322": "f78010481f4e60d6a31b6bff8cb412c45bb7e2b1", "34323": "f351f74f9a01fd8e06f8d7318d4596756c9c82f5", "34325": "c85bbc6913b9c4d2acc53c54cc858c84bf0658d1", "34326": "d91b04c30e39ee6cc1c776f60631e1c37be547ef", "34328": "6fc3da689a745388d14f6dae0607131cfe7d3771", "34329": "8ca2e37a4ad9d6fee40d9ffdf76c7382d269b240", "34330": "b05a6c2c58017763ee93fa5ab754a6f77efebf3b", "34331": "561bcea3b8206c90327813e38d00f864ce0394ea", "34332": "52e22897728d8fd907816967ce42bb542e4fc73f", "34348": "6e91a2249ae24b22d1badea53cd662ddc83c5aaa", "34349": "fc4ff26ed3e51e0a68052cefc6562e99e1169dee", "34350": "e96054a5315c0924bb241d53a72580ec8faeb9b5", "34351": "e0e138473999b16b6ced2c7a4df91e862fab73bc", "34352": "2750ee21f492bd0417f07171f646aab432516638", "34353": "7059b7b8642d748746ba968bdbd66789443a2a53", "34355": "f96020836ef7c2c9a159943f850fe0f86cf5f9a1", "34358": "381b189e333904d17b715ac30b6a93529bfc0bf3", "34359": "e44daed32234b1afd263e5880a7e743f31218ad1", "34360": "233152d9b253370427b654dd4e4aa2bd977f1d02", "34361": "3aa98731124ffb305425a2210ab11cd29eee7419", "34362": "bcd5d25ee1ec85b5b7e77c6febf196a1fb6bf265", "34364": "1ac599ca9af1be42a24a89d821b0f105c0af0169", "34365": "065b3d0bf5fb3500eafd44aaa821c79ffb767aea", "34368": "75435a77abe5f9cfb68a5f2b115d24674cf00123", "34369": "6b92b1c0133b73b405bb6dfb1b47bdeaf052329c", "34370": "423fffd533082cf989353072dbf07f6e6b1b3b40", "34375": "910f1595b8e5e424fe81ed8ca9f06b4961d7735a", "34376": "e1452b7f4281e5562051e5d9c5b111683ba790bc", "34377": "bb8067f67dd4363893cd9f62aa4a140bec0f8be4", "34378": "f94bdc444d8ef2ac716e61149f672b8dd207ec79", "34379": "c3f0aac174bcbb6567f9e1a3f404511b9097a862", "34380": "367d24f9843d5b69f5948f1b8bb5242ffc7f8a50", "34381": "80b4524d22b50baea912d0a951440522acd90bb2", "34383": "fbcbdaf70da354801d99a1cebb889153a3eca481", "34384": "84f35915a5c86decda4a2aa8e8217fb64664c77d", "34386": "681af4c52487e14dd8512b27e8761d0078c3f8ea", "34387": "e38d786f9c083ec2784573d4c63ce63c7846d16b", "34388": "eb9a3e81a946d5921e4458632e9632239ac8e8d1", "34391": "2ac0da4e129c78b41a1bf9c8c4a5b751c0bae408", "34392": "c58fa847c6bd0f88fc259f34632205a791841029", "34393": "e96ed7601d0c59cf7c5796d534d0ca80d1603a77", "34394": "34a10484278dd92d35c8f49fab6e313dfc7cc8ea", "34396": "4539f3eff40f0889b1e089c68cfe2a0b034d7ec9", "34397": "2c68dd3d9c415f40b04c500936670470c4eabd6e", "34398": "ce94afa62fbc7079863c190d89e78dd1d2e69c02", "34400": "937f774eca1dc375588d2e00b9a9b6ddcaf502dc", "34405": "f38daadab7b4ccaf5a07ad837c151c68e83b61fc", "34407": "e28d17b1f64ab36d24afd773d80c61f0ec405f5f", "34408": "7b710c75aece848eccc762c6c9f83d16f8eb8613", "34409": "fc434c4fc3d8e188cde6399a225fbdfd45f71d78", "34410": "3ec67e6707e41e23e7ef294e60bef1ef805e1f8b", "34411": "c9c6a1f05c657b1b4159d2f47be02e09448c1e78", "34412": "6f47a17ac169a72c46d7e4fd69667079596b7e5e", "34414": "37ea63d540fd27274cad6585082c91b1283f963d", "34416": "4bb8ce79f1ed029a50a7a604ff33e87fea34310b", "34417": "8cde12086699f83df22176b74fa469487e698b9a", "34419": "2613ad8b3ff2ca950f24c09e21feafeabbe2ae4d", "34420": "b548eabbb1b310d95c08169ff1c5aa6653e6ed11", "34421": "78b7802ae51010d4248c855665608aa78601bb11", "34422": "829444a28573399ecaeeefe7255df3a95b285b86", "34425": "360bf218d68c703911731aec58a52b6501b2f4ce", "34426": "aa1f96bc6b0bcd8413880be363c61177511d2481", "34428": "0223c0cfd130df7c4c2d7017b84fe2c75e226d38", "34429": "ab4eedd74bc3528e24c79179c353dffb61471176", "34430": "61738c45f23f8c27e5ca65847a9131cd69072c84", "34431": "194b6bb006a48b913b73e176b1210ece54f226a8", "34432": "c9dbb816a256cf609a87df81331dceceb4f8b2b2", "34434": "1572b3f679ee8c71e5bdc9eecfeb531d4f4b310e", "34435": "9f650a23dd30402245011b51a60f05c56ff28ff6", "34436": "26d406ff34fa2c5ff6cd9c34db1fe29fa9452bba", "34437": "4802abe3cee0afc0f59ea7b1b5345501f2d0386c", "34438": "d182a3495a95c7067c13690cfe037597c3714d5d", "34479": "400761703a39be8f115e7da18e9203988f13335f", "34480": "aa98ed218d40fd5b23274c4e374bf927f4c74bbe", "34481": "37e9e064e6d1fa44b9228837249eded4e694ef16", "34482": "bcd3492e7771c598e2c6cd2fafce86489a5e94b9", "34483": "29e5e4c96eab0e8a3546e4d198aa2c5edfe3a42d", "34484": "9442dfcc4f87c68632eb3ffbaf8dae6da4b532bd", "34485": "238eb8cc9475c24ae67ccc12db456a1b2897cf02", "34487": "000c3ed75ef63330b18f7751ac005f9a346a6d50", "34488": "f886f1311b85286f3cabd6dac255c837e9b0491b", "34489": "4ea0ce1957cebbb3d14fd769c03a3d3a172376bb", "34490": "187e2b050e916e88ec9f0c8f68f4e7cd04fcf07b", "34491": "7772f0f247acca10312062acf342f17506baf8ce", "34492": "56537f4490c14f81cf53556e832bfac01fef245d", "34494": "638a41446adf5e5f26100bdbc58cf2d9d09623b6", "34495": "80a3705e2b1cea90f948efd5d1ec49a59c9b2366", "34496": "aee55c9fd198532e30b88fd6e1828c56d649edea", "34497": "e49387d589b2807dbe3aa59ad541eb3e4e2655a5", "34498": "721bd7a22efbd1c57f86fd61d6f0e668b79942ae", "34499": "4f14b456b7d6464303edf63b6bc699c29d39a515", "34500": "3a669a7d15b9be438db1b1e0cc13464d7c014f7a", "34501": "4a5d32a51bea8f175b1df6f4ff8680b51e691799", "34502": "d389bd814b1fba0fd112f2cc40c8a915855e02bc", "34503": "6f2f74e035eaf2efb7d634d931c51533404d7ca2", "34504": "f8a503d37529ea1a1117b854c0f623894deb10e6", "34505": "388817934ea97d170c0ab7d12ff2e16bbcd44320", "34506": "042ebab0248193b343ede6d87397871bf8931fca", "34507": "a89110f513dff180932f6ceabee1f2e6d9520201", "34508": "20e9fc762a2201d09ea3af8fbea7ec52f361e06d", "34512": "a20786af53dd39d04e6d4536de81a914d490361b", "34513": "9a189802936cd47b451e86bfcb1e5e9f502d94ac", "34514": "b39f89a853f37e0f1309edb5045e295e86f663ee", "34515": "4f4184d90135c9e890d5124df547dcfff51bacec", "34516": "d3bc3722aeccb03841cda617c17f042736b04bb3", "34519": "86a4ee01c7899ef454d35b95cde11e9593921c9d", "34520": "a7c380d3875b5292b5ca92f928e49a9bf765852e", "34521": "fe7025521b69892ff811a28a4c753478654bdf97", "34522": "0dc6fdfdb28e4b775c997b7dca68a4a1aa41127c", "34525": "1132a4d92ae0f4db3387fb9b7e0dafe1ac10bc36", "34526": "13c99222ca4ef37562a0d0501a309a5b4de4c6f7", "34527": "b0140bfd1c1f70481eec6a586fafca706135db55", "34528": "5fa7f3171e4e38aaf953c12bf90b9a7cb9797a53", "34529": "284cfb25f1011a295681876e6e358ebea0b9a6f1", "34530": "efc3d953e68952257f9db2aaef729f4164d75dd8", "34531": "ddff84a5ddbf55b5f407976be359720804cd6981", "34533": "361260d4d93e4da8de92d1ef6af8babcd15ecc0c", "34534": "073156e7f755617f6f49337b041a279f6ed303a7", "34536": "34370ffb902c9ffede87f160c28022b15c36d785", "34537": "607316c9b6f5839389161441da8cff2eff5eccd0", "34538": "2cdca01e193e883516884cedf4a62dd308bf28bf", "34539": "87970b234a80963264dda5324b5030350021f292", "34540": "956b8008e90845093f57c581c97b15297c72090a", "34541": "fa29f097b6fec05e13543087905687fee92ff3cf", "34542": "8ef94a0c56d8497e369d4be1bda8453160e21073", "34543": "016c8686e594d583a2135be90fada554d585db5e", "34544": "69a50733400d65792407c9330671bfead432c7ad", "34545": "1c30d7e6b118c864319fa75716f9f5baf835d3a4", "34546": "54fb77b8856ad2482ec971af0e5b8e2d85c5a0a2", "34548": "dff1dea738975267960fef815f0dab916f3fd31f", "34549": "b7e8b47fb17de15310c731a8d6fcd13a7ca76150", "34551": "f1126610ab8a30ea58e7c5196b3c3be52b81ab85", "34552": "824fc8304e6f6f202ee169c7118242374654a4a9", "34554": "574f24127cd1eebecb4ce5b1d48b2c579ba41120", "34555": "730439603919b9a38a54477f768b775f1aaf6412", "34556": "fd9fd7adb654370fb4aa7dfb8cc9933dbdaf375e", "34557": "09d79ac6800ea5a4d37f43111f250a8fc1ef31bb", "34561": "2c164f0be1fd9dbafb8f8db38e4ddab621c73b87", "34562": "a37451f8b7dd225a29c281eea69c60eb6da99d29", "34563": "94e868a76f5dfd30e84469b47a316699eb1f083d", "34564": "9bd8b5d8d05f9513886e26765e7cf2d9998eb344", "34565": "a90fbc867ca9aeb66cc988f0afa2e0683364af6d", "34566": "225190264c9eb65be8018972b2cfe76b45bc6a39", "34567": "0a18ad7eb63ba055e63cd566084b0d970d300553", "34568": "3827cafb2390824a05bc81d1bcc045c67e27606d", "34569": "fa9bab9e1a7fd40c862411ce481dba2d6a3607b9", "34570": "fa69e1427afaec4a1f57788538095c2bcd7a5718", "34571": "45eb702c2a38216231ba7c02214e7659aa0eb5ef", "34572": "e19ceb76a4c5903469fea93040c174633c84b9b9", "34573": "779a0ffb14ee3237fdb7b9d53ef5b7b0b8ebe473", "34574": "c5524e4d6444fb56ed26ed4bc99203fa63d6319f", "34575": "0826720622e65a6af1223dbfbd6725f115a166e3", "34576": "f9a0b873a242523db6739551813cc048ecd2f01e", "34577": "2cce8385a3d8822a2058fdd4a8228fe45baf0cd1", "34578": "b033ca94e7ae6e1320c9d65a8163bd0a6049f40a", "34580": "f80436dc787795a176f717a9b58a99d8005b6627", "34581": "455c880ddbe738074cf87f8a99266646a9855386", "34582": "1771b0f0781ffe8a4d4f0d45bb085586a37da66a", "34583": "3cfd8685ee7fddba819932c92884427ee9a78866", "34585": "935244a9b9c0fe796de315cd381d6364719bfdc1", "34588": "f676c5f76f561d4ffb477bb31d63ce43b9561a9b", "34589": "e1b657a7efdc6c8663d6a747d32aa46585ee328b", "34594": "4118ed8533d9d3669eaed1e1be874c8875be7d5f", "34595": "0486799aaa38fe37c4a10b2cc3535ea7127340b8", "34596": "1a4832bd49d9f41fbbf705b2941ef4484852252a", "34597": "4f88a2a4c54bbbbd29a6046620f9453a2b9319df", "34598": "2b107bfcd84e2b6a4132329ad0d6c30f68d17554", "34599": "489f15e828ff0bd182388fe13793c1f9e89b041b", "34601": "c96dbb77eb294252b3e56837a8bce73866d9f329", "34602": "8894dcc125b124986764272a64f88ad20a090487", "34603": "9190b13c0065d8af38cdd074ecc26f79f2d09c67", "34604": "08604862bff7cd6f1c878e3f48e1485d0a8e071a", "34605": "0fa150016911de08025d82ef6975750278c5ad7b", "34606": "6730c5214e07522a41c2629a1299787b9bfab6c9", "34607": "e3c8af55f24bda855d1a6b78778a4af65d63ba35", "34608": "e2c4505ca1a7d1241f258ed1a1ed1fc08db6a1b9", "34612": "5c8c16ec25ac9b4cb7e14743f2032a8e9d4a6ce3", "34613": "93f9ae0d9d9f8297b9a04da8bc39898807e8c363", "34614": "c28017894796da14b23e624ac0be61091c715a8f", "34615": "64e88e3d45a4cebe110a20634ae280297e4951a8", "34616": "199624d6596469e3387291383e4e1cf9534ddc2e", "34617": "80b3feea900e97c8184761c8835cd79fd8bdd465", "34621": "b2bb68a88cedc22321fe1408d7ef74a871a373fa", "34622": "a2bb939ebd3aa9d78f96a72fa575f67b076f0bfa", "34623": "1ac78156dd3f81b12c1c84501ca409fdf2d997d7", "34624": "030cf5d6fd3287567a4e8b2d71a2576eb9b64a1c", "34625": "eb4658fbfb7815bfecc08774fb44a7173dd50a67", "34626": "c871284c0c5765d3d10ad1bad9fe1d4275e2d696", "34627": "634b9402466c96c51e6667af935bde01e7ecf144", "34628": "6edc456527d111a9257b80464cd2f80dc22fe811", "34629": "b6846660679751da2d5f31ebac4c1acc09096a1b", "34630": "aaf503784a7cbf6425d681551d1e1e686ce14815", "34631": "b968ce5cc1d526da86b6267f94615ac357b92f49", "34632": "7b224487f3cbd89bd97a71d5f2e32d1b35bcc821", "34633": "5e725e96404e736cc04e73e909c8601ece09a672", "34634": "df8b686b20bcb6e64e9cc7f64053141d75c3dd77", "34635": "9d38f40767da08ff46b807fd9565666a7aaf079c", "34636": "1bf3ff77174ec6448c94c2dd98882add9fecb33a", "34639": "d066fcd0cdd1b5611a497228f440a1ca685c4d0e", "34640": "85c7435c5134b99f26d1e9a7266d00f1c8b715b4", "34641": "dd11d47ab21209b9cd8a58547e5cede688b7365c", "34642": "61ae3ca4b3eb390b5c4bb30eed765a9c54c54fdc", "34644": "4467c2fe1e7cadf27d80be0ffa7ea97a43b152f9", "34645": "001b5455022aae4da69ef4d2ad6f35eca6ecb48e", "34646": "2f49f739b9eeeab16972d419b65da68b85c05960", "34647": "64c1e5ec877b28e3f0ef79c88075369027370f1e", "34648": "3e913c27faeb76cf3c6f01e688a2eeee3762980f", "34649": "29f949980170ada984ebf02770356f1d28b980ff", "34650": "7a7d684b3869a47f8a8fe3f1329d6db8cf040868", "34651": "1720520c364e63583ae28a9532d0a8916b338c18", "34652": "04134d51aeaa73dcde7c8f99738e4775ee02e117", "34653": "71cfd3a2d56ff81404e13b7e5c6a9720d52a3a81", "34655": "b0d0e4e34c93e402308f6d302b7ffbd8b198815f", "34656": "f5a5c8d7f0d1501e5d8ff31b3b5f24c916137d9c", "34657": "8253d4ec74a57bc915a0964d7dbb6361bd805fb6", "34658": "8d9792bb9db4e260ffb1580033cebdae77f44f2d", "34659": "6d17261a39c776f43d53228d8685da63ba3d580f", "34661": "901a70d35c7f1a8fb29918f7a4e3570634e8f95c", "34662": "5a0230ba3fd306b02e74ade437c2f4a0089403da", "34664": "cb26eea39b6c184f6d95bb814181923a3b942344", "34665": "2a270d8b04d9573b17b9d550a049d003a974a9d4", "34668": "75daea460b3c2f14ece2c7e10d34ce90b0e52f8a", "34669": "8bdc30447130fff11285c6551f30fda5cd665ff0", "34670": "f231c9a74a544ec94cd12e813cb2543fb5a18556", "34671": "d6ee9ad2e8f1b60eac62fbe2089c5998a381070a", "34672": "d15041b9bb0498bb70fdf5a26ca5bdd80f6519ba", "34673": "294af3dc2e1908c17585a76bd26ee62d1da64285", "34675": "65100cf9967d249554d65728eedc26becf60faa9", "34676": "eaaf0c5dcf3349097c4dddae443540fa18235eb5", "34677": "cf2c967adfcac6c36b3ba592d1135c4e1747d62b", "34678": "3863a48d8f72fc7c69083fee3140812378a159de", "34679": "10ef2ef7ded1f38f110f9a4d883d5e3307d663fe", "34680": "e8ee68ee4dfc2a0265ce2c5649e4bdd39e9ecfe7", "34681": "26bbd4b2c52f975d33a7f2211e9fd07533ed671c", "34683": "84d85fa8a002869ea3d2bcec5ff38c2280a15eca", "34685": "3a01556ddedf73ae02394eeb8864c29a80b4e543", "34686": "8cf4ab491b06274f555d1ea305c172354208747a", "34689": "965ceca9fd796940050d6fc817707bba1c4f9bff", "34691": "4ff4e63afb9f9abce281a138bd9faa16c3667795", "34696": "ad86efcb0f4adfcb4c09f664ff7596dc676f5dc1", "34697": "eeba91eb0a13a52dd885d1548755f0a22f26ad77", "34698": "cee3aefd2aaee371fcac1065382f039351d71559", "34699": "59845b71a390d70553662268a7569df876ec36e0", "34700": "d8ae9a7c91ef0995120befed19b582b37e98a1ab", "34704": "67887a838408647f1bbb73fe4a12b4a4c525c57c", "34705": "90c42d22a7266fc6071696d4b7652b0e8c3d1d84", "34706": "6afe4a0d3870b33ecd5b17e1f0e6f88105dbeea9", "34707": "563dd81b648c95779cb971bc52b4108faff87757", "34708": "a1f050aef65c218ebe1ca12adcf011b030553042", "34954": "5307062326df2034a6add893f32fe5eafb5a5aea", "34955": "efc9f0d6e5f40dc8a9fe36e24af244dd0b3ac42f", "34956": "1ea0993ae6c6cfdde5a2be34e2c1c84b7ef510c5", "34957": "b01dc6205f7e9a582181956b0854c5feaf4282f1", "34958": "ee8e01e3a1e0d6b947433d857d63cc497d4fafe7", "34960": "0f437949513225922d851e9581723d82120684a6", "34961": "c96544ed82124fd2bd73324a29996fee72c02a77", "34962": "0aa39949da228b6401f17695fa9d23b996ab966f", "34963": "0efcad2cc1ab9433df798c8e5b825240fd9ee6ca", "34964": "24f56be9ebcc4399abadf178a4e21d8452b3f3b7", "34965": "c96827b828e612085fdf6bb17802e35caa7e5f4b", "34969": "6e789c1b6b7bfceb5c1a049368210590daa8cb47", "34970": "1b33bf67cab4b7480547e68ab0eb88af33f19c66", "34971": "bd20fdc232ac910aa737db73e5180e1637ddf66b", "34972": "69acdb25277e69bb96dd07e78a87d695f8894b9e", "34973": "6d50df141e4aa77ea3245e1c7f5379a3f54fe13d", "34974": "9a9fcf60c68dd36af92758f18b6610a67e3358f2", "34975": "642eac3b781525f8473b3621c1e63250fc5c8e66", "34976": "6eb59b32bd26c4f36938b0177ef18b47f260d6f1", "34977": "25746942a93269473c83798cbbefe7d9c56aa2da", "34978": "ad178424e2d95badf6caca5f583f3f6053ba4d90", "34981": "757e7e9a35e3242151b23b90f5388dfb2d88fb68", "34982": "dd16728d1ce7626a1b1725c5d696bf690d9aaee3", "34983": "76541f5936d1f7ccdd046553ce3d121293f40da8", "34984": "56df926e8c54abc1795c8da435ddba9c7aadba91", "34985": "7e0bcf1681a66f9bdf373ea549b2104e1a72184c", "34986": "1186ee0080a43a08c3431a5bfa86898f6ec3b54d", "34988": "c4c6ae97a91af11e6744991cee4e22f588337c84", "34989": "4da9cb69f84641cbcad837cccfe7102233dd6463", "34990": "866a388412067f39e5be9ba75d0fbeff10ae5fd7", "34991": "ecc46c382a2bb1a7dfb783674064fc0c9d269ea2", "34992": "1d7cab61629e507eb28c42b48a4729d7c47321ce", "34993": "bcb3fa8e5c91059e9035ac0f4acb2fc11e1b28bc", "34994": "172b7c116a66c63bed605c633683778f828d2e57", "34995": "6cb37b6e050c374151a23e790a46ad8b822a0564", "34996": "7856c0248d9d76c6f5689a9718da270eac38c4df", "34997": "1e90f9e3c5371bf65347bc1ea5e9b3cef9dfa189", "34998": "64085dd41ad190e154b0fe12c00f00fff27bbc86", "34999": "1f7463681943d5b912ce47d627e6a7aea2014e3e", "35000": "0751cf2c04d69e5a144c622d35a7952a47e4924c", "35011": "1a3f522397507e4cd14046da475b7775bb6170fe", "35012": "8a413c11f760a56f35dc9b8289829a959a4f19ad", "35013": "ea1e0c85c3a736865a931d8cef85cd3890144cdb", "35014": "e997175638bae0a8365367a98319f2c174b51505", "35015": "eceaffbe3f8e6387ccc1970455e1d828f7f5702e", "35016": "431dd6fce8795e69431e9d565fd6150c3a90afe0", "35017": "6b4254efc4421aa90ea0a6a30f620f0535d926b9", "35018": "011d1d0143f139bc1d5bade750218dd2fc9df646", "35019": "d73e9e5428c8c17a0593d12cf451d9e10a1df136", "35020": "fad7abcd6f2460512a1d8867a26960975f75512e", "35021": "d32d02527c6b04ff1ccd9f5a33e3029097ae1f35", "35022": "12cfc16a73d65d1351ad3b1f6d972dd3ba6c3ee1", "35023": "bdbe4d2ee857afd73b1a4570eab51b9d808b52f6", "35024": "457690995ccbfc5b8eee80a0818d62070d078bcf", "35028": "3e643810d7d3eafeb38d6b4c8e3ea1a21b701d35", "35030": "c126eeb39206e1fb68db19e9289f30b35e25fa9f", "35031": "b5d666c5fb51aa1fa43e633c71922fbd610a4dc1", "35032": "070fdc0e9abb0969e96040b4c65c71e583fd8d64", "35033": "ac3153b30a611d2593b002ca5d9ff22a2bb30af0", "35034": "30814ee4635c1055bb0ccb4d6c2648c783bc98b8", "35035": "f9672605cfc875bbbb8b53091703d8a0733b5dba", "35036": "4019d41816e6114d41731638fe027a8b0597db72", "35041": "48690d4c23b56559ad90cee8d02a035fbdfc1274", "35042": "eed299f4e39f77e9c91ad2ad6e8321a342c5348d", "35043": "b33bd87a6aa53a23b960d304a74d240014299492", "35044": "997699e619531498ef98d2915035f8b558069b1f", "35045": "b4929f8536fdfa9cd8abb181cdd16a522035f9e7", "35052": "e0c3a98a07403e9952ec2ad32f25300e0193d600", "35053": "9d1d1b129a82648a8352a6183fa3686af17d7dc0", "35054": "41dfcccf0771950ed94b7bd4110c92a0c7397af7", "35055": "dbb19b9f6ec77edcbdf535ff506c3b7659fc0c69", "35056": "e758a19e4c67a4684a6054096f2619c1f1fcab87", "35057": "c68449a65cb594f4cc449795ad4cc057eb30856f", "35058": "ea56ebbd1322054237e1a1872abae47029b81ecd", "35059": "12c886a6a2af4262ee2212b96509feb5965075cf", "35060": "be09d66901525caaad3fd975bc6bc893851a5ebb", "35061": "0a720b6495be7cf190daa1c007fb68e2e12d1bf1", "35062": "4d38764f25444c0e61401e583cb684d75ac858a3", "35063": "0511c494a2d8fbce3694c970cf9773587baa53be", "35064": "4b27e94817c9a53c5690f4bd23df8f12a9bbbba6", "35065": "9629b3a4d56e247180bf4ae35221fb11a43af2e3", "35066": "ea0a08f042a96fd963c40a33e089fbe4a85d4097", "35067": "7672459d83b77598c8b653ab20ca66a788a09a9c", "35068": "7d0b0e25748f2c36de87f167805afe13050f7619", "35069": "9ff33222d29d82c91bf6344f31f2d8ddc299977f", "35070": "527bfc5e8be6bc2a44e0bdf2b5faecfdf4c2ab33", "35071": "dc830eab5516f6911c894abdb1e3782cb18c503e", "35072": "7c876ed63294a260f3a7a3e3071127a7d2e2659e", "35073": "9372d217b05c432a041a312e9df2a580d15b1e8c", "35074": "3d7a44ab39b092feb30bbf79923e6d970a6f67fc", "35075": "2b0ea6036fcda9f7605312551395d6036b163b6d", "35076": "cadfd1c5c9a52e7d97f986228391f8491499e796", "35077": "47734e78285e3269be9f23b7c0babf7071fac1a1", "35078": "e1808b8757326392ca450be2578cf1fa2c5eca58", "35079": "747afcaa919c7868ce454625889fd453ac1553d3", "35080": "db27c36272fc3d7ce76cfecbeaa1eac704c2644a", "35081": "f1211e72396a709e7a6eb2cbfcb12a375c7c9978", "35082": "dec49044fe44f2b4dd8b13f87138f0c80b31fbda", "35083": "aa4922a96b4c6c34b5fc6943437d902f6cc662b1", "35085": "fcf781112a3b7ba17e9df04fc662231745db663f", "35086": "4d9a6e4e847d3dab249deac9bfbf6e83f09eff2e", "35087": "d3870de71459511861dcdb39a151b56e9e20ee29", "35088": "2f08999a537646ee9d9d698a3fd502ccebb3d79d", "35104": "c2af783751b1e4ade1be03a378d7d4cc26cc3505", "35105": "689a91ae9671fb7672da145cc010fc145e0b3d56", "35106": "569ca469070f76466f4b41ece711bbef0bf8d43b", "35107": "ab85d7a114e4dbd22e5b704a27f5f27cf75ab1ad", "35108": "c539d1f18df9ff8a5fa1c64b809da062c66bb614", "35109": "6dbc455628047878977f8642b5083f3eb50d6d86", "35110": "6e7025d50dbb1c669cddc557f8a1a9682de72fdc", "35111": "c92b3701efff16293bd110a3f06f458040b43d97", "35112": "ee18e0605c615ff62af9c40eb71f88313939acef", "35113": "8e403e4cb8802c358f374ef4d5ad957d67de160f", "35114": "811610d1ab5c881a72aa907cdde21fa5e42d515f", "35115": "894bcd98f4f239c36f508b8dd30bc94a04254a85", "35120": "f77a0e64044eeb539ebf04cdca06edf575e0a5d2", "35121": "3713834bcfbd476a42293a941f127b7fecfb8dc2", "35122": "44c416821d801866f2e8440bb2c074c049479d3f", "35123": "289e0813704c37a6a3df36019e42ccbea7c47c83", "35124": "e0964c2da4486896302e933044c6059d523c681f", "35125": "406abd95647386d136000613b6a754d40e90d0df", "35126": "6501fa56ef681e1a5e1ae821383fd3c9d6da2577", "35127": "0fff817aca15bbefccf6fa27bf13225db0ee6235", "35128": "ab89aefcf70a1371df2eb7f6f8dc3c78335352ec", "35129": "19618ba7c02e852087c1b4605900759782615a69", "35130": "9be48ef953fe080c68440b21cfd6d232d1537ba7", "35131": "587176ea5e1bfff0fe7f0ca8ac07bced301813ea", "35132": "c1f673b71d2a4a7d11cb05d4803f279914c543d4", "35133": "273c8c66478cdea171253f78df7943f8bfd10d05", "35134": "beb4dc490f2fa6c15f368d46dcc48f9d16398dc5", "35135": "8f1c56dc5b65cc428b8379b06524913e0264fe88", "35136": "743111ec236c03ba23d4689b7b094776dab619ce", "35137": "b75d6ad6569d814c18b6b93c4682deb8471b610c", "35138": "bf75b2038d2792e9b1fafa41a1a94ddbc0327002", "35139": "be63ff5153b7bac7dd4c7df5a4a901e3d88177f3", "35140": "fcb33570667e9af5a258c6730c3f5927655680e9", "35141": "2e881c35d22fd4268420d724608c3aea5f84bde0", "35142": "2907b2098a3444d45be5391319657e69f214b9bb", "35143": "d4889bc61669642d79372746d697c4ccc5d274d4", "35144": "af76d785ccae9383f5cf9b73e0bce79aa8ae8326", "35145": "7211049c0b203c66a91a9d3eda890ea74d85b5be", "35146": "620ae26355929abe25bc11c023fd6845586828c6", "35147": "3c01ce2af5099a8a830195b2050d3a4036d14ff3", "35148": "67209ee117050ef47e3c5e0174014126a2d7c1ee", "35149": "db3efcbaf3485d37e11a3e5bbc7a7eaf6eff3f0e", "35150": "5369767433916f626fd5422d4ba69282a9e4bed5", "35151": "c9b863373d39aa74e9665fcfe4ef49363bc7e75f", "35152": "f218fa3ebf144386cb4393f1759b5bfae3525715", "35158": "b3b1bebded4c20564cd54224bbdc451a7544bfe5", "35159": "2faf70916800ecf6fcf98eb3efa0a04f9bc8ea69", "35160": "3ee0585c034a34ceb75fc708fa5ac34e49ae26ca", "35161": "23a17670059ef8d6eb8d3bab40bd4de7b96d5055", "35162": "1a4ac0ecb8073dcd996cf908816d68c5790fc9ac", "35163": "dfc4c3900a181e8a9dff724217d5a14e59ca2e4f", "35164": "b8e4a3e43098ee3fe460c6b8ab1ed60e16a64b3e", "35165": "e4b085c61c80deac765359f57046756c0731174b", "35167": "474c1e20b99f963a7f03884f9b8cb242d48358fa", "35168": "4107aba5c994fdae0016cfbef0e1b4c811755d3e", "35169": "f49cd3b2011c22de922b7d9b1bebbc95c656b5e9", "35170": "d2f05c2d237d8d23781f3aeaa12051ef4b4389af", "35171": "ee5cf2cf2e39b0586c40729417302fa8ea1402d9", "35172": "c9a8f95f3ccfed00ba600aa8eb0789261854614c", "35173": "317290a32398a685186bc4b593c8e73275268ecd", "35174": "edc087025f55152761d2e6a5be3cb6954948f02a", "35175": "e35916da65558fe140df80355ca70d70d3dda0f5", "35176": "4f55280decaee1d0d1373fe2258f9667c07baf47", "35177": "577bb7239cfb7ea301c9003b9fc1c7e43c0fbbfb", "35178": "498c4380293f8580eb779bd49c860a7688572886", "35179": "7b48899aa2fd2d0a9c5d279db915e73657a371d8", "35180": "b8e14ec56b303a54b77ec6491d0916a6815b7337", "35181": "0e8c730fd8346a9872199c55cac01750f0f761cd", "35182": "ed255326ac000e637a138298f7029cdf532c1754", "35183": "3fb33d67e3f0e796ccab48338af32bc491f061bf", "35186": "a32a328e5830a1582b5bd2d840b5c7374649edf1", "35187": "6f419a8db79f667f591af67770f7d8f39aab2976", "35188": "c6353c49e2691a356e774cef52ea293c56a96899", "35189": "a45c2353e57f4634188b9d207203e60271ffe420", "35190": "ccd41e45cf20ff67ef4ecec272c14b94af16ef4c", "35191": "a6f5705e5a77a561ad63b1bfaf0dc8ad0a018e7d", "35192": "075c6c01210eb370fb86fbec93bbca4d1caedd43", "35193": "6a40f3b5443ef96775042e5c52db47802ca0d58c", "35194": "d75e26b922ba1bc4f272f9ebf4e1d46572b1e183", "35195": "aefede93b1c2b0a2e311220bfdd8c1af97a92441", "35196": "564b7d2e6334ec7077c97f8a50a2a0de3ad11e31", "35197": "829cf60da405249549fed654171f4793299bb597", "35198": "12c23c27fadd7ce8c988a9cfa59099f70d9f4f53", "35202": "fe1a81e7a0e20b0ddbb246c88deab95aa262dd39", "35203": "41ab6afdaa0cf87966af2a556d8dec0c68311aff", "35204": "d1dd468272f3272dfde78cf8446a8a940427a978", "35205": "ed487e00e7bf3d2bcbfd9b05e718bbe5243e21cb", "35206": "069554ad791702a6c3af569ffc495b43111d5885", "35214": "206eb021b2b62c905e8c5c85f8728125e26efd52", "35215": "b91d7f0daa2e0480f93078c48f0ad5165453418c", "35216": "2bb3557ac2be0a8ce9d8f416fe04087332862cb6", "35217": "e8961f1c03960394e0fd19b91f3d700e2910ce2f", "35218": "435762115d960a7a22d9fab738181a8b1908efa0", "35227": "90d9e2553b41a8a10354aa3ae8a340d47b8e6ba6", "35228": "5e97e6761fde7b0b1aedbbb3705bce62fc4c9956", "35229": "11cdde6f43f7b42f2a8a2417c1448439919f8235", "35230": "3d11282602c521d309e186fc19e026a5d2c3c028", "35231": "7cde20b7315f208062392d927e621aabf2899dd9", "35234": "c93e8034a13d3dbe2358b1b2f868a0d54d1034a7", "35235": "9db9baa775bee54fc1c74106ae3e6cb7b3f363a9", "35236": "1553ec33a6f75943c3295ccc3e39a3a0a7bf3d47", "35237": "42e489cc8b2ab44f52d78df25a2055a1243b8791", "35238": "c30626e2ae0542f3e27a19c814f405d5e93043f5", "35242": "fb6f704b4002f306a38e81f10986a6e12e997ed1", "35243": "292eb326f3762161ed1208bfd723210b77e2f432", "35244": "46386f0e97c14d7d1daad662977a26402e0cf468", "35245": "263828c164ae00fa8bd76f7c1eea6f1809acbeaf", "35246": "3fe61491a556d35ed2882dee940a4b7f62bb286e", "35247": "d208d64a1ea38dd5c65bc20f5ff447236ef35719", "35248": "96ba7179ea018daa29b50f63194b7b0c46345f30", "35249": "232d84e9a5add831c753e67f1c88863442dc3c92", "35250": "0d0073afa470fdbe503b47b4cfcf973d55c27afc", "35251": "818618e97d5f6ac4ed0f97f2b3f9af24346ea93a", "35252": "eaddc1d4815b96f2cdee038c6e26fe7fc9084f13", "35253": "152595cae908836f90b3c2b89ce21eb0c8777dd0", "35254": "6ffa4b7223e8cea3c357747ea71544bec83f6e50", "35255": "92d1d6a210f138bf368b189db2714839f5cf762a", "35256": "a3d6c3690a2af4527f944d8f1fb343a2eb8f7dfe", "35257": "a15711d21dd3f491620455fff2a9dade53077761", "35258": "08019533baf7cc07368c689753fdf801bef3abe6", "35259": "782f438e666ccb5c46cdb65f774d5dbd3c31eb18", "35269": "6cf13f364e22f6ecd705c6479f9a7b2b5fa1c994", "35270": "5be43398c2a9c8dbef58cc7f271297794923a4d8", "35271": "39f9b338480f6833e93e45312b923595a4bc2cb8", "35272": "23b3ac8433cbcb93b2b72fcea9646ce20fbb852d", "35273": "7bc2000827d1a3f00bc3aeaea24ee966ab4183aa", "35274": "3d67c31efb3ac12422cbdf9b9711ee7f0df6235f", "35279": "dd742d62193cd68c54f0f274dca964b562541af7", "35280": "3cc06796ef32e712ca499237c27747f569ae1be3", "35281": "315797c4093505da850367c70fa40ec73675c770", "35282": "befc7ea10356d23434e3a2c0b20064ed74ef79e3", "35283": "71a6d53fcf13063b0ca2d817f69035c3cee47c92", "35284": "24c0c1ab7c8efb33522911a4f55f01ebc3d36da8", "35285": "6704f6b8910678e1200e90b13145b1f56ff65fc5", "35286": "22a038e8c3443c983b90e9878a94327fdd1c284f", "35287": "5a54a81dd5d79e8dbc83a2c1776552cf793f3e2c", "35288": "b864b8eb54605124827e6af84aa7fbc816cfc1e0", "35289": "fac929faf1f95856337c3585d2e5d23ba87d9d81", "35290": "78c79b9a143e12c696b4c92eb1d70e4eb6bc3686", "35291": "80753e2b4e336f56e3c31587cf0d3520093a4796", "35292": "0128a5ba52eee74a2f6159334212284e7b89a2e3", "35293": "809f3710807efedc684c8f0ed4adef8d01af3171", "35294": "bbe11b27c4c33bee844d36203158e4f36e7f506d", "35295": "5f672dc70479de509f7f10f9f39f27539c2defa3", "35296": "9b1d261a7bec3f03c67f94c5ccf2e1aa97e9d203", "35297": "a68b97d438c89ec1052a6f313a9131895663adc3", "35298": "2451b420d7bd783763971230726616e94ff24904", "35299": "c1e309baec8c0590386c91e2940941138d802079", "35300": "bc51b2fccd018582830be87723f50af886839b74", "35301": "10bede8d1f8062cbd4f0b7b7094821cf48f61030", "35302": "3efebd4885d216ab655980f9d66ebce1434ec8d7", "35303": "cf741a492eb45603eee177d847ecfcd8dbdb6488", "35304": "79ce72bacb092c6e0e6410d1b665ebd77c6864a3", "35305": "c54ceec14cc2474f8a996a031dae5427b6f01627", "35306": "224457d89ef127b62b85c3e4ac4e821fdcf65bce", "35307": "f935543555ddb61619f500718ea8fd33810b0c9d", "35308": "a936863759b56f4452d20eaf195404044ec97e5b", "35309": "1ca117bca00449bc6397dae7600d4f7e16d38fcf", "35311": "3522b41f5cbdf697d8ae320931e76eb484ac6a0d", "35312": "cffcfed01278c7a3b56dd40da8d49953b2402813", "35313": "fa9e462f87c0904eab057241e3b1c92bb8b7e09e", "35314": "40df396648b29f27af87c1efe39421f5d3d955e0", "35315": "57c79433a5c9d5628f030a3a85bbcc0d9798d6f0", "35316": "b0e1130c658a7a9420df06d23ef6475033b9114c", "35317": "dae4fb4a025f387cdc85ec39f47d195cc3a51134", "35318": "70cd5c0cbf692c46abb100c00e8663fe307b3d03", "35319": "5122e68b237f97a4acbaafa0b937e56695082b85", "35320": "0e196b029d46ced589d6ad241c9fd8d16ab0a9e6", "35324": "0582e35aa064ecd3a054853ed2fc5d4ef9fcc847", "35325": "3edb82b8e0c3d7f8cd1894f999bf0695deb1a4ff", "35326": "906471e23e597b7326db17cab3bc826bad598059", "35327": "1b2d39cbfc3db9520e0f5455a4eb3da0f569fa0f", "35328": "49ca01ba9023b677f2b2d1c42e99f45595258b74", "35329": "62227895d26bfccfc78260ce0dddaebeab0672fe", "35330": "50910f9cdd69b09db52bf1b4c58353ff781edf5d", "35331": "1f94a1be0135be708541cd1fb9e877313b8676c0", "35335": "14050366fe8da5bc0bf490d6d130f90cbb283854", "35336": "6b69f5b725f0593ae61aaa53b9fe268a37cc13c6", "35338": "582a1be48dcba788f3c6d9e1c96d7971cdc79cc5", "35340": "19c8a4a26b466098c000883ad8de3f8c5e6db439", "35342": "c28c14fde3e8d33b47e36f8358e771f3d5a2e8b1", "35343": "fc308235f0ca6242a209c1fe19f71884fb5d50cd", "35347": "3e562ddba3631d26f13883af6fd2ee6f42297f90", "35350": "1bffa5efb681de87d20aa41119aa9185387e0db4", "35351": "bdd44e9bba78bb50121dc64a2a5a8cd8f3e98b25", "35352": "4cb2418175345b467dee217acac929a476feeaa1", "35353": "0a090066f4b1b1fa9c11e8d4f2e17ed9733c90e1", "35354": "1c5c4efbad2873d137089a1fd32267f40c966850", "35359": "31da913805e31743882fc37f51bd5108ec0407c4", "35360": "16ccbca475695acf85f2aef00b74fe533b2c37c5", "35361": "203f4834020ae2004df1a62f0c68c2e95bd9bdb0", "35362": "b6333e609fa206b6114b58d76a82d7d43452a873", "35363": "ff8617732b61e514ee687db6b8b049bb53ee7b92", "35364": "786716acaf61629681861ac61a74bf9f795a4158", "35365": "e92ea577ccce3ae8cc7da2baba44d72854f4947f", "35368": "7c9ba89c8ca8bb0f71a3fd1467b61d515611b361", "35370": "3b34c3bf395d75c5f2844f45c1b4dae767626b41", "35371": "4efc97c3b5700abc2d229f71f527a72ee2e52030", "35372": "cf7f0af69931f5a7d9c0af75194bf01e46dd42d3", "35374": "7ff13b468a1c13a1c14b61bfc454e97f5b650717", "35375": "2c4c072ade78b96a9eb05097a5fcf4347a3768f3", "35376": "8335019408932bf02e2940cad52705ce2277e8ef", "35377": "77bc67a3a794cc4d7cf3c318e70292fceb65eab7", "35378": "d8d45223195aa16fce4fd8208e3ddedf7edf6a5c", "35379": "934eebb532cf50e872f40638a788000be6e4dda4", "35382": "67b19eb88616af20c46b187e7f48a4ede840c896", "35383": "92f46fce00ffb0f50f9509f01b88ea83b4154cc0", "35384": "38761f60259b88b6ff151b3b882a8cc2584a3568", "35385": "d5a5a4d306edde37f65b678b6d92e4fd11e1f5cf", "35386": "eb98a4710b022830c8a56db57dd63d5f6db815c8", "35387": "70f90b7020370fe257e308169bb9363fdadec215", "35388": "58342662b66235a76342c0510e314bfefabb00eb", "35389": "9d70a4956e280d3ed9e44ab7c3dcc6f28e77760d", "35390": "7915acbd3fb1006b1b0a9e94b316c5538e546f1d", "35391": "14a6c9ac6873c8afe519a8b47481a12f2f66c5d2", "35394": "8af96fc3ff51bf2686f9e24029ab615fe2a5e089", "35402": "8d509409a6d3aae41d0545eb3b6ef44b630b055d", "35403": "13e034aaf68894079c61ace35e2f9d541fd64a1e", "35404": "dbe3278bebdb3e315904833a90f15c81c19685ee", "35405": "3060df9bc45c739c74be131af6a084701697e646", "35407": "61e54c2025ad8cbd63ad0919fb7447b25592d538", "35409": "43691a2f5d235b08f0f3aa813d8fdcb7c4ce1e47", "35410": "f5a8ccebf1ed67219ab8076f53a27ce4b94c15a5", "35411": "cc76b5207c30e86078cb14b2cc01cde0956bc6fc", "35412": "1845699d38c9fb2f6645657814dfa8146923c43a", "35421": "47ae3f0a40ea83b2275b3f8e88b723718a1f1a24", "35422": "cbe88f3c231308b91c68c866a103f10fc0dc13be", "35423": "b4b96fb30d21b77d2a7ea67aa4906b69b7e62147", "35424": "5e577342bc65354c54aa3174619783643ed23f45", "35425": "9268055a59d8f0eea61da6e845154529378dd97e", "35432": "563aad38f0b9854635d6d80ee48935025d14cd6d", "35433": "a38a583476934cb3cbd91224d16babf869dfee2d", "35435": "65f22a0c037df3cf360ba568465397c52293ef7d", "35436": "e8b9749ff9582574fb08b2d2108b83e6371681aa", "35437": "f9f164339c487995b197bac7ea34ff4dfa66cce1", "35440": "a44a8e12d1cd7b99a63f68f9ae0f5b51cd867782", "35441": "455699531241fe7401a3eb884851270e77f47b79", "35442": "febc1bdc3872625112a8416cd3d0e2c984d9ef72", "35443": "3948d2e105f6cc3c5be387bdbc0c8e5304ca6477", "35444": "00f79a33f07d84192519165d29e028b26b874ec1", "35448": "867cae32585b552b8a79b044248671ed54beabca", "35522": "3c041bc14ba88a6dd67ff3a032afa32379869332", "35525": "ba1cccd19da778f0c3a7d6a885685da16a072870", "35526": "b7319c1c1c46fa9f24a813d3707291f8371061d1", "35527": "d60c7d2c5e7957cd8de81d0377d4bb97427eb41f", "35528": "609c3b74b0da87e5c1f36bcf4f6b490ac94413a0", "35529": "2bca01853c84d6b18b3e841f70e574de819857df", "35530": "d822963451976c55543db50227a61197475c1b9b", "35531": "413d92d4711e4489f1d8f51b5f62744e228bceda", "35532": "65766fb14e96b31b217f4e56d7f6199a710e088d", "35533": "b12fa3d6e7ac2ed8d9d6c007d0eb0de42bf9834d", "35535": "6884d1c6fdf28c63cb2b538ee7b48fbadd95d284", "35537": "1e482ded046be87115da77453c0448182747622a", "35538": "ecc1049cd188e986c425c48a28ce4a08ab319480", "35539": "e3e1325efadaf5fb4b5b09c180e8a3bc9732de68", "35540": "eafceae6e889b74b0eeaf1c74c27e46e49ca5b4c", "35543": "a720c69a23089293e91ff632e58e15fa21b4e632", "35544": "93359af1b6fed972c7dea0012903c8e312e1e53e", "35546": "75781c26d174b35a8ce3e788201bc949fb92be02", "35547": "bb088171c2025b41bcb6b6db1fcf0f10bb8828a1", "35548": "80a1a8bc3e07972376284ffce425a2abd1e58604", "35554": "3fbb030f59d6a22ccb2b878f1c64d53fbd5e75b5", "35555": "18315c5830459535ea8471e66e82fafa4c538e08", "35556": "bc2888d67d008b32c6f4e12af0b50201488e2c94", "35557": "ace97f9f044237b834c5e7072bd5eeb5f6a76fa7", "35558": "b5854c406d0e61781350450ee416a66a495b3b07", "35561": "ac8d34dd9a3a05bf0c5108e808d3ab0a4e80a93b", "35562": "53243e8ec73ecf5035a63f426a9c703d6835e9a7", "35563": "51135cec59f333b61932bde5b1b99f9c5a92d3cd", "35566": "1e72b2be10a8822bc6ad8949d5a41f8e9cdfb3ed", "35567": "7688d52d15e9f9502cb033c0668853e4cc33bb3c", "35568": "153952642ccc1413a120e957814247322789a4eb", "35573": "1605bdfd40dbd4bc68ef9148792bbdec919cfc5f", "35574": "c866a4ad6b419f33bc004513a41b3b64e0b587f6", "35576": "4b456e23278b2e92b13e5c2bd2a5e621a8057bd1", "35577": "4d3b536975a285b180b5fc5f6d1b77700ea5d256", "35578": "31d4d8b547d1872de2fc10351c3f906d68a9c48a", "35579": "982d619bddbf85a905b4ec1e719275e2ab4f833d", "35580": "e30e5f85c2e28aedb6273116f1e112c1ecc859f0", "35581": "f03482094a6f17cedf1e0db3bc474ff4944a518f", "35582": "4683e920434cbc2ee9e797e106d616c74f72afd0", "35586": "00bf889426ac40426cec0b4d71eb361a24ad1a8f", "35587": "e1ec244688b80b52456264285033659bed01ffcd", "35588": "e7a1f9ddc88a32fe1c9f4379f9344595137f8d20", "35589": "a317995665c5185a7a31316555d34fe5653941fc", "35590": "e6814133c3df0948d5fb10a01074cea569a852fe", "35592": "1b3ebe4656fca6607738851e46eaa53a9f970293", "35593": "da849a95646717013c93838cc798dcc31aee2290", "35599": "876d7858721b4f364f431d38f849594aa0eadc7e", "35600": "a7005e0343cdfa682593400ed96fc72ddad629a1", "35601": "e5f81ac8a2645316a42db6348d2e5dc699f10783", "35602": "f87b7e309ff34541158fe06cc0c915c09fa37c37", "35603": "6cb1da95fcd2df9689f5c957a85c299d67b9aec9", "35604": "3e1dc77866d3313f85564e7c67f8e6f7339c2cc6", "35605": "1aa885730ae3e01bb7123059d59220e67012343b", "35606": "88683e9dbc4ba2fe7b1185d88b538e2bbb2d3601", "35607": "faeedade7966d6f2a5b601c26205a71362913c47", "35609": "cf6100b2aa8f2210fc60c34865587c4c24d42582", "35610": "c118953c380ed82b01e57caee4b8b58f993760f4", "35611": "ba1e73500756fab064b83e6421ae7f42dffe55f8", "35612": "b1e9b58340110b63dc74f5c5b5de4aaa8db184fa", "35613": "a7cb22631dd607f8c36292118c69cbd7bed1485c", "35614": "cea0cc0a54725ed234e2f51cc21a1182674a6032", "35615": "d04747c367d00ee03c5d008ce5670892d450e801", "35620": "3334832eb9a8dec8928e197a2930dba018dd6160", "35621": "5c7abca175c92f2dab7331e9f63a58b4e0d29c7a", "35623": "711fea0bdb216f9c489a70829393e0a26671d779", "35624": "5cf6e74e198ba34c8f64bed32082fddc2292986d", "35625": "9aa3f95a87eab4afe5dbd8cba8cd99432ec12899", "35627": "723feb984e6516e3e1798d3c4440c844b12ea18f", "35629": "20e87cb343a18d6af4085ab6b368d433ca07be8d", "35630": "a0d4725dd14176602761a3b8edd7d6c0ce41aa08", "35631": "8929630664bd6d4898de7c6309759ce21b9818a1", "35632": "debf5ace2e63b09901ec11bc9d533a9e9b40545c", "35633": "aadd9e3a13660a7ac0b11730130447e5b07c01d1", "35634": "ce5fdf0f55f47014240931a1f975f65767c2442a", "35635": "417a5e7fcfdc36385c0599f40bd1b0b8e96a3720", "35636": "705d4312cf1d94ef2497bcd8091e0eabd1085f4a", "35639": "79067a76adc448d17210f2cf4a858b0eb853be4c", "35640": "0bdbc44babac09225bdde02b642252ce054723e3", "35641": "67b1e8b1f1fbf98c8e4e10473e6ac691d515593e", "35642": "310f8a8a31dd88a55641ce742c7d13a2a8b0e238", "35643": "4e28925751491581a8bf92531714204f2a68dcde", "35645": "13b132e7d154cee2b6daf3133a283d745fee4def", "35646": "51c2300210533a27fbd8bb58f93c2f382bbbdc40", "35647": "81fb7e76073ffe6adb875f15cdcfbac52c15b339", "35648": "f00efd0344bd4e22cc867e76c776cb88669e6cde", "35649": "7134f2c14e614980bcf366f979a0f85aafacbde6", "35650": "cc58350c92a9e24bef586cd1b898c01640b33abc", "35651": "85062f0e09590b7da3edfe1cabd427f224180b9e", "35652": "7b4df5a0b7a58566c673bd32e7280ce74a95fcb9", "35655": "52bed6dfa9ba99df21fba2740da2a5a2832ef96c", "35656": "f4f598fb36c0809da01cade2d5d832ee09564101", "35657": "36aa531b0f0e31cac32e56633ab90eb4b3fccda8", "35663": "e0c5b87850f924a2e7ab680979c628784d96181b", "35664": "271144ae64d44399e9e23d147aa83281925a21fc", "35665": "66a49457900a6b50b9d2bf2bcf6664ef7351475b", "35666": "95b6057ebd5d774bf5f3ab90514fe5fcee2cbe90", "35667": "1496630d35337425d860128cad2e8bc624b9b25d", "35670": "025e6ae2e9de9036c0b64f9f6571f00888b9f403", "35671": "68268458ae3091875841b750c9763e64de835e2f", "35672": "6b3e66b53d10e19e83b51f14a66a335d5ff3394b", "35673": "ebca6dfb8f159ddc00081a463a6d9eda0fc96d8c", "35675": "df7c0b772c775a65ae5fa2dae3ac192060ea2fae", "35678": "20949e287d2688ef3e0e76bb39143db42fcbb813", "35679": "696d21b5fea1c768ee833c3f67db321f9d329921", "35680": "ef5c01673510341d9045d492027c46ccaa246f13", "35681": "cb5b2e6f5280df2d26b0a9550828c4bdf1098053", "35682": "f1bf7d4b30a162d7b52417c918e3cf1cc6c14863", "35683": "6d58277feef818bb488dbd437f71aaf0bfb5e412", "35685": "5d8cacda9dd086e340c0cb39e546070d6d313472", "35686": "49c89d292c343617f417aaccc6cd564f1a42207c", "35687": "b303665df0337448abbc6e3107be1f0ff7c98fb5", "35688": "d303b7cb76d099e77eaf9afd7ae33030c39a33f6", "35689": "9dc5163f93db643a764976c52bf76ee6c2ad817a", "35693": "c4efa9203ef7e13a797058600010876fdee7eee6", "35698": "8371d18218f854fce4c22104eb78eee9c14c62d8", "35699": "61a6335263c6dfc5909357584ba33967a69c9b16", "35700": "a98be065e365c3d673d759414586345b14de50ac", "35701": "28f274cb107ef0a252eb4cb954c1cfbe43968395", "35703": "e86ed377639948c64c429059127bcf5b359ab6be", "35704": "2a08b052305ed35150d1355bc537548bec697778", "35705": "52036d9f67ad00be7fcf81e0dbf9159f74dd7853", "35706": "b43d79d5cb7d9797321f3c7252206b0078124c47", "35707": "2d16863717c82457522aa915249ba185df79a9c2", "35708": "ee9a736c723f0d6b7097cd608d57a977e8285a77", "35709": "cae3f16986e73d2dc9a245a52149d8aec1307ab2", "35710": "f19f81fc1ed21a797ada3ede1c17645d12cc261f", "35711": "d9a2ad17f8a34f9aa954b43ee52c3e0ccc0fe2b4", "35713": "9e1096e8373bc99675fd1b3490cfb7cf26041395", "35714": "d01669f5cdfff4edc889994331901b1f97946fdd", "35716": "37221468b5ed118595606d4b0e67321b163a8b09", "35717": "f9ade667e2ebc6cc1731065ccbf40d4e70d9c3b5", "35718": "bdc2cd4c6423c23e8796d80b589dea937fffc2aa", "35719": "ce814c211c787216f10d251081d44ea8996ca9f7", "35720": "2e3cb7685887f94997b9b83d0662aeb7a406e665", "35721": "764c460cdd1d14dfa9a28d9367ab9874ac8037ba", "35723": "89bd5695df3ccf5b9186b4645118656656831593", "35725": "1f167626987f0d87970f966a083124b8d1fe6ade", "35726": "98f5a787940e02966f2747edbcbd992f0031c277", "35727": "61d2056e4251b8d1c387f2577f0407062b9ab903", "35729": "824a2738dc0b2cdd8dce2d4256c9dc34bb589e6b", "35730": "69b5d5ae40cd544ba6e47dc9ba715f0e8951ac46", "35731": "8f20e82c4eee12d605ad4eb9d49b4fc37069e2dd", "35732": "c8e7a98d6e8ef88d2c397d524dcfdb302f6fb4c8", "35733": "6f0cd8d9ed251aa80f7415c565176fc33487110a", "35735": "0db27c0df815718bb4cb31ae69dddfc68828bc69", "35736": "9282d9ff003f9a116110f6fc21c7c181d7c6109f", "35740": "cd8516aa93159c7d97df3c285d3709e890df3063", "35741": "618bf88acb4325ef92719829d885c2727489df73", "35742": "71062f6c4ba78c2408993698d135795632b88e93", "35743": "f4427918624e21faac3b31725a357e55f8292821", "35744": "7e681836d46fdcd4aa72cc0538f3ebf86516975d", "35747": "6e6a6831aaa2d1606aa897b34f106e655180034b", "35748": "3bf0f647ca42bf21de76f9e6027de38cb5589147", "35750": "06a54adb45bd9c94ad460de09f942aa331814096", "35751": "59616c57d6abcf0fb4eb5f81928120c7b000ba88", "35754": "7df42118d2fca966c86a75ac6bf2c1d0df718eae", "35755": "f196319e52b5823e89648af0c9d26dfdbe821d0c", "35756": "8664572fe63dbcb865588d9d564b49a572c3351e", "35759": "22452174d44fd9821289e823e5d3bce21cd68315", "35760": "4976b692ce638594046d79becadb692576fade33", "35762": "1c1bb854cce61a8d653c468bcce70db84ac07cf9", "35763": "6b84daa3be369d9032cb2965d539407b9b98ff45", "35764": "6a83910674a2be1f95d75cfd935fdff22b09bd33", "35773": "364c9cb65acf47119dc251b25226ab415cc9a100", "35774": "4145278fa169a79fb44db15c563091e695c54d64", "35775": "6d4819bb01276a86657a83f7251104f550ceb1f8", "35777": "a5c79461f8a5cf252ea83aec90c2eb9c89fe93a0", "35778": "d943c26c8587d1410eccb557db436d97b52b51b8", "35780": "6c58a217f5d9a2520d9d4bee665edff5397bbfc6", "35781": "e4b7174137476e2c1d31ac12067a0565bbf7f262", "35782": "940a1b4fafdeca220dc24f15555f6c334dd3d864", "35783": "a76b3f4c73a351a11d2cae6236773192e630d4f5", "35784": "40f219ccf74182843cb87e6d00f1af4736105987", "35785": "7ec95e4be4b814b92b671a91d544feee2a106d87", "35787": "494df5c767656a7108dc3100a04f785eaf8dc567", "35788": "c18ae3b2e5706031f1b03a00e1038dd4020af767", "35789": "40c2d4d8c00a3be74a5a81bc565ae6c6d8e6bebb", "35790": "a6893c1dd7c2c4a91657742346750628c0afd7e2", "35791": "e4635ac3d3982bd9b3872b21ad8390bde312d226", "35792": "29834640fc3d1c7a3cd6e255ffaa9126ebae8328", "35793": "1681cc79d2af88e4f70152a8f8a4caa671fd6b5b", "35794": "21689e5fabf1a75f66948d5da35aa4cef97af416", "35796": "43332c279ef013bae8f11992a7e903cd8c90ccb3", "35797": "fe5f0c97ef71f2cd7a0657155a3e7d5ee7c65092", "35798": "a0babcb2c63dd721ea47e75f6229c5fe727b2395", "35799": "3fac6f26927a67718afafc42facfb199987c8548", "35800": "cbac7cdecd45e2fc07a0a187b8591bada7e75736", "35802": "288ab31ce5696c4207dce9f48b41de2a4ba9bb9d", "35803": "a984fed0d734bfb1f10104b0c1f9de737cd70013", "35806": "fa96a52d7cb7ad44267db57fa0803c7e4fd52b7d", "35807": "42282ce514e1dd265aad0c80b4a4610e4254be97", "35808": "dc3035da0aee23089a66b7f01bb2f1ee76d3f7be", "35809": "361b62ecc2327c8cf0b6173482e1edd1641c54bb", "35810": "e74138cb1cd02211ecfa68e8ca187dcfc381f5f5", "35812": "1ab06f85be101a0e9ea7e5b129398a8f5f6ef6da", "35814": "2a65fdd227734cbda5d8e33171e857ab4aaeb9d5", "35815": "f7b49d8eac88f9db365def1cd2babe03b84dadf4", "35816": "1025151f71cb4f0efa1fd935e41d943428bd3d33", "35817": "e22bfb3e1721d602086c0ca0b3af311cbe84cd9b", "35818": "66a54a37d843cb641bfd4f694946e63a49124b3d", "35819": "b284101fbcfede2ce805324407a2a3072f640fa6", "35820": "6786846764cd9cf9d5041e5bdc86430be38eeb8e", "35821": "943c3cb38d23e60905891724f878b91483597c83", "35822": "c9a98f0f0fe3a1ff2ce549b2f2c7551cc9afc58a", "35823": "7e8148f4ff44482b8541959d5e095fef00adad23", "35824": "7ef617e88e1e51bbfd5d0cf71f57ef4502b91b38", "35825": "ae177e88472a0f71e4fa8d41e773f6fb7029a8dc", "35826": "9de2a19b9651336cc14a2830c8460e9ad1e2d505", "35827": "fe07fd5a201c551df679053fbe068302a1337a4a", "35829": "579b8268474c5c89133ae7106a323dd94e1e33fa", "35830": "c1d36044bd80e987105518a8986b016f7b54d584", "35831": "e1368cfd506a782f386a0c3afe02b32c31e2856e", "35832": "abba4e2df1ba1651f89ca4b02f8eeeffc17375c2", "35833": "2f3b0eda7231f33131c5fabf065483e61ac1ea59", "35834": "b5b8be04b2a63fc02e89650a740779e718d7a99b", "35835": "0021d241c6aa1b8db91151361b48d7864201fd01", "35836": "10cf330662b34a2686722abe5fab35009fb3ee9a", "35837": "68e3c4b2f855e6e9a8469aeca6eb73ae60327160", "35838": "7b8c6f6b410331f7b83348cb5f8812a58dab2b39", "35842": "e0d6051f985994e594b07a2b93b9ca2eff43eae4", "35843": "e61a0a8a9de56a2876a4468aed25b8a49608b660", "35844": "5bfb41f66388bfb46ad7025c954354562193c7f0", "35845": "ea14a466799fe6c2ba42dc468cda5212ea431026", "35846": "32c9c8feaf46d85119d66ddb09a4b69b28721c50", "35847": "746e5eee860b6e143c33c9b985e095dac2e42677", "35849": "bd5455e95534174a6f151c1e54ca07aac34e9c38", "35850": "87386359a169ab0d761373bd8cb95d7d13fa0595", "35851": "a83f6aae255d7d88fe26ac12565c26253a95751b", "35852": "3ccdc5b662b72ff9c573b1de4b450d262f2278bb", "35853": "b2a622e6f3f5c61dae62b0ed71ebc0006188a91b", "35854": "910fa77ca5fbe4c70aee828f9fd2cdbeea660e8c", "35856": "59d4e84128eceea8c37066e588e7b9daa0994630", "35858": "a9fce50ffa393c3ef247fc75ee86a8847a303555", "35859": "864596b26ca31d341203dd8ff37c39a88de08ad0", "35861": "940ea7a4f8ecbdfbf1a398649c3ccfe9705ede49", "35862": "820d5a902f50b076d10fbc97a2b50d4d2995cd4e", "35864": "ca39324dcd1af36a3dbc2773e904d518ebd247c6", "35865": "c31c6bacb324da14177f254cab555e5e312cc71b", "35866": "c0a1e2a2388b7dfb7582746aeffa2cfd5ca2e9f8", "35867": "192aec7943cf74621253dbcbfa039bee73fbca24", "35868": "c9dc91d8ed61317a6a62702546c6ff59d5f68044", "35870": "b3fa178b094d3efb6f24e514a964e1fe06b64a7f", "35872": "70a11418a7626d4f251580700e1f4d401ebf933f", "35873": "503e8e86604c82cdb5d3ea899ce9a3201d5b8080", "35874": "a5e55fb563b1c8ebf615c14c10229dcf48211b80", "35876": "52cdc34da70472c3c2eff44ce697b730d4013481", "35877": "af5fa36d9e754cd233aedab8673bed8e85e6eef7", "35878": "00f10db680c6cf836fad80dda33849081e540230", "35880": "c072ffbfc02032919f54d9ef194c1edf7b73b1ea", "35881": "3a90faa99186ae3b349d480f289f0341154c35b6", "35882": "839ed72f3de11ea4309ad66cd35a06b45afdc387", "35885": "5c7d89db4583bfa8cf628235f4d566d104776278", "35889": "fdcdd4c2dc4f7ab049879cbaa64cfc430b0b86d9", "35890": "b3a4b9740e4d1c864f8977ab81027db0686063fe", "35891": "ad3f3f78b02d84a3a89907094e5a5702d3288a20", "35892": "206f9812cb6197cf65fdad9d7aa1cb62df4090b3", "35893": "ac5587cf092315d5cd30612e25c10c4c0325b107", "35895": "b57080bf216582454e379a4e702fd7246dfbb8c4", "35896": "599058a32003363c6c19779b41c69539cd0dc885", "35898": "54fe86a4caa17b22007701f3ce35da5bdcd9c00b", "35899": "df828190a434b5e6f7870b2874bef126d7881a7b", "35901": "ea65f90ec60bc596872bfe92e7b7cd135608bc85", "35902": "0c7d303853070cd85dddfa08a0f2ca151fa9653a", "35903": "f64c60850b524c39d70c963ec39a6d92f3b6d7ee", "35904": "2b6af64bb034c28727c399eed41d622c339e63a0", "35905": "03a49813074c84665c9ea611c56bb0059f434227", "35906": "625d8d6e53b11f8099eb8987e030e28cdb972747", "35907": "92d261159515618fe5a7d18968caf77948d9d90f", "35908": "0de3bcbcb5bf3010173d478f4c327e4defcbe6b2", "35909": "8b7fd0d7ea13d83adac001fd95d2fa372e301d0b", "35910": "e7d2c7a537d1aebf7b93acb4c75b49e73dd8b600", "35913": "7959578c73d3cad1c5820f51dfefa4e442d39b2a", "35914": "6f950c1c36eecce7aad3527b20da25943ebb028d", "35915": "d3956ec20cb75dde25c1ef5a0597667ee5462bd6", "35916": "5622b1bf85fec3f226412a0df59c5f971b67bed0", "35917": "e48df1cf18cb1a5d21085e55dd05d0b6c988ab51", "35921": "bb2d2e00524fb31d08a43fc54706035f810d2489", "35922": "029980982e1492d4532019565d6962726e55001e", "35923": "0cd5428d41e1f1f541c49c33265460944712e542", "35924": "8b5ba3c78d476e1018087c8a0e87165132a27592", "35925": "43c7d4023009ceee4ca11f2148a8debd372e437a", "35932": "de50590c7c6cd70606cb2e8db2a78ca3afb0971e", "35933": "2f4c93e8322775a0bb06429a02429b95ba6abb26", "35934": "d6aea32f27df80a2a858c6a61c44354794307bfc", "35935": "455b8681c45ef0c147390c8cc64cbf644bf0d4bc", "35936": "074ab2f87d2aeb9586c90b7266f7f1f4488f1db0", "35938": "fe178189e589711559a3064fcefa4d330b7f41fa", "35939": "54814c3bc022b91447c27e72b8f79cdac1f6df15", "35940": "aeb3644567a10296cc09aed03bf7e0a3780e67ee", "35945": "8afd868106dec889df89e3abed36af09bb7ddf8c", "35946": "05f2f715c4b2c26d9ec5f02acdff258023b0f741", "35947": "5e872ce6380a09e6c7515525556eaf7b96b9ca31", "35948": "d7b94432377d5a4e9ce539002ca0c4c57e9caaaa", "35949": "0cbe41ad0bab42fa6fc8694adcf6db3804447740", "35952": "a60ad39b4a9febdea9a59d602dad44b1538b0ea5", "35954": "ccca5df8259923430a2fbf17989cfe4be306660c", "35955": "0a7477bb1a45bfff7cb7d6a48986b6e16d6cb770", "35956": "6ba0d7fdac9b5300577302d2751ec6f310c5fb8c", "35957": "af72b637b952cda75bb76271a39419793c6291aa", "35958": "beed6bc555bd82935257747236b2ef6b65a65bb9", "35959": "b7ab856124254a0f950b32992aacae07421bdc0c", "35961": "c36e302c7b30bc7945119a77f255d0302307847e", "35963": "984d75543fce5c68f0dcc4f0b3500256e4a9c0c9", "35964": "4490da7dc4acfe2d8f0790d2f4b2018f6e9ddf06", "35965": "26412353a0239cfc926dcfbc16a9ad567e968619", "35967": "8425c971974584fdc24db05dc3adbef3d71fcf2b", "35968": "adae693b9f8f18602708e4177de80de9b960fc51", "35969": "5180fee9c5c52151bcdbc428c9cac8cfa940f4a5", "35970": "bd21f6b46c5a7ad9c270d7262eb268228e7e2ba4", "35971": "a39f783c1026aacbbfbaa9767c153bf7b197b9d9", "35972": "192a4e3e5964dcf991db5225bfc4a468e6ea90ed", "35973": "a4aa6998393f1f885cf2a9f74e8411e97f37ad9e", "35977": "f7bda1734cde43adb2e867304668e56e14c17a9f", "35978": "1d20b870141ca303e8546f2d759147875a795c74", "35979": "73e085ec1478f90e3251697d6d9e681713d0e60b", "35980": "0287cdec34bd80f75a4107da703989ec6d8a2074", "35981": "2d2d67db48413fde356bce5c8d376d5b9dd5d0c2", "35982": "964367917906a415a90dfdd76d69057953969fac", "35983": "2f977dc471f4929c3baac2d4c6826ecb51b6cba1", "35984": "4b249748880780f1cc3825ac28b0d5f3179c3c5e", "35985": "386a1eb1d2e9d6109fcaf305752d2e4bb29cc3ee", "35986": "f04da3c1c9f5fd81ce7a04e55a965e4021de2ae9", "35987": "b0a0c6851571016daf8f2fba24c0228bb224a712", "35988": "ecf449b503b51f6344f7dfcaac8d58d2967f52a4", "35989": "eedf0d5cc2801cc3849ec9abb4e8b3f509d91ee9", "35990": "9465449b09668c7fe6081e5ec4f96d5e4287d082", "35991": "589d97d8adc5f04fd212601be2e2adad29aa264d", "35992": "d1b2c44761e96cbab6413897119f113dc7d657b9", "35994": "2f689ff56627eabe981a14ea848a290cba5d7077", "35995": "f3b9309b750985191a7b2fceaef449439e481655", "35996": "ba4322431d1261fa7f4203aafad74621d6f8bc72", "35997": "4e5576d13ab1929aaab9bcc45689939f6d82e178", "35998": "0cdb37c445fc0a0a2144f981fd1acbf4f07d88ee", "35999": "8e0411f70c9d26719cab4004609f602b802316d4", "36000": "2c1d4bb1fd9562d777da6cbcc33d217d5b4d5542", "36001": "dd7441bd4617eb16f21e2e381378a3365599eebe", "36002": "3fd3756d2177b052ad3a3d16419d04833901d297", "36003": "5f5ee751c080df89f68b56ab5c4bf378143b0bdd", "36004": "c2cdeaf3615ee21a2995ee37e14b35175beaae8f", "36005": "407ec334a9f36b06d82e4b49b273bcb66139ef03", "36006": "365448dc665f6d49f3d3071a6c3a04aaccacb3d2", "36007": "32b8cd2c81108dc51d59d2d09287df29d40d255b", "36008": "6493d2a4bcf402d5fcb8b5349e70928d8dbf3344", "36009": "95c2a7d840e7070eef902019ad57b745e7340c2f", "36011": "e31a6865958442435ae9b31f312129c44f66eb5e", "36012": "5d82d8bb0e31fed9735efbe76348998c8f959828", "36013": "56a4d57d9ebc17948feee4eb970cfb5a5402f86a", "36014": "2c128531170d9b36954bd5386b62d7edfa7aea6f", "36015": "ef52feaf66386e77436cd326b957b58cb33e0126", "36020": "8c52003df4e00618f53cc4b58916417b6ad6b6a5", "36021": "1ce10d66e2c9c1cf954435c152e976e3cb9da6bf", "36022": "c095a39fd437409462f4b38ecc05b3ec0eb629dc", "36023": "31fde44d6616a7e3c0f184d47ef74be8e3ca72cd", "36024": "bf375608c10a6021c8933939a00c3b733cfee287", "36029": "4377dd10c413ef3e9ea17d3d953206a356385520", "36030": "1307608a8c1cbe88a9002a5fd7ee050593d9a2ad", "36032": "b8fc8cdbf540d7e29e305358c5f2e378a0e9e635", "36033": "0e2277b443bad28c798b36e2db2ebcab84ad8811", "36035": "7b32c179b8b3929a50c783dc8599e2067e56ad8e", "36036": "f2794fd4f90e29e41cdaab205328182e264c8e1c", "36037": "21fa3548fe925bfbe0a3a3b255275b1624c5210e", "36038": "97c61e841b7857fdd50f7ba46b4754a11776e7f0", "36039": "51f3d03087414bdff763d3f45b11e37b2a28ea84", "36041": "bf248a105da7b1993f71a75bc99fa10a5df90a29", "36042": "7ae6b8e164084f0d295af9f531aa412dde73b05f", "36043": "a167f13876870067ba610b808919f6b85b6b761e", "36044": "775f71625b4f70edbf15afa3ca01c1d15488a169", "36045": "95561fc41665d717b7876400d163e8138d9282be", "36046": "7e0d36f2ae1c015643f2aac3e75e40de18e8f2fc", "36047": "14cc1fe1cc383da768c6b19f9ed7ff0bb6630ae1", "36048": "6755b817d5331ce9e8018fa728a348c88eb9c379", "36049": "d73449638820b3ac686cbff82159f85089c99bf6", "36050": "0d786bf6192bda15e61f0eb67782be69fc32bb89", "36051": "5cedf87cccd77c7b4b6aaa64bfec98b32b512f68", "36053": "a41b5450bde541d684d9415bb5fb2b96ef4f4237", "36055": "851fea0ea38985cd7d5e0a3b7a7a7539b5883307", "36057": "af6622522c9d046fd5d031e41181657453ad19ca", "36058": "c6848300ecd23fc7fbf433b628f3f8d5c6c51742", "36060": "09ed69edc3a83141244b3b7e1098d0083c8a9440", "36062": "2a953cf80b77e4348bf50ed724f8abc0d814d9dd", "36063": "d6502124e07d652d133658401b7bae68bb8fb317", "36064": "d9c7b50bd35662c768e0539c28e6ac4e8fd37e7b", "36065": "f66246e63f4004c6f0c400ecbd5ccd22bef407bd", "36066": "ea9c19c7e7fdab2c6e1a5fcb8decf605c13e2023", "36067": "590dfe1b965b923069d86e4a24168fc741bc80f0", "36068": "6296e03ee2a9ca2a8e42606e06d75d146ec1af8c", "36069": "b2d9ec17c52084ee2b629633c9119c01ea11d387", "36070": "17431d24d6da9483a4dfcc08b3508069a1aa76e8", "36071": "8df36a2f9f787af7fcc08326c6d7b3456b3ff0b7", "36073": "0ff8968afa9a5ed0ad988059b7feb52b7b792a72", "36074": "ccc04c468af72adc2d7706e9f93835a3752b8876", "36075": "c0f12a183e58be38cc3eca5dd9fc2d3265972d0c", "36076": "70ce4eb5ce1374e206937e526940921a74b7aa80", "36077": "76d28c7a199bcdb9824b0e3084d846dd65307c44", "36079": "9a40316f095206ae7b7f50a2c5ea42065f3d2b23", "36080": "c4f0e6fce4b92180a87ecfb588245b3ce2d1881d", "36081": "112fd0b5cbf222db44ae6215b30db2d21c718c85", "36082": "feca574525b2c37fac8d1d26bf82d428b95630c8", "36083": "6e4f10b227dc65db95d1d660e1099414f027a793", "36084": "66b52353b6cb27c8cb7ca32055fcc755a5b6946b", "36086": "f777e67d2b29cda5b835d30c855b633269f5e8e8", "36087": "7f0b8907408d0d8986c15c45a7c455cce5472005", "36088": "00d88e93f9dc0e912ece93638cc4b9d73a7551e4", "36091": "a7e4af42d8701787f6caed9c745cb38785b2b92a", "36092": "795357d709ac1a450140cc8d21880d0a356017f6", "36093": "6f04606702deec9df7adb19360d7ddb4cceaf590", "36094": "d7da0e68fcb4101d459a9b979e80558c9bfad4a1", "36095": "e89d18c81b5ca74425f63b189d52b656b963b377", "36096": "55d78caa38925e8cf94623adcd0721cc15a56bdd", "36097": "e477eee4916ab0a867f2755d008dde9cf006f671", "36098": "800ae259494e14287b87773fe5b89a337f444886", "36099": "d999aac09246eb819ba4067e601b6c2c40d82afd", "36100": "55cd96a1aaf255f5b74d4d37bab3fe834d210f98", "36101": "3bb8ad19cec5f785c513ddac9ae6d2b0ade6e04f", "36102": "713c4dc49cdc1be5a6e1de12f4c045c6c662adb6", "36103": "5457e593559048ca32729b75146ea00dcc63cecd", "36104": "4c359a336ccd29a6b1dd4c07871658e27ad9702c", "36105": "500b57c1cdc1bf835b556b5c9b0a3c558f35840a", "36106": "a8b2989d0058632c1353490ff2c55f85c2f5bf85", "36107": "2ab836d87a5330d1a159263c8407934cd669c157", "36108": "640fe265517e902749d5529677345f2930df65e4", "36109": "ffbc9c83b84ec05292470e4c95ca8103fc21b3a1", "36110": "120db4474ee6194efd83cd799565e233c15a84c9", "36115": "02e2baed7769bb62620cfa198f8e4fc302ab145b", "36116": "e5301a8ef999259f23c2603c79e1cc933861a40b", "36117": "4fd56b817935b025d3bdc4582436a3f3c65cfe15", "36118": "c9c58ae092850ef6526e4d185bf9f45923480c70", "36119": "41bb4344327e6dc15b67e530c0aac3517372ba39", "36120": "1d56672407d44bd825c8905d1663e277b244c056", "36121": "089481f2246c7abc2667a6286ad9739dbcf17bee", "36129": "de9815c6c596cda2c06b9e6a1a2fe3b0ca7dcec8", "36130": "ec9be9ddcb7f3b35673cecb633565271d83bc3b9", "36131": "97828e4a4ecdf857a2c6c87f2c1d194ef60f2be1", "36132": "fc0164cd1786a5d3d1d095f48666670b77864e31", "36133": "ef2c61ae69add5c6fb960cd235b10b0e741b9aa4", "36140": "e75a2a1c9280721ae0130eeb4c9d22096873123d", "36141": "b348eacdcb957d1b94d6908bc641371bfed42697", "36142": "12305299405041d1a87c433b58956c5a14e907d0", "36143": "b2b27afc8a04b071661929d6247777ab8cd1bb84", "36144": "2b67593be687b2a09ca1d5a7fbb929f747d690cd", "36145": "ab144c4d48008d54bd3b64c59230f1173a76290e", "36146": "2393a2334623bee5acc704be9a9ca6b9e45a3f6d", "36147": "50171fce7ec06967374ef6c848d42dec106df7b9", "36148": "4ac5cf6436becb9e7f8f561ac2c708dc7996b163", "36149": "47a596e47fb1523fa28942f9147c5f993fe8429d", "36150": "19690796ab1340c47f273617a1fc15cf750f787a", "36151": "4514636af7eca60c0fba3f749639a3233636cea7", "36152": "5b16332d02054de139ac4d53e141fcb1b8b21f57", "36153": "6833344ceceb6ae25696c196739d7da2c6c9aa19", "36154": "8f0c4d2ca6856cc345917d62c3f989ada00617c0", "36156": "6e5e3934b7ff072a0a33462c3f28bef2d5b0272d", "36157": "d22adf6a4bed08050b161207d86e02c1bec6d5c4", "36158": "0994ecd4560b6b10ad129505130397f080ff080d", "36159": "2dfb2ddc52b9be4b7d74fbfa27ef01e1a5a6acad", "36160": "9aa176687c04227af1c645712ea73296861858a3", "36162": "02a27208446a8a5c1153ad9d3884568c7d23e3ac", "36165": "92fa9ca076d9b5faebfe41ef378063acd9397ed1", "36166": "91af4faf39e331540234124755257d3123278239", "36167": "8438fe76a37fb59ae9df7bd14aed8c8f0a6c59cd", "36168": "caab88b1a3ba5c697bb71129038c90f5b6df6b79", "36169": "d5e97d09a99f2572b795f2ff5da885d2297c068f", "36174": "acf5d7d84187b5ba53e54b2a5d91a34725814bf9", "36175": "b2b0f978b5871ce5bcd3b042e39e1ac44643853f", "36176": "562523602b4ac10d1b30d813d7c2bfe02adc0469", "36178": "6a8370eb84e20c21bfc01bb901c68b4acdebfb87", "36179": "1e1f53c805b1095824bffa8f71b6d97cc81076e5", "36181": "df6a3235cddf4973be72b17a1c273f7a6dc8ea09", "36182": "f53eb7b65870d2bf05028cc329d1ab868136fc39", "36185": "639bd6695940be8737db5c47b71b7ec6c4c88fb7", "36186": "2c2333244468b60007ee6d972c864a257cb57af5", "36187": "772d2850d07c6372f2e60c8d6a3051aca6e1eff7", "36188": "9138b5b410c4cd3237064f4f7cdb04745ed20e82", "36189": "34f39a9b053703e39f58ad1d1edc559c2465cf78", "36191": "f331b83fa1ac6fcf3f587647cd7bca6f8cbcaa55", "36192": "219bc5ecf872ed8527c0aef0b82167b051612c51", "36194": "fbe024fa36a6b20f7b2fb3d094bfa5cd3b8ca31e", "36195": "edbdf95f04518f6eb849b13f0aa11f23b02f7ccf", "36196": "05c32ba18f88921b78dc5984c70956247497ab4c", "36202": "d9f70b397a010754ae41e7d201bba05834294559", "36204": "bb9ef02ede41825da414b80730e306a6acf0f718", "36205": "38e29ab7d049015b428a880ed0a160b10418fae6", "36206": "325e04c7f3ed80b9993459f24d512947e44179bb", "36207": "4cd6d7efbc74d27061d5f5734ffb1e8895c388e5", "36209": "68ef1dac651f3012e6da0ec6cab00ac8f0160ed4", "36210": "1c606d5f014c5296d6028af28001311b67ee3721", "36211": "86982eb188383e7be38ef78eccd4ccbfd4f11e61", "36212": "b6834f8b93d20c99cf3f1c527ba4ba2a462c69d9", "36213": "5437d7af52d18fe9cf7e7be440bd690d098b8058", "36214": "4744064744f82230fdb437de07c32a154cba7687", "36215": "a869a73869ba8cc62830fedbfbac138559880602", "36216": "0229225c195f1372e3dbb9192043322f0dbd0625", "36217": "0437fdb67c3c12a9a8e950012f2509d1f19faf23", "36218": "24fdde62c6afc383baecd9a3aceada4dca804266", "36219": "aeed91c027dd30da25f6641a1784f81f2782b6df", "36220": "3530b3d21c99ebb57aafb4780f5b91a46bdaf6db", "36221": "9ac15629534f9ce4cf85e1340a9ddf99635ffe58", "36229": "ac45f880fcde415ffea3d96280ff39ed4f7dac9e", "36230": "b8d04712e4953bf69b68a1911a9f56c571b24720", "36231": "24219311ec72eae247125e09411fd536a4551a44", "36232": "e84bd1ce90944158c0d90b14fdd42c6dada1777d", "36233": "6971c9ca62c47785414bd5ddcc7a895147d07f51", "36234": "6d1b07f11b3f383bb8e4f895cfead3125e89379d", "36236": "99bcf6bac6324bc631318de7c2ef2a5827bddfa0", "36237": "74b2c37c11b35e1645b658f8bef65e9e3e1c2057", "36238": "20ce643c1a7c5038eb129af55b73fba6b6d43ab1", "36239": "09fb8e576306610af1b6b5dc613979e6150c9957", "36240": "762b61dfb3028bc3b9c96c664243ba188b0ed923", "36243": "4b6a80ea9f7547dbfe016137ecf91ad60ad305bc", "36244": "3fc83203910aa7196d88850ab5becea41e30f6d7", "36245": "82c591d3ff2d49cb4605a6b70388f1bd4a20f9ab", "36246": "27ec8873be0c5958c5cf7c76a32180da31bd56cf", "36247": "a38ecd5b84a96ae1453e889f3dfebb0d218a575c", "36253": "a29e4f656cc2ba8f9b3499af52f503d832b50c9a", "36254": "f6eee830c7f2e089af16e7249bd3f66fe5de55ee", "36255": "50d99caa2604b8271ee26eeaa6b346ab8492019e", "36256": "b19a0938d4a41e57d94454b9b397bcf7f46bfd0a", "36257": "17eec96a6e993e8f2105cd2de0e78361c42abe21", "36258": "cf78582982816c28da9be8b51dc9b03273099eca", "36259": "3934e56f5d402f1ebf28ff89db02ce718e30cc8e", "36260": "13bdca4ddad57e58974ab5882831cedbc5ab9346", "36261": "4c520e35f95429ceaf91ea67cd2ced5aabba9619", "36262": "2b7af8477803c5a94b4caf1d9295b2887a552d55", "36263": "f3f0249c611bf41e2946ad5fc89abfa0af89ab85", "36264": "83f6275d109d78a6517acf767fabfb6692440142", "36265": "5ad9abd5052c29b38692db49afaed723d1d1a044", "36266": "e973b42222405e847ef1fb27ab0f2491d734990f", "36268": "ae6d27937b763af21502af839d0a738da6137bb0", "36269": "7012d6a60724bf55d1fc0d03d6c50484aa19fb85", "36270": "e8f05983b5743de3690cbd3d4f8b9896f9429c4c", "36271": "8dd497a73af933c88c666ea65e5e53d9522ffbcd", "36272": "c1c6db7318776f4637fdc3dc3b9f313d69145160", "36273": "1ef827385590ad162cb6f1f26b74c52fcaade63e", "36274": "1aa9aeacb1dc2bf85505880bf0fe6f038d0acda3", "36275": "44b6cb95da305ba29c19bdde838bb1b4e15fd1b1", "36276": "d377cc9bf5aae098eef9f86651ece22f84458c0b", "36277": "0ae4dfda05a18a9a6ab8049f54c19e28b0a3a582", "36278": "0e8174fbb89972690ea4e825d727d2ddf7653c73", "36279": "e2aa710c4abe6329be6c85689e27787868e44cdd", "36280": "60930743d882903bf769a1694793d787dd399475", "36281": "adcb36ee217af563f29f13852298b6bb42627c97", "36282": "8e36cd136972b07332de033aaf2594a0a1daf415", "36283": "4a06c0f91abb598a8ac4ea97428562ece9caa598", "36287": "d47ad02987402273c9b012a9124b0fcd0930b9ba", "36288": "9cbf95db675cbea9d01b25f146cff021590f6de3", "36289": "eb7a8c85d2ad92164d5de5d19118214462e427b8", "36291": "4f080b8f2e5c93d1b0dd1ceb5487fba67feb02ab", "36292": "f7c73a5f1aaf0724598e60c0cc5732604ec842a8", "36293": "09cb36710aab9d9a724602aa7ccfde33fbc51f63", "36296": "fa07d05c5d8cd7b8267eb33e1fc382c7a63ba114", "36297": "958e7f58d7c25fd86ce1ed563aa499f2cf587804", "36298": "147d68a3385aa91d1c2b853b22b81bed1449d047", "36299": "65af776208578edf1a42be8f6ca76c3d2b1487fb", "36300": "2a0e253688a44fa93d0000515c0a904a3ed346b0", "36301": "6f245e61b9e3c2107e77742130db0839e864b9e4", "36302": "7c6d26f632cb6ea4858a65a73085b89c0412f5c7", "36303": "516510275b921b3fe01c67f8bb5ac00971a65883", "36304": "ae76ad49003536f02e697fb6077c4ec3a90ce048", "36305": "6669aee381c03baf0e845714c339ca85b2e4e762", "36306": "e0f3a188f9c0b5c334dffe11a5a3ab47fe0870b4", "36308": "3cf05db9f8ecd640b5c666a7ceb05f4c5483e06b", "36309": "9211826df3e4623516ff8044626cb9242b117f05", "36310": "dd7c34f1f3c32bc51ebcf4f9c22389c01ee1df62", "36311": "0d224881fa142727cd5d76be7c0a3e2193ea8708", "36312": "7b528c91e5e273f38ea779b548ca64e80df4b346", "36325": "daa9cdb1c70932afd6d5146c98b48bd95b1c5dd1", "36327": "0d8e0a4cd07f12c044a2f7d2b779958270dade00", "36328": "17a4cac3a086f0643fd5fe3f9d64549fd6e0725c", "36329": "12b80a6defc8da84a6b426a9efcaf14d41fa35de", "36330": "593fa85504e3d6cc114c12526c103ef9dc619e68", "36332": "52649eab12137913b6df0d0b2e55fdf5f42dc1b5", "36333": "dc4c474c4dfa43c7cee94666fe843f2037278050", "36334": "0b9e784fe5606d8383a8e825e5475d35e9552a2a", "36335": "33ff3d97e6a671cabff4d851330fe472ec1f7f70", "36336": "c99981a0266d12fb00eaa6a43d89322298425d7f", "36341": "c08e7b3587b5527ca9bc232efacac59006f37451", "36343": "7808ecf8cb10969f2f8d46e3a01503830e880d6b", "36344": "f2b37958ebe4b1d5775395ae331051a526aa3012", "36345": "b64d87bf13e96411fbcde4b8fa3057b90e934b79", "36346": "025a2394d6a0c340aa85f9d513416725fcca2304", "36347": "fce776059054f4a559a1b0b740e4ee171cfdb9f9", "36348": "a16427161ad08bc15a07ed49ee29cd899a921ce5", "36349": "75d27504fbb047cd9d95e20fd77b5c751584dfb3", "36350": "5e4f2b27db3c7363041b2d969921454b63279e26", "36351": "d36fb98ddba74631812f113050c0a6f945868051", "36352": "0d853e7707bdc6995e0cb058fc34bd042a6e9ec5", "36355": "2fc264aeb0b906168eab462ba7183aa6fa51da7e", "36356": "9f51d4fb481e0cbee97e0100d39c52d3ff5207e9", "36357": "4e2cb22464f63896aa520d225d5708cf30db15c9", "36358": "c369d93cf7c82455bd3dd98233c7c09d8c567025", "36359": "5e0df27fadfeb29e76336b527f4c01cd2f575136", "36360": "aed4df1f609a434a37e3b5bed5c02481e0a406b3", "36364": "3b9d1f6ee5480691410c0702dc4e616fa8aa1bb0", "36367": "3d492f175077788df89b6fc82608c201164d81e2", "36369": "025ccb5675c4773409d6d0e8145b21da17e0e011", "36370": "91e251c3234333efadd0b467020bfcd300d9b6d8", "36371": "657da071c86fdef5e35ba3bfd45cda2ebc35fad4", "36372": "8399185ad3618cd7d4bc5018e8afad5cd357e813", "36373": "68c1af5358561b4655861f99ac1dfb27ac5d4d56", "36374": "a671b5a8bf5dd13fb19f0e88edc679bc9e15c673", "36375": "46c8da3e5b987154d2e0a44562c71be635ae826a", "36377": "45361a48582bde02941b02050fb4a9ae096faadd", "36378": "a3626f27f297b1d22b0690548fd3c5016e7522d4", "36379": "e3073b503527c17ed8bed848f534db8188428b71", "36380": "124b671787bdf726274af3ce225c79a8090c9bf0", "36381": "9893c437648f3c675016fec035e640d9c92b4806", "36382": "114f067a93c0e2c120d6538696d32d46a94f8eb8", "36383": "aa7b17e1f5d596f41950f85e9f00aa9258b5f2a7", "36384": "726e8e8a61cb3f103bc89e773089645a748ce4a4", "36385": "1ab4d031db3bdfe30ebe385f019946f930099543", "36386": "04307e717d3d227cbdf250695f2698c2cae7752d", "36398": "fb05cc7781637906728e95be9b418e774b0e67b2", "36399": "91ddc8b66a0eef9312014387ce0108f1be29a3a9", "36400": "a61c556f6abdac6284bc27c52eb2ee452c543495", "36401": "ee6a0626a42d531ece2de7fefdc514123690c191", "36402": "f0b61c561858da28d22a1df7c03787ce8f1b482f", "36403": "8aa7a96765ff4f5e2e157fdbacedc442381292b4", "36404": "9b51ab2ae6d16b4d599b99fd253aba00c959b41d", "36405": "b4c9df811a234d50646540f9b4dc92ad39d7c77b", "36408": "400ae748367cf9a356b8433c1aa59f34033f02a4", "36409": "87c40c7dedddde1bf022d6d8f1d4a897acdf11a2", "36410": "5ad2251aa5181958f1c8163aeb4e09262c489703", "36416": "feacb6faccb6e1ce016b61e091b46c11ebbe86c9", "36417": "b0ffccd489badea508d0a83431f1aea019e294b7", "36418": "d352d5a012a59ca41203c7d9b49554d43de9f903", "36419": "e552626ede07e30503489d9b36518fded2c181e9", "36420": "cf2710d49b2255fb77ad8bf6fe30917b5b680df2", "36421": "2a02b008a29a2e25919f0c736b1f9b611d28bfab", "36422": "14cf864c6e97269f6adc0e1146747aa9fd7234f1", "36423": "54441fe1483ad3a2a36a385ed8070c9211e17351", "36424": "c9480e19e81ff2c2e237c73e1b9117848855c9b5", "36425": "acc395a0fe114f686096337bcf1170833a9de5ae", "36426": "f571ccef75aed37789e1d14cb3a54089c8ca3771", "36427": "db6fd22b6b1fceb8f8e6a2b23c7cb615b55c2c5e", "36429": "cbe1b321d928bb00ab9809f109ab483db2bb6b2d", "36430": "5f2abaa88a5b22c1dc0fcc9dcad6d868a4d5389e", "36431": "026f7e35dd4894c6be412a903b831686d4f6935a", "36432": "9b2f8aa54a320de76998c227c732325b9980aeb8", "36433": "1387c4fa09ca7bb13a7f1e13ecd171aebe8fef46", "36435": "63999823379155ffa17af0ed5fbac25696010cb2", "36436": "94a6d6a989626936880b0f751fec612ce057b010", "36437": "4763b910949ed1e7b8933c8f6808c9766757f9f8", "36438": "32aeafdd2390080022349fe1a585fd0162a2658f", "36439": "ee4ceec8e313c83bbbb53309e412b470ab13a642", "36440": "bb14870efaee648b9aceeddaf081cc3988f413a1", "36441": "d77d5e54f9fb317f61caa1985df8ca156df921e1", "36442": "061c2e9190438a0df8d68e2765f486d7e9c82cda", "36443": "5834683ee8e7ca654c2e44f7d1273c2bbda744ba", "36444": "9a08863c953fd198896a55066624c406132de375"}, "revision_to_date": {"288": 1298163988000, "862": 1315859521000, "874": 1316017084000, "926": 1317000085000, "933": 1317048249000, "981": 1317617173000, "1029": 1318197429000, "1084": 1318951906000, "1185": 1319509932000, "1194": 1320196542000, "1342": 1322277354000, "1440": 1323817436000, "1632": 1325734840000, "1812": 1327034032000, "2072": 1328826175000, "2077": 1328843532000, "2196": 1330553078000, "2247": 1330658997000, "2358": 1331927660000, "2539": 1334253112000, "2555": 1334276689000, "3074": 1338253482000, "3262": 1339519295000, "3266": 1339521874000, "3344": 1340247840000, "3360": 1340393682000, "3361": 1340394271000, "3393": 1340820112000, "3412": 1340986814000, "3418": 1340991466000, "3494": 1342184152000, "3551": 1342986141000, "3557": 1343003671000, "3912": 1348197360000, "3955": 1348710085000, "4026": 1349655420000, "4249": 1352505519000, "4289": 1352940069000, "4723": 1355269526000, "4816": 1355762888000, "5022": 1358831994000, "5767": 1365818352000, "5863": 1366678471000, "6664": 1373346771000, "6794": 1374697106000, "7983": 1385527286000, "8139": 1388422887000, "8234": 1389186315000, "8327": 1389878709000, "8680": 1391395738000, "9617": 1400278770000, "9713": 1401450122000, "10140": 1405035967000, "10501": 1410094321000, "10793": 1412642319000, "10853": 1413672736000, "10956": 1415452422000, "11042": 1416578711000, "11188": 1418306362000, "11528": 1426255236000, "11564": 1427031398000, "11906": 1431306604000, "12077": 1434192334000, "12091": 1434584708000, "12722": 1441988415000, "12860": 1443887330000, "12889": 1444306718000, "13158": 1448038103000, "13524": 1455378460000, "13615": 1457534291000, "13626": 1457732611000, "13836": 1462283462000, "14282": 1473277332000, "14330": 1475416385000, "14435": 1478182795000, "14706": 1482594798000, "15300": 1492832004000, "15357": 1493909668000, "15365": 1493951109000, "15371": 1494003581000, "15372": 1494012477000, "15574": 1496609647000, "15686": 1499446527000, "16095": 1507858703000, "16141": 1509117925000, "16142": 1509128814000, "16592": 1513050947000, "16694": 1514550565000, "16721": 1514663812000, "17530": 1525259813000, "17532": 1525272424000, "17589": 1526415166000, "17590": 1526438450000, "17746": 1528825328000, "17916": 1530828264000, "17943": 1530976196000, "18118": 1533316766000, "19274": 1547215888000, "19354": 1548430346000, "19355": 1548451808000, "19436": 1549228549000, "19671": 1552425131000, "20330": 1562213026000, "20423": 1563465802000, "20424": 1563479338000, "20697": 1566484565000, "21096": 1571414970000, "21232": 1572553014000, "22237": 1578605090000, "22238": 1578622290000, "22538": 1580334415000, "22700": 1580919329000, "23185": 1584024103000, "23272": 1584537529000, "24131": 1590671799000, "24338": 1592394604000, "24593": 1595012630000, "24603": 1595942099000, "24604": 1595964517000, "24770": 1597942487000, "24989": 1599582504000, "25339": 1601911652000, "25725": 1604062750000, "26258": 1607341330000, "26276": 1607430704000, "26277": 1607434178000, "26509": 1608990420000, "26847": 1611141662000, "27078": 1612868119000, "27326": 1614678216000, "27737": 1618243153000, "28350": 1623498340000, "28351": 1623500344000, "28359": 1623604768000, "28492": 1624355610000, "28584": 1625213575000, "28769": 1627203891000, "28954": 1629031534000, "29206": 1631440969000, "29489": 1634473678000, "29970": 1639304448000, "30182": 1641387616000, "30183": 1641391555000, "30391": 1642847731000, "30639": 1644656651000, "30963": 1648885576000, "31386": 1655980525000, "31689": 1660584073000, "31690": 1660584323000, "31691": 1660584477000, "31692": 1660585657000, "31693": 1660587184000, "31694": 1660597913000, "31695": 1660604949000, "31696": 1660605765000, "31697": 1660608420000, "31703": 1660674923000, "31704": 1660675099000, "31705": 1660675303000, "31706": 1660676637000, "31707": 1660685026000, "31712": 1660700310000, "31713": 1660701553000, "31714": 1660701572000, "31715": 1660701704000, "31716": 1660755064000, "31717": 1660770913000, "31718": 1660771179000, "31719": 1660773608000, "31720": 1660775584000, "31721": 1660803399000, "31727": 1660839948000, "31728": 1660847389000, "31729": 1660853637000, "31748": 1660954125000, "31749": 1660954481000, "31750": 1660963209000, "31751": 1660980586000, "31752": 1660998736000, "31754": 1661021123000, "31759": 1661198100000, "31760": 1661200583000, "31761": 1661200852000, "31764": 1661209097000, "31765": 1661213657000, "31775": 1661274765000, "31776": 1661275106000, "31777": 1661275563000, "31778": 1661341283000, "31779": 1661353248000, "31782": 1661373090000, "31783": 1661373200000, "31785": 1661426566000, "31789": 1661463476000, "31790": 1661463549000, "31791": 1661465147000, "31794": 1661466440000, "31795": 1661504846000, "31802": 1661540574000, "31803": 1661549885000, "31804": 1661550024000, "31805": 1661553641000, "31806": 1661554006000, "31807": 1661792874000, "31808": 1661792942000, "31809": 1661794855000, "31810": 1661796878000, "31811": 1661809443000, "31812": 1661813117000, "31814": 1661813314000, "31817": 1661861776000, "31818": 1661861887000, "31823": 1661880328000, "31824": 1661891970000, "31827": 1661897643000, "31828": 1661928513000, "31829": 1661936829000, "31833": 1661963410000, "31834": 1661966076000, "31835": 1661967256000, "31836": 1661973090000, "31837": 1661973206000, "31838": 1661979842000, "31839": 1661991522000, "31840": 1662016494000, "31841": 1662016580000, "31843": 1662022633000, "31845": 1662060476000, "31846": 1662063876000, "31847": 1662064506000, "31848": 1662065939000, "31849": 1662067710000, "31850": 1662102327000, "31853": 1662137657000, "31854": 1662137763000, "31855": 1662139607000, "31856": 1662146718000, "31857": 1662148093000, "31859": 1662153978000, "31860": 1662154364000, "31861": 1662219459000, "31862": 1662234797000, "31863": 1662292467000, "31864": 1662397638000, "31866": 1662455402000, "31867": 1662473035000, "31868": 1662473588000, "31869": 1662485500000, "31870": 1662486252000, "31875": 1662494929000, "31876": 1662495256000, "31877": 1662495676000, "31878": 1662495841000, "31879": 1662496790000, "31882": 1662534756000, "31885": 1662568141000, "31886": 1662572381000, "31887": 1662573514000, "31888": 1662574096000, "31889": 1662582244000, "31890": 1662582428000, "31892": 1662591015000, "31896": 1662622494000, "31898": 1662650041000, "31899": 1662650394000, "31900": 1662660399000, "31902": 1662662651000, "31903": 1662663299000, "31904": 1662663541000, "31908": 1662741681000, "31911": 1662744060000, "31912": 1662745246000, "31913": 1662745374000, "31914": 1662746972000, "31915": 1662750632000, "31917": 1662760978000, "31918": 1662807274000, "31919": 1662845595000, "31921": 1663001780000, "31922": 1663001868000, "31923": 1663002007000, "31930": 1663007512000, "31931": 1663007642000, "31933": 1663010678000, "31934": 1663027448000, "31935": 1663028025000, "31936": 1663054354000, "31937": 1663085553000, "31938": 1663085653000, "31939": 1663085769000, "31940": 1663087563000, "31942": 1663089871000, "31944": 1663096528000, "31946": 1663109917000, "31947": 1663171107000, "31948": 1663171224000, "31949": 1663171612000, "31950": 1663172357000, "31952": 1663177117000, "31953": 1663182149000, "31954": 1663191113000, "31957": 1663201007000, "31958": 1663201430000, "31960": 1663242248000, "31961": 1663242417000, "31964": 1663260362000, "31965": 1663260556000, "31966": 1663260901000, "31967": 1663263407000, "31971": 1663283989000, "31972": 1663348722000, "31973": 1663349423000, "31974": 1663349578000, "31978": 1663366275000, "31980": 1663500085000, "31982": 1663520091000, "31984": 1663538905000, "31985": 1663544674000, "31988": 1663583846000, "31989": 1663622240000, "32001": 1663628901000, "32002": 1663629067000, "32003": 1663629234000, "32004": 1663629494000, "32005": 1663629717000, "32006": 1663659759000, "32008": 1663681782000, "32009": 1663683620000, "32014": 1663695794000, "32015": 1663695895000, "32016": 1663696107000, "32017": 1663698709000, "32018": 1663699559000, "32019": 1663716189000, "32020": 1663780705000, "32021": 1663780904000, "32023": 1663781627000, "32025": 1663782881000, "32026": 1663783261000, "32027": 1663783358000, "32028": 1663786487000, "32030": 1663850991000, "32031": 1663862719000, "32032": 1663863260000, "32034": 1663864804000, "32035": 1663869013000, "32036": 1663869298000, "32037": 1663876833000, "32040": 1663929435000, "32041": 1663936071000, "32042": 1663953031000, "32045": 1663953855000, "32046": 1663955106000, "32047": 1663956055000, "32048": 1663956116000, "32049": 1663956408000, "32053": 1663969892000, "32055": 1663970803000, "32057": 1664152007000, "32058": 1664213568000, "32059": 1664214661000, "32060": 1664217363000, "32061": 1664221229000, "32065": 1664232211000, "32066": 1664232439000, "32067": 1664232538000, "32069": 1664233089000, "32070": 1664233243000, "32072": 1664265192000, "32074": 1664273119000, "32077": 1664281315000, "32078": 1664294527000, "32079": 1664296992000, "32080": 1664310084000, "32082": 1664317956000, "32084": 1664321597000, "32086": 1664372582000, "32087": 1664379630000, "32088": 1664407434000, "32089": 1664407545000, "32090": 1664456172000, "32091": 1664457739000, "32092": 1664458839000, "32093": 1664459258000, "32094": 1664459473000, "32104": 1664495671000, "32105": 1664495763000, "32106": 1664495990000, "32107": 1664499072000, "32108": 1664499140000, "32112": 1664522681000, "32113": 1664522884000, "32116": 1664538532000, "32118": 1664547535000, "32119": 1664554803000, "32122": 1664613067000, "32123": 1664716662000, "32124": 1664743717000, "32125": 1664809181000, "32126": 1664814563000, "32127": 1664814943000, "32128": 1664816993000, "32129": 1664818141000, "32130": 1664828850000, "32131": 1664830993000, "32132": 1664836173000, "32133": 1664844098000, "32135": 1664901576000, "32136": 1664906177000, "32137": 1664906521000, "32138": 1664907016000, "32139": 1664907721000, "32140": 1664908101000, "32141": 1664918589000, "32142": 1664924735000, "32144": 1664985779000, "32145": 1664986069000, "32146": 1664993041000, "32147": 1664993795000, "32150": 1665001244000, "32151": 1665005457000, "32152": 1665009018000, "32153": 1665009288000, "32154": 1665010711000, "32156": 1665043230000, "32157": 1665071960000, "32158": 1665072382000, "32159": 1665072966000, "32160": 1665074608000, "32161": 1665075381000, "32162": 1665092981000, "32163": 1665140504000, "32164": 1665142026000, "32165": 1665150868000, "32167": 1665160893000, "32168": 1665162882000, "32169": 1665163377000, "32170": 1665163439000, "32171": 1665163622000, "32173": 1665176729000, "32174": 1665188801000, "32175": 1665188925000, "32177": 1665418215000, "32178": 1665420768000, "32179": 1665420819000, "32180": 1665424953000, "32181": 1665425068000, "32183": 1665440003000, "32184": 1665440172000, "32185": 1665472127000, "32186": 1665505298000, "32187": 1665505750000, "32188": 1665505865000, "32189": 1665508631000, "32190": 1665510083000, "32191": 1665511251000, "32192": 1665520091000, "32194": 1665520946000, "32195": 1665521061000, "32196": 1665528163000, "32197": 1665595042000, "32198": 1665595356000, "32199": 1665596019000, "32200": 1665596832000, "32201": 1665615982000, "32202": 1665616717000, "32203": 1665644040000, "32205": 1665676105000, "32206": 1665676177000, "32208": 1665690385000, "32210": 1665699744000, "32211": 1665699903000, "32212": 1665700721000, "32213": 1665733418000, "32215": 1665738165000, "32216": 1665739206000, "32218": 1665766794000, "32219": 1665767069000, "32220": 1665767190000, "32221": 1665767981000, "32222": 1665769406000, "32228": 1665785838000, "32229": 1665785864000, "32230": 1665785929000, "32231": 1665786808000, "32232": 1665787196000, "32233": 1665831296000, "32235": 1665921584000, "32236": 1665921691000, "32237": 1665921789000, "32238": 1665921925000, "32239": 1665924791000, "32240": 1665990670000, "32241": 1665990891000, "32243": 1666000542000, "32244": 1666006179000, "32245": 1666021640000, "32246": 1666021969000, "32247": 1666023127000, "32248": 1666023511000, "32249": 1666023851000, "32254": 1666038212000, "32255": 1666039919000, "32256": 1666042811000, "32257": 1666043208000, "32258": 1666048937000, "32259": 1666077615000, "32261": 1666084960000, "32262": 1666085039000, "32263": 1666086298000, "32264": 1666116824000, "32265": 1666118252000, "32266": 1666118335000, "32267": 1666119030000, "32268": 1666129595000, "32269": 1666154560000, "32270": 1666167038000, "32271": 1666177197000, "32272": 1666190661000, "32273": 1666195788000, "32274": 1666196231000, "32276": 1666213941000, "32277": 1666214018000, "32281": 1666253578000, "32282": 1666253875000, "32283": 1666253983000, "32284": 1666254090000, "32285": 1666254535000, "32294": 1666285191000, "32297": 1666288704000, "32298": 1666289034000, "32299": 1666296145000, "32300": 1666296251000, "32301": 1666359725000, "32302": 1666360328000, "32303": 1666370836000, "32304": 1666372554000, "32305": 1666373375000, "32307": 1666376871000, "32308": 1666377011000, "32315": 1666394863000, "32316": 1666395089000, "32317": 1666399149000, "32318": 1666399197000, "32319": 1666400675000, "32320": 1666438930000, "32321": 1666546061000, "32322": 1666546293000, "32323": 1666563340000, "32324": 1666571012000, "32325": 1666590367000, "32326": 1666590502000, "32327": 1666590544000, "32328": 1666626066000, "32329": 1666628529000, "32330": 1666634758000, "32339": 1666645609000, "32340": 1666645811000, "32341": 1666646995000, "32342": 1666647048000, "32343": 1666647819000, "32344": 1666695394000, "32345": 1666706679000, "32346": 1666706797000, "32347": 1666706898000, "32351": 1666722903000, "32352": 1666723051000, "32353": 1666728011000, "32354": 1666731755000, "32355": 1666732063000, "32356": 1666769114000, "32357": 1666776789000, "32358": 1666776840000, "32359": 1666776906000, "32360": 1666777217000, "32369": 1666806154000, "32370": 1666806388000, "32371": 1666807089000, "32372": 1666811217000, "32373": 1666816440000, "32374": 1666823938000, "32375": 1666829347000, "32376": 1666862878000, "32377": 1666883640000, "32378": 1666887005000, "32379": 1666887832000, "32380": 1666887957000, "32381": 1666888638000, "32382": 1666928200000, "32383": 1666963099000, "32384": 1666963153000, "32387": 1666974684000, "32388": 1666975670000, "32389": 1666981662000, "32390": 1666982157000, "32391": 1666983162000, "32392": 1666999015000, "32393": 1667007740000, "32394": 1667062310000, "32395": 1667063473000, "32396": 1667065853000, "32397": 1667116675000, "32398": 1667132469000, "32399": 1667146700000, "32400": 1667226902000, "32401": 1667235957000, "32402": 1667236407000, "32409": 1667242054000, "32410": 1667242248000, "32411": 1667243879000, "32413": 1667252813000, "32414": 1667252899000, "32415": 1667304552000, "32416": 1667304616000, "32418": 1667314026000, "32419": 1667314086000, "32420": 1667314164000, "32421": 1667314459000, "32424": 1667324428000, "32431": 1667344835000, "32433": 1667349778000, "32434": 1667349990000, "32435": 1667350421000, "32436": 1667350937000, "32449": 1667413539000, "32450": 1667414632000, "32451": 1667415115000, "32452": 1667415215000, "32453": 1667415410000, "32454": 1667422815000, "32455": 1667423222000, "32456": 1667463919000, "32457": 1667464367000, "32466": 1667493125000, "32467": 1667493389000, "32468": 1667494194000, "32469": 1667496798000, "32470": 1667497665000, "32471": 1667501098000, "32472": 1667507363000, "32473": 1667541799000, "32474": 1667557055000, "32477": 1667580893000, "32478": 1667581014000, "32479": 1667582438000, "32480": 1667585381000, "32481": 1667585642000, "32484": 1667593843000, "32485": 1667595122000, "32486": 1667597205000, "32487": 1667605250000, "32488": 1667626270000, "32489": 1667645366000, "32490": 1667664879000, "32491": 1667667748000, "32492": 1667681548000, "32493": 1667720854000, "32494": 1667738950000, "32495": 1667746500000, "32496": 1667753624000, "32497": 1667806108000, "32498": 1667823803000, "32499": 1667842481000, "32500": 1667842761000, "32507": 1667848022000, "32508": 1667848114000, "32509": 1667849098000, "32510": 1667849922000, "32511": 1667854384000, "32512": 1667862262000, "32513": 1667862372000, "32514": 1667862480000, "32515": 1667897673000, "32516": 1667908245000, "32518": 1667932398000, "32519": 1667933329000, "32520": 1667937863000, "32521": 1667950864000, "32522": 1667950974000, "32523": 1667984936000, "32524": 1667990800000, "32528": 1668015465000, "32529": 1668016436000, "32530": 1668016736000, "32531": 1668018274000, "32532": 1668025166000, "32534": 1668027714000, "32535": 1668033441000, "32536": 1668034919000, "32537": 1668041966000, "32538": 1668043940000, "32543": 1668112402000, "32544": 1668112488000, "32545": 1668112599000, "32546": 1668113802000, "32547": 1668117551000, "32549": 1668127590000, "32550": 1668130781000, "32551": 1668136002000, "32552": 1668162276000, "32555": 1668188717000, "32556": 1668188925000, "32557": 1668191414000, "32558": 1668200038000, "32560": 1668275386000, "32561": 1668287155000, "32562": 1668326308000, "32563": 1668328211000, "32564": 1668337937000, "32565": 1668391024000, "32566": 1668452605000, "32567": 1668459124000, "32568": 1668460199000, "32569": 1668460288000, "32570": 1668487477000, "32571": 1668488136000, "32572": 1668513362000, "32573": 1668521987000, "32574": 1668536507000, "32575": 1668548911000, "32576": 1668552759000, "32577": 1668588215000, "32578": 1668589093000, "32579": 1668589353000, "32581": 1668593728000, "32582": 1668605544000, "32584": 1668613261000, "32590": 1668634172000, "32591": 1668636249000, "32592": 1668637152000, "32593": 1668638140000, "32594": 1668638740000, "32598": 1668659801000, "32599": 1668680822000, "32600": 1668680912000, "32601": 1668686391000, "32602": 1668691053000, "32608": 1668723218000, "32609": 1668727518000, "32610": 1668727963000, "32611": 1668735410000, "32612": 1668735586000, "32613": 1668793086000, "32614": 1668794185000, "32615": 1668796036000, "32616": 1668796857000, "32617": 1668797017000, "32619": 1668814279000, "32620": 1668814334000, "32621": 1668814656000, "32622": 1668815082000, "32623": 1668824470000, "32624": 1668842110000, "32627": 1668863136000, "32629": 1668886195000, "32630": 1668955665000, "32631": 1668962052000, "32632": 1669007830000, "32634": 1669008974000, "32636": 1669063680000, "32637": 1669067759000, "32638": 1669067834000, "32641": 1669082836000, "32642": 1669082973000, "32643": 1669082994000, "32644": 1669083178000, "32645": 1669083532000, "32646": 1669107326000, "32647": 1669107478000, "32648": 1669112169000, "32649": 1669112261000, "32650": 1669130514000, "32657": 1669161629000, "32658": 1669162187000, "32659": 1669170906000, "32660": 1669171888000, "32661": 1669171954000, "32668": 1669227090000, "32669": 1669229035000, "32670": 1669229331000, "32671": 1669229425000, "32672": 1669231422000, "32673": 1669237755000, "32674": 1669241351000, "32675": 1669242236000, "32676": 1669244264000, "32677": 1669251203000, "32678": 1669277142000, "32679": 1669291122000, "32681": 1669299057000, "32682": 1669301603000, "32685": 1669313020000, "32686": 1669318744000, "32687": 1669403609000, "32688": 1669403688000, "32689": 1669403784000, "32690": 1669479015000, "32691": 1669479656000, "32692": 1669500715000, "32693": 1669538749000, "32694": 1669565116000, "32695": 1669572641000, "32697": 1669625846000, "32698": 1669626498000, "32699": 1669654733000, "32700": 1669657503000, "32701": 1669659465000, "32707": 1669676148000, "32708": 1669676294000, "32709": 1669685670000, "32710": 1669690616000, "32711": 1669691918000, "32712": 1669695116000, "32714": 1669709556000, "32715": 1669710011000, "32717": 1669744276000, "32718": 1669744938000, "32719": 1669748377000, "32720": 1669748781000, "32721": 1669755101000, "32722": 1669761787000, "32723": 1669762824000, "32724": 1669763583000, "32725": 1669825891000, "32726": 1669850921000, "32727": 1669851340000, "32728": 1669851646000, "32729": 1669856437000, "32730": 1669865214000, "32731": 1669920238000, "32732": 1669921196000, "32733": 1669922786000, "32734": 1669924605000, "32735": 1669926662000, "32736": 1669927279000, "32737": 1669932397000, "32738": 1669941070000, "32739": 1669951520000, "32740": 1669951667000, "32742": 1669975398000, "32743": 1669979588000, "32744": 1669986847000, "32745": 1669994650000, "32746": 1669995006000, "32754": 1670011121000, "32755": 1670012993000, "32756": 1670015202000, "32757": 1670016447000, "32758": 1670022202000, "32759": 1670035700000, "32760": 1670045776000, "32761": 1670071631000, "32762": 1670093303000, "32763": 1670093366000, "32764": 1670097355000, "32765": 1670100616000, "32766": 1670166423000, "32767": 1670171597000, "32768": 1670174846000, "32769": 1670231902000, "32770": 1670232248000, "32771": 1670232321000, "32772": 1670232443000, "32773": 1670234398000, "32774": 1670240903000, "32775": 1670268904000, "32776": 1670269335000, "32777": 1670270879000, "32778": 1670283251000, "32779": 1670292352000, "32780": 1670346878000, "32781": 1670346909000, "32782": 1670347062000, "32785": 1670349030000, "32786": 1670351281000, "32787": 1670353331000, "32788": 1670360860000, "32789": 1670364117000, "32790": 1670415400000, "32791": 1670432658000, "32792": 1670432735000, "32793": 1670436940000, "32794": 1670437715000, "32795": 1670438513000, "32796": 1670439606000, "32797": 1670446166000, "32798": 1670459902000, "32799": 1670469790000, "32800": 1670470114000, "32801": 1670470845000, "32805": 1670512994000, "32807": 1670522690000, "32808": 1670523962000, "32809": 1670537045000, "32810": 1670545258000, "32811": 1670573744000, "32812": 1670575705000, "32813": 1670587896000, "32815": 1670601421000, "32816": 1670687050000, "32817": 1670691773000, "32818": 1670697298000, "32820": 1670699790000, "32821": 1670704384000, "32822": 1670709150000, "32823": 1670757140000, "32824": 1670767206000, "32825": 1670781734000, "32826": 1670795251000, "32827": 1670829783000, "32828": 1670864684000, "32829": 1670869361000, "32830": 1670869695000, "32832": 1670873634000, "32833": 1670877628000, "32834": 1670879647000, "32835": 1670879910000, "32841": 1670898217000, "32842": 1670899222000, "32843": 1670899863000, "32844": 1670900572000, "32845": 1670900802000, "32848": 1670934624000, "32849": 1670937777000, "32850": 1670938007000, "32851": 1670938197000, "32854": 1670948188000, "32856": 1670959506000, "32857": 1670961024000, "32858": 1671002631000, "32859": 1671032495000, "32860": 1671035332000, "32861": 1671040769000, "32862": 1671050450000, "32863": 1671091806000, "32864": 1671110338000, "32865": 1671111401000, "32867": 1671128549000, "32868": 1671128722000, "32869": 1671133399000, "32872": 1671135457000, "32873": 1671145494000, "32875": 1671161173000, "32876": 1671183379000, "32877": 1671183595000, "32878": 1671215303000, "32879": 1671217215000, "32880": 1671219691000, "32881": 1671262096000, "32882": 1671274137000, "32883": 1671285528000, "32884": 1671288289000, "32885": 1671302386000, "32886": 1671302603000, "32893": 1671310490000, "32894": 1671310732000, "32895": 1671310866000, "32896": 1671311037000, "32897": 1671316527000, "32898": 1671327883000, "32899": 1671340029000, "32900": 1671369010000, "32901": 1671440155000, "32902": 1671457381000, "32903": 1671475351000, "32904": 1671475593000, "32911": 1671478590000, "32912": 1671479841000, "32913": 1671479948000, "32914": 1671481065000, "32915": 1671486421000, "32916": 1671540944000, "32917": 1671559957000, "32918": 1671560893000, "32919": 1671572074000, "32920": 1671624383000, "32921": 1671629581000, "32922": 1671629861000, "32923": 1671630145000, "32925": 1671652152000, "32926": 1671652644000, "32927": 1671664460000, "32928": 1671709636000, "32929": 1671734029000, "32930": 1671735544000, "32931": 1671742787000, "32932": 1671744020000, "32933": 1671749354000, "32935": 1671817271000, "32941": 1671838313000, "32942": 1671865881000, "32943": 1671876071000, "32944": 1671911375000, "32945": 1671913128000, "32946": 1672120755000, "32947": 1672128967000, "32948": 1672165857000, "32949": 1672166049000, "32958": 1672173297000, "32959": 1672173426000, "32960": 1672173495000, "32961": 1672174333000, "32962": 1672180115000, "32963": 1672182660000, "32964": 1672182873000, "32965": 1672188534000, "32966": 1672211336000, "32967": 1672216073000, "32973": 1672250869000, "32974": 1672250988000, "32975": 1672251078000, "32976": 1672251123000, "32977": 1672257280000, "32978": 1672261810000, "32979": 1672263989000, "32980": 1672273068000, "32981": 1672273950000, "32982": 1672309768000, "32983": 1672327748000, "32984": 1672344903000, "32985": 1672357005000, "32986": 1672412795000, "32987": 1672412837000, "32988": 1672476906000, "32989": 1672650162000, "32990": 1672673634000, "32991": 1672684550000, "32992": 1672693021000, "32993": 1672733051000, "32994": 1672733717000, "32995": 1672748743000, "32996": 1672752124000, "32997": 1672760573000, "32998": 1672768330000, "32999": 1672771802000, "33007": 1672783821000, "33008": 1672783831000, "33009": 1672784662000, "33010": 1672784833000, "33011": 1672785724000, "33012": 1672795227000, "33013": 1672796239000, "33014": 1672796520000, "33015": 1672799812000, "33016": 1672824220000, "33025": 1672856918000, "33026": 1672858867000, "33027": 1672858960000, "33028": 1672859503000, "33030": 1672867591000, "33031": 1672886685000, "33032": 1672924530000, "33033": 1672926049000, "33035": 1672927699000, "33036": 1672953015000, "33037": 1672961252000, "33038": 1672961367000, "33039": 1672962084000, "33040": 1672962195000, "33041": 1672965550000, "33042": 1672965584000, "33043": 1672995183000, "33044": 1673001181000, "33045": 1673002480000, "33047": 1673030398000, "33048": 1673030469000, "33049": 1673031801000, "33055": 1673041421000, "33056": 1673046508000, "33057": 1673047018000, "33058": 1673047557000, "33059": 1673048879000, "33061": 1673083857000, "33062": 1673084398000, "33063": 1673113715000, "33064": 1673113807000, "33065": 1673125833000, "33066": 1673135862000, "33067": 1673172281000, "33068": 1673172431000, "33069": 1673196269000, "33070": 1673276710000, "33071": 1673286768000, "33072": 1673294357000, "33073": 1673294968000, "33082": 1673305507000, "33083": 1673307004000, "33084": 1673307541000, "33085": 1673308350000, "33086": 1673308497000, "33087": 1673339222000, "33088": 1673351283000, "33089": 1673357688000, "33090": 1673365277000, "33091": 1673369748000, "33092": 1673369898000, "33093": 1673375767000, "33094": 1673379381000, "33095": 1673384548000, "33096": 1673392135000, "33097": 1673392195000, "33098": 1673403716000, "33099": 1673434860000, "33100": 1673438035000, "33101": 1673441583000, "33102": 1673444668000, "33103": 1673480755000, "33104": 1673487906000, "33105": 1673511198000, "33106": 1673511244000, "33107": 1673515892000, "33110": 1673533468000, "33113": 1673539373000, "33114": 1673539477000, "33116": 1673543797000, "33123": 1673555701000, "33124": 1673557623000, "33125": 1673558937000, "33126": 1673559013000, "33127": 1673559586000, "33128": 1673569154000, "33129": 1673569544000, "33130": 1673596678000, "33131": 1673598090000, "33137": 1673619080000, "33139": 1673625411000, "33140": 1673628161000, "33141": 1673628266000, "33143": 1673628514000, "33149": 1673650879000, "33150": 1673651637000, "33151": 1673652422000, "33152": 1673654024000, "33153": 1673654324000, "33155": 1673694320000, "33156": 1673711565000, "33158": 1673723480000, "33159": 1673747460000, "33160": 1673796378000, "33161": 1673817236000, "33162": 1673827789000, "33163": 1673860228000, "33164": 1673881158000, "33165": 1673890433000, "33166": 1673890745000, "33173": 1673894533000, "33174": 1673895724000, "33175": 1673896693000, "33176": 1673896867000, "33177": 1673897613000, "33178": 1673928823000, "33179": 1673943744000, "33180": 1673956632000, "33181": 1673959396000, "33183": 1673976277000, "33184": 1673976922000, "33185": 1673977479000, "33186": 1673978008000, "33187": 1673978101000, "33189": 1673982468000, "33190": 1673982685000, "33191": 1673984518000, "33193": 1674003567000, "33194": 1674009280000, "33199": 1674035667000, "33200": 1674045109000, "33202": 1674053887000, "33203": 1674054777000, "33204": 1674057960000, "33226": 1674072457000, "33227": 1674072576000, "33228": 1674073779000, "33229": 1674084243000, "33230": 1674094850000, "33231": 1674098803000, "33232": 1674118190000, "33234": 1674150333000, "33235": 1674150391000, "33236": 1674150601000, "33239": 1674153433000, "33240": 1674158460000, "33241": 1674160818000, "33242": 1674162751000, "33243": 1674163891000, "33244": 1674214350000, "33245": 1674214450000, "33246": 1674234182000, "33247": 1674234194000, "33255": 1674239468000, "33256": 1674239781000, "33257": 1674240348000, "33258": 1674241006000, "33259": 1674241168000, "33260": 1674266694000, "33261": 1674288533000, "33262": 1674349360000, "33263": 1674349935000, "33264": 1674399168000, "33265": 1674413621000, "33266": 1674488591000, "33267": 1674496593000, "33272": 1674501387000, "33273": 1674501556000, "33274": 1674501912000, "33275": 1674502885000, "33276": 1674503157000, "33277": 1674547184000, "33278": 1674553911000, "33279": 1674567253000, "33280": 1674567303000, "33281": 1674573026000, "33282": 1674584493000, "33283": 1674585777000, "33284": 1674585950000, "33285": 1674586457000, "33286": 1674586953000, "33287": 1674596673000, "33288": 1674666086000, "33289": 1674667233000, "33290": 1674679904000, "33291": 1674686646000, "33292": 1674688528000, "33293": 1674693653000, "33294": 1674731055000, "33295": 1674751988000, "33298": 1674756571000, "33299": 1674759632000, "33300": 1674759739000, "33301": 1674760513000, "33302": 1674760745000, "33303": 1674761382000, "33304": 1674761778000, "33305": 1674761898000, "33306": 1674781903000, "33307": 1674783627000, "33308": 1674808417000, "33309": 1674855625000, "33310": 1674858069000, "33311": 1674858140000, "33312": 1674858455000, "33313": 1674862215000, "33314": 1674862659000, "33315": 1674867104000, "33316": 1674868450000, "33317": 1674875488000, "33318": 1674912918000, "33322": 1675071470000, "33323": 1675075866000, "33324": 1675091244000, "33325": 1675093674000, "33331": 1675105301000, "33332": 1675105541000, "33333": 1675106325000, "33334": 1675107134000, "33335": 1675107588000, "33336": 1675109087000, "33337": 1675109264000, "33339": 1675153145000, "33340": 1675179874000, "33341": 1675193010000, "33346": 1675196383000, "33347": 1675196441000, "33348": 1675200212000, "33349": 1675200512000, "33350": 1675200687000, "33351": 1675208724000, "33352": 1675225504000, "33353": 1675243825000, "33355": 1675253584000, "33356": 1675258621000, "33357": 1675258751000, "33358": 1675266688000, "33359": 1675267581000, "33367": 1675284825000, "33368": 1675288744000, "33369": 1675289727000, "33370": 1675294713000, "33371": 1675296730000, "33372": 1675345266000, "33378": 1675358266000, "33379": 1675358877000, "33380": 1675359853000, "33381": 1675360048000, "33382": 1675362306000, "33383": 1675363316000, "33384": 1675376205000, "33385": 1675385767000, "33386": 1675396031000, "33387": 1675417200000, "33388": 1675429339000, "33390": 1675440656000, "33391": 1675447967000, "33392": 1675448456000, "33393": 1675452102000, "33394": 1675452146000, "33397": 1675458426000, "33398": 1675458519000, "33399": 1675473054000, "33400": 1675473118000, "33401": 1675475201000, "33402": 1675538207000, "33403": 1675538373000, "33404": 1675538450000, "33405": 1675546525000, "33406": 1675548271000, "33407": 1675553485000, "33408": 1675603311000, "33409": 1675611510000, "33410": 1675628553000, "33411": 1675628941000, "33412": 1675638831000, "33413": 1675686801000, "33414": 1675691208000, "33415": 1675708930000, "33418": 1675712400000, "33419": 1675712972000, "33420": 1675713076000, "33421": 1675713815000, "33422": 1675717344000, "33423": 1675717766000, "33424": 1675724923000, "33425": 1675725134000, "33426": 1675735836000, "33427": 1675765607000, "33428": 1675778979000, "33429": 1675797760000, "33430": 1675798925000, "33431": 1675802092000, "33432": 1675802183000, "33433": 1675846868000, "33434": 1675865008000, "33435": 1675867303000, "33442": 1675876519000, "33443": 1675878404000, "33444": 1675878626000, "33445": 1675879062000, "33446": 1675879142000, "33448": 1675883692000, "33449": 1675893751000, "33450": 1675894387000, "33451": 1675904637000, "33452": 1675938677000, "33453": 1675938888000, "33454": 1675939743000, "33455": 1675945915000, "33471": 1675969769000, "33472": 1675978959000, "33473": 1675979198000, "33474": 1675979473000, "33475": 1675979754000, "33476": 1676004165000, "33477": 1676016011000, "33478": 1676024878000, "33479": 1676026054000, "33480": 1676031497000, "33481": 1676032004000, "33482": 1676036458000, "33490": 1676054109000, "33491": 1676055742000, "33492": 1676063950000, "33493": 1676063990000, "33494": 1676068574000, "33497": 1676091226000, "33498": 1676091343000, "33499": 1676112392000, "33500": 1676114726000, "33501": 1676115380000, "33504": 1676133059000, "33505": 1676137918000, "33506": 1676140468000, "33507": 1676142951000, "33508": 1676148528000, "33509": 1676192778000, "33510": 1676237490000, "33511": 1676310350000, "33512": 1676310494000, "33522": 1676315172000, "33523": 1676315732000, "33524": 1676321928000, "33525": 1676323209000, "33526": 1676324020000, "33527": 1676371466000, "33528": 1676373450000, "33529": 1676373938000, "33530": 1676373982000, "33531": 1676392449000, "33532": 1676400793000, "33533": 1676406989000, "33534": 1676407316000, "33535": 1676408288000, "33536": 1676408841000, "33537": 1676409304000, "33538": 1676455244000, "33539": 1676457492000, "33540": 1676458839000, "33542": 1676477701000, "33543": 1676479870000, "33544": 1676484001000, "33545": 1676484209000, "33546": 1676484502000, "33552": 1676496434000, "33553": 1676497695000, "33554": 1676501034000, "33555": 1676501698000, "33556": 1676513225000, "33567": 1676565513000, "33568": 1676565732000, "33569": 1676565872000, "33570": 1676566347000, "33571": 1676566625000, "33572": 1676581302000, "33573": 1676584794000, "33574": 1676591949000, "33575": 1676608438000, "33576": 1676629653000, "33577": 1676643053000, "33578": 1676656836000, "33579": 1676660534000, "33580": 1676661893000, "33581": 1676671392000, "33582": 1676671504000, "33583": 1676671589000, "33584": 1676682028000, "33585": 1676682253000, "33586": 1676682894000, "33587": 1676719896000, "33588": 1676741908000, "33589": 1676769551000, "33590": 1676814118000, "33591": 1676837716000, "33592": 1676863658000, "33593": 1676880667000, "33594": 1676887627000, "33595": 1676893361000, "33596": 1676910797000, "33597": 1676913330000, "33598": 1676924115000, "33599": 1676924793000, "33600": 1676926863000, "33601": 1676927124000, "33602": 1676927207000, "33603": 1676927431000, "33604": 1676929029000, "33607": 1676970295000, "33608": 1676970407000, "33609": 1676970712000, "33610": 1676971018000, "33611": 1676971113000, "33620": 1676988285000, "33621": 1677003888000, "33622": 1677005616000, "33623": 1677014040000, "33624": 1677016230000, "33625": 1677026654000, "33626": 1677057473000, "33627": 1677057863000, "33628": 1677059799000, "33629": 1677063782000, "33630": 1677074703000, "33640": 1677085796000, "33645": 1677101588000, "33646": 1677108653000, "33648": 1677110513000, "33649": 1677110607000, "33650": 1677111285000, "33653": 1677147456000, "33654": 1677147850000, "33656": 1677154038000, "33657": 1677161754000, "33658": 1677162455000, "33666": 1677195344000, "33667": 1677195486000, "33668": 1677197382000, "33670": 1677201188000, "33671": 1677201224000, "33673": 1677239790000, "33674": 1677253694000, "33675": 1677262090000, "33676": 1677262262000, "33680": 1677266001000, "33681": 1677266088000, "33682": 1677268172000, "33686": 1677276767000, "33687": 1677277309000, "33689": 1677291182000, "33690": 1677292101000, "33693": 1677346625000, "33694": 1677346837000, "33695": 1677347130000, "33696": 1677347191000, "33697": 1677347439000, "33701": 1677360194000, "33702": 1677361790000, "33703": 1677361857000, "33704": 1677365214000, "33706": 1677371033000, "33708": 1677399407000, "33709": 1677433391000, "33710": 1677436947000, "33712": 1677442849000, "33713": 1677448883000, "33715": 1677449772000, "33717": 1677458823000, "33718": 1677463921000, "33721": 1677511679000, "33722": 1677530125000, "33723": 1677532492000, "33724": 1677534781000, "33726": 1677569745000, "33727": 1677579875000, "33728": 1677581676000, "33729": 1677591219000, "33730": 1677605931000, "33731": 1677622502000, "33732": 1677624259000, "33734": 1677659439000, "33735": 1677673197000, "33738": 1677687730000, "33739": 1677687829000, "33740": 1677687901000, "33741": 1677707272000, "33742": 1677711253000, "33743": 1677711268000, "33746": 1677722653000, "33747": 1677725762000, "33748": 1677746160000, "33749": 1677747881000, "33751": 1677764541000, "33752": 1677795142000, "33754": 1677799874000, "33755": 1677800293000, "33756": 1677805775000, "33757": 1677810557000, "33758": 1677812420000, "33759": 1677835215000, "33760": 1677848007000, "33762": 1677870471000, "33763": 1677870510000, "33764": 1677893316000, "33765": 1677893458000, "33766": 1677896497000, "33767": 1677922997000, "33769": 1677947922000, "33771": 1678045040000, "33772": 1678087626000, "33773": 1678089031000, "33774": 1678091655000, "33775": 1678091941000, "33778": 1678103209000, "33779": 1678104195000, "33780": 1678111815000, "33781": 1678114649000, "33782": 1678122156000, "33783": 1678129529000, "33784": 1678139373000, "33785": 1678146200000, "33786": 1678184586000, "33787": 1678189656000, "33788": 1678213551000, "33789": 1678217999000, "33791": 1678221172000, "33793": 1678230713000, "33794": 1678230857000, "33795": 1678230989000, "33796": 1678233882000, "33797": 1678234253000, "33798": 1678249984000, "33799": 1678250084000, "33800": 1678266740000, "33801": 1678266785000, "33810": 1678311356000, "33811": 1678311893000, "33812": 1678312283000, "33813": 1678313089000, "33816": 1678319213000, "33817": 1678321296000, "33818": 1678356923000, "33820": 1678379508000, "33821": 1678381440000, "33822": 1678381907000, "33823": 1678382034000, "33824": 1678388850000, "33826": 1678398632000, "33828": 1678447926000, "33829": 1678450629000, "33830": 1678472219000, "33831": 1678472584000, "33832": 1678474623000, "33833": 1678477774000, "33835": 1678483818000, "33837": 1678495615000, "33838": 1678499878000, "33841": 1678531404000, "33842": 1678538064000, "33843": 1678538664000, "33844": 1678553542000, "33845": 1678563493000, "33846": 1678569984000, "33847": 1678588598000, "33848": 1678610541000, "33849": 1678708573000, "33851": 1678726195000, "33853": 1678727540000, "33854": 1678729791000, "33855": 1678729819000, "33856": 1678731640000, "33857": 1678735052000, "33868": 1678755227000, "33869": 1678760587000, "33871": 1678760710000, "33872": 1678760904000, "33873": 1678761102000, "33884": 1678812669000, "33885": 1678815715000, "33886": 1678816892000, "33887": 1678817015000, "33888": 1678817198000, "33889": 1678828464000, "33890": 1678836219000, "33891": 1678836236000, "33892": 1678840329000, "33900": 1678894526000, "33901": 1678896710000, "33902": 1678898201000, "33904": 1678900333000, "33905": 1678903082000, "33915": 1678919789000, "33916": 1678919843000, "33918": 1678924940000, "33922": 1678925168000, "33923": 1678925672000, "33927": 1678958126000, "33929": 1678971912000, "33930": 1678978724000, "33931": 1678990125000, "33932": 1678990166000, "33933": 1678990252000, "33934": 1678992720000, "33936": 1678997670000, "33937": 1679007842000, "33938": 1679045752000, "33941": 1679062303000, "33954": 1679073905000, "33955": 1679074015000, "33956": 1679074960000, "33957": 1679075743000, "33958": 1679076260000, "33959": 1679082529000, "33960": 1679090465000, "33961": 1679096790000, "33962": 1679142216000, "33964": 1679150205000, "33965": 1679166408000, "33966": 1679169681000, "33967": 1679175661000, "33968": 1679245217000, "33969": 1679251572000, "33971": 1679303375000, "33972": 1679328696000, "33973": 1679330456000, "33974": 1679331400000, "33975": 1679331864000, "33976": 1679332281000, "33977": 1679332675000, "33978": 1679344643000, "33980": 1679344784000, "33981": 1679351238000, "33982": 1679418567000, "33983": 1679418629000, "33984": 1679447088000, "33985": 1679502041000, "33986": 1679506499000, "33987": 1679506773000, "33989": 1679514429000, "33990": 1679516388000, "33993": 1679585831000, "33994": 1679586069000, "33995": 1679597185000, "33996": 1679614319000, "34001": 1679657482000, "34002": 1679660209000, "34004": 1679676616000, "34007": 1679677258000, "34008": 1679677436000, "34009": 1679677589000, "34010": 1679677804000, "34011": 1679678063000, "34014": 1679693289000, "34015": 1679693313000, "34016": 1679694405000, "34017": 1679694914000, "34019": 1679720943000, "34021": 1679750491000, "34024": 1679773257000, "34025": 1679777040000, "34026": 1679777073000, "34027": 1679802513000, "34029": 1679859299000, "34030": 1679890572000, "34031": 1679897915000, "34032": 1679907408000, "34033": 1679937440000, "34035": 1679940268000, "34036": 1679940559000, "34037": 1679940682000, "34038": 1679941610000, "34039": 1679942493000, "34041": 1679948588000, "34043": 1679950879000, "34044": 1679950992000, "34045": 1679951172000, "34046": 1679953710000, "34047": 1679997434000, "34049": 1680027234000, "34050": 1680027335000, "34051": 1680027837000, "34052": 1680028264000, "34053": 1680040767000, "34055": 1680047730000, "34057": 1680098693000, "34058": 1680098771000, "34059": 1680098831000, "34060": 1680100489000, "34061": 1680103767000, "34065": 1680108022000, "34078": 1680133646000, "34079": 1680135348000, "34081": 1680143009000, "34083": 1680145800000, "34084": 1680145909000, "34088": 1680193388000, "34089": 1680194138000, "34090": 1680194277000, "34091": 1680194653000, "34092": 1680195132000, "34094": 1680205767000, "34096": 1680220355000, "34098": 1680230031000, "34100": 1680244607000, "34101": 1680273332000, "34106": 1680282725000, "34107": 1680282805000, "34108": 1680283070000, "34109": 1680283515000, "34110": 1680284050000, "34111": 1680286929000, "34113": 1680302989000, "34114": 1680355716000, "34116": 1680370087000, "34117": 1680371488000, "34119": 1680431284000, "34120": 1680439906000, "34122": 1680444818000, "34123": 1680445209000, "34124": 1680446054000, "34125": 1680449075000, "34126": 1680449360000, "34131": 1680467526000, "34133": 1680513785000, "34135": 1680526113000, "34136": 1680529415000, "34137": 1680533042000, "34140": 1680542314000, "34141": 1680544308000, "34142": 1680545960000, "34143": 1680546645000, "34148": 1680561270000, "34149": 1680565063000, "34150": 1680567515000, "34151": 1680567594000, "34152": 1680567647000, "34156": 1680627279000, "34157": 1680627478000, "34158": 1680627993000, "34159": 1680628041000, "34160": 1680628443000, "34161": 1680628494000, "34162": 1680628930000, "34163": 1680629252000, "34166": 1680708161000, "34167": 1680732690000, "34168": 1680770043000, "34169": 1680777128000, "34171": 1680784993000, "34173": 1680794617000, "34174": 1680794736000, "34175": 1680795015000, "34176": 1680795573000, "34177": 1680797247000, "34193": 1680834017000, "34194": 1680834366000, "34195": 1680834545000, "34196": 1680835965000, "34197": 1680836250000, "34199": 1680867757000, "34200": 1680882385000, "34201": 1680882707000, "34202": 1680882815000, "34210": 1680901507000, "34212": 1680911847000, "34213": 1680911930000, "34214": 1680912338000, "34215": 1680915958000, "34216": 1680969088000, "34217": 1680969289000, "34218": 1680973661000, "34220": 1681026551000, "34221": 1681027924000, "34222": 1681144281000, "34224": 1681145714000, "34225": 1681148713000, "34226": 1681149166000, "34227": 1681149763000, "34228": 1681151118000, "34241": 1681168618000, "34242": 1681168669000, "34243": 1681168786000, "34244": 1681168905000, "34245": 1681172203000, "34254": 1681234365000, "34255": 1681235738000, "34256": 1681236257000, "34257": 1681237217000, "34260": 1681237673000, "34261": 1681248653000, "34263": 1681249389000, "34264": 1681251076000, "34265": 1681254555000, "34267": 1681255476000, "34272": 1681315040000, "34273": 1681318633000, "34274": 1681318969000, "34275": 1681319142000, "34276": 1681326612000, "34280": 1681333766000, "34281": 1681340209000, "34283": 1681342892000, "34284": 1681344400000, "34285": 1681350020000, "34288": 1681381155000, "34290": 1681403086000, "34292": 1681419622000, "34293": 1681419734000, "34294": 1681420017000, "34295": 1681468150000, "34296": 1681468728000, "34297": 1681490494000, "34298": 1681490585000, "34299": 1681494522000, "34301": 1681514153000, "34302": 1681514230000, "34303": 1681519615000, "34305": 1681676500000, "34306": 1681677850000, "34307": 1681738612000, "34308": 1681749677000, "34309": 1681749825000, "34311": 1681751487000, "34312": 1681751726000, "34313": 1681751808000, "34314": 1681752301000, "34315": 1681752579000, "34316": 1681768715000, "34317": 1681769711000, "34318": 1681773869000, "34319": 1681773964000, "34320": 1681823792000, "34321": 1681836962000, "34322": 1681840761000, "34323": 1681841011000, "34325": 1681847959000, "34326": 1681855615000, "34328": 1681895391000, "34329": 1681902894000, "34330": 1681908599000, "34331": 1681908829000, "34332": 1681909166000, "34348": 1681942282000, "34349": 1681942346000, "34350": 1681942391000, "34351": 1681942453000, "34352": 1681942480000, "34353": 1681948909000, "34355": 1681985858000, "34358": 1682003732000, "34359": 1682004041000, "34360": 1682004329000, "34361": 1682004600000, "34362": 1682006859000, "34364": 1682013220000, "34365": 1682013446000, "34368": 1682023049000, "34369": 1682028746000, "34370": 1682043487000, "34375": 1682088427000, "34376": 1682093387000, "34377": 1682096738000, "34378": 1682096930000, "34379": 1682098074000, "34380": 1682099966000, "34381": 1682104016000, "34383": 1682120466000, "34384": 1682156616000, "34386": 1682157318000, "34387": 1682159633000, "34388": 1682159928000, "34391": 1682184124000, "34392": 1682184222000, "34393": 1682194691000, "34394": 1682196716000, "34396": 1682239419000, "34397": 1682244173000, "34398": 1682244653000, "34400": 1682250339000, "34405": 1682257935000, "34407": 1682277072000, "34408": 1682277223000, "34409": 1682277502000, "34410": 1682277566000, "34411": 1682278220000, "34412": 1682290211000, "34414": 1682295401000, "34416": 1682340250000, "34417": 1682346966000, "34419": 1682357784000, "34420": 1682360671000, "34421": 1682361162000, "34422": 1682362187000, "34425": 1682383842000, "34426": 1682383930000, "34428": 1682436596000, "34429": 1682441199000, "34430": 1682441953000, "34431": 1682443625000, "34432": 1682443727000, "34434": 1682448690000, "34435": 1682453428000, "34436": 1682453475000, "34437": 1682453526000, "34438": 1682453645000, "34479": 1682819956000, "34480": 1682848536000, "34481": 1682848845000, "34482": 1682848891000, "34483": 1682870451000, "34484": 1682963395000, "34485": 1682963548000, "34487": 1682963969000, "34488": 1682964081000, "34489": 1682964170000, "34490": 1682964632000, "34491": 1682965338000, "34492": 1682983689000, "34494": 1683040588000, "34495": 1683044992000, "34496": 1683046259000, "34497": 1683056454000, "34498": 1683056496000, "34499": 1683061013000, "34500": 1683103319000, "34501": 1683124895000, "34502": 1683129119000, "34503": 1683129308000, "34504": 1683130284000, "34505": 1683130372000, "34506": 1683149861000, "34507": 1683207793000, "34508": 1683219915000, "34512": 1683220900000, "34513": 1683221140000, "34514": 1683222086000, "34515": 1683222218000, "34516": 1683222304000, "34519": 1683238267000, "34520": 1683283044000, "34521": 1683287134000, "34522": 1683299937000, "34525": 1683308733000, "34526": 1683308812000, "34527": 1683309581000, "34528": 1683309750000, "34529": 1683309947000, "34530": 1683314753000, "34531": 1683314783000, "34533": 1683319539000, "34534": 1683356837000, "34536": 1683384210000, "34537": 1683394169000, "34538": 1683453671000, "34539": 1683453888000, "34540": 1683464295000, "34541": 1683474244000, "34542": 1683477339000, "34543": 1683477522000, "34544": 1683539182000, "34545": 1683551674000, "34546": 1683557956000, "34548": 1683563777000, "34549": 1683563870000, "34551": 1683564273000, "34552": 1683585925000, "34554": 1683640970000, "34555": 1683643674000, "34556": 1683650618000, "34557": 1683650719000, "34561": 1683651576000, "34562": 1683654233000, "34563": 1683655443000, "34564": 1683673779000, "34565": 1683680318000, "34566": 1683766642000, "34567": 1683766908000, "34568": 1683767075000, "34569": 1683818610000, "34570": 1683836245000, "34571": 1683836641000, "34572": 1683848729000, "34573": 1683889570000, "34574": 1683910698000, "34575": 1683911790000, "34576": 1683912030000, "34577": 1683912266000, "34578": 1683919623000, "34580": 1684042258000, "34581": 1684055010000, "34582": 1684057113000, "34583": 1684057429000, "34585": 1684080932000, "34588": 1684162005000, "34589": 1684174786000, "34594": 1684182020000, "34595": 1684182439000, "34596": 1684182489000, "34597": 1684183012000, "34598": 1684183468000, "34599": 1684187462000, "34601": 1684195487000, "34602": 1684235427000, "34603": 1684256270000, "34604": 1684256586000, "34605": 1684260309000, "34606": 1684305132000, "34607": 1684322375000, "34608": 1684332855000, "34612": 1684339090000, "34613": 1684340066000, "34614": 1684341749000, "34615": 1684341932000, "34616": 1684342292000, "34617": 1684344800000, "34621": 1684408665000, "34622": 1684426308000, "34623": 1684426367000, "34624": 1684426924000, "34625": 1684427239000, "34626": 1684439873000, "34627": 1684444864000, "34628": 1684509489000, "34629": 1684519421000, "34630": 1684519613000, "34631": 1684519921000, "34632": 1684530829000, "34633": 1684543286000, "34634": 1684578971000, "34635": 1684594499000, "34636": 1684595325000, "34639": 1684689231000, "34640": 1684750791000, "34641": 1684750960000, "34642": 1684773537000, "34644": 1684778488000, "34645": 1684778581000, "34646": 1684778942000, "34647": 1684779038000, "34648": 1684779594000, "34649": 1684797735000, "34650": 1684836020000, "34651": 1684847325000, "34652": 1684859814000, "34653": 1684874109000, "34655": 1684893338000, "34656": 1684901096000, "34657": 1684941777000, "34658": 1684941887000, "34659": 1684941920000, "34661": 1684943366000, "34662": 1684944231000, "34664": 1684950596000, "34665": 1684950673000, "34668": 1684961629000, "34669": 1684984579000, "34670": 1685007224000, "34671": 1685031205000, "34672": 1685031724000, "34673": 1685032064000, "34675": 1685048922000, "34676": 1685049068000, "34677": 1685086393000, "34678": 1685088845000, "34679": 1685118121000, "34680": 1685146710000, "34681": 1685194523000, "34683": 1685215454000, "34685": 1685260550000, "34686": 1685260743000, "34689": 1685307768000, "34691": 1685466250000, "34696": 1685471531000, "34697": 1685471624000, "34698": 1685471778000, "34699": 1685471825000, "34700": 1685472185000, "34704": 1685477511000, "34705": 1685477801000, "34706": 1685479006000, "34707": 1685479276000, "34708": 1685483554000, "34954": 1687968621000, "34955": 1687968939000, "34956": 1687973419000, "34957": 1687975643000, "34958": 1687976785000, "34960": 1687987644000, "34961": 1687988990000, "34962": 1687989071000, "34963": 1687997944000, "34964": 1688007106000, "34965": 1688007131000, "34969": 1688047725000, "34970": 1688047783000, "34971": 1688054368000, "34972": 1688055231000, "34973": 1688064449000, "34974": 1688074394000, "34975": 1688076398000, "34976": 1688076444000, "34977": 1688111411000, "34978": 1688111862000, "34981": 1688147217000, "34982": 1688147330000, "34983": 1688150347000, "34984": 1688155070000, "34985": 1688155162000, "34986": 1688193370000, "34988": 1688329467000, "34989": 1688333274000, "34990": 1688414858000, "34991": 1688496789000, "34992": 1688542591000, "34993": 1688542657000, "34994": 1688544434000, "34995": 1688567172000, "34996": 1688577660000, "34997": 1688582814000, "34998": 1688648981000, "34999": 1688659949000, "35000": 1688667463000, "35011": 1688675634000, "35012": 1688676812000, "35013": 1688677798000, "35014": 1688677878000, "35015": 1688677979000, "35016": 1688687709000, "35017": 1688749512000, "35018": 1688749614000, "35019": 1688749661000, "35020": 1688749703000, "35021": 1688749934000, "35022": 1688752576000, "35023": 1688756464000, "35024": 1688756923000, "35028": 1688872199000, "35030": 1688893134000, "35031": 1689010573000, "35032": 1689011413000, "35033": 1689011497000, "35034": 1689011652000, "35035": 1689012605000, "35036": 1689019793000, "35041": 1689027715000, "35042": 1689027835000, "35043": 1689040180000, "35044": 1689040232000, "35045": 1689040307000, "35052": 1689093996000, "35053": 1689094325000, "35054": 1689096770000, "35055": 1689098993000, "35056": 1689104883000, "35057": 1689108725000, "35058": 1689110172000, "35059": 1689110279000, "35060": 1689176424000, "35061": 1689179047000, "35062": 1689179403000, "35063": 1689203722000, "35064": 1689238448000, "35065": 1689245938000, "35066": 1689246383000, "35067": 1689253961000, "35068": 1689264491000, "35069": 1689264537000, "35070": 1689265205000, "35071": 1689266408000, "35072": 1689272617000, "35073": 1689279592000, "35074": 1689280681000, "35075": 1689308094000, "35076": 1689339250000, "35077": 1689352838000, "35078": 1689356758000, "35079": 1689356982000, "35080": 1689376883000, "35081": 1689537212000, "35082": 1689539164000, "35083": 1689556734000, "35085": 1689588722000, "35086": 1689589019000, "35087": 1689590358000, "35088": 1689594812000, "35104": 1689616369000, "35105": 1689616703000, "35106": 1689616872000, "35107": 1689617640000, "35108": 1689620841000, "35109": 1689629164000, "35110": 1689637338000, "35111": 1689649700000, "35112": 1689696020000, "35113": 1689698122000, "35114": 1689699050000, "35115": 1689699955000, "35120": 1689711873000, "35121": 1689712372000, "35122": 1689721227000, "35123": 1689721295000, "35124": 1689721343000, "35125": 1689732041000, "35126": 1689757162000, "35127": 1689781294000, "35128": 1689790884000, "35129": 1689790949000, "35130": 1689791030000, "35131": 1689804130000, "35132": 1689804342000, "35133": 1689862573000, "35134": 1689866329000, "35135": 1689866492000, "35136": 1689866736000, "35137": 1689884800000, "35138": 1689884848000, "35139": 1689885057000, "35140": 1689885652000, "35141": 1689907232000, "35142": 1689924497000, "35143": 1689926368000, "35144": 1689960778000, "35145": 1690022255000, "35146": 1690032569000, "35147": 1690057848000, "35148": 1690209316000, "35149": 1690218881000, "35150": 1690218938000, "35151": 1690219261000, "35152": 1690219396000, "35158": 1690230776000, "35159": 1690243255000, "35160": 1690243344000, "35161": 1690243834000, "35162": 1690243979000, "35163": 1690270139000, "35164": 1690273092000, "35165": 1690280431000, "35167": 1690307024000, "35168": 1690307813000, "35169": 1690309950000, "35170": 1690310001000, "35171": 1690322836000, "35172": 1690328185000, "35173": 1690339127000, "35174": 1690362473000, "35175": 1690385777000, "35176": 1690391734000, "35177": 1690403381000, "35178": 1690474085000, "35179": 1690480913000, "35180": 1690484563000, "35181": 1690484601000, "35182": 1690552085000, "35183": 1690553816000, "35186": 1690566731000, "35187": 1690567028000, "35188": 1690567241000, "35189": 1690567654000, "35190": 1690568285000, "35191": 1690574420000, "35192": 1690574503000, "35193": 1690581465000, "35194": 1690585732000, "35195": 1690601433000, "35196": 1690721755000, "35197": 1690731341000, "35198": 1690816705000, "35202": 1690822280000, "35203": 1690822321000, "35204": 1690822458000, "35205": 1690822591000, "35206": 1690822684000, "35214": 1690841182000, "35215": 1690850593000, "35216": 1690850728000, "35217": 1690855472000, "35218": 1690855609000, "35227": 1690908536000, "35228": 1690909013000, "35229": 1690909340000, "35230": 1690911248000, "35231": 1690912203000, "35234": 1690918995000, "35235": 1690923929000, "35236": 1690928529000, "35237": 1690928582000, "35238": 1690939937000, "35242": 1690991282000, "35243": 1690991330000, "35244": 1690991406000, "35245": 1690991591000, "35246": 1690996287000, "35247": 1691074689000, "35248": 1691075448000, "35249": 1691079532000, "35250": 1691094224000, "35251": 1691094297000, "35252": 1691094361000, "35253": 1691095175000, "35254": 1691100499000, "35255": 1691108645000, "35256": 1691167697000, "35257": 1691167863000, "35258": 1691167947000, "35259": 1691168025000, "35269": 1691184139000, "35270": 1691184238000, "35271": 1691184374000, "35272": 1691191781000, "35273": 1691191918000, "35274": 1691258760000, "35279": 1691260352000, "35280": 1691260419000, "35281": 1691260515000, "35282": 1691260705000, "35283": 1691267827000, "35284": 1691316873000, "35285": 1691316964000, "35286": 1691317205000, "35287": 1691344851000, "35288": 1691350742000, "35289": 1691426556000, "35290": 1691430588000, "35291": 1691430936000, "35292": 1691439470000, "35293": 1691439565000, "35294": 1691439724000, "35295": 1691457581000, "35296": 1691512578000, "35297": 1691512665000, "35298": 1691524396000, "35299": 1691538373000, "35300": 1691594295000, "35301": 1691595177000, "35302": 1691595348000, "35303": 1691596038000, "35304": 1691598880000, "35305": 1691600441000, "35306": 1691618632000, "35307": 1691628281000, "35308": 1691681609000, "35309": 1691688173000, "35311": 1691700370000, "35312": 1691700470000, "35313": 1691700506000, "35314": 1691700734000, "35315": 1691700744000, "35316": 1691701033000, "35317": 1691702488000, "35318": 1691706235000, "35319": 1691738735000, "35320": 1691739040000, "35324": 1691745450000, "35325": 1691768875000, "35326": 1691770740000, "35327": 1691771053000, "35328": 1691771337000, "35329": 1691796953000, "35330": 1691841962000, "35331": 1691842289000, "35335": 1691911055000, "35336": 1691912293000, "35338": 1691928253000, "35340": 1691930857000, "35342": 1691966278000, "35343": 1691966332000, "35347": 1692122748000, "35350": 1692125355000, "35351": 1692125448000, "35352": 1692125974000, "35353": 1692126456000, "35354": 1692127085000, "35359": 1692209241000, "35360": 1692210025000, "35361": 1692210124000, "35362": 1692216282000, "35363": 1692217235000, "35364": 1692222848000, "35365": 1692223070000, "35368": 1692261756000, "35370": 1692286679000, "35371": 1692287571000, "35372": 1692287653000, "35374": 1692296802000, "35375": 1692305995000, "35376": 1692314521000, "35377": 1692314582000, "35378": 1692343839000, "35379": 1692354302000, "35382": 1692376712000, "35383": 1692377378000, "35384": 1692377444000, "35385": 1692377901000, "35386": 1692378031000, "35387": 1692390545000, "35388": 1692431134000, "35389": 1692443058000, "35390": 1692569576000, "35391": 1692609453000, "35394": 1692642736000, "35402": 1692645707000, "35403": 1692645740000, "35404": 1692645784000, "35405": 1692647967000, "35407": 1692649611000, "35409": 1692660042000, "35410": 1692707990000, "35411": 1692711381000, "35412": 1692716744000, "35421": 1692730102000, "35422": 1692730641000, "35423": 1692730782000, "35424": 1692731076000, "35425": 1692731320000, "35432": 1692744797000, "35433": 1692748527000, "35435": 1692750014000, "35436": 1692750231000, "35437": 1692750645000, "35440": 1692805056000, "35441": 1692805438000, "35442": 1692805549000, "35443": 1692805825000, "35444": 1692809017000, "35448": 1692825348000, "35522": 1693341009000, "35525": 1693394639000, "35526": 1693414024000, "35527": 1693414640000, "35528": 1693414938000, "35529": 1693423424000, "35530": 1693446463000, "35531": 1693448003000, "35532": 1693469802000, "35533": 1693470251000, "35535": 1693490046000, "35537": 1693497834000, "35538": 1693498863000, "35539": 1693498987000, "35540": 1693499189000, "35543": 1693513047000, "35544": 1693515486000, "35546": 1693527173000, "35547": 1693527510000, "35548": 1693527584000, "35554": 1693585095000, "35555": 1693587305000, "35556": 1693587349000, "35557": 1693587744000, "35558": 1693587918000, "35561": 1693590598000, "35562": 1693656436000, "35563": 1693674094000, "35566": 1693678444000, "35567": 1693678479000, "35568": 1693678551000, "35573": 1693690340000, "35574": 1693690388000, "35576": 1693773734000, "35577": 1693818581000, "35578": 1693821120000, "35579": 1693837918000, "35580": 1693848213000, "35581": 1693871539000, "35582": 1693937241000, "35586": 1693938590000, "35587": 1693939405000, "35588": 1693939498000, "35589": 1693939542000, "35590": 1693944429000, "35592": 1693953156000, "35593": 1693953711000, "35599": 1693990858000, "35600": 1694020349000, "35601": 1694020587000, "35602": 1694020652000, "35603": 1694020770000, "35604": 1694030774000, "35605": 1694030826000, "35606": 1694040023000, "35607": 1694040157000, "35609": 1694102398000, "35610": 1694102441000, "35611": 1694102708000, "35612": 1694102831000, "35613": 1694104125000, "35614": 1694104250000, "35615": 1694104372000, "35620": 1694183467000, "35621": 1694191302000, "35623": 1694193152000, "35624": 1694205140000, "35625": 1694205227000, "35627": 1694292279000, "35629": 1694445789000, "35630": 1694446183000, "35631": 1694447721000, "35632": 1694448822000, "35633": 1694448899000, "35634": 1694450044000, "35635": 1694459761000, "35636": 1694463668000, "35639": 1694550896000, "35640": 1694624454000, "35641": 1694624628000, "35642": 1694625010000, "35643": 1694625299000, "35645": 1694635508000, "35646": 1694648164000, "35647": 1694648266000, "35648": 1694648347000, "35649": 1694769052000, "35650": 1694808384000, "35651": 1694829801000, "35652": 1694871993000, "35655": 1694954725000, "35656": 1694954889000, "35657": 1695053709000, "35663": 1695055180000, "35664": 1695056052000, "35665": 1695056171000, "35666": 1695057638000, "35667": 1695057729000, "35670": 1695066158000, "35671": 1695068341000, "35672": 1695073053000, "35673": 1695074574000, "35675": 1695080830000, "35678": 1695138373000, "35679": 1695138426000, "35680": 1695138604000, "35681": 1695144090000, "35682": 1695149329000, "35683": 1695153896000, "35685": 1695162336000, "35686": 1695174603000, "35687": 1695174831000, "35688": 1695207196000, "35689": 1695211036000, "35693": 1695217954000, "35698": 1695229052000, "35699": 1695229195000, "35700": 1695229235000, "35701": 1695229463000, "35703": 1695237853000, "35704": 1695249543000, "35705": 1695341428000, "35706": 1695349851000, "35707": 1695394778000, "35708": 1695401451000, "35709": 1695402122000, "35710": 1695412510000, "35711": 1695426391000, "35713": 1695426533000, "35714": 1695576090000, "35716": 1695665286000, "35717": 1695665335000, "35718": 1695666052000, "35719": 1695666153000, "35720": 1695667365000, "35721": 1695667420000, "35723": 1695687066000, "35725": 1695743336000, "35726": 1695743860000, "35727": 1695762175000, "35729": 1695833445000, "35730": 1695917771000, "35731": 1695999050000, "35732": 1696005283000, "35733": 1696097939000, "35735": 1696240098000, "35736": 1696262655000, "35740": 1696265336000, "35741": 1696265457000, "35742": 1696265546000, "35743": 1696268066000, "35744": 1696268125000, "35747": 1696347961000, "35748": 1696348081000, "35750": 1696352134000, "35751": 1696355315000, "35754": 1696363294000, "35755": 1696363320000, "35756": 1696363356000, "35759": 1696370200000, "35760": 1696372942000, "35762": 1696379384000, "35763": 1696408760000, "35764": 1696408777000, "35773": 1696439246000, "35774": 1696443481000, "35775": 1696443545000, "35777": 1696443659000, "35778": 1696451897000, "35780": 1696466482000, "35781": 1696522405000, "35782": 1696522516000, "35783": 1696522736000, "35784": 1696546186000, "35785": 1696585225000, "35787": 1696608254000, "35788": 1696608339000, "35789": 1696608461000, "35790": 1696608614000, "35791": 1696608873000, "35792": 1696613371000, "35793": 1696622508000, "35794": 1696666846000, "35796": 1696688572000, "35797": 1696711110000, "35798": 1696773465000, "35799": 1696790997000, "35800": 1696805808000, "35802": 1696870630000, "35803": 1696870742000, "35806": 1696873910000, "35807": 1696876057000, "35808": 1696876155000, "35809": 1696876235000, "35810": 1696876393000, "35812": 1696891188000, "35814": 1696898258000, "35815": 1696952480000, "35816": 1696953043000, "35817": 1696953199000, "35818": 1696953521000, "35819": 1696964266000, "35820": 1697046863000, "35821": 1697046897000, "35822": 1697046910000, "35823": 1697123305000, "35824": 1697123459000, "35825": 1697123557000, "35826": 1697149894000, "35827": 1697149978000, "35829": 1697214456000, "35830": 1697214761000, "35831": 1697214901000, "35832": 1697215282000, "35833": 1697216260000, "35834": 1697222516000, "35835": 1697270325000, "35836": 1697333279000, "35837": 1697377149000, "35838": 1697377438000, "35842": 1697396434000, "35843": 1697474946000, "35844": 1697475061000, "35845": 1697475140000, "35846": 1697478827000, "35847": 1697482228000, "35849": 1697557585000, "35850": 1697557643000, "35851": 1697558136000, "35852": 1697577588000, "35853": 1697577807000, "35854": 1697581777000, "35856": 1697589365000, "35858": 1697647920000, "35859": 1697661022000, "35861": 1697671744000, "35862": 1697678129000, "35864": 1697731362000, "35865": 1697733295000, "35866": 1697733363000, "35867": 1697733655000, "35868": 1697733763000, "35870": 1697733976000, "35872": 1697755950000, "35873": 1697756014000, "35874": 1697756064000, "35876": 1697820223000, "35877": 1697820383000, "35878": 1697843275000, "35880": 1697923197000, "35881": 1697982073000, "35882": 1697988033000, "35885": 1698002333000, "35889": 1698003048000, "35890": 1698003323000, "35891": 1698004051000, "35892": 1698004141000, "35893": 1698004338000, "35895": 1698021751000, "35896": 1698022032000, "35898": 1698047339000, "35899": 1698053216000, "35901": 1698079875000, "35902": 1698082029000, "35903": 1698082159000, "35904": 1698082321000, "35905": 1698084515000, "35906": 1698095762000, "35907": 1698095812000, "35908": 1698101254000, "35909": 1698101643000, "35910": 1698107368000, "35913": 1698162465000, "35914": 1698163705000, "35915": 1698169272000, "35916": 1698169544000, "35917": 1698170212000, "35921": 1698197492000, "35922": 1698197547000, "35923": 1698197631000, "35924": 1698197716000, "35925": 1698197767000, "35932": 1698253514000, "35933": 1698253642000, "35934": 1698254043000, "35935": 1698254109000, "35936": 1698254285000, "35938": 1698286498000, "35939": 1698312776000, "35940": 1698314268000, "35945": 1698325848000, "35946": 1698328756000, "35947": 1698332022000, "35948": 1698332075000, "35949": 1698332314000, "35952": 1698336491000, "35954": 1698372630000, "35955": 1698372845000, "35956": 1698373025000, "35957": 1698373119000, "35958": 1698373163000, "35959": 1698400402000, "35961": 1698424803000, "35963": 1698443355000, "35964": 1698532000000, "35965": 1698532140000, "35967": 1698543854000, "35968": 1698543924000, "35969": 1698599625000, "35970": 1698599911000, "35971": 1698600176000, "35972": 1698663566000, "35973": 1698684234000, "35977": 1698685280000, "35978": 1698685318000, "35979": 1698685376000, "35980": 1698685482000, "35981": 1698688461000, "35982": 1698744188000, "35983": 1698744232000, "35984": 1698764942000, "35985": 1698769903000, "35986": 1698770012000, "35987": 1698785132000, "35988": 1698795659000, "35989": 1698841117000, "35990": 1698859255000, "35991": 1698871792000, "35992": 1698877102000, "35994": 1698886275000, "35995": 1698895437000, "35996": 1698901569000, "35997": 1698942929000, "35998": 1698963238000, "35999": 1699031568000, "36000": 1699032681000, "36001": 1699032737000, "36002": 1699050068000, "36003": 1699050374000, "36004": 1699050515000, "36005": 1699136410000, "36006": 1699138232000, "36007": 1699138326000, "36008": 1699196438000, "36009": 1699291141000, "36011": 1699291480000, "36012": 1699291638000, "36013": 1699291921000, "36014": 1699292253000, "36015": 1699299306000, "36020": 1699319818000, "36021": 1699319921000, "36022": 1699319969000, "36023": 1699320088000, "36024": 1699324209000, "36029": 1699371716000, "36030": 1699371822000, "36032": 1699372053000, "36033": 1699378177000, "36035": 1699387901000, "36036": 1699393018000, "36037": 1699393529000, "36038": 1699396618000, "36039": 1699396787000, "36041": 1699466269000, "36042": 1699471229000, "36043": 1699477355000, "36044": 1699516193000, "36045": 1699516500000, "36046": 1699537508000, "36047": 1699544272000, "36048": 1699544362000, "36049": 1699544590000, "36050": 1699544892000, "36051": 1699545110000, "36053": 1699554006000, "36055": 1699564924000, "36057": 1699623284000, "36058": 1699623385000, "36060": 1699628012000, "36062": 1699636443000, "36063": 1699656542000, "36064": 1699656660000, "36065": 1699656796000, "36066": 1699656841000, "36067": 1699661309000, "36068": 1699666791000, "36069": 1699732320000, "36070": 1699882005000, "36071": 1699883552000, "36073": 1699901591000, "36074": 1699902304000, "36075": 1699902442000, "36076": 1699904283000, "36077": 1699909295000, "36079": 1699923929000, "36080": 1699924095000, "36081": 1699924149000, "36082": 1699924272000, "36083": 1699961693000, "36084": 1699976356000, "36086": 1699976463000, "36087": 1699976549000, "36088": 1699977266000, "36091": 1699995411000, "36092": 1699995468000, "36093": 1699995549000, "36094": 1699995580000, "36095": 1699995653000, "36096": 1700020665000, "36097": 1700072446000, "36098": 1700084164000, "36099": 1700084282000, "36100": 1700090400000, "36101": 1700100804000, "36102": 1700100919000, "36103": 1700101046000, "36104": 1700101258000, "36105": 1700143560000, "36106": 1700154430000, "36107": 1700154565000, "36108": 1700154631000, "36109": 1700154717000, "36110": 1700154822000, "36115": 1700158687000, "36116": 1700166451000, "36117": 1700186593000, "36118": 1700186695000, "36119": 1700186761000, "36120": 1700214295000, "36121": 1700234405000, "36129": 1700247818000, "36130": 1700247834000, "36131": 1700251737000, "36132": 1700251976000, "36133": 1700252222000, "36140": 1700271705000, "36141": 1700271750000, "36142": 1700274902000, "36143": 1700274987000, "36144": 1700276774000, "36145": 1700350620000, "36146": 1700350686000, "36147": 1700350747000, "36148": 1700350856000, "36149": 1700350929000, "36150": 1700351103000, "36151": 1700364479000, "36152": 1700420451000, "36153": 1700421429000, "36154": 1700422005000, "36156": 1700435226000, "36157": 1700435503000, "36158": 1700445722000, "36159": 1700445879000, "36160": 1700445984000, "36162": 1700502037000, "36165": 1700502929000, "36166": 1700503108000, "36167": 1700505293000, "36168": 1700505471000, "36169": 1700508753000, "36174": 1700516030000, "36175": 1700518643000, "36176": 1700519003000, "36178": 1700531896000, "36179": 1700534179000, "36181": 1700580977000, "36182": 1700581146000, "36185": 1700597762000, "36186": 1700600080000, "36187": 1700600141000, "36188": 1700601231000, "36189": 1700601377000, "36191": 1700614770000, "36192": 1700614798000, "36194": 1700647125000, "36195": 1700676764000, "36196": 1700676806000, "36202": 1700680313000, "36204": 1700686223000, "36205": 1700686264000, "36206": 1700691237000, "36207": 1700691369000, "36209": 1700695236000, "36210": 1700704285000, "36211": 1700768695000, "36212": 1700768742000, "36213": 1700768830000, "36214": 1700776851000, "36215": 1700819193000, "36216": 1700866572000, "36217": 1700866636000, "36218": 1700866736000, "36219": 1700946173000, "36220": 1700946301000, "36221": 1700972019000, "36229": 1700974018000, "36230": 1700974254000, "36231": 1700974998000, "36232": 1700975151000, "36233": 1700978861000, "36234": 1701017196000, "36236": 1701022977000, "36237": 1701023093000, "36238": 1701023144000, "36239": 1701023725000, "36240": 1701023773000, "36243": 1701052378000, "36244": 1701052984000, "36245": 1701053081000, "36246": 1701053563000, "36247": 1701053961000, "36253": 1701095164000, "36254": 1701106236000, "36255": 1701106943000, "36256": 1701107329000, "36257": 1701110461000, "36258": 1701118147000, "36259": 1701118267000, "36260": 1701119834000, "36261": 1701125146000, "36262": 1701185678000, "36263": 1701186226000, "36264": 1701186437000, "36265": 1701186856000, "36266": 1701191254000, "36268": 1701191318000, "36269": 1701196798000, "36270": 1701231740000, "36271": 1701279783000, "36272": 1701280092000, "36273": 1701280227000, "36274": 1701280286000, "36275": 1701280315000, "36276": 1701280593000, "36277": 1701280848000, "36278": 1701280921000, "36279": 1701355081000, "36280": 1701365106000, "36281": 1701365291000, "36282": 1701365354000, "36283": 1701365466000, "36287": 1701366407000, "36288": 1701366479000, "36289": 1701368904000, "36291": 1701378434000, "36292": 1701386447000, "36293": 1701454905000, "36296": 1701455735000, "36297": 1701455802000, "36298": 1701455825000, "36299": 1701456810000, "36300": 1701459288000, "36301": 1701476061000, "36302": 1701482966000, "36303": 1701678572000, "36304": 1701684505000, "36305": 1701684813000, "36306": 1701687356000, "36308": 1701688644000, "36309": 1701692758000, "36310": 1701692794000, "36311": 1701692835000, "36312": 1701693758000, "36325": 1701719726000, "36327": 1701735752000, "36328": 1701735821000, "36329": 1701735865000, "36330": 1701736056000, "36332": 1701770197000, "36333": 1701798515000, "36334": 1701798618000, "36335": 1701808787000, "36336": 1701813439000, "36341": 1701823805000, "36343": 1701824022000, "36344": 1701824442000, "36345": 1701826949000, "36346": 1701826965000, "36347": 1701838956000, "36348": 1701886936000, "36349": 1701887057000, "36350": 1701887185000, "36351": 1701916257000, "36352": 1701928659000, "36355": 1701969334000, "36356": 1701972252000, "36357": 1701976543000, "36358": 1701976630000, "36359": 1701979512000, "36360": 1701983738000, "36364": 1701994501000, "36367": 1702004972000, "36369": 1702024365000, "36370": 1702028318000, "36371": 1702028375000, "36372": 1702033304000, "36373": 1702043730000, "36374": 1702045055000, "36375": 1702065964000, "36377": 1702077925000, "36378": 1702078099000, "36379": 1702078240000, "36380": 1702078751000, "36381": 1702078916000, "36382": 1702083655000, "36383": 1702083993000, "36384": 1702084083000, "36385": 1702084668000, "36386": 1702086214000, "36398": 1702149502000, "36399": 1702149650000, "36400": 1702149870000, "36401": 1702149969000, "36402": 1702156794000, "36403": 1702164925000, "36404": 1702235473000, "36405": 1702251949000, "36408": 1702299959000, "36409": 1702315638000, "36410": 1702315674000, "36416": 1702316505000, "36417": 1702316621000, "36418": 1702321577000, "36419": 1702322482000, "36420": 1702322534000, "36421": 1702341564000, "36422": 1702341705000, "36423": 1702381328000, "36424": 1702395104000, "36425": 1702395873000, "36426": 1702399600000, "36427": 1702444975000, "36429": 1702490031000, "36430": 1702547649000, "36431": 1702575206000, "36432": 1702575400000, "36433": 1702575499000, "36435": 1702595214000, "36436": 1702595273000, "36437": 1702595701000, "36438": 1702596979000, "36439": 1702597236000, "36440": 1702662493000, "36441": 1702680447000, "36442": 1702844461000, "36443": 1702845635000, "36444": 1702852883000}, "params": {"arch": ["x86_64"], "cpu": ["Intel(R) Core(TM) i7-4980HQ CPU @ 2.80GHz"], "machine": ["asv-runner"], "os": ["Linux 3.13.0-116-generic"], "ram": ["501692"], "python": ["3.10", "3.8"], "numpy": ["", "1.23.5", null], "Cython": ["0.29.32", "0.29.33", "3.0.0", "3.0.5"], "matplotlib": [""], "sqlalchemy": [""], "scipy": [""], "numba": [""], "numexpr": [""], "pytables": [""], "pyarrow": [""], "openpyxl": [""], "xlsxwriter": [""], "xlrd": [""], "odfpy": [""], "jinja2": [""], "xlwt": ["", null], "meson": ["", null], "meson-python": ["", null], "python-build": ["", null], "branch": ["main"]}, "graph_param_list": [{"arch": "x86_64", "cpu": "Intel(R) Core(TM) i7-4980HQ CPU @ 2.80GHz", "machine": "asv-runner", "os": "Linux 3.13.0-116-generic", "ram": "501692", "python": "3.8", "numpy": "", "Cython": "0.29.33", "matplotlib": "", "sqlalchemy": "", "scipy": "", "numba": "", "numexpr": "", "pytables": "", "pyarrow": "", "openpyxl": "", "xlsxwriter": "", "xlrd": "", "odfpy": "", "jinja2": "", "branch": "main", "xlwt": null, "meson": null, "meson-python": null, "python-build": null}, {"arch": "x86_64", "cpu": "Intel(R) Core(TM) i7-4980HQ CPU @ 2.80GHz", "machine": "asv-runner", "os": "Linux 3.13.0-116-generic", "ram": "501692", "python": "3.8", "numpy": "", "Cython": "0.29.32", "matplotlib": "", "sqlalchemy": "", "scipy": "", "numba": "", "numexpr": "", "pytables": "", "pyarrow": "", "openpyxl": "", "xlsxwriter": "", "xlrd": "", "xlwt": "", "odfpy": "", "jinja2": "", "branch": "main", "meson": null, "meson-python": null, "python-build": null}, {"arch": "x86_64", "cpu": "Intel(R) Core(TM) i7-4980HQ CPU @ 2.80GHz", "machine": "asv-runner", "os": "Linux 3.13.0-116-generic", "ram": "501692", "python": "3.8", "numpy": "1.23.5", "Cython": "0.29.32", "matplotlib": "", "sqlalchemy": "", "scipy": "", "numba": "", "numexpr": "", "pytables": "", "pyarrow": "", "openpyxl": "", "xlsxwriter": "", "xlrd": "", "odfpy": "", "jinja2": "", "branch": "main", "xlwt": null, "meson": null, "meson-python": null, "python-build": null}, {"arch": "x86_64", "cpu": "Intel(R) Core(TM) i7-4980HQ CPU @ 2.80GHz", "machine": "asv-runner", "os": "Linux 3.13.0-116-generic", "ram": "501692", "python": "3.8", "numpy": "", "Cython": "0.29.32", "matplotlib": "", "sqlalchemy": "", "scipy": "", "numba": "", "numexpr": "", "pytables": "", "pyarrow": "", "openpyxl": "", "xlsxwriter": "", "xlrd": "", "odfpy": "", "jinja2": "", "branch": "main", "xlwt": null, "meson": null, "meson-python": null, "python-build": null}, {"arch": "x86_64", "cpu": "Intel(R) Core(TM) i7-4980HQ CPU @ 2.80GHz", "machine": "asv-runner", "os": "Linux 3.13.0-116-generic", "ram": "501692", "python": "3.10", "Cython": "0.29.33", "matplotlib": "", "sqlalchemy": "", "scipy": "", "numba": "", "numexpr": "", "pytables": "", "pyarrow": "", "openpyxl": "", "xlsxwriter": "", "xlrd": "", "odfpy": "", "jinja2": "", "meson": "", "meson-python": "", "python-build": "", "branch": "main", "numpy": null, "xlwt": null}, {"arch": "x86_64", "cpu": "Intel(R) Core(TM) i7-4980HQ CPU @ 2.80GHz", "machine": "asv-runner", "os": "Linux 3.13.0-116-generic", "ram": "501692", "python": "3.10", "Cython": "3.0.5", "matplotlib": "", "sqlalchemy": "", "scipy": "", "numba": "", "numexpr": "", "pytables": "", "pyarrow": "", "openpyxl": "", "xlsxwriter": "", "xlrd": "", "odfpy": "", "jinja2": "", "meson": "", "meson-python": "", "python-build": "", "branch": "main", "numpy": null, "xlwt": null}, {"arch": "x86_64", "cpu": "Intel(R) Core(TM) i7-4980HQ CPU @ 2.80GHz", "machine": "asv-runner", "os": "Linux 3.13.0-116-generic", "ram": "501692", "python": "3.10", "numpy": "", "Cython": "0.29.33", "matplotlib": "", "sqlalchemy": "", "scipy": "", "numba": "", "numexpr": "", "pytables": "", "pyarrow": "", "openpyxl": "", "xlsxwriter": "", "xlrd": "", "odfpy": "", "jinja2": "", "branch": "main", "xlwt": null, "meson": null, "meson-python": null, "python-build": null}, {"arch": "x86_64", "cpu": "Intel(R) Core(TM) i7-4980HQ CPU @ 2.80GHz", "machine": "asv-runner", "os": "Linux 3.13.0-116-generic", "ram": "501692", "python": "3.10", "Cython": "3.0.0", "matplotlib": "", "sqlalchemy": "", "scipy": "", "numba": "", "numexpr": "", "pytables": "", "pyarrow": "", "openpyxl": "", "xlsxwriter": "", "xlrd": "", "odfpy": "", "jinja2": "", "meson": "", "meson-python": "", "python-build": "", "branch": "main", "numpy": null, "xlwt": null}], "benchmarks": {"algorithms.Duplicated.time_duplicated": {"code": "class Duplicated:\n    def time_duplicated(self, unique, keep, dtype):\n        self.idx.duplicated(keep=keep)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Duplicated:\n    def setup(self, unique, keep, dtype):\n        N = 10**5\n        if dtype in [\"int64\", \"uint64\"]:\n            data = pd.Index(np.arange(N), dtype=dtype)\n        elif dtype == \"float64\":\n            data = pd.Index(np.random.randn(N), dtype=\"float64\")\n        elif dtype == \"string\":\n            data = pd.Index([f\"i-{i}\" for i in range(N)], dtype=object)\n        elif dtype == \"datetime64[ns]\":\n            data = pd.date_range(\"2011-01-01\", freq=\"h\", periods=N)\n        elif dtype == \"datetime64[ns, tz]\":\n            data = pd.date_range(\"2011-01-01\", freq=\"h\", periods=N, tz=\"Asia/Tokyo\")\n        elif dtype in [\"timestamp[ms][pyarrow]\", \"duration[s][pyarrow]\"]:\n            data = pd.Index(np.arange(N), dtype=dtype)\n        else:\n            raise NotImplementedError\n        if not unique:\n            data = data.repeat(5)\n        self.idx = data\n        # cache is_unique\n        self.idx.is_unique", "min_run_count": 2, "name": "algorithms.Duplicated.time_duplicated", "number": 0, "param_names": ["unique", "keep", "dtype"], "params": [["True", "False"], ["'first'", "'last'", "False"], ["'int64'", "'uint64'", "'float64'", "'string'", "'datetime64[ns]'", "'datetime64[ns, tz]'", "'timestamp[ms][pyarrow]'", "'duration[s][pyarrow]'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "fe53c1038d7b25e9c8911c3bea6fb5a1548d97c07d68025391c8e89c96d7e9ad", "warmup_time": -1}, "algorithms.DuplicatedMaskedArray.time_duplicated": {"code": "class DuplicatedMaskedArray:\n    def time_duplicated(self, unique, keep, dtype):\n        self.ser.duplicated(keep=keep)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass DuplicatedMaskedArray:\n    def setup(self, unique, keep, dtype):\n        N = 10**5\n        data = pd.Series(np.arange(N), dtype=dtype)\n        data[list(range(1, N, 100))] = pd.NA\n        if not unique:\n            data = data.repeat(5)\n        self.ser = data\n        # cache is_unique\n        self.ser.is_unique", "min_run_count": 2, "name": "algorithms.DuplicatedMaskedArray.time_duplicated", "number": 0, "param_names": ["unique", "keep", "dtype"], "params": [["True", "False"], ["'first'", "'last'", "False"], ["'Int64'", "'Float64'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "9401d32efa9cbe647d328e01c1b90df12183cdceba73825c1c4d98e81f254886", "warmup_time": -1}, "algorithms.Factorize.peakmem_factorize": {"code": "class Factorize:\n    def peakmem_factorize(self, unique, sort, dtype):\n        pd.factorize(self.data, sort=sort)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Factorize:\n    def setup(self, unique, sort, dtype):\n        N = 10**5\n    \n        if dtype in [\"int64\", \"uint64\", \"Int64\", \"object\"]:\n            data = pd.Index(np.arange(N), dtype=dtype)\n        elif dtype == \"float64\":\n            data = pd.Index(np.random.randn(N), dtype=dtype)\n        elif dtype == \"boolean\":\n            data = pd.array(np.random.randint(0, 2, N), dtype=dtype)\n        elif dtype == \"datetime64[ns]\":\n            data = pd.date_range(\"2011-01-01\", freq=\"h\", periods=N)\n        elif dtype == \"datetime64[ns, tz]\":\n            data = pd.date_range(\"2011-01-01\", freq=\"h\", periods=N, tz=\"Asia/Tokyo\")\n        elif dtype == \"object_str\":\n            data = pd.Index([f\"i-{i}\" for i in range(N)], dtype=object)\n        elif dtype == \"string[pyarrow]\":\n            data = pd.array(\n                pd.Index([f\"i-{i}\" for i in range(N)], dtype=object),\n                dtype=\"string[pyarrow]\",\n            )\n        else:\n            raise NotImplementedError\n    \n        if not unique:\n            data = data.repeat(5)\n        self.data = data", "name": "algorithms.Factorize.peakmem_factorize", "param_names": ["unique", "sort", "dtype"], "params": [["True", "False"], ["True", "False"], ["'int64'", "'uint64'", "'float64'", "'object'", "'object_str'", "'datetime64[ns]'", "'datetime64[ns, tz]'", "'Int64'", "'boolean'", "'string[pyarrow]'"]], "timeout": 60.0, "type": "peakmemory", "unit": "bytes", "version": "ec743de3d9c5a026a891feb9ab8ecffae4612dcf9fba25aea48c6525c0fb7c0e"}, "algorithms.Factorize.time_factorize": {"code": "class Factorize:\n    def time_factorize(self, unique, sort, dtype):\n        pd.factorize(self.data, sort=sort)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Factorize:\n    def setup(self, unique, sort, dtype):\n        N = 10**5\n    \n        if dtype in [\"int64\", \"uint64\", \"Int64\", \"object\"]:\n            data = pd.Index(np.arange(N), dtype=dtype)\n        elif dtype == \"float64\":\n            data = pd.Index(np.random.randn(N), dtype=dtype)\n        elif dtype == \"boolean\":\n            data = pd.array(np.random.randint(0, 2, N), dtype=dtype)\n        elif dtype == \"datetime64[ns]\":\n            data = pd.date_range(\"2011-01-01\", freq=\"h\", periods=N)\n        elif dtype == \"datetime64[ns, tz]\":\n            data = pd.date_range(\"2011-01-01\", freq=\"h\", periods=N, tz=\"Asia/Tokyo\")\n        elif dtype == \"object_str\":\n            data = pd.Index([f\"i-{i}\" for i in range(N)], dtype=object)\n        elif dtype == \"string[pyarrow]\":\n            data = pd.array(\n                pd.Index([f\"i-{i}\" for i in range(N)], dtype=object),\n                dtype=\"string[pyarrow]\",\n            )\n        else:\n            raise NotImplementedError\n    \n        if not unique:\n            data = data.repeat(5)\n        self.data = data", "min_run_count": 2, "name": "algorithms.Factorize.time_factorize", "number": 0, "param_names": ["unique", "sort", "dtype"], "params": [["True", "False"], ["True", "False"], ["'int64'", "'uint64'", "'float64'", "'object'", "'object_str'", "'datetime64[ns]'", "'datetime64[ns, tz]'", "'Int64'", "'boolean'", "'string[pyarrow]'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "7a47cb209b293a023d7673dfacf5f33fc761ee2bb76ef52d7ba9c2b0cf69f50f", "warmup_time": -1}, "algorithms.Hashing.time_frame": {"code": "class Hashing:\n    def time_frame(self, df):\n        hashing.hash_pandas_object(df)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Hashing:\n    def setup_cache(self):\n        N = 10**5\n    \n        df = pd.DataFrame(\n            {\n                \"strings\": pd.Series(\n                    pd.Index([f\"i-{i}\" for i in range(10000)], dtype=object).take(\n                        np.random.randint(0, 10000, size=N)\n                    )\n                ),\n                \"floats\": np.random.randn(N),\n                \"ints\": np.arange(N),\n                \"dates\": pd.date_range(\"20110101\", freq=\"s\", periods=N),\n                \"timedeltas\": pd.timedelta_range(\"1 day\", freq=\"s\", periods=N),\n            }\n        )\n        df[\"categories\"] = df[\"strings\"].astype(\"category\")\n        df.iloc[10:20] = np.nan\n        return df", "min_run_count": 2, "name": "algorithms.Hashing.time_frame", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "setup_cache_key": "algorithms:134", "timeout": 60.0, "type": "time", "unit": "seconds", "version": "4a05c799caa1b1f5e373a44ae3039987540f271f87111d92653f37c426c76443", "warmup_time": -1}, "algorithms.Hashing.time_series_categorical": {"code": "class Hashing:\n    def time_series_categorical(self, df):\n        hashing.hash_pandas_object(df[\"categories\"])\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Hashing:\n    def setup_cache(self):\n        N = 10**5\n    \n        df = pd.DataFrame(\n            {\n                \"strings\": pd.Series(\n                    pd.Index([f\"i-{i}\" for i in range(10000)], dtype=object).take(\n                        np.random.randint(0, 10000, size=N)\n                    )\n                ),\n                \"floats\": np.random.randn(N),\n                \"ints\": np.arange(N),\n                \"dates\": pd.date_range(\"20110101\", freq=\"s\", periods=N),\n                \"timedeltas\": pd.timedelta_range(\"1 day\", freq=\"s\", periods=N),\n            }\n        )\n        df[\"categories\"] = df[\"strings\"].astype(\"category\")\n        df.iloc[10:20] = np.nan\n        return df", "min_run_count": 2, "name": "algorithms.Hashing.time_series_categorical", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "setup_cache_key": "algorithms:134", "timeout": 60.0, "type": "time", "unit": "seconds", "version": "c402e5979cad298ee4e24b9fb8fc1c18002315ac518eb757fc3dfdda2dfa8a70", "warmup_time": -1}, "algorithms.Hashing.time_series_dates": {"code": "class Hashing:\n    def time_series_dates(self, df):\n        hashing.hash_pandas_object(df[\"dates\"])\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Hashing:\n    def setup_cache(self):\n        N = 10**5\n    \n        df = pd.DataFrame(\n            {\n                \"strings\": pd.Series(\n                    pd.Index([f\"i-{i}\" for i in range(10000)], dtype=object).take(\n                        np.random.randint(0, 10000, size=N)\n                    )\n                ),\n                \"floats\": np.random.randn(N),\n                \"ints\": np.arange(N),\n                \"dates\": pd.date_range(\"20110101\", freq=\"s\", periods=N),\n                \"timedeltas\": pd.timedelta_range(\"1 day\", freq=\"s\", periods=N),\n            }\n        )\n        df[\"categories\"] = df[\"strings\"].astype(\"category\")\n        df.iloc[10:20] = np.nan\n        return df", "min_run_count": 2, "name": "algorithms.Hashing.time_series_dates", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "setup_cache_key": "algorithms:134", "timeout": 60.0, "type": "time", "unit": "seconds", "version": "480afaa0dc2d1bcfebbb58644d666d5e0110dce44f34335c99f3fc79ec3d7157", "warmup_time": -1}, "algorithms.Hashing.time_series_float": {"code": "class Hashing:\n    def time_series_float(self, df):\n        hashing.hash_pandas_object(df[\"floats\"])\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Hashing:\n    def setup_cache(self):\n        N = 10**5\n    \n        df = pd.DataFrame(\n            {\n                \"strings\": pd.Series(\n                    pd.Index([f\"i-{i}\" for i in range(10000)], dtype=object).take(\n                        np.random.randint(0, 10000, size=N)\n                    )\n                ),\n                \"floats\": np.random.randn(N),\n                \"ints\": np.arange(N),\n                \"dates\": pd.date_range(\"20110101\", freq=\"s\", periods=N),\n                \"timedeltas\": pd.timedelta_range(\"1 day\", freq=\"s\", periods=N),\n            }\n        )\n        df[\"categories\"] = df[\"strings\"].astype(\"category\")\n        df.iloc[10:20] = np.nan\n        return df", "min_run_count": 2, "name": "algorithms.Hashing.time_series_float", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "setup_cache_key": "algorithms:134", "timeout": 60.0, "type": "time", "unit": "seconds", "version": "214d3d8f8bad077c365dabffe78fc06579e82078aaef4ea7f87b4a9154f3b17d", "warmup_time": -1}, "algorithms.Hashing.time_series_int": {"code": "class Hashing:\n    def time_series_int(self, df):\n        hashing.hash_pandas_object(df[\"ints\"])\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Hashing:\n    def setup_cache(self):\n        N = 10**5\n    \n        df = pd.DataFrame(\n            {\n                \"strings\": pd.Series(\n                    pd.Index([f\"i-{i}\" for i in range(10000)], dtype=object).take(\n                        np.random.randint(0, 10000, size=N)\n                    )\n                ),\n                \"floats\": np.random.randn(N),\n                \"ints\": np.arange(N),\n                \"dates\": pd.date_range(\"20110101\", freq=\"s\", periods=N),\n                \"timedeltas\": pd.timedelta_range(\"1 day\", freq=\"s\", periods=N),\n            }\n        )\n        df[\"categories\"] = df[\"strings\"].astype(\"category\")\n        df.iloc[10:20] = np.nan\n        return df", "min_run_count": 2, "name": "algorithms.Hashing.time_series_int", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "setup_cache_key": "algorithms:134", "timeout": 60.0, "type": "time", "unit": "seconds", "version": "1e1e48b3441cae94aaaa9f1821af6faeb0ffb83a0e757306651eb81e6883ef37", "warmup_time": -1}, "algorithms.Hashing.time_series_string": {"code": "class Hashing:\n    def time_series_string(self, df):\n        hashing.hash_pandas_object(df[\"strings\"])\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Hashing:\n    def setup_cache(self):\n        N = 10**5\n    \n        df = pd.DataFrame(\n            {\n                \"strings\": pd.Series(\n                    pd.Index([f\"i-{i}\" for i in range(10000)], dtype=object).take(\n                        np.random.randint(0, 10000, size=N)\n                    )\n                ),\n                \"floats\": np.random.randn(N),\n                \"ints\": np.arange(N),\n                \"dates\": pd.date_range(\"20110101\", freq=\"s\", periods=N),\n                \"timedeltas\": pd.timedelta_range(\"1 day\", freq=\"s\", periods=N),\n            }\n        )\n        df[\"categories\"] = df[\"strings\"].astype(\"category\")\n        df.iloc[10:20] = np.nan\n        return df", "min_run_count": 2, "name": "algorithms.Hashing.time_series_string", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "setup_cache_key": "algorithms:134", "timeout": 60.0, "type": "time", "unit": "seconds", "version": "1f1baa73746106531f50db15fbbbbb902f1b33f8c128829138fb6b494b91953e", "warmup_time": -1}, "algorithms.Hashing.time_series_timedeltas": {"code": "class Hashing:\n    def time_series_timedeltas(self, df):\n        hashing.hash_pandas_object(df[\"timedeltas\"])\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Hashing:\n    def setup_cache(self):\n        N = 10**5\n    \n        df = pd.DataFrame(\n            {\n                \"strings\": pd.Series(\n                    pd.Index([f\"i-{i}\" for i in range(10000)], dtype=object).take(\n                        np.random.randint(0, 10000, size=N)\n                    )\n                ),\n                \"floats\": np.random.randn(N),\n                \"ints\": np.arange(N),\n                \"dates\": pd.date_range(\"20110101\", freq=\"s\", periods=N),\n                \"timedeltas\": pd.timedelta_range(\"1 day\", freq=\"s\", periods=N),\n            }\n        )\n        df[\"categories\"] = df[\"strings\"].astype(\"category\")\n        df.iloc[10:20] = np.nan\n        return df", "min_run_count": 2, "name": "algorithms.Hashing.time_series_timedeltas", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "setup_cache_key": "algorithms:134", "timeout": 60.0, "type": "time", "unit": "seconds", "version": "03ae26b3725783046ce19f735dfb622e46318830e1297575ea97d8b9f5928199", "warmup_time": -1}, "algorithms.Quantile.time_quantile": {"code": "class Quantile:\n    def time_quantile(self, quantile, interpolation, dtype):\n        self.ser.quantile(quantile, interpolation=interpolation)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Quantile:\n    def setup(self, quantile, interpolation, dtype):\n        N = 10**5\n        if dtype in [\"int64\", \"uint64\"]:\n            data = np.arange(N, dtype=dtype)\n        elif dtype == \"float64\":\n            data = np.random.randn(N)\n        else:\n            raise NotImplementedError\n        self.ser = pd.Series(data.repeat(5))", "min_run_count": 2, "name": "algorithms.Quantile.time_quantile", "number": 0, "param_names": ["quantile", "interpolation", "dtype"], "params": [["0", "0.5", "1"], ["'linear'", "'nearest'", "'lower'", "'higher'", "'midpoint'"], ["'float64'", "'int64'", "'uint64'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "820d0dca81e53ef4f34628fac8053f5a961e38b58bf3b780a6b0f25372409868", "warmup_time": -1}, "algorithms.SortIntegerArray.time_argsort": {"code": "class SortIntegerArray:\n    def time_argsort(self, N):\n        self.array.argsort()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass SortIntegerArray:\n    def setup(self, N):\n        data = np.arange(N, dtype=float)\n        data[40] = np.nan\n        self.array = pd.array(data, dtype=\"Int64\")", "min_run_count": 2, "name": "algorithms.SortIntegerArray.time_argsort", "number": 0, "param_names": ["param1"], "params": [["1000", "100000"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "712d4e0ba6b3b003618d30611818ce2c36c039fe0900eafca3896d3863ebbc51", "warmup_time": -1}, "algos.isin.IsIn.time_isin": {"code": "class IsIn:\n    def time_isin(self, dtype):\n        self.series.isin(self.values)\n\n    def setup(self, dtype):\n        N = 10000\n    \n        self.mismatched = [NaT.to_datetime64()] * 2\n    \n        if dtype in [\"boolean\", \"bool\"]:\n            self.series = Series(np.random.randint(0, 2, N)).astype(dtype)\n            self.values = [True, False]\n    \n        elif dtype == \"datetime64[ns]\":\n            # Note: values here is much larger than non-dt64ns cases\n    \n            # dti has length=115777\n            dti = date_range(start=\"2015-10-26\", end=\"2016-01-01\", freq=\"50s\")\n            self.series = Series(dti)\n            self.values = self.series._values[::3]\n            self.mismatched = [1, 2]\n    \n        elif dtype in [\"category[object]\", \"category[int]\"]:\n            # Note: sizes are different in this case than others\n            n = 5 * 10**5\n            sample_size = 100\n    \n            arr = list(np.random.randint(0, n // 10, size=n))\n            if dtype == \"category[object]\":\n                arr = [f\"s{i:04d}\" for i in arr]\n    \n            self.values = np.random.choice(arr, sample_size)\n            self.series = Series(arr).astype(\"category\")\n    \n        elif dtype in [\"str\", \"string[python]\", \"string[pyarrow]\"]:\n            try:\n                self.series = Series(\n                    Index([f\"i-{i}\" for i in range(N)], dtype=object), dtype=dtype\n                )\n            except ImportError:\n                raise NotImplementedError\n            self.values = list(self.series[:2])\n    \n        else:\n            self.series = Series(np.random.randint(1, 10, N)).astype(dtype)\n            self.values = [1, 2]\n    \n        self.cat_values = Categorical(self.values)", "min_run_count": 2, "name": "algos.isin.IsIn.time_isin", "number": 0, "param_names": ["dtype"], "params": [["'int64'", "'uint64'", "'object'", "'Int64'", "'boolean'", "'bool'", "'datetime64[ns]'", "'category[object]'", "'category[int]'", "'str'", "'string[python]'", "'string[pyarrow]'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "8cfa89efb286f227f4816da1c62cc76b4465e0f2c2ed7c80b7bec3631f7919a1", "warmup_time": -1}, "algos.isin.IsIn.time_isin_categorical": {"code": "class IsIn:\n    def time_isin_categorical(self, dtype):\n        self.series.isin(self.cat_values)\n\n    def setup(self, dtype):\n        N = 10000\n    \n        self.mismatched = [NaT.to_datetime64()] * 2\n    \n        if dtype in [\"boolean\", \"bool\"]:\n            self.series = Series(np.random.randint(0, 2, N)).astype(dtype)\n            self.values = [True, False]\n    \n        elif dtype == \"datetime64[ns]\":\n            # Note: values here is much larger than non-dt64ns cases\n    \n            # dti has length=115777\n            dti = date_range(start=\"2015-10-26\", end=\"2016-01-01\", freq=\"50s\")\n            self.series = Series(dti)\n            self.values = self.series._values[::3]\n            self.mismatched = [1, 2]\n    \n        elif dtype in [\"category[object]\", \"category[int]\"]:\n            # Note: sizes are different in this case than others\n            n = 5 * 10**5\n            sample_size = 100\n    \n            arr = list(np.random.randint(0, n // 10, size=n))\n            if dtype == \"category[object]\":\n                arr = [f\"s{i:04d}\" for i in arr]\n    \n            self.values = np.random.choice(arr, sample_size)\n            self.series = Series(arr).astype(\"category\")\n    \n        elif dtype in [\"str\", \"string[python]\", \"string[pyarrow]\"]:\n            try:\n                self.series = Series(\n                    Index([f\"i-{i}\" for i in range(N)], dtype=object), dtype=dtype\n                )\n            except ImportError:\n                raise NotImplementedError\n            self.values = list(self.series[:2])\n    \n        else:\n            self.series = Series(np.random.randint(1, 10, N)).astype(dtype)\n            self.values = [1, 2]\n    \n        self.cat_values = Categorical(self.values)", "min_run_count": 2, "name": "algos.isin.IsIn.time_isin_categorical", "number": 0, "param_names": ["dtype"], "params": [["'int64'", "'uint64'", "'object'", "'Int64'", "'boolean'", "'bool'", "'datetime64[ns]'", "'category[object]'", "'category[int]'", "'str'", "'string[python]'", "'string[pyarrow]'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "1f206f2539f2810a213c0d62a40fca5b8c253e208149b2f69398ff7c4fd10041", "warmup_time": -1}, "algos.isin.IsIn.time_isin_empty": {"code": "class IsIn:\n    def time_isin_empty(self, dtype):\n        self.series.isin([])\n\n    def setup(self, dtype):\n        N = 10000\n    \n        self.mismatched = [NaT.to_datetime64()] * 2\n    \n        if dtype in [\"boolean\", \"bool\"]:\n            self.series = Series(np.random.randint(0, 2, N)).astype(dtype)\n            self.values = [True, False]\n    \n        elif dtype == \"datetime64[ns]\":\n            # Note: values here is much larger than non-dt64ns cases\n    \n            # dti has length=115777\n            dti = date_range(start=\"2015-10-26\", end=\"2016-01-01\", freq=\"50s\")\n            self.series = Series(dti)\n            self.values = self.series._values[::3]\n            self.mismatched = [1, 2]\n    \n        elif dtype in [\"category[object]\", \"category[int]\"]:\n            # Note: sizes are different in this case than others\n            n = 5 * 10**5\n            sample_size = 100\n    \n            arr = list(np.random.randint(0, n // 10, size=n))\n            if dtype == \"category[object]\":\n                arr = [f\"s{i:04d}\" for i in arr]\n    \n            self.values = np.random.choice(arr, sample_size)\n            self.series = Series(arr).astype(\"category\")\n    \n        elif dtype in [\"str\", \"string[python]\", \"string[pyarrow]\"]:\n            try:\n                self.series = Series(\n                    Index([f\"i-{i}\" for i in range(N)], dtype=object), dtype=dtype\n                )\n            except ImportError:\n                raise NotImplementedError\n            self.values = list(self.series[:2])\n    \n        else:\n            self.series = Series(np.random.randint(1, 10, N)).astype(dtype)\n            self.values = [1, 2]\n    \n        self.cat_values = Categorical(self.values)", "min_run_count": 2, "name": "algos.isin.IsIn.time_isin_empty", "number": 0, "param_names": ["dtype"], "params": [["'int64'", "'uint64'", "'object'", "'Int64'", "'boolean'", "'bool'", "'datetime64[ns]'", "'category[object]'", "'category[int]'", "'str'", "'string[python]'", "'string[pyarrow]'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "14f872c5cd8b01a18f487373a9bc54627200bf45ce3e7dd057205442ffa9cef8", "warmup_time": -1}, "algos.isin.IsIn.time_isin_mismatched_dtype": {"code": "class IsIn:\n    def time_isin_mismatched_dtype(self, dtype):\n        self.series.isin(self.mismatched)\n\n    def setup(self, dtype):\n        N = 10000\n    \n        self.mismatched = [NaT.to_datetime64()] * 2\n    \n        if dtype in [\"boolean\", \"bool\"]:\n            self.series = Series(np.random.randint(0, 2, N)).astype(dtype)\n            self.values = [True, False]\n    \n        elif dtype == \"datetime64[ns]\":\n            # Note: values here is much larger than non-dt64ns cases\n    \n            # dti has length=115777\n            dti = date_range(start=\"2015-10-26\", end=\"2016-01-01\", freq=\"50s\")\n            self.series = Series(dti)\n            self.values = self.series._values[::3]\n            self.mismatched = [1, 2]\n    \n        elif dtype in [\"category[object]\", \"category[int]\"]:\n            # Note: sizes are different in this case than others\n            n = 5 * 10**5\n            sample_size = 100\n    \n            arr = list(np.random.randint(0, n // 10, size=n))\n            if dtype == \"category[object]\":\n                arr = [f\"s{i:04d}\" for i in arr]\n    \n            self.values = np.random.choice(arr, sample_size)\n            self.series = Series(arr).astype(\"category\")\n    \n        elif dtype in [\"str\", \"string[python]\", \"string[pyarrow]\"]:\n            try:\n                self.series = Series(\n                    Index([f\"i-{i}\" for i in range(N)], dtype=object), dtype=dtype\n                )\n            except ImportError:\n                raise NotImplementedError\n            self.values = list(self.series[:2])\n    \n        else:\n            self.series = Series(np.random.randint(1, 10, N)).astype(dtype)\n            self.values = [1, 2]\n    \n        self.cat_values = Categorical(self.values)", "min_run_count": 2, "name": "algos.isin.IsIn.time_isin_mismatched_dtype", "number": 0, "param_names": ["dtype"], "params": [["'int64'", "'uint64'", "'object'", "'Int64'", "'boolean'", "'bool'", "'datetime64[ns]'", "'category[object]'", "'category[int]'", "'str'", "'string[python]'", "'string[pyarrow]'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "00ed208ac45681da2106c500a636e73d0b098ec4c39b4393af5840b97b856a5a", "warmup_time": -1}, "algos.isin.IsInFloat64.time_isin": {"code": "class IsInFloat64:\n    def time_isin(self, dtype, title):\n        self.series.isin(self.values)\n\n    def setup(self, dtype, title):\n        N_many = 10**5\n        N_few = 10**6\n        self.series = Series([1, 2], dtype=dtype)\n    \n        if title == \"many_different_values\":\n            # runtime is dominated by creation of the lookup-table\n            self.values = np.arange(N_many, dtype=np.float64)\n        elif title == \"few_different_values\":\n            # runtime is dominated by creation of the lookup-table\n            self.values = np.zeros(N_few, dtype=np.float64)\n        elif title == \"only_nans_values\":\n            # runtime is dominated by creation of the lookup-table\n            self.values = np.full(N_few, np.nan, dtype=np.float64)\n        else:\n            raise ValueError(title)", "min_run_count": 2, "name": "algos.isin.IsInFloat64.time_isin", "number": 0, "param_names": ["dtype", "title"], "params": [["<class 'numpy.float64'>", "'Float64'"], ["'many_different_values'", "'few_different_values'", "'only_nans_values'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "59baee11ef880339f8490c7d07fdf4f25b649d22624afd1242eefd4877e7c0bd", "warmup_time": -1}, "algos.isin.IsInForObjects.time_isin": {"code": "class IsInForObjects:\n    def time_isin(self, series_type, vals_type):\n        self.series.isin(self.values)\n\n    def setup(self, series_type, vals_type):\n        N_many = 10**5\n    \n        if series_type == \"nans\":\n            ser_vals = np.full(10**4, np.nan)\n        elif series_type == \"short\":\n            ser_vals = np.arange(2)\n        elif series_type == \"long\":\n            ser_vals = np.arange(N_many)\n        elif series_type == \"long_floats\":\n            ser_vals = np.arange(N_many, dtype=np.float64)\n    \n        self.series = Series(ser_vals).astype(object)\n    \n        if vals_type == \"nans\":\n            values = np.full(10**4, np.nan)\n        elif vals_type == \"short\":\n            values = np.arange(2)\n        elif vals_type == \"long\":\n            values = np.arange(N_many)\n        elif vals_type == \"long_floats\":\n            values = np.arange(N_many, dtype=np.float64)\n    \n        self.values = values.astype(object)", "min_run_count": 2, "name": "algos.isin.IsInForObjects.time_isin", "number": 0, "param_names": ["series_type", "vals_type"], "params": [["'nans'", "'short'", "'long'", "'long_floats'"], ["'nans'", "'short'", "'long'", "'long_floats'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "51416b624c4176717e96bb897c59ee9f59c2e4a9079df5c3893b1fb877979d84", "warmup_time": -1}, "algos.isin.IsInIndexes.time_isin_index": {"code": "class IsInIndexes:\n    def time_isin_index(self):\n        self.series.isin(self.index)\n\n    def setup(self):\n        self.range_idx = Index(range(1000))\n        self.index = Index(list(range(1000)))\n        self.series = Series(np.random.randint(100_000, size=1000))", "min_run_count": 2, "name": "algos.isin.IsInIndexes.time_isin_index", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "ce5b0b4c6a85e2c007c90998aa18d4db0fb69a82cefb1549856c75004e42fbec", "warmup_time": -1}, "algos.isin.IsInIndexes.time_isin_range_index": {"code": "class IsInIndexes:\n    def time_isin_range_index(self):\n        self.series.isin(self.range_idx)\n\n    def setup(self):\n        self.range_idx = Index(range(1000))\n        self.index = Index(list(range(1000)))\n        self.series = Series(np.random.randint(100_000, size=1000))", "min_run_count": 2, "name": "algos.isin.IsInIndexes.time_isin_range_index", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "f37d428d46aff6ec8ce8a340df54e194946db8454b6da0c7a39c2e85139b4efb", "warmup_time": -1}, "algos.isin.IsInLongSeriesLookUpDominates.time_isin": {"code": "class IsInLongSeriesLookUpDominates:\n    def time_isin(self, dtypes, MaxNumber, series_type):\n        self.series.isin(self.values)\n\n    def setup(self, dtype, MaxNumber, series_type):\n        N = 10**7\n    \n        if series_type == \"random_hits\":\n            array = np.random.randint(0, MaxNumber, N)\n        if series_type == \"random_misses\":\n            array = np.random.randint(0, MaxNumber, N) + MaxNumber\n        if series_type == \"monotone_hits\":\n            array = np.repeat(np.arange(MaxNumber), N // MaxNumber)\n        if series_type == \"monotone_misses\":\n            array = np.arange(N) + MaxNumber\n    \n        self.series = Series(array).astype(dtype)\n    \n        self.values = np.arange(MaxNumber).astype(dtype.lower())", "min_run_count": 2, "name": "algos.isin.IsInLongSeriesLookUpDominates.time_isin", "number": 0, "param_names": ["dtype", "MaxNumber", "series_type"], "params": [["'int64'", "'int32'", "'float64'", "'float32'", "'object'", "'Int64'", "'Float64'"], ["5", "1000"], ["'random_hits'", "'random_misses'", "'monotone_hits'", "'monotone_misses'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "0634a100f682c1a73f9cb5d84afc1695f117d58377c8ac19e9a1d4ecf3918bc4", "warmup_time": -1}, "algos.isin.IsInLongSeriesValuesDominate.time_isin": {"code": "class IsInLongSeriesValuesDominate:\n    def time_isin(self, dtypes, series_type):\n        self.series.isin(self.values)\n\n    def setup(self, dtype, series_type):\n        N = 10**7\n    \n        if series_type == \"random\":\n            vals = np.random.randint(0, 10 * N, N)\n        if series_type == \"monotone\":\n            vals = np.arange(N)\n    \n        self.values = vals.astype(dtype.lower())\n        M = 10**6 + 1\n        self.series = Series(np.arange(M)).astype(dtype)", "min_run_count": 2, "name": "algos.isin.IsInLongSeriesValuesDominate.time_isin", "number": 0, "param_names": ["dtype", "series_type"], "params": [["'int64'", "'int32'", "'float64'", "'float32'", "'object'", "'Int64'", "'Float64'"], ["'random'", "'monotone'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "8202afa03ab08eab3d80cdb10c821a35f6b73f1b178354429054668f213b8920", "warmup_time": -1}, "algos.isin.IsInWithLongTupples.time_isin": {"code": "class IsInWithLongTupples:\n    def time_isin(self):\n        self.series.isin(self.values)\n\n    def setup(self):\n        t = tuple(range(1000))\n        self.series = Series([t] * 1000)\n        self.values = [t]", "min_run_count": 2, "name": "algos.isin.IsInWithLongTupples.time_isin", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "55c634e065a928f8f1e9146932290a0b894f6f9f6f25b0d57ab2597ce60972ad", "warmup_time": -1}, "algos.isin.IsinAlmostFullWithRandomInt.time_isin": {"code": "class IsinAlmostFullWithRandomInt:\n    def time_isin(self, dtype, exponent, title):\n        self.series.isin(self.values)\n\n    def setup(self, dtype, exponent, title):\n        M = 3 * 2 ** (exponent - 2)\n        # 0.77-the maximal share of occupied buckets\n        self.series = Series(np.random.randint(0, M, M)).astype(dtype)\n    \n        values = np.random.randint(0, M, M).astype(dtype)\n        if title == \"inside\":\n            self.values = values\n        elif title == \"outside\":\n            self.values = values + M\n        else:\n            raise ValueError(title)", "min_run_count": 2, "name": "algos.isin.IsinAlmostFullWithRandomInt.time_isin", "number": 0, "param_names": ["dtype", "exponent", "title"], "params": [["<class 'numpy.float64'>", "<class 'numpy.int64'>", "<class 'numpy.uint64'>", "<class 'numpy.object_'>"], ["10", "11", "12", "13", "14", "15", "16", "17", "18", "19", "20"], ["'inside'", "'outside'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "4511839e6a4402d9c6a3c41e95fbfd6c61eb07d38c9d0069b10c837a5dfb0bb4", "warmup_time": -1}, "algos.isin.IsinWithArange.time_isin": {"code": "class IsinWithArange:\n    def time_isin(self, dtype, M, offset_factor):\n        self.series.isin(self.values)\n\n    def setup(self, dtype, M, offset_factor):\n        offset = int(M * offset_factor)\n        tmp = Series(np.random.randint(offset, M + offset, 10**6))\n        self.series = tmp.astype(dtype)\n        self.values = np.arange(M).astype(dtype)", "min_run_count": 2, "name": "algos.isin.IsinWithArange.time_isin", "number": 0, "param_names": ["dtype", "M", "offset_factor"], "params": [["<class 'numpy.float64'>", "<class 'numpy.int64'>", "<class 'numpy.uint64'>", "<class 'numpy.object_'>"], ["1000", "2000", "8000"], ["-2", "0", "2"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "a595ea736176046325e6461769d666e50df44bc5ea923058dfbdf81bc2fa9848", "warmup_time": -1}, "algos.isin.IsinWithArangeSorted.time_isin": {"code": "class IsinWithArangeSorted:\n    def time_isin(self, dtype, size):\n        self.series.isin(self.values)\n\n    def setup(self, dtype, size):\n        self.series = Series(np.arange(size)).astype(dtype)\n        self.values = np.arange(size).astype(dtype)", "min_run_count": 2, "name": "algos.isin.IsinWithArangeSorted.time_isin", "number": 0, "param_names": ["dtype", "size"], "params": [["<class 'numpy.float64'>", "<class 'numpy.int64'>", "<class 'numpy.uint64'>", "<class 'numpy.object_'>"], ["1000", "2000", "8000", "100000", "1000000"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "b3b173cabf5fb2d94e06a9a5bce98458bf646cecae54b0966cfe66adcded0fdf", "warmup_time": -1}, "algos.isin.IsinWithRandomFloat.time_isin": {"code": "class IsinWithRandomFloat:\n    def time_isin(self, dtype, size, title):\n        self.series.isin(self.values)\n\n    def setup(self, dtype, size, title):\n        self.values = np.random.rand(size)\n        self.series = Series(self.values).astype(dtype)\n        np.random.shuffle(self.values)\n    \n        if title == \"outside\":\n            self.values = self.values + 0.1", "min_run_count": 2, "name": "algos.isin.IsinWithRandomFloat.time_isin", "number": 0, "param_names": ["dtype", "size", "title"], "params": [["<class 'numpy.float64'>", "<class 'numpy.object_'>"], ["1300", "2000", "7000", "8000", "70000", "80000", "750000", "900000"], ["'inside'", "'outside'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "15f9f9bb41efd706d95b1a43ff72e5572dedbb074050cd2b857e7a91213c60a8", "warmup_time": -1}, "arithmetic.ApplyIndex.time_apply_index": {"code": "class ApplyIndex:\n    def time_apply_index(self, offset):\n        self.rng + offset\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ApplyIndex:\n    def setup(self, offset):\n        N = 10000\n        rng = date_range(start=\"1/1/2000\", periods=N, freq=\"min\")\n        self.rng = rng", "min_run_count": 2, "name": "arithmetic.ApplyIndex.time_apply_index", "number": 0, "param_names": ["offset"], "params": [["<YearEnd: month=12>", "<YearBegin: month=1>", "<QuarterEnd: startingMonth=3>", "<QuarterBegin: startingMonth=3>", "<MonthEnd>", "<MonthBegin>", "<DateOffset: days=2, months=2>", "<BusinessDay>", "<SemiMonthEnd: day_of_month=15>", "<SemiMonthBegin: day_of_month=15>"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "3a6382c9a7754ab42a9c9d4af8bdaeb073d03dbe05f80288c151c0cce34ffbb7", "warmup_time": -1}, "arithmetic.BinaryOpsMultiIndex.time_binary_op_multiindex": {"code": "class BinaryOpsMultiIndex:\n    def time_binary_op_multiindex(self, func):\n        getattr(self.df, func)(self.arg_df, level=0)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass BinaryOpsMultiIndex:\n    def setup(self, func):\n        array = date_range(\"20200101 00:00\", \"20200102 0:00\", freq=\"s\")\n        level_0_names = [str(i) for i in range(30)]\n    \n        index = pd.MultiIndex.from_product([level_0_names, array])\n        column_names = [\"col_1\", \"col_2\"]\n    \n        self.df = DataFrame(\n            np.random.rand(len(index), 2), index=index, columns=column_names\n        )\n    \n        self.arg_df = DataFrame(\n            np.random.randint(1, 10, (len(level_0_names), 2)),\n            index=level_0_names,\n            columns=column_names,\n        )", "min_run_count": 2, "name": "arithmetic.BinaryOpsMultiIndex.time_binary_op_multiindex", "number": 0, "param_names": ["func"], "params": [["'sub'", "'add'", "'mul'", "'div'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "f972c5787a16a41749c4e8447ef1ff42b310cd8aa3ef3b75ab7012164ff6cd12", "warmup_time": -1}, "arithmetic.CategoricalComparisons.time_categorical_op": {"code": "class CategoricalComparisons:\n    def time_categorical_op(self, op):\n        getattr(self.cat, op)(\"b\")\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass CategoricalComparisons:\n    def setup(self, op):\n        N = 10**5\n        self.cat = pd.Categorical(list(\"aabbcd\") * N, ordered=True)", "min_run_count": 2, "name": "arithmetic.CategoricalComparisons.time_categorical_op", "number": 0, "param_names": ["op"], "params": [["'__lt__'", "'__le__'", "'__eq__'", "'__ne__'", "'__ge__'", "'__gt__'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "2f0300d246b7a2099eaf59bd3d8baf6c12093061ade66b97a650fa54a8b028f1", "warmup_time": -1}, "arithmetic.DateInferOps.time_add_timedeltas": {"code": "class DateInferOps:\n    def time_add_timedeltas(self, df):\n        df[\"timedelta\"] + df[\"timedelta\"]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass DateInferOps:\n    def setup_cache(self):\n        N = 5 * 10**5\n        df = DataFrame({\"datetime64\": np.arange(N).astype(\"datetime64[ms]\")})\n        df[\"timedelta\"] = df[\"datetime64\"] - df[\"datetime64\"]\n        return df", "min_run_count": 2, "name": "arithmetic.DateInferOps.time_add_timedeltas", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "setup_cache_key": "arithmetic:375", "timeout": 60.0, "type": "time", "unit": "seconds", "version": "d304b19271ea5e636b026bf3da9f4297f153721c9a2c3e0173d635d70bf17047", "warmup_time": -1}, "arithmetic.DateInferOps.time_subtract_datetimes": {"code": "class DateInferOps:\n    def time_subtract_datetimes(self, df):\n        df[\"datetime64\"] - df[\"datetime64\"]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass DateInferOps:\n    def setup_cache(self):\n        N = 5 * 10**5\n        df = DataFrame({\"datetime64\": np.arange(N).astype(\"datetime64[ms]\")})\n        df[\"timedelta\"] = df[\"datetime64\"] - df[\"datetime64\"]\n        return df", "min_run_count": 2, "name": "arithmetic.DateInferOps.time_subtract_datetimes", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "setup_cache_key": "arithmetic:375", "timeout": 60.0, "type": "time", "unit": "seconds", "version": "0d0d777174d233a423d74dfef6d81ae5628aaf0098dd2ba538d20b71fa74a3a4", "warmup_time": -1}, "arithmetic.DateInferOps.time_timedelta_plus_datetime": {"code": "class DateInferOps:\n    def time_timedelta_plus_datetime(self, df):\n        df[\"timedelta\"] + df[\"datetime64\"]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass DateInferOps:\n    def setup_cache(self):\n        N = 5 * 10**5\n        df = DataFrame({\"datetime64\": np.arange(N).astype(\"datetime64[ms]\")})\n        df[\"timedelta\"] = df[\"datetime64\"] - df[\"datetime64\"]\n        return df", "min_run_count": 2, "name": "arithmetic.DateInferOps.time_timedelta_plus_datetime", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "setup_cache_key": "arithmetic:375", "timeout": 60.0, "type": "time", "unit": "seconds", "version": "d88c202e97a70579bbbc882c3e1887e44880bc361f354c724dfce863a33f80b3", "warmup_time": -1}, "arithmetic.FrameWithFrameWide.time_op_different_blocks": {"code": "class FrameWithFrameWide:\n    def time_op_different_blocks(self, op, shape):\n        # blocks (and dtypes) are not aligned\n        op(self.left, self.right)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass FrameWithFrameWide:\n    def setup(self, op, shape):\n        # we choose dtypes so as to make the blocks\n        #  a) not perfectly match between right and left\n        #  b) appreciably bigger than single columns\n        n_rows, n_cols = shape\n    \n        if op is operator.floordiv:\n            # floordiv is much slower than the other operations -> use less data\n            n_rows = n_rows // 10\n    \n        # construct dataframe with 2 blocks\n        arr1 = np.random.randn(n_rows, n_cols // 2).astype(\"f8\")\n        arr2 = np.random.randn(n_rows, n_cols // 2).astype(\"f4\")\n        df = pd.concat([DataFrame(arr1), DataFrame(arr2)], axis=1, ignore_index=True)\n        # should already be the case, but just to be sure\n        df._consolidate_inplace()\n    \n        # TODO: GH#33198 the setting here shouldn't need two steps\n        arr1 = np.random.randn(n_rows, max(n_cols // 4, 3)).astype(\"f8\")\n        arr2 = np.random.randn(n_rows, n_cols // 2).astype(\"i8\")\n        arr3 = np.random.randn(n_rows, n_cols // 4).astype(\"f8\")\n        df2 = pd.concat(\n            [DataFrame(arr1), DataFrame(arr2), DataFrame(arr3)],\n            axis=1,\n            ignore_index=True,\n        )\n        # should already be the case, but just to be sure\n        df2._consolidate_inplace()\n    \n        self.left = df\n        self.right = df2", "min_run_count": 2, "name": "arithmetic.FrameWithFrameWide.time_op_different_blocks", "number": 0, "param_names": ["op", "shape"], "params": [["<built-in function add>", "<built-in function floordiv>", "<built-in function gt>"], ["(1000000, 10)", "(100000, 100)", "(10000, 1000)", "(1000, 10000)"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "08d4888de43a21340c4ca998981b96bc41102332e11cc5e9f3fa24786b3387df", "warmup_time": -1}, "arithmetic.FrameWithFrameWide.time_op_same_blocks": {"code": "class FrameWithFrameWide:\n    def time_op_same_blocks(self, op, shape):\n        # blocks (and dtypes) are aligned\n        op(self.left, self.left)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass FrameWithFrameWide:\n    def setup(self, op, shape):\n        # we choose dtypes so as to make the blocks\n        #  a) not perfectly match between right and left\n        #  b) appreciably bigger than single columns\n        n_rows, n_cols = shape\n    \n        if op is operator.floordiv:\n            # floordiv is much slower than the other operations -> use less data\n            n_rows = n_rows // 10\n    \n        # construct dataframe with 2 blocks\n        arr1 = np.random.randn(n_rows, n_cols // 2).astype(\"f8\")\n        arr2 = np.random.randn(n_rows, n_cols // 2).astype(\"f4\")\n        df = pd.concat([DataFrame(arr1), DataFrame(arr2)], axis=1, ignore_index=True)\n        # should already be the case, but just to be sure\n        df._consolidate_inplace()\n    \n        # TODO: GH#33198 the setting here shouldn't need two steps\n        arr1 = np.random.randn(n_rows, max(n_cols // 4, 3)).astype(\"f8\")\n        arr2 = np.random.randn(n_rows, n_cols // 2).astype(\"i8\")\n        arr3 = np.random.randn(n_rows, n_cols // 4).astype(\"f8\")\n        df2 = pd.concat(\n            [DataFrame(arr1), DataFrame(arr2), DataFrame(arr3)],\n            axis=1,\n            ignore_index=True,\n        )\n        # should already be the case, but just to be sure\n        df2._consolidate_inplace()\n    \n        self.left = df\n        self.right = df2", "min_run_count": 2, "name": "arithmetic.FrameWithFrameWide.time_op_same_blocks", "number": 0, "param_names": ["op", "shape"], "params": [["<built-in function add>", "<built-in function floordiv>", "<built-in function gt>"], ["(1000000, 10)", "(100000, 100)", "(10000, 1000)", "(1000, 10000)"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "5a9a092d047b1965d0bc9f942b0cf7c15def8265241bbeedb67e2fceab345e22", "warmup_time": -1}, "arithmetic.IndexArithmetic.time_add": {"code": "class IndexArithmetic:\n    def time_add(self, dtype):\n        self.index + 2\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass IndexArithmetic:\n    def setup(self, dtype):\n        N = 10**6\n        if dtype == \"float\":\n            self.index = Index(np.arange(N), dtype=np.float64)\n        elif dtype == \"int\":\n            self.index = Index(np.arange(N), dtype=np.int64)", "min_run_count": 2, "name": "arithmetic.IndexArithmetic.time_add", "number": 0, "param_names": ["dtype"], "params": [["'float'", "'int'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "e3b336a2b91023f69241b1e98b2ab708a462124c6efae19a34cbfc4088ac5c30", "warmup_time": -1}, "arithmetic.IndexArithmetic.time_divide": {"code": "class IndexArithmetic:\n    def time_divide(self, dtype):\n        self.index / 2\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass IndexArithmetic:\n    def setup(self, dtype):\n        N = 10**6\n        if dtype == \"float\":\n            self.index = Index(np.arange(N), dtype=np.float64)\n        elif dtype == \"int\":\n            self.index = Index(np.arange(N), dtype=np.int64)", "min_run_count": 2, "name": "arithmetic.IndexArithmetic.time_divide", "number": 0, "param_names": ["dtype"], "params": [["'float'", "'int'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "34015b0ed303b7d7c8f55d6a9ad20ca0fa33aadc3daa21cd5aad136f74b8dd5a", "warmup_time": -1}, "arithmetic.IndexArithmetic.time_modulo": {"code": "class IndexArithmetic:\n    def time_modulo(self, dtype):\n        self.index % 2\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass IndexArithmetic:\n    def setup(self, dtype):\n        N = 10**6\n        if dtype == \"float\":\n            self.index = Index(np.arange(N), dtype=np.float64)\n        elif dtype == \"int\":\n            self.index = Index(np.arange(N), dtype=np.int64)", "min_run_count": 2, "name": "arithmetic.IndexArithmetic.time_modulo", "number": 0, "param_names": ["dtype"], "params": [["'float'", "'int'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "79e85d4d52e5fba7c78d4758aca6497d19481845699965996f6c198f8052f100", "warmup_time": -1}, "arithmetic.IndexArithmetic.time_multiply": {"code": "class IndexArithmetic:\n    def time_multiply(self, dtype):\n        self.index * 2\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass IndexArithmetic:\n    def setup(self, dtype):\n        N = 10**6\n        if dtype == \"float\":\n            self.index = Index(np.arange(N), dtype=np.float64)\n        elif dtype == \"int\":\n            self.index = Index(np.arange(N), dtype=np.int64)", "min_run_count": 2, "name": "arithmetic.IndexArithmetic.time_multiply", "number": 0, "param_names": ["dtype"], "params": [["'float'", "'int'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "5969c44239435c557404661c30a6b18f3fdef2422cd4683cc4baa5856db98617", "warmup_time": -1}, "arithmetic.IndexArithmetic.time_subtract": {"code": "class IndexArithmetic:\n    def time_subtract(self, dtype):\n        self.index - 2\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass IndexArithmetic:\n    def setup(self, dtype):\n        N = 10**6\n        if dtype == \"float\":\n            self.index = Index(np.arange(N), dtype=np.float64)\n        elif dtype == \"int\":\n            self.index = Index(np.arange(N), dtype=np.int64)", "min_run_count": 2, "name": "arithmetic.IndexArithmetic.time_subtract", "number": 0, "param_names": ["dtype"], "params": [["'float'", "'int'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "064e28755b44443edfc8d9a9e01aa56cd0b70fde6e6ea290d84284e9bb03268a", "warmup_time": -1}, "arithmetic.IntFrameWithScalar.time_frame_op_with_scalar": {"code": "class IntFrameWithScalar:\n    def time_frame_op_with_scalar(self, dtype, scalar, op):\n        op(self.df, scalar)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass IntFrameWithScalar:\n    def setup(self, dtype, scalar, op):\n        arr = np.random.randn(20000, 100)\n        self.df = DataFrame(arr.astype(dtype))", "min_run_count": 2, "name": "arithmetic.IntFrameWithScalar.time_frame_op_with_scalar", "number": 0, "param_names": ["dtype", "scalar", "op"], "params": [["<class 'numpy.float64'>", "<class 'numpy.int64'>"], ["2", "3.0", "4", "5.0"], ["<built-in function add>", "<built-in function sub>", "<built-in function mul>", "<built-in function truediv>", "<built-in function floordiv>", "<built-in function pow>", "<built-in function mod>", "<built-in function eq>", "<built-in function ne>", "<built-in function gt>", "<built-in function ge>", "<built-in function lt>", "<built-in function le>"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "17cc3015c45764be50024cbe52247cfe2100d4020bdf03e0b04bea2f932fe975", "warmup_time": -1}, "arithmetic.IrregularOps.time_add": {"code": "class IrregularOps:\n    def time_add(self):\n        self.left + self.right\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass IrregularOps:\n    def setup(self):\n        N = 10**5\n        idx = date_range(start=\"1/1/2000\", periods=N, freq=\"s\")\n        s = Series(np.random.randn(N), index=idx)\n        self.left = s.sample(frac=1)\n        self.right = s.sample(frac=1)", "min_run_count": 2, "name": "arithmetic.IrregularOps.time_add", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "c48f5ee66f4fba32ce66ca585b4550f976b5632cf96bb22e9be34d3c2ea0a194", "warmup_time": -1}, "arithmetic.MixedFrameWithSeriesAxis.time_frame_op_with_series_axis0": {"code": "class MixedFrameWithSeriesAxis:\n    def time_frame_op_with_series_axis0(self, opname):\n        getattr(self.df, opname)(self.ser, axis=0)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass MixedFrameWithSeriesAxis:\n    def setup(self, opname):\n        arr = np.arange(10**6).reshape(1000, -1)\n        df = DataFrame(arr)\n        df[\"C\"] = 1.0\n        self.df = df\n        self.ser = df[0]\n        self.row = df.iloc[0]", "min_run_count": 2, "name": "arithmetic.MixedFrameWithSeriesAxis.time_frame_op_with_series_axis0", "number": 0, "param_names": ["opname"], "params": [["'eq'", "'ne'", "'lt'", "'le'", "'ge'", "'gt'", "'add'", "'sub'", "'truediv'", "'floordiv'", "'mul'", "'pow'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "2ec044d527bdcad8450ef35a26f4caee5ca2d8cf69f36b99665adedc140d4b71", "warmup_time": -1}, "arithmetic.MixedFrameWithSeriesAxis.time_frame_op_with_series_axis1": {"code": "class MixedFrameWithSeriesAxis:\n    def time_frame_op_with_series_axis1(self, opname):\n        getattr(operator, opname)(self.df, self.ser)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass MixedFrameWithSeriesAxis:\n    def setup(self, opname):\n        arr = np.arange(10**6).reshape(1000, -1)\n        df = DataFrame(arr)\n        df[\"C\"] = 1.0\n        self.df = df\n        self.ser = df[0]\n        self.row = df.iloc[0]", "min_run_count": 2, "name": "arithmetic.MixedFrameWithSeriesAxis.time_frame_op_with_series_axis1", "number": 0, "param_names": ["opname"], "params": [["'add'", "'sub'", "'truediv'", "'floordiv'", "'mul'", "'pow'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "1c5761284f2cd8adf60d3f65efee5881b415f0c986cfbbc8e313f298eb349a3e", "warmup_time": -1}, "arithmetic.NumericInferOps.time_add": {"code": "class NumericInferOps:\n    def time_add(self, dtype):\n        self.df[\"A\"] + self.df[\"B\"]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass NumericInferOps:\n    def setup(self, dtype):\n        N = 5 * 10**5\n        self.df = DataFrame(\n            {\"A\": np.arange(N).astype(dtype), \"B\": np.arange(N).astype(dtype)}\n        )", "min_run_count": 2, "name": "arithmetic.NumericInferOps.time_add", "number": 0, "param_names": ["dtype"], "params": [["<class 'numpy.int64'>", "<class 'numpy.int32'>", "<class 'numpy.uint32'>", "<class 'numpy.uint64'>", "<class 'numpy.float32'>", "<class 'numpy.float64'>", "<class 'numpy.int16'>", "<class 'numpy.int8'>", "<class 'numpy.uint16'>", "<class 'numpy.uint8'>"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "d8c4f5e6dc0c54cff731395cacf041f5ccf4d5fdf6605e5aea2767fdea959165", "warmup_time": -1}, "arithmetic.NumericInferOps.time_divide": {"code": "class NumericInferOps:\n    def time_divide(self, dtype):\n        self.df[\"A\"] / self.df[\"B\"]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass NumericInferOps:\n    def setup(self, dtype):\n        N = 5 * 10**5\n        self.df = DataFrame(\n            {\"A\": np.arange(N).astype(dtype), \"B\": np.arange(N).astype(dtype)}\n        )", "min_run_count": 2, "name": "arithmetic.NumericInferOps.time_divide", "number": 0, "param_names": ["dtype"], "params": [["<class 'numpy.int64'>", "<class 'numpy.int32'>", "<class 'numpy.uint32'>", "<class 'numpy.uint64'>", "<class 'numpy.float32'>", "<class 'numpy.float64'>", "<class 'numpy.int16'>", "<class 'numpy.int8'>", "<class 'numpy.uint16'>", "<class 'numpy.uint8'>"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "a435004455cc72252be9ec940814e96fbe3afb17fb5329b5d7c51208c9796979", "warmup_time": -1}, "arithmetic.NumericInferOps.time_modulo": {"code": "class NumericInferOps:\n    def time_modulo(self, dtype):\n        self.df[\"A\"] % self.df[\"B\"]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass NumericInferOps:\n    def setup(self, dtype):\n        N = 5 * 10**5\n        self.df = DataFrame(\n            {\"A\": np.arange(N).astype(dtype), \"B\": np.arange(N).astype(dtype)}\n        )", "min_run_count": 2, "name": "arithmetic.NumericInferOps.time_modulo", "number": 0, "param_names": ["dtype"], "params": [["<class 'numpy.int64'>", "<class 'numpy.int32'>", "<class 'numpy.uint32'>", "<class 'numpy.uint64'>", "<class 'numpy.float32'>", "<class 'numpy.float64'>", "<class 'numpy.int16'>", "<class 'numpy.int8'>", "<class 'numpy.uint16'>", "<class 'numpy.uint8'>"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "44d71d818e38047c0a9a5903a9d5707c2ff4eae84631c776e3dba9448493a767", "warmup_time": -1}, "arithmetic.NumericInferOps.time_multiply": {"code": "class NumericInferOps:\n    def time_multiply(self, dtype):\n        self.df[\"A\"] * self.df[\"B\"]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass NumericInferOps:\n    def setup(self, dtype):\n        N = 5 * 10**5\n        self.df = DataFrame(\n            {\"A\": np.arange(N).astype(dtype), \"B\": np.arange(N).astype(dtype)}\n        )", "min_run_count": 2, "name": "arithmetic.NumericInferOps.time_multiply", "number": 0, "param_names": ["dtype"], "params": [["<class 'numpy.int64'>", "<class 'numpy.int32'>", "<class 'numpy.uint32'>", "<class 'numpy.uint64'>", "<class 'numpy.float32'>", "<class 'numpy.float64'>", "<class 'numpy.int16'>", "<class 'numpy.int8'>", "<class 'numpy.uint16'>", "<class 'numpy.uint8'>"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "fe621ddecbe036b8b2a50405324b8024f35d0412d89bf916c6adec56d4c5f360", "warmup_time": -1}, "arithmetic.NumericInferOps.time_subtract": {"code": "class NumericInferOps:\n    def time_subtract(self, dtype):\n        self.df[\"A\"] - self.df[\"B\"]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass NumericInferOps:\n    def setup(self, dtype):\n        N = 5 * 10**5\n        self.df = DataFrame(\n            {\"A\": np.arange(N).astype(dtype), \"B\": np.arange(N).astype(dtype)}\n        )", "min_run_count": 2, "name": "arithmetic.NumericInferOps.time_subtract", "number": 0, "param_names": ["dtype"], "params": [["<class 'numpy.int64'>", "<class 'numpy.int32'>", "<class 'numpy.uint32'>", "<class 'numpy.uint64'>", "<class 'numpy.float32'>", "<class 'numpy.float64'>", "<class 'numpy.int16'>", "<class 'numpy.int8'>", "<class 'numpy.uint16'>", "<class 'numpy.uint8'>"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "2e26ca6727d932af0269ec66a57701c64b061d05601a076e2524ebf79e1b5cd6", "warmup_time": -1}, "arithmetic.OffsetArrayArithmetic.time_add_dti_offset": {"code": "class OffsetArrayArithmetic:\n    def time_add_dti_offset(self, offset):\n        with warnings.catch_warnings(record=True):\n            self.rng + offset\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass OffsetArrayArithmetic:\n    def setup(self, offset):\n        N = 10000\n        rng = date_range(start=\"1/1/2000\", periods=N, freq=\"min\")\n        self.rng = rng\n        self.ser = Series(rng)", "min_run_count": 2, "name": "arithmetic.OffsetArrayArithmetic.time_add_dti_offset", "number": 0, "param_names": ["offset"], "params": [["<Day>", "<BYearEnd: month=12>", "<BYearBegin: month=1>", "<BusinessQuarterEnd: startingMonth=3>", "<BusinessQuarterBegin: startingMonth=3>", "<BusinessMonthEnd>", "<BusinessMonthBegin>", "<CustomBusinessDay> (0)", "<CustomBusinessDay> (1)", "<CustomBusinessMonthBegin>", "<CustomBusinessMonthEnd> (0)", "<CustomBusinessMonthEnd> (1)", "<YearEnd: month=12>", "<YearBegin: month=1>", "<QuarterEnd: startingMonth=3>", "<QuarterBegin: startingMonth=3>", "<MonthEnd>", "<MonthBegin>", "<DateOffset: days=2, months=2>", "<BusinessDay>", "<SemiMonthEnd: day_of_month=15>", "<SemiMonthBegin: day_of_month=15>"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "773a2fe8364b7487aee29003e6fa3d183f2fb484205a9b055d70067c056ed277", "warmup_time": -1}, "arithmetic.OffsetArrayArithmetic.time_add_series_offset": {"code": "class OffsetArrayArithmetic:\n    def time_add_series_offset(self, offset):\n        with warnings.catch_warnings(record=True):\n            self.ser + offset\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass OffsetArrayArithmetic:\n    def setup(self, offset):\n        N = 10000\n        rng = date_range(start=\"1/1/2000\", periods=N, freq=\"min\")\n        self.rng = rng\n        self.ser = Series(rng)", "min_run_count": 2, "name": "arithmetic.OffsetArrayArithmetic.time_add_series_offset", "number": 0, "param_names": ["offset"], "params": [["<Day>", "<BYearEnd: month=12>", "<BYearBegin: month=1>", "<BusinessQuarterEnd: startingMonth=3>", "<BusinessQuarterBegin: startingMonth=3>", "<BusinessMonthEnd>", "<BusinessMonthBegin>", "<CustomBusinessDay> (0)", "<CustomBusinessDay> (1)", "<CustomBusinessMonthBegin>", "<CustomBusinessMonthEnd> (0)", "<CustomBusinessMonthEnd> (1)", "<YearEnd: month=12>", "<YearBegin: month=1>", "<QuarterEnd: startingMonth=3>", "<QuarterBegin: startingMonth=3>", "<MonthEnd>", "<MonthBegin>", "<DateOffset: days=2, months=2>", "<BusinessDay>", "<SemiMonthEnd: day_of_month=15>", "<SemiMonthBegin: day_of_month=15>"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "14f080de541934c9cd028a210635eb42296006292989ffde9a52ae195ca39452", "warmup_time": -1}, "arithmetic.OpWithFillValue.time_frame_op_with_fill_value_no_nas": {"code": "class OpWithFillValue:\n    def time_frame_op_with_fill_value_no_nas(self):\n        self.df.add(self.df, fill_value=4)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass OpWithFillValue:\n    def setup(self):\n        # GH#31300\n        arr = np.arange(10**6)\n        df = DataFrame({\"A\": arr})\n        ser = df[\"A\"]\n    \n        self.df = df\n        self.ser = ser", "min_run_count": 2, "name": "arithmetic.OpWithFillValue.time_frame_op_with_fill_value_no_nas", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "162ff770e3fdcbc51f2d5140c2cf46f028d48a27268957104ac69d7d800cc1a0", "warmup_time": -1}, "arithmetic.OpWithFillValue.time_series_op_with_fill_value_no_nas": {"code": "class OpWithFillValue:\n    def time_series_op_with_fill_value_no_nas(self):\n        self.ser.add(self.ser, fill_value=4)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass OpWithFillValue:\n    def setup(self):\n        # GH#31300\n        arr = np.arange(10**6)\n        df = DataFrame({\"A\": arr})\n        ser = df[\"A\"]\n    \n        self.df = df\n        self.ser = ser", "min_run_count": 2, "name": "arithmetic.OpWithFillValue.time_series_op_with_fill_value_no_nas", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "81d51758d1b72e5df11be69874e29ffab5fdbe1e4cd1816754c197a4833d5d8e", "warmup_time": -1}, "arithmetic.Ops.time_frame_add": {"code": "class Ops:\n    def time_frame_add(self, use_numexpr, threads):\n        self.df + self.df2\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Ops:\n    def setup(self, use_numexpr, threads):\n        self.df = DataFrame(np.random.randn(20000, 100))\n        self.df2 = DataFrame(np.random.randn(20000, 100))\n    \n        if threads != \"default\":\n            expr.set_numexpr_threads(threads)\n        if not use_numexpr:\n            expr.set_use_numexpr(False)", "min_run_count": 2, "name": "arithmetic.Ops.time_frame_add", "number": 0, "param_names": ["use_numexpr", "threads"], "params": [["True", "False"], ["'default'", "1"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "173dfb8c14d4f1e45058ae77d74a28966785fc801b28902fd8448d30ac4ff7d8", "warmup_time": -1}, "arithmetic.Ops.time_frame_comparison": {"code": "class Ops:\n    def time_frame_comparison(self, use_numexpr, threads):\n        self.df > self.df2\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Ops:\n    def setup(self, use_numexpr, threads):\n        self.df = DataFrame(np.random.randn(20000, 100))\n        self.df2 = DataFrame(np.random.randn(20000, 100))\n    \n        if threads != \"default\":\n            expr.set_numexpr_threads(threads)\n        if not use_numexpr:\n            expr.set_use_numexpr(False)", "min_run_count": 2, "name": "arithmetic.Ops.time_frame_comparison", "number": 0, "param_names": ["use_numexpr", "threads"], "params": [["True", "False"], ["'default'", "1"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "b9edf1afa79c0a69d8e9647b98beb73e32760b78ff938a190dc6b42ccac38b11", "warmup_time": -1}, "arithmetic.Ops.time_frame_mult": {"code": "class Ops:\n    def time_frame_mult(self, use_numexpr, threads):\n        self.df * self.df2\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Ops:\n    def setup(self, use_numexpr, threads):\n        self.df = DataFrame(np.random.randn(20000, 100))\n        self.df2 = DataFrame(np.random.randn(20000, 100))\n    \n        if threads != \"default\":\n            expr.set_numexpr_threads(threads)\n        if not use_numexpr:\n            expr.set_use_numexpr(False)", "min_run_count": 2, "name": "arithmetic.Ops.time_frame_mult", "number": 0, "param_names": ["use_numexpr", "threads"], "params": [["True", "False"], ["'default'", "1"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "911cfaa0ecf7737245490bf8a69723a5301ce60c296a33915a8eb9c09d7cd279", "warmup_time": -1}, "arithmetic.Ops.time_frame_multi_and": {"code": "class Ops:\n    def time_frame_multi_and(self, use_numexpr, threads):\n        self.df[(self.df > 0) & (self.df2 > 0)]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Ops:\n    def setup(self, use_numexpr, threads):\n        self.df = DataFrame(np.random.randn(20000, 100))\n        self.df2 = DataFrame(np.random.randn(20000, 100))\n    \n        if threads != \"default\":\n            expr.set_numexpr_threads(threads)\n        if not use_numexpr:\n            expr.set_use_numexpr(False)", "min_run_count": 2, "name": "arithmetic.Ops.time_frame_multi_and", "number": 0, "param_names": ["use_numexpr", "threads"], "params": [["True", "False"], ["'default'", "1"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "27fe96278213fdc7fe35ca52941a5bf4e3def23517666891d790d2d443a98ef2", "warmup_time": -1}, "arithmetic.Ops2.time_frame_dot": {"code": "class Ops2:\n    def time_frame_dot(self):\n        self.df.dot(self.df2)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Ops2:\n    def setup(self):\n        N = 10**3\n        self.df = DataFrame(np.random.randn(N, N))\n        self.df2 = DataFrame(np.random.randn(N, N))\n    \n        self.df_int = DataFrame(\n            np.random.randint(\n                np.iinfo(np.int16).min, np.iinfo(np.int16).max, size=(N, N)\n            )\n        )\n        self.df2_int = DataFrame(\n            np.random.randint(\n                np.iinfo(np.int16).min, np.iinfo(np.int16).max, size=(N, N)\n            )\n        )\n    \n        self.s = Series(np.random.randn(N))", "min_run_count": 2, "name": "arithmetic.Ops2.time_frame_dot", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "efdf52d3f6066f576d98f9b78aef45d706022d5fdf431ac33a3d411c8915c028", "warmup_time": -1}, "arithmetic.Ops2.time_frame_float_div": {"code": "class Ops2:\n    def time_frame_float_div(self):\n        self.df // self.df2\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Ops2:\n    def setup(self):\n        N = 10**3\n        self.df = DataFrame(np.random.randn(N, N))\n        self.df2 = DataFrame(np.random.randn(N, N))\n    \n        self.df_int = DataFrame(\n            np.random.randint(\n                np.iinfo(np.int16).min, np.iinfo(np.int16).max, size=(N, N)\n            )\n        )\n        self.df2_int = DataFrame(\n            np.random.randint(\n                np.iinfo(np.int16).min, np.iinfo(np.int16).max, size=(N, N)\n            )\n        )\n    \n        self.s = Series(np.random.randn(N))", "min_run_count": 2, "name": "arithmetic.Ops2.time_frame_float_div", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "859b0f256d5a19376ac8c740779c53fb2287fd0c6f8f0d2f48052d7a57050a0a", "warmup_time": -1}, "arithmetic.Ops2.time_frame_float_div_by_zero": {"code": "class Ops2:\n    def time_frame_float_div_by_zero(self):\n        self.df / 0\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Ops2:\n    def setup(self):\n        N = 10**3\n        self.df = DataFrame(np.random.randn(N, N))\n        self.df2 = DataFrame(np.random.randn(N, N))\n    \n        self.df_int = DataFrame(\n            np.random.randint(\n                np.iinfo(np.int16).min, np.iinfo(np.int16).max, size=(N, N)\n            )\n        )\n        self.df2_int = DataFrame(\n            np.random.randint(\n                np.iinfo(np.int16).min, np.iinfo(np.int16).max, size=(N, N)\n            )\n        )\n    \n        self.s = Series(np.random.randn(N))", "min_run_count": 2, "name": "arithmetic.Ops2.time_frame_float_div_by_zero", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "bacba426dd7890d79b38fd7575e9ba633c7ebc2252b393414e19e8838317b7a9", "warmup_time": -1}, "arithmetic.Ops2.time_frame_float_floor_by_zero": {"code": "class Ops2:\n    def time_frame_float_floor_by_zero(self):\n        self.df // 0\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Ops2:\n    def setup(self):\n        N = 10**3\n        self.df = DataFrame(np.random.randn(N, N))\n        self.df2 = DataFrame(np.random.randn(N, N))\n    \n        self.df_int = DataFrame(\n            np.random.randint(\n                np.iinfo(np.int16).min, np.iinfo(np.int16).max, size=(N, N)\n            )\n        )\n        self.df2_int = DataFrame(\n            np.random.randint(\n                np.iinfo(np.int16).min, np.iinfo(np.int16).max, size=(N, N)\n            )\n        )\n    \n        self.s = Series(np.random.randn(N))", "min_run_count": 2, "name": "arithmetic.Ops2.time_frame_float_floor_by_zero", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "5096a00c147e73e2a7a0be3156a440a3dd813fff99c8ed11456981814df947a2", "warmup_time": -1}, "arithmetic.Ops2.time_frame_float_mod": {"code": "class Ops2:\n    def time_frame_float_mod(self):\n        self.df % self.df2\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Ops2:\n    def setup(self):\n        N = 10**3\n        self.df = DataFrame(np.random.randn(N, N))\n        self.df2 = DataFrame(np.random.randn(N, N))\n    \n        self.df_int = DataFrame(\n            np.random.randint(\n                np.iinfo(np.int16).min, np.iinfo(np.int16).max, size=(N, N)\n            )\n        )\n        self.df2_int = DataFrame(\n            np.random.randint(\n                np.iinfo(np.int16).min, np.iinfo(np.int16).max, size=(N, N)\n            )\n        )\n    \n        self.s = Series(np.random.randn(N))", "min_run_count": 2, "name": "arithmetic.Ops2.time_frame_float_mod", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "72aa4cef09d38e4af67ae6e35e15b1304bd371e85fc3613e817cedd372852517", "warmup_time": -1}, "arithmetic.Ops2.time_frame_int_div_by_zero": {"code": "class Ops2:\n    def time_frame_int_div_by_zero(self):\n        self.df_int / 0\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Ops2:\n    def setup(self):\n        N = 10**3\n        self.df = DataFrame(np.random.randn(N, N))\n        self.df2 = DataFrame(np.random.randn(N, N))\n    \n        self.df_int = DataFrame(\n            np.random.randint(\n                np.iinfo(np.int16).min, np.iinfo(np.int16).max, size=(N, N)\n            )\n        )\n        self.df2_int = DataFrame(\n            np.random.randint(\n                np.iinfo(np.int16).min, np.iinfo(np.int16).max, size=(N, N)\n            )\n        )\n    \n        self.s = Series(np.random.randn(N))", "min_run_count": 2, "name": "arithmetic.Ops2.time_frame_int_div_by_zero", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "cdab6c35545be907f3db670b2114ccd527c652b9b3992d2ef767b26d538cc342", "warmup_time": -1}, "arithmetic.Ops2.time_frame_int_mod": {"code": "class Ops2:\n    def time_frame_int_mod(self):\n        self.df_int % self.df2_int\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Ops2:\n    def setup(self):\n        N = 10**3\n        self.df = DataFrame(np.random.randn(N, N))\n        self.df2 = DataFrame(np.random.randn(N, N))\n    \n        self.df_int = DataFrame(\n            np.random.randint(\n                np.iinfo(np.int16).min, np.iinfo(np.int16).max, size=(N, N)\n            )\n        )\n        self.df2_int = DataFrame(\n            np.random.randint(\n                np.iinfo(np.int16).min, np.iinfo(np.int16).max, size=(N, N)\n            )\n        )\n    \n        self.s = Series(np.random.randn(N))", "min_run_count": 2, "name": "arithmetic.Ops2.time_frame_int_mod", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "cb4f4230cb2354cccaed2ae0cd0fdfaf8ef908fbcf616544289f44a42a0f2eb4", "warmup_time": -1}, "arithmetic.Ops2.time_frame_series_dot": {"code": "class Ops2:\n    def time_frame_series_dot(self):\n        self.df.dot(self.s)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Ops2:\n    def setup(self):\n        N = 10**3\n        self.df = DataFrame(np.random.randn(N, N))\n        self.df2 = DataFrame(np.random.randn(N, N))\n    \n        self.df_int = DataFrame(\n            np.random.randint(\n                np.iinfo(np.int16).min, np.iinfo(np.int16).max, size=(N, N)\n            )\n        )\n        self.df2_int = DataFrame(\n            np.random.randint(\n                np.iinfo(np.int16).min, np.iinfo(np.int16).max, size=(N, N)\n            )\n        )\n    \n        self.s = Series(np.random.randn(N))", "min_run_count": 2, "name": "arithmetic.Ops2.time_frame_series_dot", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "30c45d8348c1f30ed5962671b11e5a31ae976f64b960b8cbe8eceb8c1f3716b8", "warmup_time": -1}, "arithmetic.Ops2.time_series_dot": {"code": "class Ops2:\n    def time_series_dot(self):\n        self.s.dot(self.s)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Ops2:\n    def setup(self):\n        N = 10**3\n        self.df = DataFrame(np.random.randn(N, N))\n        self.df2 = DataFrame(np.random.randn(N, N))\n    \n        self.df_int = DataFrame(\n            np.random.randint(\n                np.iinfo(np.int16).min, np.iinfo(np.int16).max, size=(N, N)\n            )\n        )\n        self.df2_int = DataFrame(\n            np.random.randint(\n                np.iinfo(np.int16).min, np.iinfo(np.int16).max, size=(N, N)\n            )\n        )\n    \n        self.s = Series(np.random.randn(N))", "min_run_count": 2, "name": "arithmetic.Ops2.time_series_dot", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "524f0eb5deba6ae021936a6721c4fec9cb92fccf0ac27c1799ab70139a436fdc", "warmup_time": -1}, "arithmetic.TimedeltaOps.time_add_td_ts": {"code": "class TimedeltaOps:\n    def time_add_td_ts(self):\n        self.td + self.ts\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass TimedeltaOps:\n    def setup(self):\n        self.td = to_timedelta(np.arange(1000000))\n        self.ts = Timestamp(\"2000\")", "min_run_count": 2, "name": "arithmetic.TimedeltaOps.time_add_td_ts", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "ee3abda2771a3808efc316e236cd6de15f8678b03e2a27e6f75792edbbe543ec", "warmup_time": -1}, "arithmetic.Timeseries.time_series_timestamp_compare": {"code": "class Timeseries:\n    def time_series_timestamp_compare(self, tz):\n        self.s <= self.ts\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Timeseries:\n    def setup(self, tz):\n        N = 10**6\n        halfway = (N // 2) - 1\n        self.s = Series(date_range(\"20010101\", periods=N, freq=\"min\", tz=tz))\n        self.ts = self.s[halfway]\n    \n        self.s2 = Series(date_range(\"20010101\", periods=N, freq=\"s\", tz=tz))\n        self.ts_different_reso = Timestamp(\"2001-01-02\", tz=tz)", "min_run_count": 2, "name": "arithmetic.Timeseries.time_series_timestamp_compare", "number": 0, "param_names": ["tz"], "params": [["None", "'US/Eastern'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "2ed5f17ee3263c0675f3f6293f63a1432f5f306de89d694585642001a6522d84", "warmup_time": -1}, "arithmetic.Timeseries.time_series_timestamp_different_reso_compare": {"code": "class Timeseries:\n    def time_series_timestamp_different_reso_compare(self, tz):\n        self.s <= self.ts_different_reso\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Timeseries:\n    def setup(self, tz):\n        N = 10**6\n        halfway = (N // 2) - 1\n        self.s = Series(date_range(\"20010101\", periods=N, freq=\"min\", tz=tz))\n        self.ts = self.s[halfway]\n    \n        self.s2 = Series(date_range(\"20010101\", periods=N, freq=\"s\", tz=tz))\n        self.ts_different_reso = Timestamp(\"2001-01-02\", tz=tz)", "min_run_count": 2, "name": "arithmetic.Timeseries.time_series_timestamp_different_reso_compare", "number": 0, "param_names": ["tz"], "params": [["None", "'US/Eastern'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "3c7524e8c0a4069313b1ec51d6e534e708d5b1d735d3b48c3c2443ee4a65f1c8", "warmup_time": -1}, "arithmetic.Timeseries.time_timestamp_ops_diff": {"code": "class Timeseries:\n    def time_timestamp_ops_diff(self, tz):\n        self.s2.diff()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Timeseries:\n    def setup(self, tz):\n        N = 10**6\n        halfway = (N // 2) - 1\n        self.s = Series(date_range(\"20010101\", periods=N, freq=\"min\", tz=tz))\n        self.ts = self.s[halfway]\n    \n        self.s2 = Series(date_range(\"20010101\", periods=N, freq=\"s\", tz=tz))\n        self.ts_different_reso = Timestamp(\"2001-01-02\", tz=tz)", "min_run_count": 2, "name": "arithmetic.Timeseries.time_timestamp_ops_diff", "number": 0, "param_names": ["tz"], "params": [["None", "'US/Eastern'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "93c02a9bd33f19256f321c09451b0f35b9b4b1b1f54c9c3ff180aad5c57503ce", "warmup_time": -1}, "arithmetic.Timeseries.time_timestamp_ops_diff_with_shift": {"code": "class Timeseries:\n    def time_timestamp_ops_diff_with_shift(self, tz):\n        self.s - self.s.shift()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Timeseries:\n    def setup(self, tz):\n        N = 10**6\n        halfway = (N // 2) - 1\n        self.s = Series(date_range(\"20010101\", periods=N, freq=\"min\", tz=tz))\n        self.ts = self.s[halfway]\n    \n        self.s2 = Series(date_range(\"20010101\", periods=N, freq=\"s\", tz=tz))\n        self.ts_different_reso = Timestamp(\"2001-01-02\", tz=tz)", "min_run_count": 2, "name": "arithmetic.Timeseries.time_timestamp_ops_diff_with_shift", "number": 0, "param_names": ["tz"], "params": [["None", "'US/Eastern'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "8cab7c77baffeef8c23dde710dd4e428b68beaad2631fd5add6969cc56fb326a", "warmup_time": -1}, "arithmetic.Timeseries.time_timestamp_series_compare": {"code": "class Timeseries:\n    def time_timestamp_series_compare(self, tz):\n        self.ts >= self.s\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Timeseries:\n    def setup(self, tz):\n        N = 10**6\n        halfway = (N // 2) - 1\n        self.s = Series(date_range(\"20010101\", periods=N, freq=\"min\", tz=tz))\n        self.ts = self.s[halfway]\n    \n        self.s2 = Series(date_range(\"20010101\", periods=N, freq=\"s\", tz=tz))\n        self.ts_different_reso = Timestamp(\"2001-01-02\", tz=tz)", "min_run_count": 2, "name": "arithmetic.Timeseries.time_timestamp_series_compare", "number": 0, "param_names": ["tz"], "params": [["None", "'US/Eastern'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "ef8d8e370d78f1580db60bb5b8997ef11749938452601dbe3816c0a1b7184c75", "warmup_time": -1}, "array.ArrowExtensionArray.time_to_numpy": {"code": "class ArrowExtensionArray:\n    def time_to_numpy(self, dtype, hasna):\n        self.arr.to_numpy()\n\n    def setup(self, dtype, hasna):\n        N = 100_000\n        if dtype == \"boolean[pyarrow]\":\n            data = np.random.choice([True, False], N, replace=True)\n        elif dtype == \"float64[pyarrow]\":\n            data = np.random.randn(N)\n        elif dtype == \"int64[pyarrow]\":\n            data = np.arange(N)\n        elif dtype == \"string[pyarrow]\":\n            data = np.array([str(i) for i in range(N)], dtype=object)\n        elif dtype == \"timestamp[ns][pyarrow]\":\n            data = pd.date_range(\"2000-01-01\", freq=\"s\", periods=N)\n        else:\n            raise NotImplementedError\n    \n        arr = pd.array(data, dtype=dtype)\n        if hasna:\n            arr[::2] = pd.NA\n        self.arr = arr", "min_run_count": 2, "name": "array.ArrowExtensionArray.time_to_numpy", "number": 0, "param_names": ["dtype", "hasna"], "params": [["'boolean[pyarrow]'", "'float64[pyarrow]'", "'int64[pyarrow]'", "'string[pyarrow]'", "'timestamp[ns][pyarrow]'"], ["False", "True"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "ae6d3539d4bf1ab5add70aed593a5fd7a6e541a28b7a0eb633a73bb9abd71cc2", "warmup_time": -1}, "array.ArrowStringArray.time_setitem": {"code": "class ArrowStringArray:\n    def time_setitem(self, multiple_chunks):\n        for i in range(200):\n            self.array[i] = \"foo\"\n\n    def setup(self, multiple_chunks):\n        try:\n            import pyarrow as pa\n        except ImportError:\n            raise NotImplementedError\n        strings = np.array([str(i) for i in range(10_000)], dtype=object)\n        if multiple_chunks:\n            chunks = [strings[i : i + 100] for i in range(0, len(strings), 100)]\n            self.array = pd.arrays.ArrowStringArray(pa.chunked_array(chunks))\n        else:\n            self.array = pd.arrays.ArrowStringArray(pa.array(strings))", "min_run_count": 2, "name": "array.ArrowStringArray.time_setitem", "number": 0, "param_names": ["multiple_chunks"], "params": [["False", "True"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "bfb804af3d209db3ec3ae18a834f3a46b5773a649e21d60cb86afbfc6bc6e902", "warmup_time": -1}, "array.ArrowStringArray.time_setitem_list": {"code": "class ArrowStringArray:\n    def time_setitem_list(self, multiple_chunks):\n        indexer = list(range(50)) + list(range(-1000, 0, 50))\n        self.array[indexer] = [\"foo\"] * len(indexer)\n\n    def setup(self, multiple_chunks):\n        try:\n            import pyarrow as pa\n        except ImportError:\n            raise NotImplementedError\n        strings = np.array([str(i) for i in range(10_000)], dtype=object)\n        if multiple_chunks:\n            chunks = [strings[i : i + 100] for i in range(0, len(strings), 100)]\n            self.array = pd.arrays.ArrowStringArray(pa.chunked_array(chunks))\n        else:\n            self.array = pd.arrays.ArrowStringArray(pa.array(strings))", "min_run_count": 2, "name": "array.ArrowStringArray.time_setitem_list", "number": 0, "param_names": ["multiple_chunks"], "params": [["False", "True"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "4a5677fdb85bec50162f154b9639b2141ead3575e367bb1fa66b91aa05dc5424", "warmup_time": -1}, "array.ArrowStringArray.time_setitem_null_slice": {"code": "class ArrowStringArray:\n    def time_setitem_null_slice(self, multiple_chunks):\n        self.array[:] = \"foo\"\n\n    def setup(self, multiple_chunks):\n        try:\n            import pyarrow as pa\n        except ImportError:\n            raise NotImplementedError\n        strings = np.array([str(i) for i in range(10_000)], dtype=object)\n        if multiple_chunks:\n            chunks = [strings[i : i + 100] for i in range(0, len(strings), 100)]\n            self.array = pd.arrays.ArrowStringArray(pa.chunked_array(chunks))\n        else:\n            self.array = pd.arrays.ArrowStringArray(pa.array(strings))", "min_run_count": 2, "name": "array.ArrowStringArray.time_setitem_null_slice", "number": 0, "param_names": ["multiple_chunks"], "params": [["False", "True"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "57adbd58e6af54e06c94b653ca7de192da37e96842f6e4a24c75dc3a66f96c5b", "warmup_time": -1}, "array.ArrowStringArray.time_setitem_slice": {"code": "class ArrowStringArray:\n    def time_setitem_slice(self, multiple_chunks):\n        self.array[::10] = \"foo\"\n\n    def setup(self, multiple_chunks):\n        try:\n            import pyarrow as pa\n        except ImportError:\n            raise NotImplementedError\n        strings = np.array([str(i) for i in range(10_000)], dtype=object)\n        if multiple_chunks:\n            chunks = [strings[i : i + 100] for i in range(0, len(strings), 100)]\n            self.array = pd.arrays.ArrowStringArray(pa.chunked_array(chunks))\n        else:\n            self.array = pd.arrays.ArrowStringArray(pa.array(strings))", "min_run_count": 2, "name": "array.ArrowStringArray.time_setitem_slice", "number": 0, "param_names": ["multiple_chunks"], "params": [["False", "True"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "4447d26de9edfb7f4ecaaf312c5e5a8971ac99cf8d661cbb0dffae46c5a78d39", "warmup_time": -1}, "array.ArrowStringArray.time_tolist": {"code": "class ArrowStringArray:\n    def time_tolist(self, multiple_chunks):\n        self.array.tolist()\n\n    def setup(self, multiple_chunks):\n        try:\n            import pyarrow as pa\n        except ImportError:\n            raise NotImplementedError\n        strings = np.array([str(i) for i in range(10_000)], dtype=object)\n        if multiple_chunks:\n            chunks = [strings[i : i + 100] for i in range(0, len(strings), 100)]\n            self.array = pd.arrays.ArrowStringArray(pa.chunked_array(chunks))\n        else:\n            self.array = pd.arrays.ArrowStringArray(pa.array(strings))", "min_run_count": 2, "name": "array.ArrowStringArray.time_tolist", "number": 0, "param_names": ["multiple_chunks"], "params": [["False", "True"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "a9e122f7ecff59b97882d28b9fd2f973b13551ad4176e9d76a59c2cb50e056cd", "warmup_time": -1}, "array.BooleanArray.time_constructor": {"code": "class BooleanArray:\n    def time_constructor(self):\n        pd.arrays.BooleanArray(self.data, self.mask)\n\n    def setup(self):\n        self.values_bool = np.array([True, False, True, False])\n        self.values_float = np.array([1.0, 0.0, 1.0, 0.0])\n        self.values_integer = np.array([1, 0, 1, 0])\n        self.values_integer_like = [1, 0, 1, 0]\n        self.data = np.array([True, False, True, False])\n        self.mask = np.array([False, False, True, False])", "min_run_count": 2, "name": "array.BooleanArray.time_constructor", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "31f0c0638e5908b3b2f79ec954e3e3c5f9b247f04708fe2a8ba53b4df1b161d5", "warmup_time": -1}, "array.BooleanArray.time_from_bool_array": {"code": "class BooleanArray:\n    def time_from_bool_array(self):\n        pd.array(self.values_bool, dtype=\"boolean\")\n\n    def setup(self):\n        self.values_bool = np.array([True, False, True, False])\n        self.values_float = np.array([1.0, 0.0, 1.0, 0.0])\n        self.values_integer = np.array([1, 0, 1, 0])\n        self.values_integer_like = [1, 0, 1, 0]\n        self.data = np.array([True, False, True, False])\n        self.mask = np.array([False, False, True, False])", "min_run_count": 2, "name": "array.BooleanArray.time_from_bool_array", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "49de818c0d3213d4624b41ad1583ffa3da28d65f2dd89a30c9ed9ce4d8902300", "warmup_time": -1}, "array.BooleanArray.time_from_float_array": {"code": "class BooleanArray:\n    def time_from_float_array(self):\n        pd.array(self.values_float, dtype=\"boolean\")\n\n    def setup(self):\n        self.values_bool = np.array([True, False, True, False])\n        self.values_float = np.array([1.0, 0.0, 1.0, 0.0])\n        self.values_integer = np.array([1, 0, 1, 0])\n        self.values_integer_like = [1, 0, 1, 0]\n        self.data = np.array([True, False, True, False])\n        self.mask = np.array([False, False, True, False])", "min_run_count": 2, "name": "array.BooleanArray.time_from_float_array", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "00f65facf261a9f506e825a7a84d17cc35d7f00ff17f090622cbbdb8e6a538dc", "warmup_time": -1}, "array.BooleanArray.time_from_integer_array": {"code": "class BooleanArray:\n    def time_from_integer_array(self):\n        pd.array(self.values_integer, dtype=\"boolean\")\n\n    def setup(self):\n        self.values_bool = np.array([True, False, True, False])\n        self.values_float = np.array([1.0, 0.0, 1.0, 0.0])\n        self.values_integer = np.array([1, 0, 1, 0])\n        self.values_integer_like = [1, 0, 1, 0]\n        self.data = np.array([True, False, True, False])\n        self.mask = np.array([False, False, True, False])", "min_run_count": 2, "name": "array.BooleanArray.time_from_integer_array", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "d27d54d2b7793c51154ffb049d0e1508e27dc0b3cdfa4f734789da01a48e0abf", "warmup_time": -1}, "array.BooleanArray.time_from_integer_like": {"code": "class BooleanArray:\n    def time_from_integer_like(self):\n        pd.array(self.values_integer_like, dtype=\"boolean\")\n\n    def setup(self):\n        self.values_bool = np.array([True, False, True, False])\n        self.values_float = np.array([1.0, 0.0, 1.0, 0.0])\n        self.values_integer = np.array([1, 0, 1, 0])\n        self.values_integer_like = [1, 0, 1, 0]\n        self.data = np.array([True, False, True, False])\n        self.mask = np.array([False, False, True, False])", "min_run_count": 2, "name": "array.BooleanArray.time_from_integer_like", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "6c37947cc0814a4fabfcf5fc4ebcb76a3e8d231c4fb5ca15eb3d0f502617a17d", "warmup_time": -1}, "array.IntegerArray.time_constructor": {"code": "class IntegerArray:\n    def time_constructor(self):\n        pd.arrays.IntegerArray(self.data, self.mask)\n\n    def setup(self):\n        N = 250_000\n        self.values_integer = np.tile(np.array([1, 0, 1, 0]), N)\n        self.data = np.tile(np.array([1, 2, 3, 4], dtype=\"int64\"), N)\n        self.mask = np.tile(np.array([False, False, True, False]), N)", "min_run_count": 2, "name": "array.IntegerArray.time_constructor", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "0ff5c1d57429763cebb625bcfc125d262aed2b7dc0532117078c943ad05a59d8", "warmup_time": -1}, "array.IntegerArray.time_from_integer_array": {"code": "class IntegerArray:\n    def time_from_integer_array(self):\n        pd.array(self.values_integer, dtype=\"Int64\")\n\n    def setup(self):\n        N = 250_000\n        self.values_integer = np.tile(np.array([1, 0, 1, 0]), N)\n        self.data = np.tile(np.array([1, 2, 3, 4], dtype=\"int64\"), N)\n        self.mask = np.tile(np.array([False, False, True, False]), N)", "min_run_count": 2, "name": "array.IntegerArray.time_from_integer_array", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "5030e9d654d92c3c38ca4b4c07b3883d555809c78cb492b2ed1be77342068a36", "warmup_time": -1}, "array.IntervalArray.time_from_tuples": {"code": "class IntervalArray:\n    def time_from_tuples(self):\n        pd.arrays.IntervalArray.from_tuples(self.tuples)\n\n    def setup(self):\n        N = 10_000\n        self.tuples = [(i, i + 1) for i in range(N)]", "min_run_count": 2, "name": "array.IntervalArray.time_from_tuples", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "ba4b21278924821c6bf31f74072230f7b2a24d7c87f7b4f0e1f99025ff60cdb8", "warmup_time": -1}, "array.StringArray.time_from_list": {"code": "class StringArray:\n    def time_from_list(self):\n        pd.array(self.values_list, dtype=\"string\")\n\n    def setup(self):\n        N = 100_000\n        values = np.array([str(i) for i in range(N)], dtype=object)\n        self.values_obj = np.array(values, dtype=\"object\")\n        self.values_str = np.array(values, dtype=\"U\")\n        self.values_list = values.tolist()", "min_run_count": 2, "name": "array.StringArray.time_from_list", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "b59bfa587e60de31e3429e020a9a8949d3d221a3932af12a9624990f3a988291", "warmup_time": -1}, "array.StringArray.time_from_np_object_array": {"code": "class StringArray:\n    def time_from_np_object_array(self):\n        pd.array(self.values_obj, dtype=\"string\")\n\n    def setup(self):\n        N = 100_000\n        values = np.array([str(i) for i in range(N)], dtype=object)\n        self.values_obj = np.array(values, dtype=\"object\")\n        self.values_str = np.array(values, dtype=\"U\")\n        self.values_list = values.tolist()", "min_run_count": 2, "name": "array.StringArray.time_from_np_object_array", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "5578afbd13efc40a2a7d729b43dd2c6bdc53313d61fb124133a837ade72dae9c", "warmup_time": -1}, "array.StringArray.time_from_np_str_array": {"code": "class StringArray:\n    def time_from_np_str_array(self):\n        pd.array(self.values_str, dtype=\"string\")\n\n    def setup(self):\n        N = 100_000\n        values = np.array([str(i) for i in range(N)], dtype=object)\n        self.values_obj = np.array(values, dtype=\"object\")\n        self.values_str = np.array(values, dtype=\"U\")\n        self.values_list = values.tolist()", "min_run_count": 2, "name": "array.StringArray.time_from_np_str_array", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "70416c5ccb3bddcfddc25060580b22d14a9fb8f45a6ff0cb06fb0c2ecf4a08ce", "warmup_time": -1}, "attrs_caching.DataFrameAttributes.time_get_index": {"code": "class DataFrameAttributes:\n    def time_get_index(self):\n        self.df.index\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass DataFrameAttributes:\n    def setup(self):\n        self.df = DataFrame(np.random.randn(10, 6))\n        self.cur_index = self.df.index", "min_run_count": 2, "name": "attrs_caching.DataFrameAttributes.time_get_index", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "3246f297f11fb6074032907dde5fb9690d93465c80b45bc0b29e284fd5c9c17c", "warmup_time": -1}, "attrs_caching.DataFrameAttributes.time_set_index": {"code": "class DataFrameAttributes:\n    def time_set_index(self):\n        self.df.index = self.cur_index\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass DataFrameAttributes:\n    def setup(self):\n        self.df = DataFrame(np.random.randn(10, 6))\n        self.cur_index = self.df.index", "min_run_count": 2, "name": "attrs_caching.DataFrameAttributes.time_set_index", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "b34bb7eb8426bdd2eb9d8e0550ea2573475694ddc9f971fd9a29f15bf16732b0", "warmup_time": -1}, "attrs_caching.SeriesArrayAttribute.time_array": {"code": "class SeriesArrayAttribute:\n    def time_array(self, dtype):\n        self.series.array\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass SeriesArrayAttribute:\n    def setup(self, dtype):\n        if dtype == \"numeric\":\n            self.series = pd.Series([1, 2, 3])\n        elif dtype == \"object\":\n            self.series = pd.Series([\"a\", \"b\", \"c\"], dtype=object)\n        elif dtype == \"category\":\n            self.series = pd.Series([\"a\", \"b\", \"c\"], dtype=\"category\")\n        elif dtype == \"datetime64\":\n            self.series = pd.Series(pd.date_range(\"2013\", periods=3))\n        elif dtype == \"datetime64tz\":\n            self.series = pd.Series(pd.date_range(\"2013\", periods=3, tz=\"UTC\"))", "min_run_count": 2, "name": "attrs_caching.SeriesArrayAttribute.time_array", "number": 0, "param_names": ["dtype"], "params": [["'numeric'", "'object'", "'category'", "'datetime64'", "'datetime64tz'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "71871bee8b7f7a74c594352ad1177b3201818e5ffe6296b02844d93f2e74c57b", "warmup_time": -1}, "attrs_caching.SeriesArrayAttribute.time_extract_array": {"code": "class SeriesArrayAttribute:\n    def time_extract_array(self, dtype):\n        extract_array(self.series)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass SeriesArrayAttribute:\n    def setup(self, dtype):\n        if dtype == \"numeric\":\n            self.series = pd.Series([1, 2, 3])\n        elif dtype == \"object\":\n            self.series = pd.Series([\"a\", \"b\", \"c\"], dtype=object)\n        elif dtype == \"category\":\n            self.series = pd.Series([\"a\", \"b\", \"c\"], dtype=\"category\")\n        elif dtype == \"datetime64\":\n            self.series = pd.Series(pd.date_range(\"2013\", periods=3))\n        elif dtype == \"datetime64tz\":\n            self.series = pd.Series(pd.date_range(\"2013\", periods=3, tz=\"UTC\"))", "min_run_count": 2, "name": "attrs_caching.SeriesArrayAttribute.time_extract_array", "number": 0, "param_names": ["dtype"], "params": [["'numeric'", "'object'", "'category'", "'datetime64'", "'datetime64tz'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "5c9e10a019a9c3c1a6f4016572eac561387c3cc14086cde81066ae5d495b6bae", "warmup_time": -1}, "attrs_caching.SeriesArrayAttribute.time_extract_array_numpy": {"code": "class SeriesArrayAttribute:\n    def time_extract_array_numpy(self, dtype):\n        extract_array(self.series, extract_numpy=True)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass SeriesArrayAttribute:\n    def setup(self, dtype):\n        if dtype == \"numeric\":\n            self.series = pd.Series([1, 2, 3])\n        elif dtype == \"object\":\n            self.series = pd.Series([\"a\", \"b\", \"c\"], dtype=object)\n        elif dtype == \"category\":\n            self.series = pd.Series([\"a\", \"b\", \"c\"], dtype=\"category\")\n        elif dtype == \"datetime64\":\n            self.series = pd.Series(pd.date_range(\"2013\", periods=3))\n        elif dtype == \"datetime64tz\":\n            self.series = pd.Series(pd.date_range(\"2013\", periods=3, tz=\"UTC\"))", "min_run_count": 2, "name": "attrs_caching.SeriesArrayAttribute.time_extract_array_numpy", "number": 0, "param_names": ["dtype"], "params": [["'numeric'", "'object'", "'category'", "'datetime64'", "'datetime64tz'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "34310e30090bb516b844f357295ebbe46f2980040632e1178dffc041a7635892", "warmup_time": -1}, "boolean.TimeLogicalOps.time_and_array": {"code": "class TimeLogicalOps:\n    def time_and_array(self):\n        self.left & self.right\n\n    def setup(self):\n        N = 10_000\n        left, right, lmask, rmask = np.random.randint(0, 2, size=(4, N)).astype(\"bool\")\n        self.left = pd.arrays.BooleanArray(left, lmask)\n        self.right = pd.arrays.BooleanArray(right, rmask)", "min_run_count": 2, "name": "boolean.TimeLogicalOps.time_and_array", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "6f948c075c42597b3abbe166b111d3f02c0aa11a2fd01b376b96547a7a0ece18", "warmup_time": -1}, "boolean.TimeLogicalOps.time_and_scalar": {"code": "class TimeLogicalOps:\n    def time_and_scalar(self):\n        self.left & True\n        self.left & False\n\n    def setup(self):\n        N = 10_000\n        left, right, lmask, rmask = np.random.randint(0, 2, size=(4, N)).astype(\"bool\")\n        self.left = pd.arrays.BooleanArray(left, lmask)\n        self.right = pd.arrays.BooleanArray(right, rmask)", "min_run_count": 2, "name": "boolean.TimeLogicalOps.time_and_scalar", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "73483ccace6f6debdb2fd885f8fd8ffee9883f4e6dad1587a13239b8be135868", "warmup_time": -1}, "boolean.TimeLogicalOps.time_or_array": {"code": "class TimeLogicalOps:\n    def time_or_array(self):\n        self.left | self.right\n\n    def setup(self):\n        N = 10_000\n        left, right, lmask, rmask = np.random.randint(0, 2, size=(4, N)).astype(\"bool\")\n        self.left = pd.arrays.BooleanArray(left, lmask)\n        self.right = pd.arrays.BooleanArray(right, rmask)", "min_run_count": 2, "name": "boolean.TimeLogicalOps.time_or_array", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "dc01bb9cbcdc979b4fbe050df208268a15ff5f328081a7fd09c41283c33bfa5d", "warmup_time": -1}, "boolean.TimeLogicalOps.time_or_scalar": {"code": "class TimeLogicalOps:\n    def time_or_scalar(self):\n        self.left | True\n        self.left | False\n\n    def setup(self):\n        N = 10_000\n        left, right, lmask, rmask = np.random.randint(0, 2, size=(4, N)).astype(\"bool\")\n        self.left = pd.arrays.BooleanArray(left, lmask)\n        self.right = pd.arrays.BooleanArray(right, rmask)", "min_run_count": 2, "name": "boolean.TimeLogicalOps.time_or_scalar", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "a9dcf90a110c0c703887ee44358e18a6930758987f7f1e9f921dd5ff4c84234e", "warmup_time": -1}, "boolean.TimeLogicalOps.time_xor_array": {"code": "class TimeLogicalOps:\n    def time_xor_array(self):\n        self.left ^ self.right\n\n    def setup(self):\n        N = 10_000\n        left, right, lmask, rmask = np.random.randint(0, 2, size=(4, N)).astype(\"bool\")\n        self.left = pd.arrays.BooleanArray(left, lmask)\n        self.right = pd.arrays.BooleanArray(right, rmask)", "min_run_count": 2, "name": "boolean.TimeLogicalOps.time_xor_array", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "e093e59c2f51a4998acf114ad54d2ab5d62d38548aab71f3f5c6adbe6bc46792", "warmup_time": -1}, "boolean.TimeLogicalOps.time_xor_scalar": {"code": "class TimeLogicalOps:\n    def time_xor_scalar(self):\n        self.left ^ True\n        self.left ^ False\n\n    def setup(self):\n        N = 10_000\n        left, right, lmask, rmask = np.random.randint(0, 2, size=(4, N)).astype(\"bool\")\n        self.left = pd.arrays.BooleanArray(left, lmask)\n        self.right = pd.arrays.BooleanArray(right, rmask)", "min_run_count": 2, "name": "boolean.TimeLogicalOps.time_xor_scalar", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "eb50d9fee1d2beff8da51a2f128bb84bfa76379e9a699ae60dec8e82655bef3c", "warmup_time": -1}, "categoricals.CategoricalSlicing.time_getitem_bool_array": {"code": "class CategoricalSlicing:\n    def time_getitem_bool_array(self, index):\n        self.data[self.data == self.cat_scalar]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass CategoricalSlicing:\n    def setup(self, index):\n        N = 10**6\n        categories = [\"a\", \"b\", \"c\"]\n        if index == \"monotonic_incr\":\n            codes = np.repeat([0, 1, 2], N)\n        elif index == \"monotonic_decr\":\n            codes = np.repeat([2, 1, 0], N)\n        elif index == \"non_monotonic\":\n            codes = np.tile([0, 1, 2], N)\n        else:\n            raise ValueError(f\"Invalid index param: {index}\")\n    \n        self.data = pd.Categorical.from_codes(codes, categories=categories)\n        self.scalar = 10000\n        self.list = list(range(10000))\n        self.cat_scalar = \"b\"", "min_run_count": 2, "name": "categoricals.CategoricalSlicing.time_getitem_bool_array", "number": 0, "param_names": ["index"], "params": [["'monotonic_incr'", "'monotonic_decr'", "'non_monotonic'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "392935c7d25151142e1191d330ed461794b00830ba9e56c8f000ae6eeb6e5d45", "warmup_time": -1}, "categoricals.CategoricalSlicing.time_getitem_list": {"code": "class CategoricalSlicing:\n    def time_getitem_list(self, index):\n        self.data[self.list]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass CategoricalSlicing:\n    def setup(self, index):\n        N = 10**6\n        categories = [\"a\", \"b\", \"c\"]\n        if index == \"monotonic_incr\":\n            codes = np.repeat([0, 1, 2], N)\n        elif index == \"monotonic_decr\":\n            codes = np.repeat([2, 1, 0], N)\n        elif index == \"non_monotonic\":\n            codes = np.tile([0, 1, 2], N)\n        else:\n            raise ValueError(f\"Invalid index param: {index}\")\n    \n        self.data = pd.Categorical.from_codes(codes, categories=categories)\n        self.scalar = 10000\n        self.list = list(range(10000))\n        self.cat_scalar = \"b\"", "min_run_count": 2, "name": "categoricals.CategoricalSlicing.time_getitem_list", "number": 0, "param_names": ["index"], "params": [["'monotonic_incr'", "'monotonic_decr'", "'non_monotonic'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "5ba8074c37da942843683f8b852bf64ef44ae6f2be96c77aba4bccac3bce8f10", "warmup_time": -1}, "categoricals.CategoricalSlicing.time_getitem_list_like": {"code": "class CategoricalSlicing:\n    def time_getitem_list_like(self, index):\n        self.data[[self.scalar]]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass CategoricalSlicing:\n    def setup(self, index):\n        N = 10**6\n        categories = [\"a\", \"b\", \"c\"]\n        if index == \"monotonic_incr\":\n            codes = np.repeat([0, 1, 2], N)\n        elif index == \"monotonic_decr\":\n            codes = np.repeat([2, 1, 0], N)\n        elif index == \"non_monotonic\":\n            codes = np.tile([0, 1, 2], N)\n        else:\n            raise ValueError(f\"Invalid index param: {index}\")\n    \n        self.data = pd.Categorical.from_codes(codes, categories=categories)\n        self.scalar = 10000\n        self.list = list(range(10000))\n        self.cat_scalar = \"b\"", "min_run_count": 2, "name": "categoricals.CategoricalSlicing.time_getitem_list_like", "number": 0, "param_names": ["index"], "params": [["'monotonic_incr'", "'monotonic_decr'", "'non_monotonic'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "30460a50c9cb11dd9282ec072489495e0335dcccb727a27666919c81757c0dde", "warmup_time": -1}, "categoricals.CategoricalSlicing.time_getitem_scalar": {"code": "class CategoricalSlicing:\n    def time_getitem_scalar(self, index):\n        self.data[self.scalar]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass CategoricalSlicing:\n    def setup(self, index):\n        N = 10**6\n        categories = [\"a\", \"b\", \"c\"]\n        if index == \"monotonic_incr\":\n            codes = np.repeat([0, 1, 2], N)\n        elif index == \"monotonic_decr\":\n            codes = np.repeat([2, 1, 0], N)\n        elif index == \"non_monotonic\":\n            codes = np.tile([0, 1, 2], N)\n        else:\n            raise ValueError(f\"Invalid index param: {index}\")\n    \n        self.data = pd.Categorical.from_codes(codes, categories=categories)\n        self.scalar = 10000\n        self.list = list(range(10000))\n        self.cat_scalar = \"b\"", "min_run_count": 2, "name": "categoricals.CategoricalSlicing.time_getitem_scalar", "number": 0, "param_names": ["index"], "params": [["'monotonic_incr'", "'monotonic_decr'", "'non_monotonic'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "cede26e07c3b0d4aab9f6039da5d92a27c78c09893576e4fac2591b9115d35bb", "warmup_time": -1}, "categoricals.CategoricalSlicing.time_getitem_slice": {"code": "class CategoricalSlicing:\n    def time_getitem_slice(self, index):\n        self.data[: self.scalar]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass CategoricalSlicing:\n    def setup(self, index):\n        N = 10**6\n        categories = [\"a\", \"b\", \"c\"]\n        if index == \"monotonic_incr\":\n            codes = np.repeat([0, 1, 2], N)\n        elif index == \"monotonic_decr\":\n            codes = np.repeat([2, 1, 0], N)\n        elif index == \"non_monotonic\":\n            codes = np.tile([0, 1, 2], N)\n        else:\n            raise ValueError(f\"Invalid index param: {index}\")\n    \n        self.data = pd.Categorical.from_codes(codes, categories=categories)\n        self.scalar = 10000\n        self.list = list(range(10000))\n        self.cat_scalar = \"b\"", "min_run_count": 2, "name": "categoricals.CategoricalSlicing.time_getitem_slice", "number": 0, "param_names": ["index"], "params": [["'monotonic_incr'", "'monotonic_decr'", "'non_monotonic'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "9c3df2609445fec8c3f08508d3bef72e89181594564d1d1d6aa4916879ddd608", "warmup_time": -1}, "categoricals.Concat.time_append_non_overlapping_index": {"code": "class Concat:\n    def time_append_non_overlapping_index(self):\n        self.idx_a.append(self.idx_b)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Concat:\n    def setup(self):\n        N = 10**5\n        self.s = pd.Series(list(\"aabbcd\") * N).astype(\"category\")\n    \n        self.a = pd.Categorical(list(\"aabbcd\") * N)\n        self.b = pd.Categorical(list(\"bbcdjk\") * N)\n    \n        self.idx_a = pd.CategoricalIndex(range(N), range(N))\n        self.idx_b = pd.CategoricalIndex(range(N + 1), range(N + 1))\n        self.df_a = pd.DataFrame(range(N), columns=[\"a\"], index=self.idx_a)\n        self.df_b = pd.DataFrame(range(N + 1), columns=[\"a\"], index=self.idx_b)", "min_run_count": 2, "name": "categoricals.Concat.time_append_non_overlapping_index", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "7c08f6f4a37c69d20540206d1bb4eac69032087283c327ea354e4e58b28e8e8a", "warmup_time": -1}, "categoricals.Concat.time_append_overlapping_index": {"code": "class Concat:\n    def time_append_overlapping_index(self):\n        self.idx_a.append(self.idx_a)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Concat:\n    def setup(self):\n        N = 10**5\n        self.s = pd.Series(list(\"aabbcd\") * N).astype(\"category\")\n    \n        self.a = pd.Categorical(list(\"aabbcd\") * N)\n        self.b = pd.Categorical(list(\"bbcdjk\") * N)\n    \n        self.idx_a = pd.CategoricalIndex(range(N), range(N))\n        self.idx_b = pd.CategoricalIndex(range(N + 1), range(N + 1))\n        self.df_a = pd.DataFrame(range(N), columns=[\"a\"], index=self.idx_a)\n        self.df_b = pd.DataFrame(range(N + 1), columns=[\"a\"], index=self.idx_b)", "min_run_count": 2, "name": "categoricals.Concat.time_append_overlapping_index", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "86138129674bef3e164dd5e409ec0b275c1168e83dd747378cf52b02eb2311ea", "warmup_time": -1}, "categoricals.Concat.time_concat": {"code": "class Concat:\n    def time_concat(self):\n        pd.concat([self.s, self.s])\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Concat:\n    def setup(self):\n        N = 10**5\n        self.s = pd.Series(list(\"aabbcd\") * N).astype(\"category\")\n    \n        self.a = pd.Categorical(list(\"aabbcd\") * N)\n        self.b = pd.Categorical(list(\"bbcdjk\") * N)\n    \n        self.idx_a = pd.CategoricalIndex(range(N), range(N))\n        self.idx_b = pd.CategoricalIndex(range(N + 1), range(N + 1))\n        self.df_a = pd.DataFrame(range(N), columns=[\"a\"], index=self.idx_a)\n        self.df_b = pd.DataFrame(range(N + 1), columns=[\"a\"], index=self.idx_b)", "min_run_count": 2, "name": "categoricals.Concat.time_concat", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "60e2b37af13d3ba791a2c5fa40b92f67b1d3f6421e301d9dfcfcd4ff1da10041", "warmup_time": -1}, "categoricals.Concat.time_concat_non_overlapping_index": {"code": "class Concat:\n    def time_concat_non_overlapping_index(self):\n        pd.concat([self.df_a, self.df_b])\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Concat:\n    def setup(self):\n        N = 10**5\n        self.s = pd.Series(list(\"aabbcd\") * N).astype(\"category\")\n    \n        self.a = pd.Categorical(list(\"aabbcd\") * N)\n        self.b = pd.Categorical(list(\"bbcdjk\") * N)\n    \n        self.idx_a = pd.CategoricalIndex(range(N), range(N))\n        self.idx_b = pd.CategoricalIndex(range(N + 1), range(N + 1))\n        self.df_a = pd.DataFrame(range(N), columns=[\"a\"], index=self.idx_a)\n        self.df_b = pd.DataFrame(range(N + 1), columns=[\"a\"], index=self.idx_b)", "min_run_count": 2, "name": "categoricals.Concat.time_concat_non_overlapping_index", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "471ef66a2a2b2f051d1de9ad1ff46d1f9db09d862d97bedea6868f6ddd1f19f8", "warmup_time": -1}, "categoricals.Concat.time_concat_overlapping_index": {"code": "class Concat:\n    def time_concat_overlapping_index(self):\n        pd.concat([self.df_a, self.df_a])\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Concat:\n    def setup(self):\n        N = 10**5\n        self.s = pd.Series(list(\"aabbcd\") * N).astype(\"category\")\n    \n        self.a = pd.Categorical(list(\"aabbcd\") * N)\n        self.b = pd.Categorical(list(\"bbcdjk\") * N)\n    \n        self.idx_a = pd.CategoricalIndex(range(N), range(N))\n        self.idx_b = pd.CategoricalIndex(range(N + 1), range(N + 1))\n        self.df_a = pd.DataFrame(range(N), columns=[\"a\"], index=self.idx_a)\n        self.df_b = pd.DataFrame(range(N + 1), columns=[\"a\"], index=self.idx_b)", "min_run_count": 2, "name": "categoricals.Concat.time_concat_overlapping_index", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "ecdea66fab8e41b9f198da14c16f2281c65bcff35fb98ddab2baf37924133287", "warmup_time": -1}, "categoricals.Concat.time_union": {"code": "class Concat:\n    def time_union(self):\n        union_categoricals([self.a, self.b])\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Concat:\n    def setup(self):\n        N = 10**5\n        self.s = pd.Series(list(\"aabbcd\") * N).astype(\"category\")\n    \n        self.a = pd.Categorical(list(\"aabbcd\") * N)\n        self.b = pd.Categorical(list(\"bbcdjk\") * N)\n    \n        self.idx_a = pd.CategoricalIndex(range(N), range(N))\n        self.idx_b = pd.CategoricalIndex(range(N + 1), range(N + 1))\n        self.df_a = pd.DataFrame(range(N), columns=[\"a\"], index=self.idx_a)\n        self.df_b = pd.DataFrame(range(N + 1), columns=[\"a\"], index=self.idx_b)", "min_run_count": 2, "name": "categoricals.Concat.time_union", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "b7637f08baccfad51b169c40b0d317647c40413dadb0068206d81bc916c9d71b", "warmup_time": -1}, "categoricals.Constructor.time_all_nan": {"code": "class Constructor:\n    def time_all_nan(self):\n        pd.Categorical(self.values_all_nan)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Constructor:\n    def setup(self):\n        N = 10**5\n        self.categories = list(\"abcde\")\n        self.cat_idx = pd.Index(self.categories)\n        self.values = np.tile(self.categories, N)\n        self.codes = np.tile(range(len(self.categories)), N)\n    \n        self.datetimes = pd.Series(\n            pd.date_range(\"1995-01-01 00:00:00\", periods=N / 10, freq=\"s\")\n        )\n        self.datetimes_with_nat = self.datetimes.copy()\n        self.datetimes_with_nat.iloc[-1] = pd.NaT\n    \n        self.values_some_nan = list(np.tile(self.categories + [np.nan], N))\n        self.values_all_nan = [np.nan] * len(self.values)\n        self.values_all_int8 = np.ones(N, \"int8\")\n        self.categorical = pd.Categorical(self.values, self.categories)\n        self.series = pd.Series(self.categorical)\n        self.intervals = pd.interval_range(0, 1, periods=N // 10)", "min_run_count": 2, "name": "categoricals.Constructor.time_all_nan", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "7313e9ac9f46adb8c4a7b2e56649b840805b73f2e8ad314e3c6c25aba2ae4765", "warmup_time": -1}, "categoricals.Constructor.time_datetimes": {"code": "class Constructor:\n    def time_datetimes(self):\n        pd.Categorical(self.datetimes)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Constructor:\n    def setup(self):\n        N = 10**5\n        self.categories = list(\"abcde\")\n        self.cat_idx = pd.Index(self.categories)\n        self.values = np.tile(self.categories, N)\n        self.codes = np.tile(range(len(self.categories)), N)\n    \n        self.datetimes = pd.Series(\n            pd.date_range(\"1995-01-01 00:00:00\", periods=N / 10, freq=\"s\")\n        )\n        self.datetimes_with_nat = self.datetimes.copy()\n        self.datetimes_with_nat.iloc[-1] = pd.NaT\n    \n        self.values_some_nan = list(np.tile(self.categories + [np.nan], N))\n        self.values_all_nan = [np.nan] * len(self.values)\n        self.values_all_int8 = np.ones(N, \"int8\")\n        self.categorical = pd.Categorical(self.values, self.categories)\n        self.series = pd.Series(self.categorical)\n        self.intervals = pd.interval_range(0, 1, periods=N // 10)", "min_run_count": 2, "name": "categoricals.Constructor.time_datetimes", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "1a19b241eb3585b2ce56b672e956326b957375a6810b9d068ceceedc180eb0b3", "warmup_time": -1}, "categoricals.Constructor.time_datetimes_with_nat": {"code": "class Constructor:\n    def time_datetimes_with_nat(self):\n        pd.Categorical(self.datetimes_with_nat)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Constructor:\n    def setup(self):\n        N = 10**5\n        self.categories = list(\"abcde\")\n        self.cat_idx = pd.Index(self.categories)\n        self.values = np.tile(self.categories, N)\n        self.codes = np.tile(range(len(self.categories)), N)\n    \n        self.datetimes = pd.Series(\n            pd.date_range(\"1995-01-01 00:00:00\", periods=N / 10, freq=\"s\")\n        )\n        self.datetimes_with_nat = self.datetimes.copy()\n        self.datetimes_with_nat.iloc[-1] = pd.NaT\n    \n        self.values_some_nan = list(np.tile(self.categories + [np.nan], N))\n        self.values_all_nan = [np.nan] * len(self.values)\n        self.values_all_int8 = np.ones(N, \"int8\")\n        self.categorical = pd.Categorical(self.values, self.categories)\n        self.series = pd.Series(self.categorical)\n        self.intervals = pd.interval_range(0, 1, periods=N // 10)", "min_run_count": 2, "name": "categoricals.Constructor.time_datetimes_with_nat", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "bd3372456db022df20c40a27e9a9aedf7b42eaafc8f781ecb6e058823ac427b7", "warmup_time": -1}, "categoricals.Constructor.time_existing_categorical": {"code": "class Constructor:\n    def time_existing_categorical(self):\n        pd.Categorical(self.categorical)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Constructor:\n    def setup(self):\n        N = 10**5\n        self.categories = list(\"abcde\")\n        self.cat_idx = pd.Index(self.categories)\n        self.values = np.tile(self.categories, N)\n        self.codes = np.tile(range(len(self.categories)), N)\n    \n        self.datetimes = pd.Series(\n            pd.date_range(\"1995-01-01 00:00:00\", periods=N / 10, freq=\"s\")\n        )\n        self.datetimes_with_nat = self.datetimes.copy()\n        self.datetimes_with_nat.iloc[-1] = pd.NaT\n    \n        self.values_some_nan = list(np.tile(self.categories + [np.nan], N))\n        self.values_all_nan = [np.nan] * len(self.values)\n        self.values_all_int8 = np.ones(N, \"int8\")\n        self.categorical = pd.Categorical(self.values, self.categories)\n        self.series = pd.Series(self.categorical)\n        self.intervals = pd.interval_range(0, 1, periods=N // 10)", "min_run_count": 2, "name": "categoricals.Constructor.time_existing_categorical", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "35dcdd523b144b1c390233fb583c57670ee350c63b2a314559c14d3f4356744c", "warmup_time": -1}, "categoricals.Constructor.time_existing_series": {"code": "class Constructor:\n    def time_existing_series(self):\n        pd.Categorical(self.series)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Constructor:\n    def setup(self):\n        N = 10**5\n        self.categories = list(\"abcde\")\n        self.cat_idx = pd.Index(self.categories)\n        self.values = np.tile(self.categories, N)\n        self.codes = np.tile(range(len(self.categories)), N)\n    \n        self.datetimes = pd.Series(\n            pd.date_range(\"1995-01-01 00:00:00\", periods=N / 10, freq=\"s\")\n        )\n        self.datetimes_with_nat = self.datetimes.copy()\n        self.datetimes_with_nat.iloc[-1] = pd.NaT\n    \n        self.values_some_nan = list(np.tile(self.categories + [np.nan], N))\n        self.values_all_nan = [np.nan] * len(self.values)\n        self.values_all_int8 = np.ones(N, \"int8\")\n        self.categorical = pd.Categorical(self.values, self.categories)\n        self.series = pd.Series(self.categorical)\n        self.intervals = pd.interval_range(0, 1, periods=N // 10)", "min_run_count": 2, "name": "categoricals.Constructor.time_existing_series", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "7f95670c86db933fe267eeef555e4402ede21b4de4b9a4d97a33a2f209c49417", "warmup_time": -1}, "categoricals.Constructor.time_fastpath": {"code": "class Constructor:\n    def time_fastpath(self):\n        dtype = pd.CategoricalDtype(categories=self.cat_idx)\n        pd.Categorical._simple_new(self.codes, dtype)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Constructor:\n    def setup(self):\n        N = 10**5\n        self.categories = list(\"abcde\")\n        self.cat_idx = pd.Index(self.categories)\n        self.values = np.tile(self.categories, N)\n        self.codes = np.tile(range(len(self.categories)), N)\n    \n        self.datetimes = pd.Series(\n            pd.date_range(\"1995-01-01 00:00:00\", periods=N / 10, freq=\"s\")\n        )\n        self.datetimes_with_nat = self.datetimes.copy()\n        self.datetimes_with_nat.iloc[-1] = pd.NaT\n    \n        self.values_some_nan = list(np.tile(self.categories + [np.nan], N))\n        self.values_all_nan = [np.nan] * len(self.values)\n        self.values_all_int8 = np.ones(N, \"int8\")\n        self.categorical = pd.Categorical(self.values, self.categories)\n        self.series = pd.Series(self.categorical)\n        self.intervals = pd.interval_range(0, 1, periods=N // 10)", "min_run_count": 2, "name": "categoricals.Constructor.time_fastpath", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "d35e308ff26b484edf9c507377d31c32972fb3d1ad6860476e6837e09ad73b5c", "warmup_time": -1}, "categoricals.Constructor.time_from_codes_all_int8": {"code": "class Constructor:\n    def time_from_codes_all_int8(self):\n        pd.Categorical.from_codes(self.values_all_int8, self.categories)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Constructor:\n    def setup(self):\n        N = 10**5\n        self.categories = list(\"abcde\")\n        self.cat_idx = pd.Index(self.categories)\n        self.values = np.tile(self.categories, N)\n        self.codes = np.tile(range(len(self.categories)), N)\n    \n        self.datetimes = pd.Series(\n            pd.date_range(\"1995-01-01 00:00:00\", periods=N / 10, freq=\"s\")\n        )\n        self.datetimes_with_nat = self.datetimes.copy()\n        self.datetimes_with_nat.iloc[-1] = pd.NaT\n    \n        self.values_some_nan = list(np.tile(self.categories + [np.nan], N))\n        self.values_all_nan = [np.nan] * len(self.values)\n        self.values_all_int8 = np.ones(N, \"int8\")\n        self.categorical = pd.Categorical(self.values, self.categories)\n        self.series = pd.Series(self.categorical)\n        self.intervals = pd.interval_range(0, 1, periods=N // 10)", "min_run_count": 2, "name": "categoricals.Constructor.time_from_codes_all_int8", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "8e99b2ce968c4ca587be75672cad6d5c2ddfeff553b10b26fc0727a493194172", "warmup_time": -1}, "categoricals.Constructor.time_interval": {"code": "class Constructor:\n    def time_interval(self):\n        pd.Categorical(self.datetimes, categories=self.datetimes)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Constructor:\n    def setup(self):\n        N = 10**5\n        self.categories = list(\"abcde\")\n        self.cat_idx = pd.Index(self.categories)\n        self.values = np.tile(self.categories, N)\n        self.codes = np.tile(range(len(self.categories)), N)\n    \n        self.datetimes = pd.Series(\n            pd.date_range(\"1995-01-01 00:00:00\", periods=N / 10, freq=\"s\")\n        )\n        self.datetimes_with_nat = self.datetimes.copy()\n        self.datetimes_with_nat.iloc[-1] = pd.NaT\n    \n        self.values_some_nan = list(np.tile(self.categories + [np.nan], N))\n        self.values_all_nan = [np.nan] * len(self.values)\n        self.values_all_int8 = np.ones(N, \"int8\")\n        self.categorical = pd.Categorical(self.values, self.categories)\n        self.series = pd.Series(self.categorical)\n        self.intervals = pd.interval_range(0, 1, periods=N // 10)", "min_run_count": 2, "name": "categoricals.Constructor.time_interval", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "792e5ccdfd0875754cf88f95cc59fff6ce96143d5dcc3ea942241c2f0f71a428", "warmup_time": -1}, "categoricals.Constructor.time_regular": {"code": "class Constructor:\n    def time_regular(self):\n        pd.Categorical(self.values, self.categories)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Constructor:\n    def setup(self):\n        N = 10**5\n        self.categories = list(\"abcde\")\n        self.cat_idx = pd.Index(self.categories)\n        self.values = np.tile(self.categories, N)\n        self.codes = np.tile(range(len(self.categories)), N)\n    \n        self.datetimes = pd.Series(\n            pd.date_range(\"1995-01-01 00:00:00\", periods=N / 10, freq=\"s\")\n        )\n        self.datetimes_with_nat = self.datetimes.copy()\n        self.datetimes_with_nat.iloc[-1] = pd.NaT\n    \n        self.values_some_nan = list(np.tile(self.categories + [np.nan], N))\n        self.values_all_nan = [np.nan] * len(self.values)\n        self.values_all_int8 = np.ones(N, \"int8\")\n        self.categorical = pd.Categorical(self.values, self.categories)\n        self.series = pd.Series(self.categorical)\n        self.intervals = pd.interval_range(0, 1, periods=N // 10)", "min_run_count": 2, "name": "categoricals.Constructor.time_regular", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "6872d6c509be44733c6d83cf8a3a6c718329853cd6a5d15ba5c56398c96499e9", "warmup_time": -1}, "categoricals.Constructor.time_with_nan": {"code": "class Constructor:\n    def time_with_nan(self):\n        pd.Categorical(self.values_some_nan)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Constructor:\n    def setup(self):\n        N = 10**5\n        self.categories = list(\"abcde\")\n        self.cat_idx = pd.Index(self.categories)\n        self.values = np.tile(self.categories, N)\n        self.codes = np.tile(range(len(self.categories)), N)\n    \n        self.datetimes = pd.Series(\n            pd.date_range(\"1995-01-01 00:00:00\", periods=N / 10, freq=\"s\")\n        )\n        self.datetimes_with_nat = self.datetimes.copy()\n        self.datetimes_with_nat.iloc[-1] = pd.NaT\n    \n        self.values_some_nan = list(np.tile(self.categories + [np.nan], N))\n        self.values_all_nan = [np.nan] * len(self.values)\n        self.values_all_int8 = np.ones(N, \"int8\")\n        self.categorical = pd.Categorical(self.values, self.categories)\n        self.series = pd.Series(self.categorical)\n        self.intervals = pd.interval_range(0, 1, periods=N // 10)", "min_run_count": 2, "name": "categoricals.Constructor.time_with_nan", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "fcb1339a8633427497fc1fdea3d103b6575a5914b056831f806bec409ab545cc", "warmup_time": -1}, "categoricals.Contains.time_categorical_contains": {"code": "class Contains:\n    def time_categorical_contains(self):\n        self.key in self.c\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Contains:\n    def setup(self):\n        N = 10**5\n        self.ci = pd.CategoricalIndex(np.arange(N))\n        self.c = self.ci.values\n        self.key = self.ci.categories[0]", "min_run_count": 2, "name": "categoricals.Contains.time_categorical_contains", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "32365d05fca5315293e957770f928baaa798b4cd2133f97632aef854e0cbaf52", "warmup_time": -1}, "categoricals.Contains.time_categorical_index_contains": {"code": "class Contains:\n    def time_categorical_index_contains(self):\n        self.key in self.ci\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Contains:\n    def setup(self):\n        N = 10**5\n        self.ci = pd.CategoricalIndex(np.arange(N))\n        self.c = self.ci.values\n        self.key = self.ci.categories[0]", "min_run_count": 2, "name": "categoricals.Contains.time_categorical_index_contains", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "761e6e22b7fea3c9293e4bc5bfb69fb4843ae255301402ca5202bab136712748", "warmup_time": -1}, "categoricals.Indexing.time_align": {"code": "class Indexing:\n    def time_align(self):\n        pd.DataFrame({\"a\": self.series, \"b\": self.series[:500]})\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Indexing:\n    def setup(self):\n        N = 10**5\n        self.index = pd.CategoricalIndex(range(N), range(N))\n        self.series = pd.Series(range(N), index=self.index).sort_index()\n        self.category = self.index[500]", "min_run_count": 2, "name": "categoricals.Indexing.time_align", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "f218e6d543ab19db3fea1db2b664146198dd39dadac2966494426b556613d32d", "warmup_time": -1}, "categoricals.Indexing.time_get_loc": {"code": "class Indexing:\n    def time_get_loc(self):\n        self.index.get_loc(self.category)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Indexing:\n    def setup(self):\n        N = 10**5\n        self.index = pd.CategoricalIndex(range(N), range(N))\n        self.series = pd.Series(range(N), index=self.index).sort_index()\n        self.category = self.index[500]", "min_run_count": 2, "name": "categoricals.Indexing.time_get_loc", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "5f38e85f8450cba2264bb47680c1a9cd76458677f62e8ec8b53aac9e29c4fe62", "warmup_time": -1}, "categoricals.Indexing.time_intersection": {"code": "class Indexing:\n    def time_intersection(self):\n        self.index[:750].intersection(self.index[250:])\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Indexing:\n    def setup(self):\n        N = 10**5\n        self.index = pd.CategoricalIndex(range(N), range(N))\n        self.series = pd.Series(range(N), index=self.index).sort_index()\n        self.category = self.index[500]", "min_run_count": 2, "name": "categoricals.Indexing.time_intersection", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "a413f3ef1a42a84770cc263a3ffc018c0623a71a70d26e58676660ab47210939", "warmup_time": -1}, "categoricals.Indexing.time_reindex": {"code": "class Indexing:\n    def time_reindex(self):\n        self.index.reindex(self.index[:500])\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Indexing:\n    def setup(self):\n        N = 10**5\n        self.index = pd.CategoricalIndex(range(N), range(N))\n        self.series = pd.Series(range(N), index=self.index).sort_index()\n        self.category = self.index[500]", "min_run_count": 2, "name": "categoricals.Indexing.time_reindex", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "f068d9fbc3b599870598bc5ca8891b88762d7882d98234cd287b7021ae6ebdc2", "warmup_time": -1}, "categoricals.Indexing.time_reindex_missing": {"code": "class Indexing:\n    def time_reindex_missing(self):\n        self.index.reindex([\"a\", \"b\", \"c\", \"d\"])\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Indexing:\n    def setup(self):\n        N = 10**5\n        self.index = pd.CategoricalIndex(range(N), range(N))\n        self.series = pd.Series(range(N), index=self.index).sort_index()\n        self.category = self.index[500]", "min_run_count": 2, "name": "categoricals.Indexing.time_reindex_missing", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "8b7b5234b7e636fd26fb1d2ab98bfc3f744be66628ba69f7642a1f723887547f", "warmup_time": -1}, "categoricals.Indexing.time_shallow_copy": {"code": "class Indexing:\n    def time_shallow_copy(self):\n        self.index._view()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Indexing:\n    def setup(self):\n        N = 10**5\n        self.index = pd.CategoricalIndex(range(N), range(N))\n        self.series = pd.Series(range(N), index=self.index).sort_index()\n        self.category = self.index[500]", "min_run_count": 2, "name": "categoricals.Indexing.time_shallow_copy", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "a719f97efeb6e929cfd555a6be02dce8108efd04f1f5bda591f52a642f5adbf9", "warmup_time": -1}, "categoricals.Indexing.time_sort_values": {"code": "class Indexing:\n    def time_sort_values(self):\n        self.index.sort_values(ascending=False)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Indexing:\n    def setup(self):\n        N = 10**5\n        self.index = pd.CategoricalIndex(range(N), range(N))\n        self.series = pd.Series(range(N), index=self.index).sort_index()\n        self.category = self.index[500]", "min_run_count": 2, "name": "categoricals.Indexing.time_sort_values", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "57dcf263eeda37b74d296554b77303db6387683cbff9d7e4ec8fbd03cab2f4d4", "warmup_time": -1}, "categoricals.Indexing.time_unique": {"code": "class Indexing:\n    def time_unique(self):\n        self.index.unique()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Indexing:\n    def setup(self):\n        N = 10**5\n        self.index = pd.CategoricalIndex(range(N), range(N))\n        self.series = pd.Series(range(N), index=self.index).sort_index()\n        self.category = self.index[500]", "min_run_count": 2, "name": "categoricals.Indexing.time_unique", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "410cd9935506da614c2c46ec84a159befdeefe6b74e61c91bd5daa01f7d3e677", "warmup_time": -1}, "categoricals.IsMonotonic.time_categorical_index_is_monotonic_decreasing": {"code": "class IsMonotonic:\n    def time_categorical_index_is_monotonic_decreasing(self):\n        self.c.is_monotonic_decreasing\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass IsMonotonic:\n    def setup(self):\n        N = 1000\n        self.c = pd.CategoricalIndex(list(\"a\" * N + \"b\" * N + \"c\" * N))\n        self.s = pd.Series(self.c)", "min_run_count": 2, "name": "categoricals.IsMonotonic.time_categorical_index_is_monotonic_decreasing", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "c4d103c6279f0b80ce554b92ebb3e5bc2c44dc1e40f2fa4ab07455ea280ab8cb", "warmup_time": -1}, "categoricals.IsMonotonic.time_categorical_index_is_monotonic_increasing": {"code": "class IsMonotonic:\n    def time_categorical_index_is_monotonic_increasing(self):\n        self.c.is_monotonic_increasing\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass IsMonotonic:\n    def setup(self):\n        N = 1000\n        self.c = pd.CategoricalIndex(list(\"a\" * N + \"b\" * N + \"c\" * N))\n        self.s = pd.Series(self.c)", "min_run_count": 2, "name": "categoricals.IsMonotonic.time_categorical_index_is_monotonic_increasing", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "fcebf885784c8e801b36cabd669598864a44b3d464eaef9eda7ca74df92105ad", "warmup_time": -1}, "categoricals.IsMonotonic.time_categorical_series_is_monotonic_decreasing": {"code": "class IsMonotonic:\n    def time_categorical_series_is_monotonic_decreasing(self):\n        self.s.is_monotonic_decreasing\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass IsMonotonic:\n    def setup(self):\n        N = 1000\n        self.c = pd.CategoricalIndex(list(\"a\" * N + \"b\" * N + \"c\" * N))\n        self.s = pd.Series(self.c)", "min_run_count": 2, "name": "categoricals.IsMonotonic.time_categorical_series_is_monotonic_decreasing", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "fa8a5687d97343fae36bb22d0c776cfb090faec43b933d9f88facde7ba72c762", "warmup_time": -1}, "categoricals.IsMonotonic.time_categorical_series_is_monotonic_increasing": {"code": "class IsMonotonic:\n    def time_categorical_series_is_monotonic_increasing(self):\n        self.s.is_monotonic_increasing\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass IsMonotonic:\n    def setup(self):\n        N = 1000\n        self.c = pd.CategoricalIndex(list(\"a\" * N + \"b\" * N + \"c\" * N))\n        self.s = pd.Series(self.c)", "min_run_count": 2, "name": "categoricals.IsMonotonic.time_categorical_series_is_monotonic_increasing", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "834fbde98d28981a9f726086c81fcfaed2914996bff27fdcdafe4769d95bb3d3", "warmup_time": -1}, "categoricals.Rank.time_rank_int": {"code": "class Rank:\n    def time_rank_int(self):\n        self.s_int.rank()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Rank:\n    def setup(self):\n        N = 10**5\n        ncats = 15\n    \n        self.s_str = pd.Series(np.random.randint(0, ncats, size=N).astype(str))\n        self.s_str_cat = pd.Series(self.s_str, dtype=\"category\")\n        with warnings.catch_warnings(record=True):\n            str_cat_type = pd.CategoricalDtype(set(self.s_str), ordered=True)\n            self.s_str_cat_ordered = self.s_str.astype(str_cat_type)\n    \n        self.s_int = pd.Series(np.random.randint(0, ncats, size=N))\n        self.s_int_cat = pd.Series(self.s_int, dtype=\"category\")\n        with warnings.catch_warnings(record=True):\n            int_cat_type = pd.CategoricalDtype(set(self.s_int), ordered=True)\n            self.s_int_cat_ordered = self.s_int.astype(int_cat_type)", "min_run_count": 2, "name": "categoricals.Rank.time_rank_int", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "7341bab0d3444509ae6d5889790fdd91da0b1c61f6f9417809486f6fd9ea7b41", "warmup_time": -1}, "categoricals.Rank.time_rank_int_cat": {"code": "class Rank:\n    def time_rank_int_cat(self):\n        self.s_int_cat.rank()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Rank:\n    def setup(self):\n        N = 10**5\n        ncats = 15\n    \n        self.s_str = pd.Series(np.random.randint(0, ncats, size=N).astype(str))\n        self.s_str_cat = pd.Series(self.s_str, dtype=\"category\")\n        with warnings.catch_warnings(record=True):\n            str_cat_type = pd.CategoricalDtype(set(self.s_str), ordered=True)\n            self.s_str_cat_ordered = self.s_str.astype(str_cat_type)\n    \n        self.s_int = pd.Series(np.random.randint(0, ncats, size=N))\n        self.s_int_cat = pd.Series(self.s_int, dtype=\"category\")\n        with warnings.catch_warnings(record=True):\n            int_cat_type = pd.CategoricalDtype(set(self.s_int), ordered=True)\n            self.s_int_cat_ordered = self.s_int.astype(int_cat_type)", "min_run_count": 2, "name": "categoricals.Rank.time_rank_int_cat", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "73d1356f38bf95ad1cb847a06f70e5b406869b4257c3d29cda2b3324f960af3c", "warmup_time": -1}, "categoricals.Rank.time_rank_int_cat_ordered": {"code": "class Rank:\n    def time_rank_int_cat_ordered(self):\n        self.s_int_cat_ordered.rank()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Rank:\n    def setup(self):\n        N = 10**5\n        ncats = 15\n    \n        self.s_str = pd.Series(np.random.randint(0, ncats, size=N).astype(str))\n        self.s_str_cat = pd.Series(self.s_str, dtype=\"category\")\n        with warnings.catch_warnings(record=True):\n            str_cat_type = pd.CategoricalDtype(set(self.s_str), ordered=True)\n            self.s_str_cat_ordered = self.s_str.astype(str_cat_type)\n    \n        self.s_int = pd.Series(np.random.randint(0, ncats, size=N))\n        self.s_int_cat = pd.Series(self.s_int, dtype=\"category\")\n        with warnings.catch_warnings(record=True):\n            int_cat_type = pd.CategoricalDtype(set(self.s_int), ordered=True)\n            self.s_int_cat_ordered = self.s_int.astype(int_cat_type)", "min_run_count": 2, "name": "categoricals.Rank.time_rank_int_cat_ordered", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "12fcb558345d99ff95da65bdfa35893f93ebf3851a96a7e82adb63a959b2f501", "warmup_time": -1}, "categoricals.Rank.time_rank_string": {"code": "class Rank:\n    def time_rank_string(self):\n        self.s_str.rank()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Rank:\n    def setup(self):\n        N = 10**5\n        ncats = 15\n    \n        self.s_str = pd.Series(np.random.randint(0, ncats, size=N).astype(str))\n        self.s_str_cat = pd.Series(self.s_str, dtype=\"category\")\n        with warnings.catch_warnings(record=True):\n            str_cat_type = pd.CategoricalDtype(set(self.s_str), ordered=True)\n            self.s_str_cat_ordered = self.s_str.astype(str_cat_type)\n    \n        self.s_int = pd.Series(np.random.randint(0, ncats, size=N))\n        self.s_int_cat = pd.Series(self.s_int, dtype=\"category\")\n        with warnings.catch_warnings(record=True):\n            int_cat_type = pd.CategoricalDtype(set(self.s_int), ordered=True)\n            self.s_int_cat_ordered = self.s_int.astype(int_cat_type)", "min_run_count": 2, "name": "categoricals.Rank.time_rank_string", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "1234230d925b2b0fb2ead89ed4cab63499e7382657ae6bb6de6149643645185c", "warmup_time": -1}, "categoricals.Rank.time_rank_string_cat": {"code": "class Rank:\n    def time_rank_string_cat(self):\n        self.s_str_cat.rank()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Rank:\n    def setup(self):\n        N = 10**5\n        ncats = 15\n    \n        self.s_str = pd.Series(np.random.randint(0, ncats, size=N).astype(str))\n        self.s_str_cat = pd.Series(self.s_str, dtype=\"category\")\n        with warnings.catch_warnings(record=True):\n            str_cat_type = pd.CategoricalDtype(set(self.s_str), ordered=True)\n            self.s_str_cat_ordered = self.s_str.astype(str_cat_type)\n    \n        self.s_int = pd.Series(np.random.randint(0, ncats, size=N))\n        self.s_int_cat = pd.Series(self.s_int, dtype=\"category\")\n        with warnings.catch_warnings(record=True):\n            int_cat_type = pd.CategoricalDtype(set(self.s_int), ordered=True)\n            self.s_int_cat_ordered = self.s_int.astype(int_cat_type)", "min_run_count": 2, "name": "categoricals.Rank.time_rank_string_cat", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "03fe33c89451ca7fb520c8aec7c05066e1ec116e56df2993a738b4e57ab9fbf8", "warmup_time": -1}, "categoricals.Rank.time_rank_string_cat_ordered": {"code": "class Rank:\n    def time_rank_string_cat_ordered(self):\n        self.s_str_cat_ordered.rank()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Rank:\n    def setup(self):\n        N = 10**5\n        ncats = 15\n    \n        self.s_str = pd.Series(np.random.randint(0, ncats, size=N).astype(str))\n        self.s_str_cat = pd.Series(self.s_str, dtype=\"category\")\n        with warnings.catch_warnings(record=True):\n            str_cat_type = pd.CategoricalDtype(set(self.s_str), ordered=True)\n            self.s_str_cat_ordered = self.s_str.astype(str_cat_type)\n    \n        self.s_int = pd.Series(np.random.randint(0, ncats, size=N))\n        self.s_int_cat = pd.Series(self.s_int, dtype=\"category\")\n        with warnings.catch_warnings(record=True):\n            int_cat_type = pd.CategoricalDtype(set(self.s_int), ordered=True)\n            self.s_int_cat_ordered = self.s_int.astype(int_cat_type)", "min_run_count": 2, "name": "categoricals.Rank.time_rank_string_cat_ordered", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "73135df6f2f87a366fb11675cc71b241c448b8d91ca00b54a9e95c3a239d1cb6", "warmup_time": -1}, "categoricals.RemoveCategories.time_remove_categories": {"code": "class RemoveCategories:\n    def time_remove_categories(self):\n        self.ts.cat.remove_categories(self.ts.cat.categories[::2])\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass RemoveCategories:\n    def setup(self):\n        n = 5 * 10**5\n        arr = [f\"s{i:04d}\" for i in np.random.randint(0, n // 10, size=n)]\n        self.ts = pd.Series(arr).astype(\"category\")", "min_run_count": 2, "name": "categoricals.RemoveCategories.time_remove_categories", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "f41a55fefb120d979e5bcb1f387b4b8b8929b1b97c1b49370b42482deb07b426", "warmup_time": -1}, "categoricals.Repr.time_rendering": {"code": "class Repr:\n    def time_rendering(self):\n        str(self.sel)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Repr:\n    def setup(self):\n        self.sel = pd.Series([\"s1234\"]).astype(\"category\")", "min_run_count": 2, "name": "categoricals.Repr.time_rendering", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "8d10d682b8918c4fac813851a9bf9304346e145623189c433d8d75ac72c1e1e6", "warmup_time": -1}, "categoricals.SearchSorted.time_categorical_contains": {"code": "class SearchSorted:\n    def time_categorical_contains(self):\n        self.c.searchsorted(self.key)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass SearchSorted:\n    def setup(self):\n        N = 10**5\n        self.ci = pd.CategoricalIndex(np.arange(N)).sort_values()\n        self.c = self.ci.values\n        self.key = self.ci.categories[1]", "min_run_count": 2, "name": "categoricals.SearchSorted.time_categorical_contains", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "f33b78283987333ad6f166fd3f25a3cdf67998d5924b845d1372b1ac943eed47", "warmup_time": -1}, "categoricals.SearchSorted.time_categorical_index_contains": {"code": "class SearchSorted:\n    def time_categorical_index_contains(self):\n        self.ci.searchsorted(self.key)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass SearchSorted:\n    def setup(self):\n        N = 10**5\n        self.ci = pd.CategoricalIndex(np.arange(N)).sort_values()\n        self.c = self.ci.values\n        self.key = self.ci.categories[1]", "min_run_count": 2, "name": "categoricals.SearchSorted.time_categorical_index_contains", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "7490e013ffd75c03cef3c770842c908f9b3f2e947c41b4f7398e117b125ff1ae", "warmup_time": -1}, "categoricals.SetCategories.time_set_categories": {"code": "class SetCategories:\n    def time_set_categories(self):\n        self.ts.cat.set_categories(self.ts.cat.categories[::2])\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass SetCategories:\n    def setup(self):\n        n = 5 * 10**5\n        arr = [f\"s{i:04d}\" for i in np.random.randint(0, n // 10, size=n)]\n        self.ts = pd.Series(arr).astype(\"category\")", "min_run_count": 2, "name": "categoricals.SetCategories.time_set_categories", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "ee0d827baaa17c4f7f69783df06df5805e927698ff8dca902182228231f975c1", "warmup_time": -1}, "categoricals.ValueCounts.time_value_counts": {"code": "class ValueCounts:\n    def time_value_counts(self, dropna):\n        self.ts.value_counts(dropna=dropna)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ValueCounts:\n    def setup(self, dropna):\n        n = 5 * 10**5\n        arr = [f\"s{i:04d}\" for i in np.random.randint(0, n // 10, size=n)]\n        self.ts = pd.Series(arr).astype(\"category\")", "min_run_count": 2, "name": "categoricals.ValueCounts.time_value_counts", "number": 0, "param_names": ["dropna"], "params": [["True", "False"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "4866939b81ce70129183c8d44e1a9d6b42c864346912c27670eb457cdf9fcfbb", "warmup_time": -1}, "ctors.DatetimeIndexConstructor.time_from_list_of_dates": {"code": "class DatetimeIndexConstructor:\n    def time_from_list_of_dates(self):\n        DatetimeIndex(self.list_of_dates)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass DatetimeIndexConstructor:\n    def setup(self):\n        N = 20_000\n        dti = date_range(\"1900-01-01\", periods=N)\n    \n        self.list_of_timestamps = dti.tolist()\n        self.list_of_dates = dti.date.tolist()\n        self.list_of_datetimes = dti.to_pydatetime().tolist()\n        self.list_of_str = dti.strftime(\"%Y-%m-%d\").tolist()", "min_run_count": 2, "name": "ctors.DatetimeIndexConstructor.time_from_list_of_dates", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "bacd3eaca4814bb06e43ffa8586971974452ebd4e463efae8cac42b893d58a82", "warmup_time": -1}, "ctors.DatetimeIndexConstructor.time_from_list_of_datetimes": {"code": "class DatetimeIndexConstructor:\n    def time_from_list_of_datetimes(self):\n        DatetimeIndex(self.list_of_datetimes)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass DatetimeIndexConstructor:\n    def setup(self):\n        N = 20_000\n        dti = date_range(\"1900-01-01\", periods=N)\n    \n        self.list_of_timestamps = dti.tolist()\n        self.list_of_dates = dti.date.tolist()\n        self.list_of_datetimes = dti.to_pydatetime().tolist()\n        self.list_of_str = dti.strftime(\"%Y-%m-%d\").tolist()", "min_run_count": 2, "name": "ctors.DatetimeIndexConstructor.time_from_list_of_datetimes", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "365ef0bfc846c299de2e9ec59316033adc76ea95a7f73a97d4ca958b3d6e913e", "warmup_time": -1}, "ctors.DatetimeIndexConstructor.time_from_list_of_str": {"code": "class DatetimeIndexConstructor:\n    def time_from_list_of_str(self):\n        DatetimeIndex(self.list_of_str)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass DatetimeIndexConstructor:\n    def setup(self):\n        N = 20_000\n        dti = date_range(\"1900-01-01\", periods=N)\n    \n        self.list_of_timestamps = dti.tolist()\n        self.list_of_dates = dti.date.tolist()\n        self.list_of_datetimes = dti.to_pydatetime().tolist()\n        self.list_of_str = dti.strftime(\"%Y-%m-%d\").tolist()", "min_run_count": 2, "name": "ctors.DatetimeIndexConstructor.time_from_list_of_str", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "11575c62b8c3127835edd05f4d19329b690f6ef06c30d58b8e772d2b7e7f0abf", "warmup_time": -1}, "ctors.DatetimeIndexConstructor.time_from_list_of_timestamps": {"code": "class DatetimeIndexConstructor:\n    def time_from_list_of_timestamps(self):\n        DatetimeIndex(self.list_of_timestamps)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass DatetimeIndexConstructor:\n    def setup(self):\n        N = 20_000\n        dti = date_range(\"1900-01-01\", periods=N)\n    \n        self.list_of_timestamps = dti.tolist()\n        self.list_of_dates = dti.date.tolist()\n        self.list_of_datetimes = dti.to_pydatetime().tolist()\n        self.list_of_str = dti.strftime(\"%Y-%m-%d\").tolist()", "min_run_count": 2, "name": "ctors.DatetimeIndexConstructor.time_from_list_of_timestamps", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "1aba152c467ee66bcd374fe2d77743a9eef413d7057a74818aa8426b86441b71", "warmup_time": -1}, "ctors.MultiIndexConstructor.time_multiindex_from_iterables": {"code": "class MultiIndexConstructor:\n    def time_multiindex_from_iterables(self):\n        MultiIndex.from_product(self.iterables)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass MultiIndexConstructor:\n    def setup(self):\n        N = 10**4\n        self.iterables = [Index([f\"i-{i}\" for i in range(N)], dtype=object), range(20)]", "min_run_count": 2, "name": "ctors.MultiIndexConstructor.time_multiindex_from_iterables", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "7f0175b308859072a4a56134ed322bfc0508e9bbe03567849e74731bd45665b6", "warmup_time": -1}, "ctors.SeriesConstructors.time_series_constructor": {"code": "class SeriesConstructors:\n    def time_series_constructor(self, data_fmt, with_index, dtype):\n        Series(self.data, index=self.index)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass SeriesConstructors:\n    def setup(self, data_fmt, with_index, dtype):\n        if data_fmt in (gen_of_str, gen_of_tuples) and with_index:\n            raise NotImplementedError(\n                \"Series constructors do not support using generators with indexes\"\n            )\n        N = 10**4\n        if dtype == \"float\":\n            arr = np.random.randn(N)\n        else:\n            arr = np.arange(N)\n        self.data = data_fmt(arr)\n        self.index = np.arange(N) if with_index else None", "min_run_count": 2, "name": "ctors.SeriesConstructors.time_series_constructor", "number": 1, "param_names": ["data_fmt", "with_index", "dtype"], "params": [["<function no_change>", "<class 'list'>", "<function list_of_str>", "<function gen_of_str>", "<function arr_dict>", "<function list_of_tuples>", "<function gen_of_tuples>", "<function list_of_lists>", "<function list_of_tuples_with_none>", "<function list_of_lists_with_none>"], ["False", "True"], ["'float'", "'int'"]], "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "796b7e6dd06a06983968b54d6752714fff49f711f0da87ab239d7c33fe9306ba", "warmup_time": -1}, "ctors.SeriesDtypesConstructors.time_dtindex_from_index_with_series": {"code": "class SeriesDtypesConstructors:\n    def time_dtindex_from_index_with_series(self):\n        Index(self.s)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass SeriesDtypesConstructors:\n    def setup(self):\n        N = 10**4\n        self.arr = np.random.randn(N)\n        self.arr_str = np.array([\"foo\", \"bar\", \"baz\"], dtype=object)\n        self.s = Series(\n            [Timestamp(\"20110101\"), Timestamp(\"20120101\"), Timestamp(\"20130101\")]\n            * N\n            * 10\n        )", "min_run_count": 2, "name": "ctors.SeriesDtypesConstructors.time_dtindex_from_index_with_series", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "33f43d3855a48b47442f806cad0e6e7466e35fc29158753066509c648f173543", "warmup_time": -1}, "ctors.SeriesDtypesConstructors.time_dtindex_from_series": {"code": "class SeriesDtypesConstructors:\n    def time_dtindex_from_series(self):\n        DatetimeIndex(self.s)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass SeriesDtypesConstructors:\n    def setup(self):\n        N = 10**4\n        self.arr = np.random.randn(N)\n        self.arr_str = np.array([\"foo\", \"bar\", \"baz\"], dtype=object)\n        self.s = Series(\n            [Timestamp(\"20110101\"), Timestamp(\"20120101\"), Timestamp(\"20130101\")]\n            * N\n            * 10\n        )", "min_run_count": 2, "name": "ctors.SeriesDtypesConstructors.time_dtindex_from_series", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "158ae6c81517f39c972e1bc3b7aab12bf753c0b37a15ca694e51998994283273", "warmup_time": -1}, "ctors.SeriesDtypesConstructors.time_index_from_array_floats": {"code": "class SeriesDtypesConstructors:\n    def time_index_from_array_floats(self):\n        Index(self.arr)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass SeriesDtypesConstructors:\n    def setup(self):\n        N = 10**4\n        self.arr = np.random.randn(N)\n        self.arr_str = np.array([\"foo\", \"bar\", \"baz\"], dtype=object)\n        self.s = Series(\n            [Timestamp(\"20110101\"), Timestamp(\"20120101\"), Timestamp(\"20130101\")]\n            * N\n            * 10\n        )", "min_run_count": 2, "name": "ctors.SeriesDtypesConstructors.time_index_from_array_floats", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "e0189b13b8400123e9a8d5d5c5d55240f975dd207efd63375f6fb000e228d534", "warmup_time": -1}, "ctors.SeriesDtypesConstructors.time_index_from_array_string": {"code": "class SeriesDtypesConstructors:\n    def time_index_from_array_string(self):\n        Index(self.arr_str)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass SeriesDtypesConstructors:\n    def setup(self):\n        N = 10**4\n        self.arr = np.random.randn(N)\n        self.arr_str = np.array([\"foo\", \"bar\", \"baz\"], dtype=object)\n        self.s = Series(\n            [Timestamp(\"20110101\"), Timestamp(\"20120101\"), Timestamp(\"20130101\")]\n            * N\n            * 10\n        )", "min_run_count": 2, "name": "ctors.SeriesDtypesConstructors.time_index_from_array_string", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "1403f63eb248697b83050c2515ddca96862bb42fdcd2fd7d5453bcafb3a9881e", "warmup_time": -1}, "dtypes.CheckDtypes.time_is_extension_array_dtype_false": {"code": "class CheckDtypes:\n    def time_is_extension_array_dtype_false(self):\n        is_extension_array_dtype(self.np_dtype)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass CheckDtypes:\n    def setup(self):\n        self.ext_dtype = pd.Int64Dtype()\n        self.np_dtype = np.dtype(\"int64\")", "min_run_count": 2, "name": "dtypes.CheckDtypes.time_is_extension_array_dtype_false", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "81c7f57fc1b501fb5fe42b1928b850081d7fc62c6bda218e1faf99d2623a9dd7", "warmup_time": -1}, "dtypes.CheckDtypes.time_is_extension_array_dtype_true": {"code": "class CheckDtypes:\n    def time_is_extension_array_dtype_true(self):\n        is_extension_array_dtype(self.ext_dtype)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass CheckDtypes:\n    def setup(self):\n        self.ext_dtype = pd.Int64Dtype()\n        self.np_dtype = np.dtype(\"int64\")", "min_run_count": 2, "name": "dtypes.CheckDtypes.time_is_extension_array_dtype_true", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "23b5bb2e01f5d1546ced81b111d6d84415d3945fe1392317283755c6205327cf", "warmup_time": -1}, "dtypes.Dtypes.time_pandas_dtype": {"code": "class Dtypes:\n    def time_pandas_dtype(self, dtype):\n        pandas_dtype(dtype)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)", "min_run_count": 2, "name": "dtypes.Dtypes.time_pandas_dtype", "number": 0, "param_names": ["dtype"], "params": [["dtype('int64')", "dtype('int32')", "dtype('uint32')", "dtype('uint64')", "dtype('float32')", "dtype('float64')", "dtype('int16')", "dtype('int8')", "dtype('uint16')", "dtype('uint8')", "dtype('<M8')", "dtype('<m8')", "dtype('O')", "<class 'pandas.core.arrays.integer.Int8Dtype'>", "<class 'pandas.core.arrays.integer.Int16Dtype'>", "<class 'pandas.core.arrays.integer.Int32Dtype'>", "<class 'pandas.core.arrays.integer.Int64Dtype'>", "<class 'pandas.core.arrays.integer.UInt8Dtype'>", "<class 'pandas.core.arrays.integer.UInt16Dtype'>", "<class 'pandas.core.arrays.integer.UInt32Dtype'>", "<class 'pandas.core.arrays.integer.UInt64Dtype'>", "<class 'pandas.core.dtypes.dtypes.CategoricalDtype'>", "<class 'pandas.core.dtypes.dtypes.IntervalDtype'>", "datetime64[ns, UTC]", "period[D]", "'int64'", "'int32'", "'uint32'", "'uint64'", "'float32'", "'float64'", "'int16'", "'int8'", "'uint16'", "'uint8'", "'datetime64'", "'timedelta64'", "'object'", "'Int8'", "'Int16'", "'Int32'", "'Int64'", "'UInt8'", "'UInt16'", "'UInt32'", "'UInt64'", "'category'", "'interval'", "'datetime64[ns, UTC]'", "'period[D]'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "fd9b99f460a442066f655fd285e96e7bc3a2fd5599a6e62433c98e0811c6d2ad", "warmup_time": -1}, "dtypes.DtypesInvalid.time_pandas_dtype_invalid": {"code": "class DtypesInvalid:\n    def time_pandas_dtype_invalid(self, dtype):\n        try:\n            pandas_dtype(self.data_dict[dtype])\n        except TypeError:\n            pass\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)", "min_run_count": 2, "name": "dtypes.DtypesInvalid.time_pandas_dtype_invalid", "number": 0, "param_names": ["dtype"], "params": [["'scalar-string'", "'scalar-int'", "'list-string'", "'array-string'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "7f3ba4b4c7fbd54b7a1820ab3b4dd151e482f73fe3403b9bc5250c8abb048f3b", "warmup_time": -1}, "dtypes.SelectDtypes.time_select_dtype_bool_exclude": {"code": "class SelectDtypes:\n    def time_select_dtype_bool_exclude(self, dtype):\n        self.df_bool.select_dtypes(exclude=dtype)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass SelectDtypes:\n    def setup(self, dtype):\n        N, K = 5000, 50\n        self.index = Index([f\"i-{i}\" for i in range(N)], dtype=object)\n        self.columns = Index([f\"i-{i}\" for i in range(K)], dtype=object)\n    \n        def create_df(data):\n            return DataFrame(data, index=self.index, columns=self.columns)\n    \n        self.df_int = create_df(np.random.randint(low=100, size=(N, K)))\n        self.df_float = create_df(np.random.randn(N, K))\n        self.df_bool = create_df(np.random.choice([True, False], size=(N, K)))\n        self.df_string = create_df(\n            np.random.choice(list(string.ascii_letters), size=(N, K))\n        )", "min_run_count": 2, "name": "dtypes.SelectDtypes.time_select_dtype_bool_exclude", "number": 0, "param_names": ["dtype"], "params": [["'uint8'", "'uint16'", "'uint32'", "'uint64'", "<class 'int'>", "'int8'", "'int16'", "'int32'", "'int64'", "'UInt8'", "'UInt16'", "'UInt32'", "'UInt64'", "'Int8'", "'Int16'", "'Int32'", "'Int64'", "<class 'float'>", "'float32'", "'float64'", "<class 'complex'>", "'complex64'", "'complex128'", "'datetime64[ns]'", "'M8[ns]'", "'timedelta64[ns]'", "'m8[ns]'", "<class 'bool'>", "'bool'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "df61255244e9be8fc0d248c55f3e063ddbef5c245f81a5411c66a28002c4bb65", "warmup_time": -1}, "dtypes.SelectDtypes.time_select_dtype_bool_include": {"code": "class SelectDtypes:\n    def time_select_dtype_bool_include(self, dtype):\n        self.df_bool.select_dtypes(include=dtype)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass SelectDtypes:\n    def setup(self, dtype):\n        N, K = 5000, 50\n        self.index = Index([f\"i-{i}\" for i in range(N)], dtype=object)\n        self.columns = Index([f\"i-{i}\" for i in range(K)], dtype=object)\n    \n        def create_df(data):\n            return DataFrame(data, index=self.index, columns=self.columns)\n    \n        self.df_int = create_df(np.random.randint(low=100, size=(N, K)))\n        self.df_float = create_df(np.random.randn(N, K))\n        self.df_bool = create_df(np.random.choice([True, False], size=(N, K)))\n        self.df_string = create_df(\n            np.random.choice(list(string.ascii_letters), size=(N, K))\n        )", "min_run_count": 2, "name": "dtypes.SelectDtypes.time_select_dtype_bool_include", "number": 0, "param_names": ["dtype"], "params": [["'uint8'", "'uint16'", "'uint32'", "'uint64'", "<class 'int'>", "'int8'", "'int16'", "'int32'", "'int64'", "'UInt8'", "'UInt16'", "'UInt32'", "'UInt64'", "'Int8'", "'Int16'", "'Int32'", "'Int64'", "<class 'float'>", "'float32'", "'float64'", "<class 'complex'>", "'complex64'", "'complex128'", "'datetime64[ns]'", "'M8[ns]'", "'timedelta64[ns]'", "'m8[ns]'", "<class 'bool'>", "'bool'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "f0c2f1bc4901e7d306373868e213c49d8d54794baf5de80fb27088cfe9bd4eef", "warmup_time": -1}, "dtypes.SelectDtypes.time_select_dtype_float_exclude": {"code": "class SelectDtypes:\n    def time_select_dtype_float_exclude(self, dtype):\n        self.df_float.select_dtypes(exclude=dtype)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass SelectDtypes:\n    def setup(self, dtype):\n        N, K = 5000, 50\n        self.index = Index([f\"i-{i}\" for i in range(N)], dtype=object)\n        self.columns = Index([f\"i-{i}\" for i in range(K)], dtype=object)\n    \n        def create_df(data):\n            return DataFrame(data, index=self.index, columns=self.columns)\n    \n        self.df_int = create_df(np.random.randint(low=100, size=(N, K)))\n        self.df_float = create_df(np.random.randn(N, K))\n        self.df_bool = create_df(np.random.choice([True, False], size=(N, K)))\n        self.df_string = create_df(\n            np.random.choice(list(string.ascii_letters), size=(N, K))\n        )", "min_run_count": 2, "name": "dtypes.SelectDtypes.time_select_dtype_float_exclude", "number": 0, "param_names": ["dtype"], "params": [["'uint8'", "'uint16'", "'uint32'", "'uint64'", "<class 'int'>", "'int8'", "'int16'", "'int32'", "'int64'", "'UInt8'", "'UInt16'", "'UInt32'", "'UInt64'", "'Int8'", "'Int16'", "'Int32'", "'Int64'", "<class 'float'>", "'float32'", "'float64'", "<class 'complex'>", "'complex64'", "'complex128'", "'datetime64[ns]'", "'M8[ns]'", "'timedelta64[ns]'", "'m8[ns]'", "<class 'bool'>", "'bool'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "c3819287ad630000615230fed62878a437c4adaf18567017b87aa79f998a39c8", "warmup_time": -1}, "dtypes.SelectDtypes.time_select_dtype_float_include": {"code": "class SelectDtypes:\n    def time_select_dtype_float_include(self, dtype):\n        self.df_float.select_dtypes(include=dtype)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass SelectDtypes:\n    def setup(self, dtype):\n        N, K = 5000, 50\n        self.index = Index([f\"i-{i}\" for i in range(N)], dtype=object)\n        self.columns = Index([f\"i-{i}\" for i in range(K)], dtype=object)\n    \n        def create_df(data):\n            return DataFrame(data, index=self.index, columns=self.columns)\n    \n        self.df_int = create_df(np.random.randint(low=100, size=(N, K)))\n        self.df_float = create_df(np.random.randn(N, K))\n        self.df_bool = create_df(np.random.choice([True, False], size=(N, K)))\n        self.df_string = create_df(\n            np.random.choice(list(string.ascii_letters), size=(N, K))\n        )", "min_run_count": 2, "name": "dtypes.SelectDtypes.time_select_dtype_float_include", "number": 0, "param_names": ["dtype"], "params": [["'uint8'", "'uint16'", "'uint32'", "'uint64'", "<class 'int'>", "'int8'", "'int16'", "'int32'", "'int64'", "'UInt8'", "'UInt16'", "'UInt32'", "'UInt64'", "'Int8'", "'Int16'", "'Int32'", "'Int64'", "<class 'float'>", "'float32'", "'float64'", "<class 'complex'>", "'complex64'", "'complex128'", "'datetime64[ns]'", "'M8[ns]'", "'timedelta64[ns]'", "'m8[ns]'", "<class 'bool'>", "'bool'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "ec02ea504a673f4cff6ac450fe51e76ad048e83ded067055b143b3124192c38c", "warmup_time": -1}, "dtypes.SelectDtypes.time_select_dtype_int_exclude": {"code": "class SelectDtypes:\n    def time_select_dtype_int_exclude(self, dtype):\n        self.df_int.select_dtypes(exclude=dtype)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass SelectDtypes:\n    def setup(self, dtype):\n        N, K = 5000, 50\n        self.index = Index([f\"i-{i}\" for i in range(N)], dtype=object)\n        self.columns = Index([f\"i-{i}\" for i in range(K)], dtype=object)\n    \n        def create_df(data):\n            return DataFrame(data, index=self.index, columns=self.columns)\n    \n        self.df_int = create_df(np.random.randint(low=100, size=(N, K)))\n        self.df_float = create_df(np.random.randn(N, K))\n        self.df_bool = create_df(np.random.choice([True, False], size=(N, K)))\n        self.df_string = create_df(\n            np.random.choice(list(string.ascii_letters), size=(N, K))\n        )", "min_run_count": 2, "name": "dtypes.SelectDtypes.time_select_dtype_int_exclude", "number": 0, "param_names": ["dtype"], "params": [["'uint8'", "'uint16'", "'uint32'", "'uint64'", "<class 'int'>", "'int8'", "'int16'", "'int32'", "'int64'", "'UInt8'", "'UInt16'", "'UInt32'", "'UInt64'", "'Int8'", "'Int16'", "'Int32'", "'Int64'", "<class 'float'>", "'float32'", "'float64'", "<class 'complex'>", "'complex64'", "'complex128'", "'datetime64[ns]'", "'M8[ns]'", "'timedelta64[ns]'", "'m8[ns]'", "<class 'bool'>", "'bool'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "63425c0b6c4bfde374a64deda9bf4636080d34b8f7af826fa3f1d71c549ebc06", "warmup_time": -1}, "dtypes.SelectDtypes.time_select_dtype_int_include": {"code": "class SelectDtypes:\n    def time_select_dtype_int_include(self, dtype):\n        self.df_int.select_dtypes(include=dtype)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass SelectDtypes:\n    def setup(self, dtype):\n        N, K = 5000, 50\n        self.index = Index([f\"i-{i}\" for i in range(N)], dtype=object)\n        self.columns = Index([f\"i-{i}\" for i in range(K)], dtype=object)\n    \n        def create_df(data):\n            return DataFrame(data, index=self.index, columns=self.columns)\n    \n        self.df_int = create_df(np.random.randint(low=100, size=(N, K)))\n        self.df_float = create_df(np.random.randn(N, K))\n        self.df_bool = create_df(np.random.choice([True, False], size=(N, K)))\n        self.df_string = create_df(\n            np.random.choice(list(string.ascii_letters), size=(N, K))\n        )", "min_run_count": 2, "name": "dtypes.SelectDtypes.time_select_dtype_int_include", "number": 0, "param_names": ["dtype"], "params": [["'uint8'", "'uint16'", "'uint32'", "'uint64'", "<class 'int'>", "'int8'", "'int16'", "'int32'", "'int64'", "'UInt8'", "'UInt16'", "'UInt32'", "'UInt64'", "'Int8'", "'Int16'", "'Int32'", "'Int64'", "<class 'float'>", "'float32'", "'float64'", "<class 'complex'>", "'complex64'", "'complex128'", "'datetime64[ns]'", "'M8[ns]'", "'timedelta64[ns]'", "'m8[ns]'", "<class 'bool'>", "'bool'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "ded41b293fecd74fd41f47735fe03f5f06ddb9a870a1a2cac4c88816f0d12210", "warmup_time": -1}, "dtypes.SelectDtypes.time_select_dtype_string_exclude": {"code": "class SelectDtypes:\n    def time_select_dtype_string_exclude(self, dtype):\n        self.df_string.select_dtypes(exclude=dtype)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass SelectDtypes:\n    def setup(self, dtype):\n        N, K = 5000, 50\n        self.index = Index([f\"i-{i}\" for i in range(N)], dtype=object)\n        self.columns = Index([f\"i-{i}\" for i in range(K)], dtype=object)\n    \n        def create_df(data):\n            return DataFrame(data, index=self.index, columns=self.columns)\n    \n        self.df_int = create_df(np.random.randint(low=100, size=(N, K)))\n        self.df_float = create_df(np.random.randn(N, K))\n        self.df_bool = create_df(np.random.choice([True, False], size=(N, K)))\n        self.df_string = create_df(\n            np.random.choice(list(string.ascii_letters), size=(N, K))\n        )", "min_run_count": 2, "name": "dtypes.SelectDtypes.time_select_dtype_string_exclude", "number": 0, "param_names": ["dtype"], "params": [["'uint8'", "'uint16'", "'uint32'", "'uint64'", "<class 'int'>", "'int8'", "'int16'", "'int32'", "'int64'", "'UInt8'", "'UInt16'", "'UInt32'", "'UInt64'", "'Int8'", "'Int16'", "'Int32'", "'Int64'", "<class 'float'>", "'float32'", "'float64'", "<class 'complex'>", "'complex64'", "'complex128'", "'datetime64[ns]'", "'M8[ns]'", "'timedelta64[ns]'", "'m8[ns]'", "<class 'bool'>", "'bool'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "f7ec4762bcc09823b04a3e5cb9713f0e1e7120a85eb2c1f040a944a491e88f1e", "warmup_time": -1}, "dtypes.SelectDtypes.time_select_dtype_string_include": {"code": "class SelectDtypes:\n    def time_select_dtype_string_include(self, dtype):\n        self.df_string.select_dtypes(include=dtype)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass SelectDtypes:\n    def setup(self, dtype):\n        N, K = 5000, 50\n        self.index = Index([f\"i-{i}\" for i in range(N)], dtype=object)\n        self.columns = Index([f\"i-{i}\" for i in range(K)], dtype=object)\n    \n        def create_df(data):\n            return DataFrame(data, index=self.index, columns=self.columns)\n    \n        self.df_int = create_df(np.random.randint(low=100, size=(N, K)))\n        self.df_float = create_df(np.random.randn(N, K))\n        self.df_bool = create_df(np.random.choice([True, False], size=(N, K)))\n        self.df_string = create_df(\n            np.random.choice(list(string.ascii_letters), size=(N, K))\n        )", "min_run_count": 2, "name": "dtypes.SelectDtypes.time_select_dtype_string_include", "number": 0, "param_names": ["dtype"], "params": [["'uint8'", "'uint16'", "'uint32'", "'uint64'", "<class 'int'>", "'int8'", "'int16'", "'int32'", "'int64'", "'UInt8'", "'UInt16'", "'UInt32'", "'UInt64'", "'Int8'", "'Int16'", "'Int32'", "'Int64'", "<class 'float'>", "'float32'", "'float64'", "<class 'complex'>", "'complex64'", "'complex128'", "'datetime64[ns]'", "'M8[ns]'", "'timedelta64[ns]'", "'m8[ns]'", "<class 'bool'>", "'bool'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "2d8ac290640b9e1ef5db1c2db3a2f6aac6007549995a6004381d6499370d2cff", "warmup_time": -1}, "eval.Eval.time_add": {"code": "class Eval:\n    def time_add(self, engine, threads):\n        pd.eval(\"self.df + self.df2 + self.df3 + self.df4\", engine=engine)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Eval:\n    def setup(self, engine, threads):\n        self.df = pd.DataFrame(np.random.randn(20000, 100))\n        self.df2 = pd.DataFrame(np.random.randn(20000, 100))\n        self.df3 = pd.DataFrame(np.random.randn(20000, 100))\n        self.df4 = pd.DataFrame(np.random.randn(20000, 100))\n    \n        if threads == 1:\n            expr.set_numexpr_threads(1)", "min_run_count": 2, "name": "eval.Eval.time_add", "number": 0, "param_names": ["engine", "threads"], "params": [["'numexpr'", "'python'"], ["1", "'all'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "3b50f88f4cebf64200f50ab348ee13f8589e7dfb5962f7176004d30730f99112", "warmup_time": -1}, "eval.Eval.time_and": {"code": "class Eval:\n    def time_and(self, engine, threads):\n        pd.eval(\n            \"(self.df > 0) & (self.df2 > 0) & (self.df3 > 0) & (self.df4 > 0)\",\n            engine=engine,\n        )\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Eval:\n    def setup(self, engine, threads):\n        self.df = pd.DataFrame(np.random.randn(20000, 100))\n        self.df2 = pd.DataFrame(np.random.randn(20000, 100))\n        self.df3 = pd.DataFrame(np.random.randn(20000, 100))\n        self.df4 = pd.DataFrame(np.random.randn(20000, 100))\n    \n        if threads == 1:\n            expr.set_numexpr_threads(1)", "min_run_count": 2, "name": "eval.Eval.time_and", "number": 0, "param_names": ["engine", "threads"], "params": [["'numexpr'", "'python'"], ["1", "'all'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "e48d6e775f144cea8cd29b74723eb86f939c566bd1c688845dd864d16d60de1b", "warmup_time": -1}, "eval.Eval.time_chained_cmp": {"code": "class Eval:\n    def time_chained_cmp(self, engine, threads):\n        pd.eval(\"self.df < self.df2 < self.df3 < self.df4\", engine=engine)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Eval:\n    def setup(self, engine, threads):\n        self.df = pd.DataFrame(np.random.randn(20000, 100))\n        self.df2 = pd.DataFrame(np.random.randn(20000, 100))\n        self.df3 = pd.DataFrame(np.random.randn(20000, 100))\n        self.df4 = pd.DataFrame(np.random.randn(20000, 100))\n    \n        if threads == 1:\n            expr.set_numexpr_threads(1)", "min_run_count": 2, "name": "eval.Eval.time_chained_cmp", "number": 0, "param_names": ["engine", "threads"], "params": [["'numexpr'", "'python'"], ["1", "'all'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "0fe4b18c6cfabf06e6e4cac4c651276743a49df6a947913f8cabba517ba91786", "warmup_time": -1}, "eval.Eval.time_mult": {"code": "class Eval:\n    def time_mult(self, engine, threads):\n        pd.eval(\"self.df * self.df2 * self.df3 * self.df4\", engine=engine)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Eval:\n    def setup(self, engine, threads):\n        self.df = pd.DataFrame(np.random.randn(20000, 100))\n        self.df2 = pd.DataFrame(np.random.randn(20000, 100))\n        self.df3 = pd.DataFrame(np.random.randn(20000, 100))\n        self.df4 = pd.DataFrame(np.random.randn(20000, 100))\n    \n        if threads == 1:\n            expr.set_numexpr_threads(1)", "min_run_count": 2, "name": "eval.Eval.time_mult", "number": 0, "param_names": ["engine", "threads"], "params": [["'numexpr'", "'python'"], ["1", "'all'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "a2085f987e1ce9ac0c43a0fe2cba5ad5be060d477671017c4323e892a23899a2", "warmup_time": -1}, "eval.Query.time_query_datetime_column": {"code": "class Query:\n    def time_query_datetime_column(self):\n        self.df.query(\"dates < @self.ts\")\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Query:\n    def setup(self):\n        N = 10**6\n        halfway = (N // 2) - 1\n        index = pd.date_range(\"20010101\", periods=N, freq=\"min\")\n        s = pd.Series(index)\n        self.ts = s.iloc[halfway]\n        self.df = pd.DataFrame({\"a\": np.random.randn(N), \"dates\": index}, index=index)\n        data = np.random.randn(N)\n        self.min_val = data.min()\n        self.max_val = data.max()", "min_run_count": 2, "name": "eval.Query.time_query_datetime_column", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "1d140272522b8968337a65f5bbde890d721057d547e6496ce5ac4cacf49a12c6", "warmup_time": -1}, "eval.Query.time_query_datetime_index": {"code": "class Query:\n    def time_query_datetime_index(self):\n        self.df.query(\"index < @self.ts\")\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Query:\n    def setup(self):\n        N = 10**6\n        halfway = (N // 2) - 1\n        index = pd.date_range(\"20010101\", periods=N, freq=\"min\")\n        s = pd.Series(index)\n        self.ts = s.iloc[halfway]\n        self.df = pd.DataFrame({\"a\": np.random.randn(N), \"dates\": index}, index=index)\n        data = np.random.randn(N)\n        self.min_val = data.min()\n        self.max_val = data.max()", "min_run_count": 2, "name": "eval.Query.time_query_datetime_index", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "e92d36300cfda073c91694f6d7c09a034bfef434123510ab0a1a271d6f82893f", "warmup_time": -1}, "eval.Query.time_query_with_boolean_selection": {"code": "class Query:\n    def time_query_with_boolean_selection(self):\n        self.df.query(\"(a >= @self.min_val) & (a <= @self.max_val)\")\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Query:\n    def setup(self):\n        N = 10**6\n        halfway = (N // 2) - 1\n        index = pd.date_range(\"20010101\", periods=N, freq=\"min\")\n        s = pd.Series(index)\n        self.ts = s.iloc[halfway]\n        self.df = pd.DataFrame({\"a\": np.random.randn(N), \"dates\": index}, index=index)\n        data = np.random.randn(N)\n        self.min_val = data.min()\n        self.max_val = data.max()", "min_run_count": 2, "name": "eval.Query.time_query_with_boolean_selection", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "2e364600de60ccd8ec4ba833f5c80ab650db44896f1fc7b6b1c3271ae2750fe2", "warmup_time": -1}, "finalize.Finalize.time_finalize_micro": {"code": "class Finalize:\n    def time_finalize_micro(self, param):\n        self.obj.__finalize__(self.obj, method=\"__finalize__\")\n\n    def setup(self, param):\n        N = 1000\n        obj = param(dtype=float)\n        for i in range(N):\n            obj.attrs[i] = i\n        self.obj = obj", "min_run_count": 2, "name": "finalize.Finalize.time_finalize_micro", "number": 0, "param_names": ["series"], "params": [["<class 'pandas.core.series.Series'>", "<class 'pandas.core.frame.DataFrame'>"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "bd2eab1eb436d45e913e54877c33d964695d4ac5fd0e7fd575f97eb347240a13", "warmup_time": -1}, "frame_ctor.FromArrays.time_frame_from_arrays_float": {"code": "class FromArrays:\n    def time_frame_from_arrays_float(self):\n        self.df = DataFrame._from_arrays(\n            self.float_arrays,\n            index=self.index,\n            columns=self.columns,\n            verify_integrity=False,\n        )\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass FromArrays:\n    def setup(self):\n        N_rows = 1000\n        N_cols = 1000\n        self.float_arrays = [np.random.randn(N_rows) for _ in range(N_cols)]\n        self.sparse_arrays = [\n            pd.arrays.SparseArray(np.random.randint(0, 2, N_rows), dtype=\"float64\")\n            for _ in range(N_cols)\n        ]\n        self.int_arrays = [\n            pd.array(np.random.randint(1000, size=N_rows), dtype=\"Int64\")\n            for _ in range(N_cols)\n        ]\n        self.index = pd.Index(range(N_rows))\n        self.columns = pd.Index(range(N_cols))", "min_run_count": 2, "name": "frame_ctor.FromArrays.time_frame_from_arrays_float", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "325f63d87ecbf9ad645d78740a1aa8328bbd4c29f349c5b13a9117e526ce3866", "warmup_time": -1}, "frame_ctor.FromArrays.time_frame_from_arrays_int": {"code": "class FromArrays:\n    def time_frame_from_arrays_int(self):\n        self.df = DataFrame._from_arrays(\n            self.int_arrays,\n            index=self.index,\n            columns=self.columns,\n            verify_integrity=False,\n        )\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass FromArrays:\n    def setup(self):\n        N_rows = 1000\n        N_cols = 1000\n        self.float_arrays = [np.random.randn(N_rows) for _ in range(N_cols)]\n        self.sparse_arrays = [\n            pd.arrays.SparseArray(np.random.randint(0, 2, N_rows), dtype=\"float64\")\n            for _ in range(N_cols)\n        ]\n        self.int_arrays = [\n            pd.array(np.random.randint(1000, size=N_rows), dtype=\"Int64\")\n            for _ in range(N_cols)\n        ]\n        self.index = pd.Index(range(N_rows))\n        self.columns = pd.Index(range(N_cols))", "min_run_count": 2, "name": "frame_ctor.FromArrays.time_frame_from_arrays_int", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "0ea63af2ba6a6bc03ab7882f007240ed2d5183ed6fa7b85d15c9eb6f3c6f67f7", "warmup_time": -1}, "frame_ctor.FromArrays.time_frame_from_arrays_sparse": {"code": "class FromArrays:\n    def time_frame_from_arrays_sparse(self):\n        self.df = DataFrame._from_arrays(\n            self.sparse_arrays,\n            index=self.index,\n            columns=self.columns,\n            verify_integrity=False,\n        )\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass FromArrays:\n    def setup(self):\n        N_rows = 1000\n        N_cols = 1000\n        self.float_arrays = [np.random.randn(N_rows) for _ in range(N_cols)]\n        self.sparse_arrays = [\n            pd.arrays.SparseArray(np.random.randint(0, 2, N_rows), dtype=\"float64\")\n            for _ in range(N_cols)\n        ]\n        self.int_arrays = [\n            pd.array(np.random.randint(1000, size=N_rows), dtype=\"Int64\")\n            for _ in range(N_cols)\n        ]\n        self.index = pd.Index(range(N_rows))\n        self.columns = pd.Index(range(N_cols))", "min_run_count": 2, "name": "frame_ctor.FromArrays.time_frame_from_arrays_sparse", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "225c22c0601994be668586bdb257030c2fd0d83e6dec0712bd820db812484318", "warmup_time": -1}, "frame_ctor.FromDicts.time_dict_of_categoricals": {"code": "class FromDicts:\n    def time_dict_of_categoricals(self):\n        # dict of arrays that we won't consolidate\n        DataFrame(self.dict_of_categoricals)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass FromDicts:\n    def setup(self):\n        N, K = 5000, 50\n        self.index = pd.Index([f\"i-{i}\" for i in range(N)], dtype=object)\n        self.columns = pd.Index([f\"i-{i}\" for i in range(K)], dtype=object)\n        frame = DataFrame(np.random.randn(N, K), index=self.index, columns=self.columns)\n        self.data = frame.to_dict()\n        self.dict_list = frame.to_dict(orient=\"records\")\n        self.data2 = {i: {j: float(j) for j in range(100)} for i in range(2000)}\n    \n        # arrays which we won't consolidate\n        self.dict_of_categoricals = {i: Categorical(np.arange(N)) for i in range(K)}", "min_run_count": 2, "name": "frame_ctor.FromDicts.time_dict_of_categoricals", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "31bd8e5276983e0e0e3b54a1067e23e1e752f382dbb023f29dfb8b0e7ac5e72d", "warmup_time": -1}, "frame_ctor.FromDicts.time_list_of_dict": {"code": "class FromDicts:\n    def time_list_of_dict(self):\n        DataFrame(self.dict_list)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass FromDicts:\n    def setup(self):\n        N, K = 5000, 50\n        self.index = pd.Index([f\"i-{i}\" for i in range(N)], dtype=object)\n        self.columns = pd.Index([f\"i-{i}\" for i in range(K)], dtype=object)\n        frame = DataFrame(np.random.randn(N, K), index=self.index, columns=self.columns)\n        self.data = frame.to_dict()\n        self.dict_list = frame.to_dict(orient=\"records\")\n        self.data2 = {i: {j: float(j) for j in range(100)} for i in range(2000)}\n    \n        # arrays which we won't consolidate\n        self.dict_of_categoricals = {i: Categorical(np.arange(N)) for i in range(K)}", "min_run_count": 2, "name": "frame_ctor.FromDicts.time_list_of_dict", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "6c0dbbebd6c0771feeaf375a1d39dbba020a4c12fad6bfee70c573d4414e1469", "warmup_time": -1}, "frame_ctor.FromDicts.time_nested_dict": {"code": "class FromDicts:\n    def time_nested_dict(self):\n        DataFrame(self.data)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass FromDicts:\n    def setup(self):\n        N, K = 5000, 50\n        self.index = pd.Index([f\"i-{i}\" for i in range(N)], dtype=object)\n        self.columns = pd.Index([f\"i-{i}\" for i in range(K)], dtype=object)\n        frame = DataFrame(np.random.randn(N, K), index=self.index, columns=self.columns)\n        self.data = frame.to_dict()\n        self.dict_list = frame.to_dict(orient=\"records\")\n        self.data2 = {i: {j: float(j) for j in range(100)} for i in range(2000)}\n    \n        # arrays which we won't consolidate\n        self.dict_of_categoricals = {i: Categorical(np.arange(N)) for i in range(K)}", "min_run_count": 2, "name": "frame_ctor.FromDicts.time_nested_dict", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "6a72f77f78250c8d1bad34fed6e994a8fd896e30b59e0d1802ea0ea8193f587e", "warmup_time": -1}, "frame_ctor.FromDicts.time_nested_dict_columns": {"code": "class FromDicts:\n    def time_nested_dict_columns(self):\n        DataFrame(self.data, columns=self.columns)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass FromDicts:\n    def setup(self):\n        N, K = 5000, 50\n        self.index = pd.Index([f\"i-{i}\" for i in range(N)], dtype=object)\n        self.columns = pd.Index([f\"i-{i}\" for i in range(K)], dtype=object)\n        frame = DataFrame(np.random.randn(N, K), index=self.index, columns=self.columns)\n        self.data = frame.to_dict()\n        self.dict_list = frame.to_dict(orient=\"records\")\n        self.data2 = {i: {j: float(j) for j in range(100)} for i in range(2000)}\n    \n        # arrays which we won't consolidate\n        self.dict_of_categoricals = {i: Categorical(np.arange(N)) for i in range(K)}", "min_run_count": 2, "name": "frame_ctor.FromDicts.time_nested_dict_columns", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "e010dffc67442ff3250ce0a129b779c57637d00426ee53d397adc88b39992d63", "warmup_time": -1}, "frame_ctor.FromDicts.time_nested_dict_index": {"code": "class FromDicts:\n    def time_nested_dict_index(self):\n        DataFrame(self.data, index=self.index)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass FromDicts:\n    def setup(self):\n        N, K = 5000, 50\n        self.index = pd.Index([f\"i-{i}\" for i in range(N)], dtype=object)\n        self.columns = pd.Index([f\"i-{i}\" for i in range(K)], dtype=object)\n        frame = DataFrame(np.random.randn(N, K), index=self.index, columns=self.columns)\n        self.data = frame.to_dict()\n        self.dict_list = frame.to_dict(orient=\"records\")\n        self.data2 = {i: {j: float(j) for j in range(100)} for i in range(2000)}\n    \n        # arrays which we won't consolidate\n        self.dict_of_categoricals = {i: Categorical(np.arange(N)) for i in range(K)}", "min_run_count": 2, "name": "frame_ctor.FromDicts.time_nested_dict_index", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "48f1d011862f36806877b5da55102998d46466a016974d06f9495942c3585905", "warmup_time": -1}, "frame_ctor.FromDicts.time_nested_dict_index_columns": {"code": "class FromDicts:\n    def time_nested_dict_index_columns(self):\n        DataFrame(self.data, index=self.index, columns=self.columns)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass FromDicts:\n    def setup(self):\n        N, K = 5000, 50\n        self.index = pd.Index([f\"i-{i}\" for i in range(N)], dtype=object)\n        self.columns = pd.Index([f\"i-{i}\" for i in range(K)], dtype=object)\n        frame = DataFrame(np.random.randn(N, K), index=self.index, columns=self.columns)\n        self.data = frame.to_dict()\n        self.dict_list = frame.to_dict(orient=\"records\")\n        self.data2 = {i: {j: float(j) for j in range(100)} for i in range(2000)}\n    \n        # arrays which we won't consolidate\n        self.dict_of_categoricals = {i: Categorical(np.arange(N)) for i in range(K)}", "min_run_count": 2, "name": "frame_ctor.FromDicts.time_nested_dict_index_columns", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "e8d48e85e7f0256d3a1429fba5e9eb60305bb9282b505830ecd2625e858835d4", "warmup_time": -1}, "frame_ctor.FromDicts.time_nested_dict_int64": {"code": "class FromDicts:\n    def time_nested_dict_int64(self):\n        # nested dict, integer indexes, regression described in #621\n        DataFrame(self.data2)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass FromDicts:\n    def setup(self):\n        N, K = 5000, 50\n        self.index = pd.Index([f\"i-{i}\" for i in range(N)], dtype=object)\n        self.columns = pd.Index([f\"i-{i}\" for i in range(K)], dtype=object)\n        frame = DataFrame(np.random.randn(N, K), index=self.index, columns=self.columns)\n        self.data = frame.to_dict()\n        self.dict_list = frame.to_dict(orient=\"records\")\n        self.data2 = {i: {j: float(j) for j in range(100)} for i in range(2000)}\n    \n        # arrays which we won't consolidate\n        self.dict_of_categoricals = {i: Categorical(np.arange(N)) for i in range(K)}", "min_run_count": 2, "name": "frame_ctor.FromDicts.time_nested_dict_int64", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "90614f59dcc399707a19e251cedb7098d4a033b2c6a6436a0225cb69703c33e0", "warmup_time": -1}, "frame_ctor.FromDictwithTimestamp.time_dict_with_timestamp_offsets": {"code": "class FromDictwithTimestamp:\n    def time_dict_with_timestamp_offsets(self, offset):\n        DataFrame(self.d)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass FromDictwithTimestamp:\n    def setup(self, offset):\n        N = 10**3\n        idx = date_range(Timestamp(\"1/1/1900\"), freq=offset, periods=N)\n        df = DataFrame(np.random.randn(N, 10), index=idx)\n        self.d = df.to_dict()", "min_run_count": 2, "name": "frame_ctor.FromDictwithTimestamp.time_dict_with_timestamp_offsets", "number": 0, "param_names": ["offset"], "params": [["<Nano>", "<Hour>"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "edbcf77be1e9f491a8866f3f510790d47d2c68aa69eb8e349b4662c23e071ce4", "warmup_time": -1}, "frame_ctor.FromLists.time_frame_from_lists": {"code": "class FromLists:\n    def time_frame_from_lists(self):\n        self.df = DataFrame(self.data)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass FromLists:\n    def setup(self):\n        N = 1000\n        M = 100\n        self.data = [list(range(M)) for i in range(N)]", "min_run_count": 2, "name": "frame_ctor.FromLists.time_frame_from_lists", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "31e3e4ee69561a2f18687d4fe38117db21e57a6862eba4174561ab425ca7791a", "warmup_time": -1}, "frame_ctor.FromNDArray.time_frame_from_ndarray": {"code": "class FromNDArray:\n    def time_frame_from_ndarray(self):\n        self.df = DataFrame(self.data)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass FromNDArray:\n    def setup(self):\n        N = 100000\n        self.data = np.random.randn(N)", "min_run_count": 2, "name": "frame_ctor.FromNDArray.time_frame_from_ndarray", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "42412f191926bccd17fde73d100476018ba3e35421ee311ca6a8d71ef8817e04", "warmup_time": -1}, "frame_ctor.FromRange.time_frame_from_range": {"code": "class FromRange:\n    def time_frame_from_range(self):\n        self.df = DataFrame(self.data)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass FromRange:\n    def setup(self):\n        N = 1_000_000\n        self.data = range(N)", "min_run_count": 2, "name": "frame_ctor.FromRange.time_frame_from_range", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "8eac1f82a2a2f08e5f9e50dfcf68b362211c18712ce5adbbc12bc772d7d7f156", "warmup_time": -1}, "frame_ctor.FromRecords.time_frame_from_records_generator": {"code": "class FromRecords:\n    def time_frame_from_records_generator(self, nrows):\n        # issue-6700\n        self.df = DataFrame.from_records(self.gen, nrows=nrows)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass FromRecords:\n    def setup(self, nrows):\n        N = 100000\n        self.gen = ((x, (x * 20), (x * 100)) for x in range(N))", "min_run_count": 2, "name": "frame_ctor.FromRecords.time_frame_from_records_generator", "number": 1, "param_names": ["nrows"], "params": [["None", "1000"]], "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "37ac2364875f70b5e255d9371c8fd77229fbb2bb221090c4004cce2af1f510b4", "warmup_time": -1}, "frame_ctor.FromScalar.time_frame_from_scalar_ea_float64": {"code": "class FromScalar:\n    def time_frame_from_scalar_ea_float64(self):\n        DataFrame(\n            1.0,\n            index=range(self.nrows),\n            columns=list(\"abc\"),\n            dtype=Float64Dtype(),\n        )\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass FromScalar:\n    def setup(self):\n        self.nrows = 100_000", "min_run_count": 2, "name": "frame_ctor.FromScalar.time_frame_from_scalar_ea_float64", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "c0971ae1b0ebe91e20c2c53f71217475a9812d27e00b303f343bae2612d9828d", "warmup_time": -1}, "frame_ctor.FromScalar.time_frame_from_scalar_ea_float64_na": {"code": "class FromScalar:\n    def time_frame_from_scalar_ea_float64_na(self):\n        DataFrame(\n            NA,\n            index=range(self.nrows),\n            columns=list(\"abc\"),\n            dtype=Float64Dtype(),\n        )\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass FromScalar:\n    def setup(self):\n        self.nrows = 100_000", "min_run_count": 2, "name": "frame_ctor.FromScalar.time_frame_from_scalar_ea_float64_na", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "9075f068d48f77d734b775cec79405c4847fd0a6e1abfac3461c0dc12981f0b0", "warmup_time": -1}, "frame_ctor.FromSeries.time_mi_series": {"code": "class FromSeries:\n    def time_mi_series(self):\n        DataFrame(self.s)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass FromSeries:\n    def setup(self):\n        mi = MultiIndex.from_product([range(100), range(100)])\n        self.s = Series(np.random.randn(10000), index=mi)", "min_run_count": 2, "name": "frame_ctor.FromSeries.time_mi_series", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "00d66d6b3fb76fd4030a0096f492a7b2040615acbd38000c2317b116f3156fa2", "warmup_time": -1}, "frame_methods.Apply.time_apply_axis_1": {"code": "class Apply:\n    def time_apply_axis_1(self):\n        self.df.apply(lambda x: x + 1, axis=1)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Apply:\n    def setup(self):\n        self.df = DataFrame(np.random.randn(1000, 100))\n    \n        self.s = Series(np.arange(1028.0))\n        self.df2 = DataFrame({i: self.s for i in range(1028)})\n        self.df3 = DataFrame(np.random.randn(1000, 3), columns=list(\"ABC\"))", "min_run_count": 2, "name": "frame_methods.Apply.time_apply_axis_1", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "1abb619fc583026b4a26e477881f01094dbeb880dded525e7cbea1815b8c3c7b", "warmup_time": -1}, "frame_methods.Apply.time_apply_lambda_mean": {"code": "class Apply:\n    def time_apply_lambda_mean(self):\n        self.df.apply(lambda x: x.mean())\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Apply:\n    def setup(self):\n        self.df = DataFrame(np.random.randn(1000, 100))\n    \n        self.s = Series(np.arange(1028.0))\n        self.df2 = DataFrame({i: self.s for i in range(1028)})\n        self.df3 = DataFrame(np.random.randn(1000, 3), columns=list(\"ABC\"))", "min_run_count": 2, "name": "frame_methods.Apply.time_apply_lambda_mean", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "e070e421516f44eee71e66e3fbf7ef0021872ca7eb578f4d11231ed83d441a64", "warmup_time": -1}, "frame_methods.Apply.time_apply_pass_thru": {"code": "class Apply:\n    def time_apply_pass_thru(self):\n        self.df.apply(lambda x: x)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Apply:\n    def setup(self):\n        self.df = DataFrame(np.random.randn(1000, 100))\n    \n        self.s = Series(np.arange(1028.0))\n        self.df2 = DataFrame({i: self.s for i in range(1028)})\n        self.df3 = DataFrame(np.random.randn(1000, 3), columns=list(\"ABC\"))", "min_run_count": 2, "name": "frame_methods.Apply.time_apply_pass_thru", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "7ab6875c70f560ff825c524d780a53db1cad1e43c32e17fe6707f66113694e4c", "warmup_time": -1}, "frame_methods.Apply.time_apply_ref_by_name": {"code": "class Apply:\n    def time_apply_ref_by_name(self):\n        self.df3.apply(lambda x: x[\"A\"] + x[\"B\"], axis=1)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Apply:\n    def setup(self):\n        self.df = DataFrame(np.random.randn(1000, 100))\n    \n        self.s = Series(np.arange(1028.0))\n        self.df2 = DataFrame({i: self.s for i in range(1028)})\n        self.df3 = DataFrame(np.random.randn(1000, 3), columns=list(\"ABC\"))", "min_run_count": 2, "name": "frame_methods.Apply.time_apply_ref_by_name", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "2195dd01ad2f3a289b3754239166687e0753c2a9d5efc0d8be4978c886628236", "warmup_time": -1}, "frame_methods.Apply.time_apply_str_mean": {"code": "class Apply:\n    def time_apply_str_mean(self):\n        self.df.apply(\"mean\")\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Apply:\n    def setup(self):\n        self.df = DataFrame(np.random.randn(1000, 100))\n    \n        self.s = Series(np.arange(1028.0))\n        self.df2 = DataFrame({i: self.s for i in range(1028)})\n        self.df3 = DataFrame(np.random.randn(1000, 3), columns=list(\"ABC\"))", "min_run_count": 2, "name": "frame_methods.Apply.time_apply_str_mean", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "521315810d8415e08556972f62c418fa4eabe181b49caea873ca989ae060e78f", "warmup_time": -1}, "frame_methods.Apply.time_apply_user_func": {"code": "class Apply:\n    def time_apply_user_func(self):\n        self.df2.apply(lambda x: np.corrcoef(x, self.s)[(0, 1)])\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Apply:\n    def setup(self):\n        self.df = DataFrame(np.random.randn(1000, 100))\n    \n        self.s = Series(np.arange(1028.0))\n        self.df2 = DataFrame({i: self.s for i in range(1028)})\n        self.df3 = DataFrame(np.random.randn(1000, 3), columns=list(\"ABC\"))", "min_run_count": 2, "name": "frame_methods.Apply.time_apply_user_func", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "f52de9d070093a84321a5d00e1ff6810b8c4b83e274a1daabf52699c0244b257", "warmup_time": -1}, "frame_methods.AsType.time_astype": {"code": "class AsType:\n    def time_astype(self, from_to_dtypes, copy):\n        self.df.astype(from_to_dtypes[1], copy=copy)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass AsType:\n    def setup(self, from_to_dtypes, copy):\n        from_dtype = from_to_dtypes[0]\n        if from_dtype in (\"float64\", \"Float64\", \"float64[pyarrow]\"):\n            data = np.random.randn(100, 100)\n        elif from_dtype in (\"int64\", \"Int64\", \"int64[pyarrow]\"):\n            data = np.random.randint(0, 1000, (100, 100))\n        else:\n            raise NotImplementedError\n        self.df = DataFrame(data, dtype=from_dtype)", "min_run_count": 2, "name": "frame_methods.AsType.time_astype", "number": 0, "param_names": ["from_to_dtypes", "copy"], "params": [["('Float64', 'Float64')", "('float64[pyarrow]', 'float64[pyarrow]')", "('float64', 'Float64')", "('float64', 'float64[pyarrow]')", "('Float64', 'float64')", "('float64[pyarrow]', 'float64')", "('Int64', 'Float64')", "('int64[pyarrow]', 'float64[pyarrow]')"], ["False", "True"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "a9374f8b9c978c55710c85c55c7a9fd7794a57da8cf27963be077ff661b3c688", "warmup_time": -1}, "frame_methods.Clip.time_clip": {"code": "class Clip:\n    def time_clip(self, dtype):\n        self.df.clip(-1.0, 1.0)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Clip:\n    def setup(self, dtype):\n        data = np.random.randn(100_000, 10)\n        df = DataFrame(data, dtype=dtype)\n        self.df = df", "min_run_count": 2, "name": "frame_methods.Clip.time_clip", "number": 0, "param_names": ["dtype"], "params": [["'float64'", "'Float64'", "'float64[pyarrow]'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "e377218cbb14d1e57e275faade93ca8bb525a9a1b596836b7b181b935186f968", "warmup_time": -1}, "frame_methods.Count.time_count": {"code": "class Count:\n    def time_count(self, axis):\n        self.df.count(axis=axis)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Count:\n    def setup(self, axis):\n        self.df = DataFrame(np.random.randn(10000, 1000))\n        self.df.iloc[50:1000, 20:50] = np.nan\n        self.df.iloc[2000:3000] = np.nan\n        self.df.iloc[:, 60:70] = np.nan\n        self.df_mixed = self.df.copy()\n        self.df_mixed[\"foo\"] = \"bar\"", "min_run_count": 2, "name": "frame_methods.Count.time_count", "number": 0, "param_names": ["axis"], "params": [["0", "1"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "6d0fb3a3427b887565c31a8e63dda9d7ddd21b17b3f6da46237aac13dcc606e1", "warmup_time": -1}, "frame_methods.Count.time_count_mixed_dtypes": {"code": "class Count:\n    def time_count_mixed_dtypes(self, axis):\n        self.df_mixed.count(axis=axis)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Count:\n    def setup(self, axis):\n        self.df = DataFrame(np.random.randn(10000, 1000))\n        self.df.iloc[50:1000, 20:50] = np.nan\n        self.df.iloc[2000:3000] = np.nan\n        self.df.iloc[:, 60:70] = np.nan\n        self.df_mixed = self.df.copy()\n        self.df_mixed[\"foo\"] = \"bar\"", "min_run_count": 2, "name": "frame_methods.Count.time_count_mixed_dtypes", "number": 0, "param_names": ["axis"], "params": [["0", "1"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "7676f0fd5db04a5cff602ddb81b98c1ced3e13ae9438e99839dab87c73cfced6", "warmup_time": -1}, "frame_methods.Describe.time_dataframe_describe": {"code": "class Describe:\n    def time_dataframe_describe(self):\n        self.df.describe()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Describe:\n    def setup(self):\n        self.df = DataFrame(\n            {\n                \"a\": np.random.randint(0, 100, 10**6),\n                \"b\": np.random.randint(0, 100, 10**6),\n                \"c\": np.random.randint(0, 100, 10**6),\n            }\n        )", "min_run_count": 2, "name": "frame_methods.Describe.time_dataframe_describe", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "a874bed44cb683ca51210e26724792fcdf88f6ff721f785384c8fb834049538a", "warmup_time": -1}, "frame_methods.Describe.time_series_describe": {"code": "class Describe:\n    def time_series_describe(self):\n        self.df[\"a\"].describe()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Describe:\n    def setup(self):\n        self.df = DataFrame(\n            {\n                \"a\": np.random.randint(0, 100, 10**6),\n                \"b\": np.random.randint(0, 100, 10**6),\n                \"c\": np.random.randint(0, 100, 10**6),\n            }\n        )", "min_run_count": 2, "name": "frame_methods.Describe.time_series_describe", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "bec8143392a0ea823e7bb51cdbc8e7e85a7655f739b8e049e7568f9d33a744f4", "warmup_time": -1}, "frame_methods.Dropna.time_dropna": {"code": "class Dropna:\n    def time_dropna(self, how, axis):\n        self.df.dropna(how=how, axis=axis)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Dropna:\n    def setup(self, how, axis):\n        self.df = DataFrame(np.random.randn(10000, 1000))\n        self.df.iloc[50:1000, 20:50] = np.nan\n        self.df.iloc[2000:3000] = np.nan\n        self.df.iloc[:, 60:70] = np.nan\n        self.df_mixed = self.df.copy()\n        self.df_mixed[\"foo\"] = \"bar\"", "min_run_count": 2, "name": "frame_methods.Dropna.time_dropna", "number": 0, "param_names": ["how", "axis"], "params": [["'all'", "'any'"], ["0", "1"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "0ae9be10365366634edb6b6490363a365b53e5bb30376f429aa6cd8501e99f60", "warmup_time": -1}, "frame_methods.Dropna.time_dropna_axis_mixed_dtypes": {"code": "class Dropna:\n    def time_dropna_axis_mixed_dtypes(self, how, axis):\n        self.df_mixed.dropna(how=how, axis=axis)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Dropna:\n    def setup(self, how, axis):\n        self.df = DataFrame(np.random.randn(10000, 1000))\n        self.df.iloc[50:1000, 20:50] = np.nan\n        self.df.iloc[2000:3000] = np.nan\n        self.df.iloc[:, 60:70] = np.nan\n        self.df_mixed = self.df.copy()\n        self.df_mixed[\"foo\"] = \"bar\"", "min_run_count": 2, "name": "frame_methods.Dropna.time_dropna_axis_mixed_dtypes", "number": 0, "param_names": ["how", "axis"], "params": [["'all'", "'any'"], ["0", "1"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "211ec5d6bd6568e1ab93ad31c07d7ea015f9540b948fa60ae1ce9846c9d0aaf8", "warmup_time": -1}, "frame_methods.Dtypes.time_frame_dtypes": {"code": "class Dtypes:\n    def time_frame_dtypes(self):\n        self.df.dtypes\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Dtypes:\n    def setup(self):\n        self.df = DataFrame(np.random.randn(1000, 1000))", "min_run_count": 2, "name": "frame_methods.Dtypes.time_frame_dtypes", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "a32eaac056e26349ac255f6354f2a8916b634a88bcf2fd8439b28dc9a21e4ff4", "warmup_time": -1}, "frame_methods.Duplicated.time_frame_duplicated": {"code": "class Duplicated:\n    def time_frame_duplicated(self):\n        self.df.duplicated()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Duplicated:\n    def setup(self):\n        n = 1 << 20\n        t = date_range(\"2015-01-01\", freq=\"s\", periods=(n // 64))\n        xs = np.random.randn(n // 64).round(2)\n        self.df = DataFrame(\n            {\n                \"a\": np.random.randint(-1 << 8, 1 << 8, n),\n                \"b\": np.random.choice(t, n),\n                \"c\": np.random.choice(xs, n),\n            }\n        )\n        self.df2 = DataFrame(np.random.randn(1000, 100).astype(str)).T", "min_run_count": 2, "name": "frame_methods.Duplicated.time_frame_duplicated", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "8a4abe4aaf65e24b3da4f462809f17932a37cc967c623d8b7ff091daba1eb543", "warmup_time": -1}, "frame_methods.Duplicated.time_frame_duplicated_subset": {"code": "class Duplicated:\n    def time_frame_duplicated_subset(self):\n        self.df.duplicated(subset=[\"a\"])\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Duplicated:\n    def setup(self):\n        n = 1 << 20\n        t = date_range(\"2015-01-01\", freq=\"s\", periods=(n // 64))\n        xs = np.random.randn(n // 64).round(2)\n        self.df = DataFrame(\n            {\n                \"a\": np.random.randint(-1 << 8, 1 << 8, n),\n                \"b\": np.random.choice(t, n),\n                \"c\": np.random.choice(xs, n),\n            }\n        )\n        self.df2 = DataFrame(np.random.randn(1000, 100).astype(str)).T", "min_run_count": 2, "name": "frame_methods.Duplicated.time_frame_duplicated_subset", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "23f21c0b6b3f598648f33cbab727152cfaee3599521704a18f47a8184502b9f2", "warmup_time": -1}, "frame_methods.Duplicated.time_frame_duplicated_wide": {"code": "class Duplicated:\n    def time_frame_duplicated_wide(self):\n        self.df2.duplicated()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Duplicated:\n    def setup(self):\n        n = 1 << 20\n        t = date_range(\"2015-01-01\", freq=\"s\", periods=(n // 64))\n        xs = np.random.randn(n // 64).round(2)\n        self.df = DataFrame(\n            {\n                \"a\": np.random.randint(-1 << 8, 1 << 8, n),\n                \"b\": np.random.choice(t, n),\n                \"c\": np.random.choice(xs, n),\n            }\n        )\n        self.df2 = DataFrame(np.random.randn(1000, 100).astype(str)).T", "min_run_count": 2, "name": "frame_methods.Duplicated.time_frame_duplicated_wide", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "097f9842171e94103f87e1898827b9193a138985565752f4880b1b4df539adb7", "warmup_time": -1}, "frame_methods.Equals.time_frame_float_equal": {"code": "class Equals:\n    def time_frame_float_equal(self):\n        self.float_df.equals(self.float_df)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Equals:\n    def setup(self):\n        N = 10**3\n        self.float_df = DataFrame(np.random.randn(N, N))\n        self.float_df_nan = self.float_df.copy()\n        self.float_df_nan.iloc[-1, -1] = np.nan\n    \n        self.object_df = DataFrame(\"foo\", index=range(N), columns=range(N))\n        self.object_df_nan = self.object_df.copy()\n        self.object_df_nan.iloc[-1, -1] = np.nan\n    \n        self.nonunique_cols = self.object_df.copy()\n        self.nonunique_cols.columns = [\"A\"] * len(self.nonunique_cols.columns)\n        self.nonunique_cols_nan = self.nonunique_cols.copy()\n        self.nonunique_cols_nan.iloc[-1, -1] = np.nan", "min_run_count": 2, "name": "frame_methods.Equals.time_frame_float_equal", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "3e43e40c9afb93fdb9e4dc0b1153cb7e251f37639262f67e949b58d4cdec6de6", "warmup_time": -1}, "frame_methods.Equals.time_frame_float_unequal": {"code": "class Equals:\n    def time_frame_float_unequal(self):\n        self.float_df.equals(self.float_df_nan)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Equals:\n    def setup(self):\n        N = 10**3\n        self.float_df = DataFrame(np.random.randn(N, N))\n        self.float_df_nan = self.float_df.copy()\n        self.float_df_nan.iloc[-1, -1] = np.nan\n    \n        self.object_df = DataFrame(\"foo\", index=range(N), columns=range(N))\n        self.object_df_nan = self.object_df.copy()\n        self.object_df_nan.iloc[-1, -1] = np.nan\n    \n        self.nonunique_cols = self.object_df.copy()\n        self.nonunique_cols.columns = [\"A\"] * len(self.nonunique_cols.columns)\n        self.nonunique_cols_nan = self.nonunique_cols.copy()\n        self.nonunique_cols_nan.iloc[-1, -1] = np.nan", "min_run_count": 2, "name": "frame_methods.Equals.time_frame_float_unequal", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "096c7821b123d68c85d2ed32adda440daf4043608ac9a04e121f66aef041e33a", "warmup_time": -1}, "frame_methods.Equals.time_frame_nonunique_equal": {"code": "class Equals:\n    def time_frame_nonunique_equal(self):\n        self.nonunique_cols.equals(self.nonunique_cols)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Equals:\n    def setup(self):\n        N = 10**3\n        self.float_df = DataFrame(np.random.randn(N, N))\n        self.float_df_nan = self.float_df.copy()\n        self.float_df_nan.iloc[-1, -1] = np.nan\n    \n        self.object_df = DataFrame(\"foo\", index=range(N), columns=range(N))\n        self.object_df_nan = self.object_df.copy()\n        self.object_df_nan.iloc[-1, -1] = np.nan\n    \n        self.nonunique_cols = self.object_df.copy()\n        self.nonunique_cols.columns = [\"A\"] * len(self.nonunique_cols.columns)\n        self.nonunique_cols_nan = self.nonunique_cols.copy()\n        self.nonunique_cols_nan.iloc[-1, -1] = np.nan", "min_run_count": 2, "name": "frame_methods.Equals.time_frame_nonunique_equal", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "ea0c51f42ef266ee9b0fafafaa48a2192674cd615ae9f7b648b83aafbc5dcdce", "warmup_time": -1}, "frame_methods.Equals.time_frame_nonunique_unequal": {"code": "class Equals:\n    def time_frame_nonunique_unequal(self):\n        self.nonunique_cols.equals(self.nonunique_cols_nan)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Equals:\n    def setup(self):\n        N = 10**3\n        self.float_df = DataFrame(np.random.randn(N, N))\n        self.float_df_nan = self.float_df.copy()\n        self.float_df_nan.iloc[-1, -1] = np.nan\n    \n        self.object_df = DataFrame(\"foo\", index=range(N), columns=range(N))\n        self.object_df_nan = self.object_df.copy()\n        self.object_df_nan.iloc[-1, -1] = np.nan\n    \n        self.nonunique_cols = self.object_df.copy()\n        self.nonunique_cols.columns = [\"A\"] * len(self.nonunique_cols.columns)\n        self.nonunique_cols_nan = self.nonunique_cols.copy()\n        self.nonunique_cols_nan.iloc[-1, -1] = np.nan", "min_run_count": 2, "name": "frame_methods.Equals.time_frame_nonunique_unequal", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "0afac18ed2411295c0adc10e398c9e4b02682bb882a28427a848f9b9455ad7dd", "warmup_time": -1}, "frame_methods.Equals.time_frame_object_equal": {"code": "class Equals:\n    def time_frame_object_equal(self):\n        self.object_df.equals(self.object_df)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Equals:\n    def setup(self):\n        N = 10**3\n        self.float_df = DataFrame(np.random.randn(N, N))\n        self.float_df_nan = self.float_df.copy()\n        self.float_df_nan.iloc[-1, -1] = np.nan\n    \n        self.object_df = DataFrame(\"foo\", index=range(N), columns=range(N))\n        self.object_df_nan = self.object_df.copy()\n        self.object_df_nan.iloc[-1, -1] = np.nan\n    \n        self.nonunique_cols = self.object_df.copy()\n        self.nonunique_cols.columns = [\"A\"] * len(self.nonunique_cols.columns)\n        self.nonunique_cols_nan = self.nonunique_cols.copy()\n        self.nonunique_cols_nan.iloc[-1, -1] = np.nan", "min_run_count": 2, "name": "frame_methods.Equals.time_frame_object_equal", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "fcfdbbe9b7bbe39721d77c9ea49fde74df25c32913469a26570f9cedeeebe789", "warmup_time": -1}, "frame_methods.Equals.time_frame_object_unequal": {"code": "class Equals:\n    def time_frame_object_unequal(self):\n        self.object_df.equals(self.object_df_nan)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Equals:\n    def setup(self):\n        N = 10**3\n        self.float_df = DataFrame(np.random.randn(N, N))\n        self.float_df_nan = self.float_df.copy()\n        self.float_df_nan.iloc[-1, -1] = np.nan\n    \n        self.object_df = DataFrame(\"foo\", index=range(N), columns=range(N))\n        self.object_df_nan = self.object_df.copy()\n        self.object_df_nan.iloc[-1, -1] = np.nan\n    \n        self.nonunique_cols = self.object_df.copy()\n        self.nonunique_cols.columns = [\"A\"] * len(self.nonunique_cols.columns)\n        self.nonunique_cols_nan = self.nonunique_cols.copy()\n        self.nonunique_cols_nan.iloc[-1, -1] = np.nan", "min_run_count": 2, "name": "frame_methods.Equals.time_frame_object_unequal", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "8bb79f98af91ebb0756c6d77ad92778236c4b7ac8b01c041ed655dfb3fed7ce7", "warmup_time": -1}, "frame_methods.Fillna.time_bfill": {"code": "class Fillna:\n    def time_bfill(self, inplace, dtype):\n        self.df.bfill(inplace=inplace)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Fillna:\n    def setup(self, inplace, dtype):\n        N, M = 10000, 100\n        if dtype in (\"datetime64[ns]\", \"datetime64[ns, tz]\", \"timedelta64[ns]\"):\n            data = {\n                \"datetime64[ns]\": date_range(\"2011-01-01\", freq=\"h\", periods=N),\n                \"datetime64[ns, tz]\": date_range(\n                    \"2011-01-01\", freq=\"h\", periods=N, tz=\"Asia/Tokyo\"\n                ),\n                \"timedelta64[ns]\": timedelta_range(start=\"1 day\", periods=N, freq=\"1D\"),\n            }\n            self.df = DataFrame({f\"col_{i}\": data[dtype] for i in range(M)})\n            self.df[::2] = None\n        else:\n            values = np.random.randn(N, M)\n            values[::2] = np.nan\n            if dtype == \"Int64\":\n                values = values.round()\n            self.df = DataFrame(values, dtype=dtype)\n        self.fill_values = self.df.iloc[self.df.first_valid_index()].to_dict()", "min_run_count": 2, "name": "frame_methods.Fillna.time_bfill", "number": 0, "param_names": ["inplace", "dtype"], "params": [["True", "False"], ["'float64'", "'float32'", "'object'", "'Int64'", "'Float64'", "'datetime64[ns]'", "'datetime64[ns, tz]'", "'timedelta64[ns]'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "ab1619ca6d7bbaad9c0eac1f7dd4ea723ac82673224aa8dbce70c1984f22acb3", "warmup_time": -1}, "frame_methods.Fillna.time_ffill": {"code": "class Fillna:\n    def time_ffill(self, inplace, dtype):\n        self.df.ffill(inplace=inplace)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Fillna:\n    def setup(self, inplace, dtype):\n        N, M = 10000, 100\n        if dtype in (\"datetime64[ns]\", \"datetime64[ns, tz]\", \"timedelta64[ns]\"):\n            data = {\n                \"datetime64[ns]\": date_range(\"2011-01-01\", freq=\"h\", periods=N),\n                \"datetime64[ns, tz]\": date_range(\n                    \"2011-01-01\", freq=\"h\", periods=N, tz=\"Asia/Tokyo\"\n                ),\n                \"timedelta64[ns]\": timedelta_range(start=\"1 day\", periods=N, freq=\"1D\"),\n            }\n            self.df = DataFrame({f\"col_{i}\": data[dtype] for i in range(M)})\n            self.df[::2] = None\n        else:\n            values = np.random.randn(N, M)\n            values[::2] = np.nan\n            if dtype == \"Int64\":\n                values = values.round()\n            self.df = DataFrame(values, dtype=dtype)\n        self.fill_values = self.df.iloc[self.df.first_valid_index()].to_dict()", "min_run_count": 2, "name": "frame_methods.Fillna.time_ffill", "number": 0, "param_names": ["inplace", "dtype"], "params": [["True", "False"], ["'float64'", "'float32'", "'object'", "'Int64'", "'Float64'", "'datetime64[ns]'", "'datetime64[ns, tz]'", "'timedelta64[ns]'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "0912aa084abd2d5fc47d46ff25b6d897cec70cdab63de87d29937622654d060a", "warmup_time": -1}, "frame_methods.Fillna.time_fillna": {"code": "class Fillna:\n    def time_fillna(self, inplace, dtype):\n        self.df.fillna(value=self.fill_values, inplace=inplace)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Fillna:\n    def setup(self, inplace, dtype):\n        N, M = 10000, 100\n        if dtype in (\"datetime64[ns]\", \"datetime64[ns, tz]\", \"timedelta64[ns]\"):\n            data = {\n                \"datetime64[ns]\": date_range(\"2011-01-01\", freq=\"h\", periods=N),\n                \"datetime64[ns, tz]\": date_range(\n                    \"2011-01-01\", freq=\"h\", periods=N, tz=\"Asia/Tokyo\"\n                ),\n                \"timedelta64[ns]\": timedelta_range(start=\"1 day\", periods=N, freq=\"1D\"),\n            }\n            self.df = DataFrame({f\"col_{i}\": data[dtype] for i in range(M)})\n            self.df[::2] = None\n        else:\n            values = np.random.randn(N, M)\n            values[::2] = np.nan\n            if dtype == \"Int64\":\n                values = values.round()\n            self.df = DataFrame(values, dtype=dtype)\n        self.fill_values = self.df.iloc[self.df.first_valid_index()].to_dict()", "min_run_count": 2, "name": "frame_methods.Fillna.time_fillna", "number": 0, "param_names": ["inplace", "dtype"], "params": [["True", "False"], ["'float64'", "'float32'", "'object'", "'Int64'", "'Float64'", "'datetime64[ns]'", "'datetime64[ns, tz]'", "'timedelta64[ns]'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "ba97c9ea4cd6a522136714fca9cc26d5060c052e08f8ff392def7c3b1ce4578e", "warmup_time": -1}, "frame_methods.FindValidIndex.time_first_valid_index": {"code": "class FindValidIndex:\n    def time_first_valid_index(self, dtype):\n        self.df.first_valid_index()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass FindValidIndex:\n    def setup(self, dtype):\n        df = DataFrame(\n            np.random.randn(100000, 2),\n            columns=list(\"AB\"),\n            dtype=dtype,\n        )\n        df.iloc[:100, 0] = None\n        df.iloc[:200, 1] = None\n        df.iloc[-100:, 0] = None\n        df.iloc[-200:, 1] = None\n        self.df = df", "min_run_count": 2, "name": "frame_methods.FindValidIndex.time_first_valid_index", "number": 0, "param_names": ["dtype"], "params": [["'float'", "'Float64'", "'float64[pyarrow]'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "25a643509f423207f4a1c6d8a57a39a4a2fb113489c72c587ab77425b9d0ed8c", "warmup_time": -1}, "frame_methods.FindValidIndex.time_last_valid_index": {"code": "class FindValidIndex:\n    def time_last_valid_index(self, dtype):\n        self.df.last_valid_index()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass FindValidIndex:\n    def setup(self, dtype):\n        df = DataFrame(\n            np.random.randn(100000, 2),\n            columns=list(\"AB\"),\n            dtype=dtype,\n        )\n        df.iloc[:100, 0] = None\n        df.iloc[:200, 1] = None\n        df.iloc[-100:, 0] = None\n        df.iloc[-200:, 1] = None\n        self.df = df", "min_run_count": 2, "name": "frame_methods.FindValidIndex.time_last_valid_index", "number": 0, "param_names": ["dtype"], "params": [["'float'", "'Float64'", "'float64[pyarrow]'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "7aa1cbbe0fc10c07e441950795f86f657072d95abb3fc53a6cd08af9ca145bb5", "warmup_time": -1}, "frame_methods.GetDtypeCounts.time_frame_get_dtype_counts": {"code": "class GetDtypeCounts:\n    def time_frame_get_dtype_counts(self):\n        with warnings.catch_warnings(record=True):\n            self.df.dtypes.value_counts()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass GetDtypeCounts:\n    def setup(self):\n        self.df = DataFrame(np.random.randn(10, 10000))", "min_run_count": 2, "name": "frame_methods.GetDtypeCounts.time_frame_get_dtype_counts", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "d1e0466afc9058166debec31e7ff688df837d407655e8faf0621969115aee0dd", "warmup_time": -1}, "frame_methods.GetDtypeCounts.time_info": {"code": "class GetDtypeCounts:\n    def time_info(self):\n        self.df.info()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass GetDtypeCounts:\n    def setup(self):\n        self.df = DataFrame(np.random.randn(10, 10000))", "min_run_count": 2, "name": "frame_methods.GetDtypeCounts.time_info", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "e08ed8e2402f26a376b2c946606fe2bc255214bd7eebee091fe34b3aa4df80db", "warmup_time": -1}, "frame_methods.GetNumericData.time_frame_get_numeric_data": {"code": "class GetNumericData:\n    def time_frame_get_numeric_data(self):\n        self.df._get_numeric_data()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass GetNumericData:\n    def setup(self):\n        self.df = DataFrame(np.random.randn(10000, 25))\n        self.df[\"foo\"] = \"bar\"\n        self.df[\"bar\"] = \"baz\"\n        self.df = self.df._consolidate()", "min_run_count": 2, "name": "frame_methods.GetNumericData.time_frame_get_numeric_data", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "a6f6ccd03d2a3e6a5b9533bf09fd1f3d852fb8c066e10da43dee6c5b1b958b16", "warmup_time": -1}, "frame_methods.Interpolate.time_interpolate": {"code": "class Interpolate:\n    def time_interpolate(self):\n        self.df.interpolate()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Interpolate:\n    def setup(self):\n        N = 10000\n        # this is the worst case, where every column has NaNs.\n        arr = np.random.randn(N, 100)\n        # NB: we need to set values in array, not in df.values, otherwise\n        #  the benchmark will be misleading for ArrayManager\n        arr[::2] = np.nan\n    \n        self.df = DataFrame(arr)\n    \n        self.df2 = DataFrame(\n            {\n                \"A\": np.arange(0, N),\n                \"B\": np.random.randint(0, 100, N),\n                \"C\": np.random.randn(N),\n                \"D\": np.random.randn(N),\n            }\n        )\n        self.df2.loc[1::5, \"A\"] = np.nan\n        self.df2.loc[1::5, \"C\"] = np.nan", "min_run_count": 2, "name": "frame_methods.Interpolate.time_interpolate", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "75df383a49bab3d37d0849bebc65a817072b3ca58388e506fd931cc2246ebf3f", "warmup_time": -1}, "frame_methods.Interpolate.time_interpolate_some_good": {"code": "class Interpolate:\n    def time_interpolate_some_good(self):\n        self.df2.interpolate()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Interpolate:\n    def setup(self):\n        N = 10000\n        # this is the worst case, where every column has NaNs.\n        arr = np.random.randn(N, 100)\n        # NB: we need to set values in array, not in df.values, otherwise\n        #  the benchmark will be misleading for ArrayManager\n        arr[::2] = np.nan\n    \n        self.df = DataFrame(arr)\n    \n        self.df2 = DataFrame(\n            {\n                \"A\": np.arange(0, N),\n                \"B\": np.random.randint(0, 100, N),\n                \"C\": np.random.randn(N),\n                \"D\": np.random.randn(N),\n            }\n        )\n        self.df2.loc[1::5, \"A\"] = np.nan\n        self.df2.loc[1::5, \"C\"] = np.nan", "min_run_count": 2, "name": "frame_methods.Interpolate.time_interpolate_some_good", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "11a6199fd079c1bfb2c61aaaef0e83b9a18e342592cc29040249c28c1128d012", "warmup_time": -1}, "frame_methods.Isna.time_isna": {"code": "class Isna:\n    def time_isna(self, dtype):\n        self.df.isna()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Isna:\n    def setup(self, dtype):\n        data = np.random.randn(10000, 1000)\n        # all-na columns\n        data[:, 600:800] = np.nan\n        # partial-na columns\n        data[800:1000, 4000:5000] = np.nan\n        self.df = DataFrame(data, dtype=dtype)", "min_run_count": 2, "name": "frame_methods.Isna.time_isna", "number": 0, "param_names": ["dtype"], "params": [["'float64'", "'Float64'", "'float64[pyarrow]'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "16c807e189d1c06f5c7693f87fb8211e7206b4807b9eba3c390f1dd2c5e5cf37", "warmup_time": -1}, "frame_methods.Isnull.time_isnull": {"code": "class Isnull:\n    def time_isnull(self):\n        isnull(self.df)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Isnull:\n    def setup(self):\n        N = 10**3\n        self.df_no_null = DataFrame(np.random.randn(N, N))\n    \n        sample = np.array([np.nan, 1.0])\n        data = np.random.choice(sample, (N, N))\n        self.df = DataFrame(data)\n    \n        sample = np.array(list(string.ascii_letters + string.whitespace))\n        data = np.random.choice(sample, (N, N))\n        self.df_strings = DataFrame(data)\n    \n        sample = np.array(\n            [\n                NaT,\n                np.nan,\n                None,\n                np.datetime64(\"NaT\"),\n                np.timedelta64(\"NaT\"),\n                0,\n                1,\n                2.0,\n                \"\",\n                \"abcd\",\n            ]\n        )\n        data = np.random.choice(sample, (N, N))\n        self.df_obj = DataFrame(data)", "min_run_count": 2, "name": "frame_methods.Isnull.time_isnull", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "de22a45fa388dfa02f30c3a7cb1acae9fe966c2d1e68671882fa38eda4e52b3e", "warmup_time": -1}, "frame_methods.Isnull.time_isnull_floats_no_null": {"code": "class Isnull:\n    def time_isnull_floats_no_null(self):\n        isnull(self.df_no_null)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Isnull:\n    def setup(self):\n        N = 10**3\n        self.df_no_null = DataFrame(np.random.randn(N, N))\n    \n        sample = np.array([np.nan, 1.0])\n        data = np.random.choice(sample, (N, N))\n        self.df = DataFrame(data)\n    \n        sample = np.array(list(string.ascii_letters + string.whitespace))\n        data = np.random.choice(sample, (N, N))\n        self.df_strings = DataFrame(data)\n    \n        sample = np.array(\n            [\n                NaT,\n                np.nan,\n                None,\n                np.datetime64(\"NaT\"),\n                np.timedelta64(\"NaT\"),\n                0,\n                1,\n                2.0,\n                \"\",\n                \"abcd\",\n            ]\n        )\n        data = np.random.choice(sample, (N, N))\n        self.df_obj = DataFrame(data)", "min_run_count": 2, "name": "frame_methods.Isnull.time_isnull_floats_no_null", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "d52c0900c393b15f62670fa1ccbc7018957cad8e340de411ad4bd5b33da9ee72", "warmup_time": -1}, "frame_methods.Isnull.time_isnull_obj": {"code": "class Isnull:\n    def time_isnull_obj(self):\n        isnull(self.df_obj)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Isnull:\n    def setup(self):\n        N = 10**3\n        self.df_no_null = DataFrame(np.random.randn(N, N))\n    \n        sample = np.array([np.nan, 1.0])\n        data = np.random.choice(sample, (N, N))\n        self.df = DataFrame(data)\n    \n        sample = np.array(list(string.ascii_letters + string.whitespace))\n        data = np.random.choice(sample, (N, N))\n        self.df_strings = DataFrame(data)\n    \n        sample = np.array(\n            [\n                NaT,\n                np.nan,\n                None,\n                np.datetime64(\"NaT\"),\n                np.timedelta64(\"NaT\"),\n                0,\n                1,\n                2.0,\n                \"\",\n                \"abcd\",\n            ]\n        )\n        data = np.random.choice(sample, (N, N))\n        self.df_obj = DataFrame(data)", "min_run_count": 2, "name": "frame_methods.Isnull.time_isnull_obj", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "02fc103a644b76b012203138d72c1aedc60734a2ca5eaa97a80a3cac46bcf039", "warmup_time": -1}, "frame_methods.Isnull.time_isnull_strngs": {"code": "class Isnull:\n    def time_isnull_strngs(self):\n        isnull(self.df_strings)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Isnull:\n    def setup(self):\n        N = 10**3\n        self.df_no_null = DataFrame(np.random.randn(N, N))\n    \n        sample = np.array([np.nan, 1.0])\n        data = np.random.choice(sample, (N, N))\n        self.df = DataFrame(data)\n    \n        sample = np.array(list(string.ascii_letters + string.whitespace))\n        data = np.random.choice(sample, (N, N))\n        self.df_strings = DataFrame(data)\n    \n        sample = np.array(\n            [\n                NaT,\n                np.nan,\n                None,\n                np.datetime64(\"NaT\"),\n                np.timedelta64(\"NaT\"),\n                0,\n                1,\n                2.0,\n                \"\",\n                \"abcd\",\n            ]\n        )\n        data = np.random.choice(sample, (N, N))\n        self.df_obj = DataFrame(data)", "min_run_count": 2, "name": "frame_methods.Isnull.time_isnull_strngs", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "ff2d41de239a32889b66173e7caa3c0017fac8052762ae9703e5f9e07e1ef5a5", "warmup_time": -1}, "frame_methods.Iteration.mem_itertuples_raw_start": {"code": "class Iteration:\n    def mem_itertuples_raw_start(self):\n        return self.df4.itertuples(index=False, name=None)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Iteration:\n    def setup(self):\n        N = 1000\n        self.df = DataFrame(np.random.randn(N * 10, N))\n        self.df2 = DataFrame(np.random.randn(N * 50, 10))\n        self.df3 = DataFrame(\n            np.random.randn(N, 5 * N), columns=[\"C\" + str(c) for c in range(N * 5)]\n        )\n        self.df4 = DataFrame(np.random.randn(N * 1000, 10))", "name": "frame_methods.Iteration.mem_itertuples_raw_start", "param_names": [], "params": [], "timeout": 120, "type": "memory", "unit": "bytes", "version": "bde9d2373c7953bbf4a4d7fe73bd19e60eb7c15b50f8978637098fec3d837ed1"}, "frame_methods.Iteration.mem_itertuples_raw_to_list": {"code": "class Iteration:\n    def mem_itertuples_raw_to_list(self):\n        return list(self.df4.itertuples(index=False, name=None))\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Iteration:\n    def setup(self):\n        N = 1000\n        self.df = DataFrame(np.random.randn(N * 10, N))\n        self.df2 = DataFrame(np.random.randn(N * 50, 10))\n        self.df3 = DataFrame(\n            np.random.randn(N, 5 * N), columns=[\"C\" + str(c) for c in range(N * 5)]\n        )\n        self.df4 = DataFrame(np.random.randn(N * 1000, 10))", "name": "frame_methods.Iteration.mem_itertuples_raw_to_list", "param_names": [], "params": [], "timeout": 120, "type": "memory", "unit": "bytes", "version": "14959ad0e6b16ce24b2986d509e67eeccc6ad44f09ce481e44781dd903d37a04"}, "frame_methods.Iteration.mem_itertuples_read_first": {"code": "class Iteration:\n    def mem_itertuples_read_first(self):\n        return next(self.df4.itertuples())\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Iteration:\n    def setup(self):\n        N = 1000\n        self.df = DataFrame(np.random.randn(N * 10, N))\n        self.df2 = DataFrame(np.random.randn(N * 50, 10))\n        self.df3 = DataFrame(\n            np.random.randn(N, 5 * N), columns=[\"C\" + str(c) for c in range(N * 5)]\n        )\n        self.df4 = DataFrame(np.random.randn(N * 1000, 10))", "name": "frame_methods.Iteration.mem_itertuples_read_first", "param_names": [], "params": [], "timeout": 120, "type": "memory", "unit": "bytes", "version": "fa14a67958421e77045287ab0dfe58c2d22462f3b77070715024772201c64770"}, "frame_methods.Iteration.mem_itertuples_start": {"code": "class Iteration:\n    def mem_itertuples_start(self):\n        return self.df4.itertuples()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Iteration:\n    def setup(self):\n        N = 1000\n        self.df = DataFrame(np.random.randn(N * 10, N))\n        self.df2 = DataFrame(np.random.randn(N * 50, 10))\n        self.df3 = DataFrame(\n            np.random.randn(N, 5 * N), columns=[\"C\" + str(c) for c in range(N * 5)]\n        )\n        self.df4 = DataFrame(np.random.randn(N * 1000, 10))", "name": "frame_methods.Iteration.mem_itertuples_start", "param_names": [], "params": [], "timeout": 120, "type": "memory", "unit": "bytes", "version": "cf2518d7a524f33405fe8b9f5e7dd8af1e52820e56cf14f92d6ff79ca33bbca9"}, "frame_methods.Iteration.mem_itertuples_to_list": {"code": "class Iteration:\n    def mem_itertuples_to_list(self):\n        return list(self.df4.itertuples())\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Iteration:\n    def setup(self):\n        N = 1000\n        self.df = DataFrame(np.random.randn(N * 10, N))\n        self.df2 = DataFrame(np.random.randn(N * 50, 10))\n        self.df3 = DataFrame(\n            np.random.randn(N, 5 * N), columns=[\"C\" + str(c) for c in range(N * 5)]\n        )\n        self.df4 = DataFrame(np.random.randn(N * 1000, 10))", "name": "frame_methods.Iteration.mem_itertuples_to_list", "param_names": [], "params": [], "timeout": 120, "type": "memory", "unit": "bytes", "version": "fc2c86822b2a65a5dd8df96b9003fe69eb2c82b3b8543140d1744b7d7fbc099f"}, "frame_methods.Iteration.peakmem_itertuples": {"code": "class Iteration:\n    def peakmem_itertuples(self):\n        for row in self.df4.itertuples():\n            pass\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Iteration:\n    def setup(self):\n        N = 1000\n        self.df = DataFrame(np.random.randn(N * 10, N))\n        self.df2 = DataFrame(np.random.randn(N * 50, 10))\n        self.df3 = DataFrame(\n            np.random.randn(N, 5 * N), columns=[\"C\" + str(c) for c in range(N * 5)]\n        )\n        self.df4 = DataFrame(np.random.randn(N * 1000, 10))", "name": "frame_methods.Iteration.peakmem_itertuples", "param_names": [], "params": [], "timeout": 120, "type": "peakmemory", "unit": "bytes", "version": "f8c4bb246773a09f62d6963200ac6dd08accf63f8701099b39f34450db0baa76"}, "frame_methods.Iteration.peakmem_itertuples_raw": {"code": "class Iteration:\n    def peakmem_itertuples_raw(self):\n        for row in self.df4.itertuples(index=False, name=None):\n            pass\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Iteration:\n    def setup(self):\n        N = 1000\n        self.df = DataFrame(np.random.randn(N * 10, N))\n        self.df2 = DataFrame(np.random.randn(N * 50, 10))\n        self.df3 = DataFrame(\n            np.random.randn(N, 5 * N), columns=[\"C\" + str(c) for c in range(N * 5)]\n        )\n        self.df4 = DataFrame(np.random.randn(N * 1000, 10))", "name": "frame_methods.Iteration.peakmem_itertuples_raw", "param_names": [], "params": [], "timeout": 120, "type": "peakmemory", "unit": "bytes", "version": "51be24a7edeb484ceaa5e24c608c890c59c56b210c778564af1c40cde9c6582b"}, "frame_methods.Iteration.peakmem_itertuples_raw_read_first": {"code": "class Iteration:\n    def peakmem_itertuples_raw_read_first(self):\n        next(self.df4.itertuples(index=False, name=None))\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Iteration:\n    def setup(self):\n        N = 1000\n        self.df = DataFrame(np.random.randn(N * 10, N))\n        self.df2 = DataFrame(np.random.randn(N * 50, 10))\n        self.df3 = DataFrame(\n            np.random.randn(N, 5 * N), columns=[\"C\" + str(c) for c in range(N * 5)]\n        )\n        self.df4 = DataFrame(np.random.randn(N * 1000, 10))", "name": "frame_methods.Iteration.peakmem_itertuples_raw_read_first", "param_names": [], "params": [], "timeout": 120, "type": "peakmemory", "unit": "bytes", "version": "3bcec70cbf3d3ea880425ba6e3a7a604504d19716e82dbbb4a70fb8351eda7f3"}, "frame_methods.Iteration.peakmem_itertuples_raw_start": {"code": "class Iteration:\n    def peakmem_itertuples_raw_start(self):\n        self.df4.itertuples(index=False, name=None)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Iteration:\n    def setup(self):\n        N = 1000\n        self.df = DataFrame(np.random.randn(N * 10, N))\n        self.df2 = DataFrame(np.random.randn(N * 50, 10))\n        self.df3 = DataFrame(\n            np.random.randn(N, 5 * N), columns=[\"C\" + str(c) for c in range(N * 5)]\n        )\n        self.df4 = DataFrame(np.random.randn(N * 1000, 10))", "name": "frame_methods.Iteration.peakmem_itertuples_raw_start", "param_names": [], "params": [], "timeout": 120, "type": "peakmemory", "unit": "bytes", "version": "8d85d7a2d0ceb456c1eae16a3f138a7ea0a13edf1bd76492d262b00cc32013cf"}, "frame_methods.Iteration.peakmem_itertuples_raw_to_list": {"code": "class Iteration:\n    def peakmem_itertuples_raw_to_list(self):\n        list(self.df4.itertuples(index=False, name=None))\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Iteration:\n    def setup(self):\n        N = 1000\n        self.df = DataFrame(np.random.randn(N * 10, N))\n        self.df2 = DataFrame(np.random.randn(N * 50, 10))\n        self.df3 = DataFrame(\n            np.random.randn(N, 5 * N), columns=[\"C\" + str(c) for c in range(N * 5)]\n        )\n        self.df4 = DataFrame(np.random.randn(N * 1000, 10))", "name": "frame_methods.Iteration.peakmem_itertuples_raw_to_list", "param_names": [], "params": [], "timeout": 120, "type": "peakmemory", "unit": "bytes", "version": "702541458ae59bd0fa6a7654edf93ba6de30013419a4591073b4077ffaaa9ec1"}, "frame_methods.Iteration.peakmem_itertuples_start": {"code": "class Iteration:\n    def peakmem_itertuples_start(self):\n        self.df4.itertuples()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Iteration:\n    def setup(self):\n        N = 1000\n        self.df = DataFrame(np.random.randn(N * 10, N))\n        self.df2 = DataFrame(np.random.randn(N * 50, 10))\n        self.df3 = DataFrame(\n            np.random.randn(N, 5 * N), columns=[\"C\" + str(c) for c in range(N * 5)]\n        )\n        self.df4 = DataFrame(np.random.randn(N * 1000, 10))", "name": "frame_methods.Iteration.peakmem_itertuples_start", "param_names": [], "params": [], "timeout": 120, "type": "peakmemory", "unit": "bytes", "version": "2e9870eb171bfbc3718dac5dc495cf2a5fc860a65acca33db4110a97d819f905"}, "frame_methods.Iteration.peakmem_itertuples_to_list": {"code": "class Iteration:\n    def peakmem_itertuples_to_list(self):\n        list(self.df4.itertuples())\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Iteration:\n    def setup(self):\n        N = 1000\n        self.df = DataFrame(np.random.randn(N * 10, N))\n        self.df2 = DataFrame(np.random.randn(N * 50, 10))\n        self.df3 = DataFrame(\n            np.random.randn(N, 5 * N), columns=[\"C\" + str(c) for c in range(N * 5)]\n        )\n        self.df4 = DataFrame(np.random.randn(N * 1000, 10))", "name": "frame_methods.Iteration.peakmem_itertuples_to_list", "param_names": [], "params": [], "timeout": 120, "type": "peakmemory", "unit": "bytes", "version": "3b1c891c821d3baa961e2ac7bbba794eaaa5fdde90643e15273782165349694d"}, "frame_methods.Iteration.time_items": {"code": "class Iteration:\n    def time_items(self):\n        # (monitor no-copying behaviour)\n        if hasattr(self.df, \"_item_cache\"):\n            self.df._item_cache.clear()\n        for name, col in self.df.items():\n            pass\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Iteration:\n    def setup(self):\n        N = 1000\n        self.df = DataFrame(np.random.randn(N * 10, N))\n        self.df2 = DataFrame(np.random.randn(N * 50, 10))\n        self.df3 = DataFrame(\n            np.random.randn(N, 5 * N), columns=[\"C\" + str(c) for c in range(N * 5)]\n        )\n        self.df4 = DataFrame(np.random.randn(N * 1000, 10))", "min_run_count": 2, "name": "frame_methods.Iteration.time_items", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 120, "type": "time", "unit": "seconds", "version": "61a76eb1cc78a07500c444849ab0ff0f8e5db1091090d34b6a1cdaee55952a78", "warmup_time": -1}, "frame_methods.Iteration.time_items_cached": {"code": "class Iteration:\n    def time_items_cached(self):\n        for name, col in self.df.items():\n            pass\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Iteration:\n    def setup(self):\n        N = 1000\n        self.df = DataFrame(np.random.randn(N * 10, N))\n        self.df2 = DataFrame(np.random.randn(N * 50, 10))\n        self.df3 = DataFrame(\n            np.random.randn(N, 5 * N), columns=[\"C\" + str(c) for c in range(N * 5)]\n        )\n        self.df4 = DataFrame(np.random.randn(N * 1000, 10))", "min_run_count": 2, "name": "frame_methods.Iteration.time_items_cached", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 120, "type": "time", "unit": "seconds", "version": "c306e5ac3eb89a326c9bc3a472c6040fc7e21e71d498483a3aa5263ed417b87a", "warmup_time": -1}, "frame_methods.Iteration.time_iteritems_indexing": {"code": "class Iteration:\n    def time_iteritems_indexing(self):\n        for col in self.df3:\n            self.df3[col]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Iteration:\n    def setup(self):\n        N = 1000\n        self.df = DataFrame(np.random.randn(N * 10, N))\n        self.df2 = DataFrame(np.random.randn(N * 50, 10))\n        self.df3 = DataFrame(\n            np.random.randn(N, 5 * N), columns=[\"C\" + str(c) for c in range(N * 5)]\n        )\n        self.df4 = DataFrame(np.random.randn(N * 1000, 10))", "min_run_count": 2, "name": "frame_methods.Iteration.time_iteritems_indexing", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 120, "type": "time", "unit": "seconds", "version": "32a0d9e470a05a943e062be7e53224b0a8d3c4753f3ea203564451fe73e00be6", "warmup_time": -1}, "frame_methods.Iteration.time_iterrows": {"code": "class Iteration:\n    def time_iterrows(self):\n        for row in self.df.iterrows():\n            pass\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Iteration:\n    def setup(self):\n        N = 1000\n        self.df = DataFrame(np.random.randn(N * 10, N))\n        self.df2 = DataFrame(np.random.randn(N * 50, 10))\n        self.df3 = DataFrame(\n            np.random.randn(N, 5 * N), columns=[\"C\" + str(c) for c in range(N * 5)]\n        )\n        self.df4 = DataFrame(np.random.randn(N * 1000, 10))", "min_run_count": 2, "name": "frame_methods.Iteration.time_iterrows", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 120, "type": "time", "unit": "seconds", "version": "1872356d18d8d38838ccef4e38aea113cb033fcd589da146758d76d6aba725c1", "warmup_time": -1}, "frame_methods.Iteration.time_itertuples": {"code": "class Iteration:\n    def time_itertuples(self):\n        for row in self.df4.itertuples():\n            pass\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Iteration:\n    def setup(self):\n        N = 1000\n        self.df = DataFrame(np.random.randn(N * 10, N))\n        self.df2 = DataFrame(np.random.randn(N * 50, 10))\n        self.df3 = DataFrame(\n            np.random.randn(N, 5 * N), columns=[\"C\" + str(c) for c in range(N * 5)]\n        )\n        self.df4 = DataFrame(np.random.randn(N * 1000, 10))", "min_run_count": 2, "name": "frame_methods.Iteration.time_itertuples", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 120, "type": "time", "unit": "seconds", "version": "bc1f6d845378bd6d1c53d1ef7b8e0f725f9a6ca74b0b1bfe928c5a21e6829fd9", "warmup_time": -1}, "frame_methods.Iteration.time_itertuples_raw_read_first": {"code": "class Iteration:\n    def time_itertuples_raw_read_first(self):\n        next(self.df4.itertuples(index=False, name=None))\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Iteration:\n    def setup(self):\n        N = 1000\n        self.df = DataFrame(np.random.randn(N * 10, N))\n        self.df2 = DataFrame(np.random.randn(N * 50, 10))\n        self.df3 = DataFrame(\n            np.random.randn(N, 5 * N), columns=[\"C\" + str(c) for c in range(N * 5)]\n        )\n        self.df4 = DataFrame(np.random.randn(N * 1000, 10))", "min_run_count": 2, "name": "frame_methods.Iteration.time_itertuples_raw_read_first", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 120, "type": "time", "unit": "seconds", "version": "78a787f4a6eb7dd27f3ac2434d4d26567eca763890c14bd2b86b54d88ade5db4", "warmup_time": -1}, "frame_methods.Iteration.time_itertuples_raw_start": {"code": "class Iteration:\n    def time_itertuples_raw_start(self):\n        self.df4.itertuples(index=False, name=None)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Iteration:\n    def setup(self):\n        N = 1000\n        self.df = DataFrame(np.random.randn(N * 10, N))\n        self.df2 = DataFrame(np.random.randn(N * 50, 10))\n        self.df3 = DataFrame(\n            np.random.randn(N, 5 * N), columns=[\"C\" + str(c) for c in range(N * 5)]\n        )\n        self.df4 = DataFrame(np.random.randn(N * 1000, 10))", "min_run_count": 2, "name": "frame_methods.Iteration.time_itertuples_raw_start", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 120, "type": "time", "unit": "seconds", "version": "e34eb99379456d0e4ff1da68c34d436747af447b5d80f49bca78a9095da18426", "warmup_time": -1}, "frame_methods.Iteration.time_itertuples_raw_tuples": {"code": "class Iteration:\n    def time_itertuples_raw_tuples(self):\n        for row in self.df4.itertuples(index=False, name=None):\n            pass\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Iteration:\n    def setup(self):\n        N = 1000\n        self.df = DataFrame(np.random.randn(N * 10, N))\n        self.df2 = DataFrame(np.random.randn(N * 50, 10))\n        self.df3 = DataFrame(\n            np.random.randn(N, 5 * N), columns=[\"C\" + str(c) for c in range(N * 5)]\n        )\n        self.df4 = DataFrame(np.random.randn(N * 1000, 10))", "min_run_count": 2, "name": "frame_methods.Iteration.time_itertuples_raw_tuples", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 120, "type": "time", "unit": "seconds", "version": "ef2cf1b3767b908e25cbd488502ea2b91b43cfcd491b12389acfbea37699cc95", "warmup_time": -1}, "frame_methods.Iteration.time_itertuples_raw_tuples_to_list": {"code": "class Iteration:\n    def time_itertuples_raw_tuples_to_list(self):\n        list(self.df4.itertuples(index=False, name=None))\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Iteration:\n    def setup(self):\n        N = 1000\n        self.df = DataFrame(np.random.randn(N * 10, N))\n        self.df2 = DataFrame(np.random.randn(N * 50, 10))\n        self.df3 = DataFrame(\n            np.random.randn(N, 5 * N), columns=[\"C\" + str(c) for c in range(N * 5)]\n        )\n        self.df4 = DataFrame(np.random.randn(N * 1000, 10))", "min_run_count": 2, "name": "frame_methods.Iteration.time_itertuples_raw_tuples_to_list", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 120, "type": "time", "unit": "seconds", "version": "f372d26bf89b90dd1e24ac2a01493a7435fdf11710e9e65324adc1d350725816", "warmup_time": -1}, "frame_methods.Iteration.time_itertuples_read_first": {"code": "class Iteration:\n    def time_itertuples_read_first(self):\n        next(self.df4.itertuples())\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Iteration:\n    def setup(self):\n        N = 1000\n        self.df = DataFrame(np.random.randn(N * 10, N))\n        self.df2 = DataFrame(np.random.randn(N * 50, 10))\n        self.df3 = DataFrame(\n            np.random.randn(N, 5 * N), columns=[\"C\" + str(c) for c in range(N * 5)]\n        )\n        self.df4 = DataFrame(np.random.randn(N * 1000, 10))", "min_run_count": 2, "name": "frame_methods.Iteration.time_itertuples_read_first", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 120, "type": "time", "unit": "seconds", "version": "9ed674f5820c7707be515d2f9a891d84a09efcf8f785fc428335dac028a682a6", "warmup_time": -1}, "frame_methods.Iteration.time_itertuples_start": {"code": "class Iteration:\n    def time_itertuples_start(self):\n        self.df4.itertuples()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Iteration:\n    def setup(self):\n        N = 1000\n        self.df = DataFrame(np.random.randn(N * 10, N))\n        self.df2 = DataFrame(np.random.randn(N * 50, 10))\n        self.df3 = DataFrame(\n            np.random.randn(N, 5 * N), columns=[\"C\" + str(c) for c in range(N * 5)]\n        )\n        self.df4 = DataFrame(np.random.randn(N * 1000, 10))", "min_run_count": 2, "name": "frame_methods.Iteration.time_itertuples_start", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 120, "type": "time", "unit": "seconds", "version": "beae2a24376ed50a9a214101ac7828899ca3db4436d6f61cc38ac099202d2dfd", "warmup_time": -1}, "frame_methods.Iteration.time_itertuples_to_list": {"code": "class Iteration:\n    def time_itertuples_to_list(self):\n        list(self.df4.itertuples())\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Iteration:\n    def setup(self):\n        N = 1000\n        self.df = DataFrame(np.random.randn(N * 10, N))\n        self.df2 = DataFrame(np.random.randn(N * 50, 10))\n        self.df3 = DataFrame(\n            np.random.randn(N, 5 * N), columns=[\"C\" + str(c) for c in range(N * 5)]\n        )\n        self.df4 = DataFrame(np.random.randn(N * 1000, 10))", "min_run_count": 2, "name": "frame_methods.Iteration.time_itertuples_to_list", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 120, "type": "time", "unit": "seconds", "version": "a5fc1a49acb90aa9c123ba866a88ff4f8c508c4cfef59faa117d0da770f63698", "warmup_time": -1}, "frame_methods.MaskBool.time_frame_mask_bools": {"code": "class MaskBool:\n    def time_frame_mask_bools(self):\n        self.bools.mask(self.mask)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass MaskBool:\n    def setup(self):\n        data = np.random.randn(1000, 500)\n        df = DataFrame(data)\n        df = df.where(df > 0)\n        self.bools = df > 0\n        self.mask = isnull(df)", "min_run_count": 2, "name": "frame_methods.MaskBool.time_frame_mask_bools", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "75d26deea512c14af4e7569f5dc1e43324ed79283c789db2fb4999d0d7853441", "warmup_time": -1}, "frame_methods.MaskBool.time_frame_mask_floats": {"code": "class MaskBool:\n    def time_frame_mask_floats(self):\n        self.bools.astype(float).mask(self.mask)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass MaskBool:\n    def setup(self):\n        data = np.random.randn(1000, 500)\n        df = DataFrame(data)\n        df = df.where(df > 0)\n        self.bools = df > 0\n        self.mask = isnull(df)", "min_run_count": 2, "name": "frame_methods.MaskBool.time_frame_mask_floats", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "77725b9d5309bb967bcd8a8abd4d5a8168f1759ac192d051fe68d191166e9b7e", "warmup_time": -1}, "frame_methods.MemoryUsage.time_memory_usage": {"code": "class MemoryUsage:\n    def time_memory_usage(self):\n        self.df.memory_usage(deep=True)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass MemoryUsage:\n    def setup(self):\n        self.df = DataFrame(np.random.randn(100000, 2), columns=list(\"AB\"))\n        self.df2 = self.df.copy()\n        self.df2[\"A\"] = self.df2[\"A\"].astype(\"object\")", "min_run_count": 2, "name": "frame_methods.MemoryUsage.time_memory_usage", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "abaa03ed61b94b958c09bee89d52d1b87d72796639ec7588559d5b158f8dede9", "warmup_time": -1}, "frame_methods.MemoryUsage.time_memory_usage_object_dtype": {"code": "class MemoryUsage:\n    def time_memory_usage_object_dtype(self):\n        self.df2.memory_usage(deep=True)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass MemoryUsage:\n    def setup(self):\n        self.df = DataFrame(np.random.randn(100000, 2), columns=list(\"AB\"))\n        self.df2 = self.df.copy()\n        self.df2[\"A\"] = self.df2[\"A\"].astype(\"object\")", "min_run_count": 2, "name": "frame_methods.MemoryUsage.time_memory_usage_object_dtype", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "f25a399ce1ee970c20943c1c0c1d8359a80848bf10be1b7912eae51ee454231a", "warmup_time": -1}, "frame_methods.NSort.time_nlargest_one_column": {"code": "class NSort:\n    def time_nlargest_one_column(self, keep):\n        self.df.nlargest(100, \"A\", keep=keep)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass NSort:\n    def setup(self, keep):\n        self.df = DataFrame(np.random.randn(100000, 3), columns=list(\"ABC\"))", "min_run_count": 2, "name": "frame_methods.NSort.time_nlargest_one_column", "number": 0, "param_names": ["keep"], "params": [["'first'", "'last'", "'all'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "ae8ee646412a2720d7755ec64e5f1a787ddb6242469e44c8e3f548a93c55eb32", "warmup_time": -1}, "frame_methods.NSort.time_nlargest_two_columns": {"code": "class NSort:\n    def time_nlargest_two_columns(self, keep):\n        self.df.nlargest(100, [\"A\", \"B\"], keep=keep)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass NSort:\n    def setup(self, keep):\n        self.df = DataFrame(np.random.randn(100000, 3), columns=list(\"ABC\"))", "min_run_count": 2, "name": "frame_methods.NSort.time_nlargest_two_columns", "number": 0, "param_names": ["keep"], "params": [["'first'", "'last'", "'all'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "fb06c1f8251bd2a6af6ab02b7dbf651402818b3898c88c5f634d4999eb180730", "warmup_time": -1}, "frame_methods.NSort.time_nsmallest_one_column": {"code": "class NSort:\n    def time_nsmallest_one_column(self, keep):\n        self.df.nsmallest(100, \"A\", keep=keep)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass NSort:\n    def setup(self, keep):\n        self.df = DataFrame(np.random.randn(100000, 3), columns=list(\"ABC\"))", "min_run_count": 2, "name": "frame_methods.NSort.time_nsmallest_one_column", "number": 0, "param_names": ["keep"], "params": [["'first'", "'last'", "'all'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "602770ac5530f5b88477e395308b8146dcf5adb79187c8d34b0201ba44680a2e", "warmup_time": -1}, "frame_methods.NSort.time_nsmallest_two_columns": {"code": "class NSort:\n    def time_nsmallest_two_columns(self, keep):\n        self.df.nsmallest(100, [\"A\", \"B\"], keep=keep)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass NSort:\n    def setup(self, keep):\n        self.df = DataFrame(np.random.randn(100000, 3), columns=list(\"ABC\"))", "min_run_count": 2, "name": "frame_methods.NSort.time_nsmallest_two_columns", "number": 0, "param_names": ["keep"], "params": [["'first'", "'last'", "'all'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "27757c983389573bb278541de8a55e9ac92f47fc4c94a64054207953192b17d7", "warmup_time": -1}, "frame_methods.Nunique.time_frame_nunique": {"code": "class Nunique:\n    def time_frame_nunique(self):\n        self.df.nunique()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Nunique:\n    def setup(self):\n        self.df = DataFrame(np.random.randn(10000, 1000))", "min_run_count": 2, "name": "frame_methods.Nunique.time_frame_nunique", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "7b4f1bb3132faa41cd11750a8882705594d2e2437af6d28e1c6648950e7d0c46", "warmup_time": -1}, "frame_methods.Quantile.time_frame_quantile": {"code": "class Quantile:\n    def time_frame_quantile(self, axis):\n        self.df.quantile([0.1, 0.5], axis=axis)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Quantile:\n    def setup(self, axis):\n        self.df = DataFrame(np.random.randn(1000, 3), columns=list(\"ABC\"))", "min_run_count": 2, "name": "frame_methods.Quantile.time_frame_quantile", "number": 0, "param_names": ["axis"], "params": [["0", "1"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "e46972758e099994281698947a2e05eda1f226d307e25f58fb72796cedd8908f", "warmup_time": -1}, "frame_methods.Rank.time_rank": {"code": "class Rank:\n    def time_rank(self, dtype):\n        self.df.rank()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Rank:\n    def setup(self, dtype):\n        self.df = DataFrame(\n            np.random.randn(10000, 10).astype(dtype), columns=range(10), dtype=dtype\n        )", "min_run_count": 2, "name": "frame_methods.Rank.time_rank", "number": 0, "param_names": ["dtype"], "params": [["'int'", "'uint'", "'float'", "'object'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "4512f531d4398c0997ffb9c0b076476cab3bef280e5662032d20d3b76f2e26cb", "warmup_time": -1}, "frame_methods.Reindex.time_reindex_axis0": {"code": "class Reindex:\n    def time_reindex_axis0(self):\n        self.df.reindex(self.idx)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Reindex:\n    def setup(self):\n        N = 10**3\n        self.df = DataFrame(np.random.randn(N * 10, N))\n        self.idx = np.arange(4 * N, 7 * N)\n        self.idx_cols = np.random.randint(0, N, N)\n        self.df2 = DataFrame(\n            {\n                c: {\n                    0: np.random.randint(0, 2, N).astype(np.bool_),\n                    1: np.random.randint(0, N, N).astype(np.int16),\n                    2: np.random.randint(0, N, N).astype(np.int32),\n                    3: np.random.randint(0, N, N).astype(np.int64),\n                }[np.random.randint(0, 4)]\n                for c in range(N)\n            }\n        )", "min_run_count": 2, "name": "frame_methods.Reindex.time_reindex_axis0", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "8e312cd3e03e3d1f3c1440ed72a1f0a6056d79a9045d8f1ee844b2188f613054", "warmup_time": -1}, "frame_methods.Reindex.time_reindex_axis1": {"code": "class Reindex:\n    def time_reindex_axis1(self):\n        self.df.reindex(columns=self.idx_cols)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Reindex:\n    def setup(self):\n        N = 10**3\n        self.df = DataFrame(np.random.randn(N * 10, N))\n        self.idx = np.arange(4 * N, 7 * N)\n        self.idx_cols = np.random.randint(0, N, N)\n        self.df2 = DataFrame(\n            {\n                c: {\n                    0: np.random.randint(0, 2, N).astype(np.bool_),\n                    1: np.random.randint(0, N, N).astype(np.int16),\n                    2: np.random.randint(0, N, N).astype(np.int32),\n                    3: np.random.randint(0, N, N).astype(np.int64),\n                }[np.random.randint(0, 4)]\n                for c in range(N)\n            }\n        )", "min_run_count": 2, "name": "frame_methods.Reindex.time_reindex_axis1", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "4a93950c7bd7528bd910907cda4f0ff4d5194febad4f498b87cc400feff0d1a6", "warmup_time": -1}, "frame_methods.Reindex.time_reindex_axis1_missing": {"code": "class Reindex:\n    def time_reindex_axis1_missing(self):\n        self.df.reindex(columns=self.idx)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Reindex:\n    def setup(self):\n        N = 10**3\n        self.df = DataFrame(np.random.randn(N * 10, N))\n        self.idx = np.arange(4 * N, 7 * N)\n        self.idx_cols = np.random.randint(0, N, N)\n        self.df2 = DataFrame(\n            {\n                c: {\n                    0: np.random.randint(0, 2, N).astype(np.bool_),\n                    1: np.random.randint(0, N, N).astype(np.int16),\n                    2: np.random.randint(0, N, N).astype(np.int32),\n                    3: np.random.randint(0, N, N).astype(np.int64),\n                }[np.random.randint(0, 4)]\n                for c in range(N)\n            }\n        )", "min_run_count": 2, "name": "frame_methods.Reindex.time_reindex_axis1_missing", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "7749b0b3b38ff50cbd6509455c235277f2f3cc7ea7bb8642397cfe79fcd2025d", "warmup_time": -1}, "frame_methods.Reindex.time_reindex_both_axes": {"code": "class Reindex:\n    def time_reindex_both_axes(self):\n        self.df.reindex(index=self.idx, columns=self.idx_cols)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Reindex:\n    def setup(self):\n        N = 10**3\n        self.df = DataFrame(np.random.randn(N * 10, N))\n        self.idx = np.arange(4 * N, 7 * N)\n        self.idx_cols = np.random.randint(0, N, N)\n        self.df2 = DataFrame(\n            {\n                c: {\n                    0: np.random.randint(0, 2, N).astype(np.bool_),\n                    1: np.random.randint(0, N, N).astype(np.int16),\n                    2: np.random.randint(0, N, N).astype(np.int32),\n                    3: np.random.randint(0, N, N).astype(np.int64),\n                }[np.random.randint(0, 4)]\n                for c in range(N)\n            }\n        )", "min_run_count": 2, "name": "frame_methods.Reindex.time_reindex_both_axes", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "06ce9de462c065fcb31edc17bbaa87b044287b757a29abc717d85764e418e727", "warmup_time": -1}, "frame_methods.Reindex.time_reindex_upcast": {"code": "class Reindex:\n    def time_reindex_upcast(self):\n        self.df2.reindex(np.random.permutation(range(1200)))\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Reindex:\n    def setup(self):\n        N = 10**3\n        self.df = DataFrame(np.random.randn(N * 10, N))\n        self.idx = np.arange(4 * N, 7 * N)\n        self.idx_cols = np.random.randint(0, N, N)\n        self.df2 = DataFrame(\n            {\n                c: {\n                    0: np.random.randint(0, 2, N).astype(np.bool_),\n                    1: np.random.randint(0, N, N).astype(np.int16),\n                    2: np.random.randint(0, N, N).astype(np.int32),\n                    3: np.random.randint(0, N, N).astype(np.int64),\n                }[np.random.randint(0, 4)]\n                for c in range(N)\n            }\n        )", "min_run_count": 2, "name": "frame_methods.Reindex.time_reindex_upcast", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "8d05018638e09bdfc144121f846b4c2bef1cf019e84b76006bbdef08e268a466", "warmup_time": -1}, "frame_methods.Rename.time_dict_rename_both_axes": {"code": "class Rename:\n    def time_dict_rename_both_axes(self):\n        self.df.rename(index=self.dict_idx, columns=self.dict_idx)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Rename:\n    def setup(self):\n        N = 10**3\n        self.df = DataFrame(np.random.randn(N * 10, N))\n        self.idx = np.arange(4 * N, 7 * N)\n        self.dict_idx = {k: k for k in self.idx}\n        self.df2 = DataFrame(\n            {\n                c: {\n                    0: np.random.randint(0, 2, N).astype(np.bool_),\n                    1: np.random.randint(0, N, N).astype(np.int16),\n                    2: np.random.randint(0, N, N).astype(np.int32),\n                    3: np.random.randint(0, N, N).astype(np.int64),\n                }[np.random.randint(0, 4)]\n                for c in range(N)\n            }\n        )", "min_run_count": 2, "name": "frame_methods.Rename.time_dict_rename_both_axes", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "060b0d33988e4009693f1109e6274a165c7e1b54c2ce817d60a436c7b6f46325", "warmup_time": -1}, "frame_methods.Rename.time_rename_axis0": {"code": "class Rename:\n    def time_rename_axis0(self):\n        self.df.rename(self.dict_idx)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Rename:\n    def setup(self):\n        N = 10**3\n        self.df = DataFrame(np.random.randn(N * 10, N))\n        self.idx = np.arange(4 * N, 7 * N)\n        self.dict_idx = {k: k for k in self.idx}\n        self.df2 = DataFrame(\n            {\n                c: {\n                    0: np.random.randint(0, 2, N).astype(np.bool_),\n                    1: np.random.randint(0, N, N).astype(np.int16),\n                    2: np.random.randint(0, N, N).astype(np.int32),\n                    3: np.random.randint(0, N, N).astype(np.int64),\n                }[np.random.randint(0, 4)]\n                for c in range(N)\n            }\n        )", "min_run_count": 2, "name": "frame_methods.Rename.time_rename_axis0", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "7442ed7fc2e73ac7a280c1909b8a01ab6e5269f51652c483a3af6288beea66ea", "warmup_time": -1}, "frame_methods.Rename.time_rename_axis1": {"code": "class Rename:\n    def time_rename_axis1(self):\n        self.df.rename(columns=self.dict_idx)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Rename:\n    def setup(self):\n        N = 10**3\n        self.df = DataFrame(np.random.randn(N * 10, N))\n        self.idx = np.arange(4 * N, 7 * N)\n        self.dict_idx = {k: k for k in self.idx}\n        self.df2 = DataFrame(\n            {\n                c: {\n                    0: np.random.randint(0, 2, N).astype(np.bool_),\n                    1: np.random.randint(0, N, N).astype(np.int16),\n                    2: np.random.randint(0, N, N).astype(np.int32),\n                    3: np.random.randint(0, N, N).astype(np.int64),\n                }[np.random.randint(0, 4)]\n                for c in range(N)\n            }\n        )", "min_run_count": 2, "name": "frame_methods.Rename.time_rename_axis1", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "95e21d6ec76ff34607840fa82609ec8b610013d6bd877d0092453f968a5384f6", "warmup_time": -1}, "frame_methods.Rename.time_rename_both_axes": {"code": "class Rename:\n    def time_rename_both_axes(self):\n        self.df.rename(index=self.dict_idx, columns=self.dict_idx)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Rename:\n    def setup(self):\n        N = 10**3\n        self.df = DataFrame(np.random.randn(N * 10, N))\n        self.idx = np.arange(4 * N, 7 * N)\n        self.dict_idx = {k: k for k in self.idx}\n        self.df2 = DataFrame(\n            {\n                c: {\n                    0: np.random.randint(0, 2, N).astype(np.bool_),\n                    1: np.random.randint(0, N, N).astype(np.int16),\n                    2: np.random.randint(0, N, N).astype(np.int32),\n                    3: np.random.randint(0, N, N).astype(np.int64),\n                }[np.random.randint(0, 4)]\n                for c in range(N)\n            }\n        )", "min_run_count": 2, "name": "frame_methods.Rename.time_rename_both_axes", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "57060b21c7592bb4bd46070429134f61a772694a95ed1014c9c65df5e0f43873", "warmup_time": -1}, "frame_methods.Rename.time_rename_single": {"code": "class Rename:\n    def time_rename_single(self):\n        self.df.rename({0: 0})\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Rename:\n    def setup(self):\n        N = 10**3\n        self.df = DataFrame(np.random.randn(N * 10, N))\n        self.idx = np.arange(4 * N, 7 * N)\n        self.dict_idx = {k: k for k in self.idx}\n        self.df2 = DataFrame(\n            {\n                c: {\n                    0: np.random.randint(0, 2, N).astype(np.bool_),\n                    1: np.random.randint(0, N, N).astype(np.int16),\n                    2: np.random.randint(0, N, N).astype(np.int32),\n                    3: np.random.randint(0, N, N).astype(np.int64),\n                }[np.random.randint(0, 4)]\n                for c in range(N)\n            }\n        )", "min_run_count": 2, "name": "frame_methods.Rename.time_rename_single", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "ddc80d464ece8f0b4fabad5fcb4cbb0729ffdb09e225469ff23f5e49ed1ac8c4", "warmup_time": -1}, "frame_methods.Repr.time_frame_repr_wide": {"code": "class Repr:\n    def time_frame_repr_wide(self):\n        repr(self.df_wide)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Repr:\n    def setup(self):\n        nrows = 10000\n        data = np.random.randn(nrows, 10)\n        arrays = np.tile(np.random.randn(3, nrows // 100), 100)\n        idx = MultiIndex.from_arrays(arrays)\n        self.df3 = DataFrame(data, index=idx)\n        self.df4 = DataFrame(data, index=np.random.randn(nrows))\n        self.df_tall = DataFrame(np.random.randn(nrows, 10))\n        self.df_wide = DataFrame(np.random.randn(10, nrows))", "min_run_count": 2, "name": "frame_methods.Repr.time_frame_repr_wide", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "b7c902cd0a2f02eebcb938f83eb0bc567c8bf80146ce7c09a335b559e8715a33", "warmup_time": -1}, "frame_methods.Repr.time_html_repr_trunc_mi": {"code": "class Repr:\n    def time_html_repr_trunc_mi(self):\n        self.df3._repr_html_()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Repr:\n    def setup(self):\n        nrows = 10000\n        data = np.random.randn(nrows, 10)\n        arrays = np.tile(np.random.randn(3, nrows // 100), 100)\n        idx = MultiIndex.from_arrays(arrays)\n        self.df3 = DataFrame(data, index=idx)\n        self.df4 = DataFrame(data, index=np.random.randn(nrows))\n        self.df_tall = DataFrame(np.random.randn(nrows, 10))\n        self.df_wide = DataFrame(np.random.randn(10, nrows))", "min_run_count": 2, "name": "frame_methods.Repr.time_html_repr_trunc_mi", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "c5988920e0b3d00d1ec74379b4576a53ad6b17e4c9b71625316958d163ed4164", "warmup_time": -1}, "frame_methods.Repr.time_html_repr_trunc_si": {"code": "class Repr:\n    def time_html_repr_trunc_si(self):\n        self.df4._repr_html_()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Repr:\n    def setup(self):\n        nrows = 10000\n        data = np.random.randn(nrows, 10)\n        arrays = np.tile(np.random.randn(3, nrows // 100), 100)\n        idx = MultiIndex.from_arrays(arrays)\n        self.df3 = DataFrame(data, index=idx)\n        self.df4 = DataFrame(data, index=np.random.randn(nrows))\n        self.df_tall = DataFrame(np.random.randn(nrows, 10))\n        self.df_wide = DataFrame(np.random.randn(10, nrows))", "min_run_count": 2, "name": "frame_methods.Repr.time_html_repr_trunc_si", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "8fd8968223faa897090a27941e475b84b23f11c40bb5c7541e6f71c9fb9376a3", "warmup_time": -1}, "frame_methods.Repr.time_repr_tall": {"code": "class Repr:\n    def time_repr_tall(self):\n        repr(self.df_tall)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Repr:\n    def setup(self):\n        nrows = 10000\n        data = np.random.randn(nrows, 10)\n        arrays = np.tile(np.random.randn(3, nrows // 100), 100)\n        idx = MultiIndex.from_arrays(arrays)\n        self.df3 = DataFrame(data, index=idx)\n        self.df4 = DataFrame(data, index=np.random.randn(nrows))\n        self.df_tall = DataFrame(np.random.randn(nrows, 10))\n        self.df_wide = DataFrame(np.random.randn(10, nrows))", "min_run_count": 2, "name": "frame_methods.Repr.time_repr_tall", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "57c3fcd319895e084cdc6f5e24084880d4817e72dd3fe35856b00b69e7ea1742", "warmup_time": -1}, "frame_methods.Round.peakmem_round": {"code": "class Round:\n    def peakmem_round(self):\n        self.df.round()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Round:\n    def setup(self):\n        self.df = DataFrame(np.random.randn(10000, 10))\n        self.df_t = self.df.transpose(copy=True)", "name": "frame_methods.Round.peakmem_round", "param_names": [], "params": [], "timeout": 60.0, "type": "peakmemory", "unit": "bytes", "version": "6030b93289557c8c988898eb2865291b8bbb65999e8761c6dedd7d32eeae984c"}, "frame_methods.Round.peakmem_round_transposed": {"code": "class Round:\n    def peakmem_round_transposed(self):\n        self.df_t.round()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Round:\n    def setup(self):\n        self.df = DataFrame(np.random.randn(10000, 10))\n        self.df_t = self.df.transpose(copy=True)", "name": "frame_methods.Round.peakmem_round_transposed", "param_names": [], "params": [], "timeout": 60.0, "type": "peakmemory", "unit": "bytes", "version": "919cd08ae6984fe9193852f5e8b5432e1bc12537c5e39da7333f549a5e72ab37"}, "frame_methods.Round.time_round": {"code": "class Round:\n    def time_round(self):\n        self.df.round()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Round:\n    def setup(self):\n        self.df = DataFrame(np.random.randn(10000, 10))\n        self.df_t = self.df.transpose(copy=True)", "min_run_count": 2, "name": "frame_methods.Round.time_round", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "96ca48bf009b1f5637ae83a659df490757d37c26fee67d6a45104d6e0bf32219", "warmup_time": -1}, "frame_methods.Round.time_round_transposed": {"code": "class Round:\n    def time_round_transposed(self):\n        self.df_t.round()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Round:\n    def setup(self):\n        self.df = DataFrame(np.random.randn(10000, 10))\n        self.df_t = self.df.transpose(copy=True)", "min_run_count": 2, "name": "frame_methods.Round.time_round_transposed", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "19596a27ad277a08b79ca33e2b9773ebc43379e2443ff070f4b60f930bcef9d8", "warmup_time": -1}, "frame_methods.SeriesNuniqueWithNan.time_series_nunique_nan": {"code": "class SeriesNuniqueWithNan:\n    def time_series_nunique_nan(self):\n        self.ser.nunique()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass SeriesNuniqueWithNan:\n    def setup(self):\n        values = 100 * [np.nan] + list(range(100))\n        self.ser = Series(np.tile(values, 10000), dtype=float)", "min_run_count": 2, "name": "frame_methods.SeriesNuniqueWithNan.time_series_nunique_nan", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "bdb51c04637dc0c9c73bb2a3b6a2ffee3ae1b5517fb485dfb8f1c5e562c5c6c7", "warmup_time": -1}, "frame_methods.Shift.time_shift": {"code": "class Shift:\n    def time_shift(self, axis):\n        self.df.shift(1, axis=axis)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Shift:\n    def setup(self, axis):\n        self.df = DataFrame(np.random.rand(10000, 500))", "min_run_count": 2, "name": "frame_methods.Shift.time_shift", "number": 0, "param_names": ["axis"], "params": [["0", "1"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "09d28e1e7b36fe4dfa6ed22317da40bcde0164c120b61d4efff8f61b02c768af", "warmup_time": -1}, "frame_methods.SortMultiKey.time_sort_index": {"code": "class SortMultiKey:\n    def time_sort_index(self, monotonic):\n        self.df_by_index.sort_index()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass SortMultiKey:\n    def setup(self, monotonic):\n        N = 10000\n        K = 10\n        df = DataFrame(\n            {\n                \"key1\": Index([f\"i-{i}\" for i in range(N)], dtype=object).values.repeat(\n                    K\n                ),\n                \"key2\": Index([f\"i-{i}\" for i in range(N)], dtype=object).values.repeat(\n                    K\n                ),\n                \"value\": np.random.randn(N * K),\n            }\n        )\n        if monotonic:\n            df = df.sort_values([\"key1\", \"key2\"])\n        self.df_by_columns = df\n        self.df_by_index = df.set_index([\"key1\", \"key2\"])", "min_run_count": 2, "name": "frame_methods.SortMultiKey.time_sort_index", "number": 0, "param_names": ["monotonic"], "params": [["True", "False"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "14e8d6aab1e556f8caea675776001969164ccf76049c529a3e0077ee8a56b7ba", "warmup_time": -1}, "frame_methods.SortMultiKey.time_sort_values": {"code": "class SortMultiKey:\n    def time_sort_values(self, monotonic):\n        self.df_by_columns.sort_values(by=[\"key1\", \"key2\"])\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass SortMultiKey:\n    def setup(self, monotonic):\n        N = 10000\n        K = 10\n        df = DataFrame(\n            {\n                \"key1\": Index([f\"i-{i}\" for i in range(N)], dtype=object).values.repeat(\n                    K\n                ),\n                \"key2\": Index([f\"i-{i}\" for i in range(N)], dtype=object).values.repeat(\n                    K\n                ),\n                \"value\": np.random.randn(N * K),\n            }\n        )\n        if monotonic:\n            df = df.sort_values([\"key1\", \"key2\"])\n        self.df_by_columns = df\n        self.df_by_index = df.set_index([\"key1\", \"key2\"])", "min_run_count": 2, "name": "frame_methods.SortMultiKey.time_sort_values", "number": 0, "param_names": ["monotonic"], "params": [["True", "False"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "2742a8d577f8f9f13eee3c04ba10dec5ca223b766b72708333b2bb9240ff7007", "warmup_time": -1}, "frame_methods.SortValues.time_frame_sort_values": {"code": "class SortValues:\n    def time_frame_sort_values(self, ascending):\n        self.df.sort_values(by=\"A\", ascending=ascending)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass SortValues:\n    def setup(self, ascending):\n        self.df = DataFrame(np.random.randn(1000000, 2), columns=list(\"AB\"))", "min_run_count": 2, "name": "frame_methods.SortValues.time_frame_sort_values", "number": 0, "param_names": ["ascending"], "params": [["True", "False"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "bf9c8ff877f2cd95431692cfe963e37b3de4634176be673d3de0b663177d7ad3", "warmup_time": -1}, "frame_methods.ToDict.time_to_dict_datetimelike": {"code": "class ToDict:\n    def time_to_dict_datetimelike(self, orient):\n        self.datetimelike_df.to_dict(orient=orient)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToDict:\n    def setup(self, orient):\n        data = np.random.randint(0, 1000, size=(10000, 4))\n        self.int_df = DataFrame(data)\n        self.datetimelike_df = self.int_df.astype(\"timedelta64[ns]\")", "min_run_count": 2, "name": "frame_methods.ToDict.time_to_dict_datetimelike", "number": 0, "param_names": ["orient"], "params": [["'dict'", "'list'", "'series'", "'split'", "'records'", "'index'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "939f612766529ae46a0b196a3dc13061331265310113f5a5c18d503fd623eb63", "warmup_time": -1}, "frame_methods.ToDict.time_to_dict_ints": {"code": "class ToDict:\n    def time_to_dict_ints(self, orient):\n        self.int_df.to_dict(orient=orient)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToDict:\n    def setup(self, orient):\n        data = np.random.randint(0, 1000, size=(10000, 4))\n        self.int_df = DataFrame(data)\n        self.datetimelike_df = self.int_df.astype(\"timedelta64[ns]\")", "min_run_count": 2, "name": "frame_methods.ToDict.time_to_dict_ints", "number": 0, "param_names": ["orient"], "params": [["'dict'", "'list'", "'series'", "'split'", "'records'", "'index'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "8ca05db38583b86c56e9781a0ba1f399533c5e196accee6737c23ade9750f5c9", "warmup_time": -1}, "frame_methods.ToHTML.time_to_html_mixed": {"code": "class ToHTML:\n    def time_to_html_mixed(self):\n        self.df2.to_html()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToHTML:\n    def setup(self):\n        nrows = 500\n        self.df2 = DataFrame(np.random.randn(nrows, 10))\n        self.df2[0] = period_range(\"2000\", periods=nrows)\n        self.df2[1] = range(nrows)", "min_run_count": 2, "name": "frame_methods.ToHTML.time_to_html_mixed", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "a63bfb2f9452ef12121452e5a13a47f1ddf16d3a2ecc961f1d143598ae48a31a", "warmup_time": -1}, "frame_methods.ToNumpy.time_to_numpy_mixed_tall": {"code": "class ToNumpy:\n    def time_to_numpy_mixed_tall(self):\n        self.df_mixed_tall.to_numpy()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToNumpy:\n    def setup(self):\n        N = 10000\n        M = 10\n        self.df_tall = DataFrame(np.random.randn(N, M))\n        self.df_wide = DataFrame(np.random.randn(M, N))\n        self.df_mixed_tall = self.df_tall.copy()\n        self.df_mixed_tall[\"foo\"] = \"bar\"\n        self.df_mixed_tall[0] = period_range(\"2000\", periods=N)\n        self.df_mixed_tall[1] = range(N)\n        self.df_mixed_wide = self.df_wide.copy()\n        self.df_mixed_wide[\"foo\"] = \"bar\"\n        self.df_mixed_wide[0] = period_range(\"2000\", periods=M)\n        self.df_mixed_wide[1] = range(M)", "min_run_count": 2, "name": "frame_methods.ToNumpy.time_to_numpy_mixed_tall", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "5609d5ea9c8d63719954d185af31995af502969500f52a283b95dee96b206b21", "warmup_time": -1}, "frame_methods.ToNumpy.time_to_numpy_mixed_wide": {"code": "class ToNumpy:\n    def time_to_numpy_mixed_wide(self):\n        self.df_mixed_wide.to_numpy()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToNumpy:\n    def setup(self):\n        N = 10000\n        M = 10\n        self.df_tall = DataFrame(np.random.randn(N, M))\n        self.df_wide = DataFrame(np.random.randn(M, N))\n        self.df_mixed_tall = self.df_tall.copy()\n        self.df_mixed_tall[\"foo\"] = \"bar\"\n        self.df_mixed_tall[0] = period_range(\"2000\", periods=N)\n        self.df_mixed_tall[1] = range(N)\n        self.df_mixed_wide = self.df_wide.copy()\n        self.df_mixed_wide[\"foo\"] = \"bar\"\n        self.df_mixed_wide[0] = period_range(\"2000\", periods=M)\n        self.df_mixed_wide[1] = range(M)", "min_run_count": 2, "name": "frame_methods.ToNumpy.time_to_numpy_mixed_wide", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "b8cf4cdbf480bfa101b1e9bbf6df8e6a9516540d5888f9acf40c29f0b39c4178", "warmup_time": -1}, "frame_methods.ToNumpy.time_to_numpy_tall": {"code": "class ToNumpy:\n    def time_to_numpy_tall(self):\n        self.df_tall.to_numpy()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToNumpy:\n    def setup(self):\n        N = 10000\n        M = 10\n        self.df_tall = DataFrame(np.random.randn(N, M))\n        self.df_wide = DataFrame(np.random.randn(M, N))\n        self.df_mixed_tall = self.df_tall.copy()\n        self.df_mixed_tall[\"foo\"] = \"bar\"\n        self.df_mixed_tall[0] = period_range(\"2000\", periods=N)\n        self.df_mixed_tall[1] = range(N)\n        self.df_mixed_wide = self.df_wide.copy()\n        self.df_mixed_wide[\"foo\"] = \"bar\"\n        self.df_mixed_wide[0] = period_range(\"2000\", periods=M)\n        self.df_mixed_wide[1] = range(M)", "min_run_count": 2, "name": "frame_methods.ToNumpy.time_to_numpy_tall", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "5569b6deed04489b4f459b07dc638df2d11771fc68bd230503521874fd8280e9", "warmup_time": -1}, "frame_methods.ToNumpy.time_to_numpy_wide": {"code": "class ToNumpy:\n    def time_to_numpy_wide(self):\n        self.df_wide.to_numpy()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToNumpy:\n    def setup(self):\n        N = 10000\n        M = 10\n        self.df_tall = DataFrame(np.random.randn(N, M))\n        self.df_wide = DataFrame(np.random.randn(M, N))\n        self.df_mixed_tall = self.df_tall.copy()\n        self.df_mixed_tall[\"foo\"] = \"bar\"\n        self.df_mixed_tall[0] = period_range(\"2000\", periods=N)\n        self.df_mixed_tall[1] = range(N)\n        self.df_mixed_wide = self.df_wide.copy()\n        self.df_mixed_wide[\"foo\"] = \"bar\"\n        self.df_mixed_wide[0] = period_range(\"2000\", periods=M)\n        self.df_mixed_wide[1] = range(M)", "min_run_count": 2, "name": "frame_methods.ToNumpy.time_to_numpy_wide", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "bf654b3ba6daa0281ee0f2802eb3d2aeda580273f37f51975c0a6949c7f80d88", "warmup_time": -1}, "frame_methods.ToNumpy.time_values_mixed_tall": {"code": "class ToNumpy:\n    def time_values_mixed_tall(self):\n        self.df_mixed_tall.values\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToNumpy:\n    def setup(self):\n        N = 10000\n        M = 10\n        self.df_tall = DataFrame(np.random.randn(N, M))\n        self.df_wide = DataFrame(np.random.randn(M, N))\n        self.df_mixed_tall = self.df_tall.copy()\n        self.df_mixed_tall[\"foo\"] = \"bar\"\n        self.df_mixed_tall[0] = period_range(\"2000\", periods=N)\n        self.df_mixed_tall[1] = range(N)\n        self.df_mixed_wide = self.df_wide.copy()\n        self.df_mixed_wide[\"foo\"] = \"bar\"\n        self.df_mixed_wide[0] = period_range(\"2000\", periods=M)\n        self.df_mixed_wide[1] = range(M)", "min_run_count": 2, "name": "frame_methods.ToNumpy.time_values_mixed_tall", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "63f9938602ca8bd629ccf01754db81ac30be79e67c04b0f0773bc5b0d042f33d", "warmup_time": -1}, "frame_methods.ToNumpy.time_values_mixed_wide": {"code": "class ToNumpy:\n    def time_values_mixed_wide(self):\n        self.df_mixed_wide.values\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToNumpy:\n    def setup(self):\n        N = 10000\n        M = 10\n        self.df_tall = DataFrame(np.random.randn(N, M))\n        self.df_wide = DataFrame(np.random.randn(M, N))\n        self.df_mixed_tall = self.df_tall.copy()\n        self.df_mixed_tall[\"foo\"] = \"bar\"\n        self.df_mixed_tall[0] = period_range(\"2000\", periods=N)\n        self.df_mixed_tall[1] = range(N)\n        self.df_mixed_wide = self.df_wide.copy()\n        self.df_mixed_wide[\"foo\"] = \"bar\"\n        self.df_mixed_wide[0] = period_range(\"2000\", periods=M)\n        self.df_mixed_wide[1] = range(M)", "min_run_count": 2, "name": "frame_methods.ToNumpy.time_values_mixed_wide", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "fafed5c463a9d832b1c45ce00e7755cf10235ae288cb4939713e9e25b2884d1e", "warmup_time": -1}, "frame_methods.ToNumpy.time_values_tall": {"code": "class ToNumpy:\n    def time_values_tall(self):\n        self.df_tall.values\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToNumpy:\n    def setup(self):\n        N = 10000\n        M = 10\n        self.df_tall = DataFrame(np.random.randn(N, M))\n        self.df_wide = DataFrame(np.random.randn(M, N))\n        self.df_mixed_tall = self.df_tall.copy()\n        self.df_mixed_tall[\"foo\"] = \"bar\"\n        self.df_mixed_tall[0] = period_range(\"2000\", periods=N)\n        self.df_mixed_tall[1] = range(N)\n        self.df_mixed_wide = self.df_wide.copy()\n        self.df_mixed_wide[\"foo\"] = \"bar\"\n        self.df_mixed_wide[0] = period_range(\"2000\", periods=M)\n        self.df_mixed_wide[1] = range(M)", "min_run_count": 2, "name": "frame_methods.ToNumpy.time_values_tall", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "d7415d8faba6d4a8ac5b59b9db979d88981de08547167f51ec5c31b322149dfb", "warmup_time": -1}, "frame_methods.ToNumpy.time_values_wide": {"code": "class ToNumpy:\n    def time_values_wide(self):\n        self.df_wide.values\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToNumpy:\n    def setup(self):\n        N = 10000\n        M = 10\n        self.df_tall = DataFrame(np.random.randn(N, M))\n        self.df_wide = DataFrame(np.random.randn(M, N))\n        self.df_mixed_tall = self.df_tall.copy()\n        self.df_mixed_tall[\"foo\"] = \"bar\"\n        self.df_mixed_tall[0] = period_range(\"2000\", periods=N)\n        self.df_mixed_tall[1] = range(N)\n        self.df_mixed_wide = self.df_wide.copy()\n        self.df_mixed_wide[\"foo\"] = \"bar\"\n        self.df_mixed_wide[0] = period_range(\"2000\", periods=M)\n        self.df_mixed_wide[1] = range(M)", "min_run_count": 2, "name": "frame_methods.ToNumpy.time_values_wide", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "5f1b62f28c9211bb22340a6af83d5b86811950ef975bfd00e0684048cb2de22f", "warmup_time": -1}, "frame_methods.ToRecords.time_to_records": {"code": "class ToRecords:\n    def time_to_records(self):\n        self.df.to_records(index=True)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToRecords:\n    def setup(self):\n        N = 100_000\n        data = np.random.randn(N, 2)\n        mi = MultiIndex.from_arrays(\n            [\n                np.arange(N),\n                date_range(\"1970-01-01\", periods=N, freq=\"ms\"),\n            ]\n        )\n        self.df = DataFrame(data)\n        self.df_mi = DataFrame(data, index=mi)", "min_run_count": 2, "name": "frame_methods.ToRecords.time_to_records", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "f42f25126b3a450ab55465c858ae504d2ded8b644488689fa856b421d41c0cba", "warmup_time": -1}, "frame_methods.ToRecords.time_to_records_multiindex": {"code": "class ToRecords:\n    def time_to_records_multiindex(self):\n        self.df_mi.to_records(index=True)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToRecords:\n    def setup(self):\n        N = 100_000\n        data = np.random.randn(N, 2)\n        mi = MultiIndex.from_arrays(\n            [\n                np.arange(N),\n                date_range(\"1970-01-01\", periods=N, freq=\"ms\"),\n            ]\n        )\n        self.df = DataFrame(data)\n        self.df_mi = DataFrame(data, index=mi)", "min_run_count": 2, "name": "frame_methods.ToRecords.time_to_records_multiindex", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "ba7c2132dec45f9679103e1739697a3c005f6921b9c766546d8535303d90777d", "warmup_time": -1}, "frame_methods.ToString.time_to_string_floats": {"code": "class ToString:\n    def time_to_string_floats(self):\n        self.df.to_string()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToString:\n    def setup(self):\n        self.df = DataFrame(np.random.randn(100, 10))", "min_run_count": 2, "name": "frame_methods.ToString.time_to_string_floats", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "e56ad6695cac3b92e88feb11d8c47fa92f10fb86e51634e87529d771f168cdbf", "warmup_time": -1}, "frame_methods.Where.time_where": {"code": "class Where:\n    def time_where(self, inplace, dtype):\n        self.df.where(self.mask, other=0.0, inplace=inplace)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Where:\n    def setup(self, inplace, dtype):\n        self.df = DataFrame(np.random.randn(100_000, 10), dtype=dtype)\n        self.mask = self.df < 0", "min_run_count": 2, "name": "frame_methods.Where.time_where", "number": 0, "param_names": ["dtype", "param2"], "params": [["True", "False"], ["'float64'", "'Float64'", "'float64[pyarrow]'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "d16b5044f854c91f698425fe60c4f71b7f819334706ddf4e2e6bb35a27c1a928", "warmup_time": -1}, "frame_methods.XS.time_frame_xs": {"code": "class XS:\n    def time_frame_xs(self, axis):\n        self.df.xs(self.N / 2, axis=axis)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass XS:\n    def setup(self, axis):\n        self.N = 10**4\n        self.df = DataFrame(np.random.randn(self.N, self.N))", "min_run_count": 2, "name": "frame_methods.XS.time_frame_xs", "number": 0, "param_names": ["axis"], "params": [["0", "1"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "4c10ba567aab8044d880b7e51f27220a7353cda967ee331f4bf88ebbc2406d4f", "warmup_time": -1}, "gil.ParallelDatetimeFields.time_datetime_field_day": {"code": "class ParallelDatetimeFields:\n    def time_datetime_field_day(self):\n        @test_parallel(num_threads=2)\n        def run(dti):\n            dti.day\n    \n        run(self.dti)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ParallelDatetimeFields:\n    def setup(self):\n        N = 10**6\n        self.dti = date_range(\"1900-01-01\", periods=N, freq=\"min\")\n        self.period = self.dti.to_period(\"D\")", "min_run_count": 2, "name": "gil.ParallelDatetimeFields.time_datetime_field_day", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "57949cef8376be9aca572d8c68a05289b9950b538c13e861ad1b71df817c3515", "warmup_time": -1}, "gil.ParallelDatetimeFields.time_datetime_field_daysinmonth": {"code": "class ParallelDatetimeFields:\n    def time_datetime_field_daysinmonth(self):\n        @test_parallel(num_threads=2)\n        def run(dti):\n            dti.days_in_month\n    \n        run(self.dti)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ParallelDatetimeFields:\n    def setup(self):\n        N = 10**6\n        self.dti = date_range(\"1900-01-01\", periods=N, freq=\"min\")\n        self.period = self.dti.to_period(\"D\")", "min_run_count": 2, "name": "gil.ParallelDatetimeFields.time_datetime_field_daysinmonth", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "e08964e060471859275a5a734b94e650445f8e0db22890e06d5c36b207e103a8", "warmup_time": -1}, "gil.ParallelDatetimeFields.time_datetime_field_normalize": {"code": "class ParallelDatetimeFields:\n    def time_datetime_field_normalize(self):\n        @test_parallel(num_threads=2)\n        def run(dti):\n            dti.normalize()\n    \n        run(self.dti)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ParallelDatetimeFields:\n    def setup(self):\n        N = 10**6\n        self.dti = date_range(\"1900-01-01\", periods=N, freq=\"min\")\n        self.period = self.dti.to_period(\"D\")", "min_run_count": 2, "name": "gil.ParallelDatetimeFields.time_datetime_field_normalize", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "59282e48b58fc897cac7af777786d7dc152983bf0f08d5e8ca7049410a9edfb1", "warmup_time": -1}, "gil.ParallelDatetimeFields.time_datetime_field_year": {"code": "class ParallelDatetimeFields:\n    def time_datetime_field_year(self):\n        @test_parallel(num_threads=2)\n        def run(dti):\n            dti.year\n    \n        run(self.dti)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ParallelDatetimeFields:\n    def setup(self):\n        N = 10**6\n        self.dti = date_range(\"1900-01-01\", periods=N, freq=\"min\")\n        self.period = self.dti.to_period(\"D\")", "min_run_count": 2, "name": "gil.ParallelDatetimeFields.time_datetime_field_year", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "4e6d8e9847ac5022c75aabaff81f2a4ce4528c29b8d2f44d50f8729b732bef51", "warmup_time": -1}, "gil.ParallelDatetimeFields.time_datetime_to_period": {"code": "class ParallelDatetimeFields:\n    def time_datetime_to_period(self):\n        @test_parallel(num_threads=2)\n        def run(dti):\n            dti.to_period(\"s\")\n    \n        run(self.dti)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ParallelDatetimeFields:\n    def setup(self):\n        N = 10**6\n        self.dti = date_range(\"1900-01-01\", periods=N, freq=\"min\")\n        self.period = self.dti.to_period(\"D\")", "min_run_count": 2, "name": "gil.ParallelDatetimeFields.time_datetime_to_period", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "cf5a4f24f7ea1d7e1842a834d7a3ed311331d1375098ccb8bd2423d9df91f03c", "warmup_time": -1}, "gil.ParallelDatetimeFields.time_period_to_datetime": {"code": "class ParallelDatetimeFields:\n    def time_period_to_datetime(self):\n        @test_parallel(num_threads=2)\n        def run(period):\n            period.to_timestamp()\n    \n        run(self.period)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ParallelDatetimeFields:\n    def setup(self):\n        N = 10**6\n        self.dti = date_range(\"1900-01-01\", periods=N, freq=\"min\")\n        self.period = self.dti.to_period(\"D\")", "min_run_count": 2, "name": "gil.ParallelDatetimeFields.time_period_to_datetime", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "3766967574deb647b538a27545eb395e8fce97e83e988ac9785f6865c97084d1", "warmup_time": -1}, "gil.ParallelFactorize.time_loop": {"code": "class ParallelFactorize:\n    def time_loop(self, threads):\n        for i in range(threads):\n            self.loop()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ParallelFactorize:\n    def setup(self, threads):\n        strings = Index([f\"i-{i}\" for i in range(100000)], dtype=object)\n    \n        @test_parallel(num_threads=threads)\n        def parallel():\n            factorize(strings)\n    \n        self.parallel = parallel\n    \n        def loop():\n            factorize(strings)\n    \n        self.loop = loop", "min_run_count": 2, "name": "gil.ParallelFactorize.time_loop", "number": 1, "param_names": ["threads"], "params": [["2", "4", "8"]], "repeat": 5, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "3d702042bf0b72599271c4f0aca5d1cc55c8de89f03071bd59d498a5dbdb8448", "warmup_time": -1}, "gil.ParallelFactorize.time_parallel": {"code": "class ParallelFactorize:\n    def time_parallel(self, threads):\n        self.parallel()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ParallelFactorize:\n    def setup(self, threads):\n        strings = Index([f\"i-{i}\" for i in range(100000)], dtype=object)\n    \n        @test_parallel(num_threads=threads)\n        def parallel():\n            factorize(strings)\n    \n        self.parallel = parallel\n    \n        def loop():\n            factorize(strings)\n    \n        self.loop = loop", "min_run_count": 2, "name": "gil.ParallelFactorize.time_parallel", "number": 1, "param_names": ["threads"], "params": [["2", "4", "8"]], "repeat": 5, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "7a105748ab3e006bf2a891c0883f2103a5c368902e13d14f3a64656e1968793a", "warmup_time": -1}, "gil.ParallelGroupbyMethods.time_loop": {"code": "class ParallelGroupbyMethods:\n    def time_loop(self, threads, method):\n        for i in range(threads):\n            self.loop()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ParallelGroupbyMethods:\n    def setup(self, threads, method):\n        N = 10**6\n        ngroups = 10**3\n        df = DataFrame(\n            {\"key\": np.random.randint(0, ngroups, size=N), \"data\": np.random.randn(N)}\n        )\n    \n        @test_parallel(num_threads=threads)\n        def parallel():\n            getattr(df.groupby(\"key\")[\"data\"], method)()\n    \n        self.parallel = parallel\n    \n        def loop():\n            getattr(df.groupby(\"key\")[\"data\"], method)()\n    \n        self.loop = loop", "min_run_count": 2, "name": "gil.ParallelGroupbyMethods.time_loop", "number": 0, "param_names": ["threads", "method"], "params": [["2", "4", "8"], ["'count'", "'last'", "'max'", "'mean'", "'min'", "'prod'", "'sum'", "'var'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "eb7b8df45f4491f84224614922e1b5e9a4f93453147833890ec096562f96b248", "warmup_time": -1}, "gil.ParallelGroupbyMethods.time_parallel": {"code": "class ParallelGroupbyMethods:\n    def time_parallel(self, threads, method):\n        self.parallel()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ParallelGroupbyMethods:\n    def setup(self, threads, method):\n        N = 10**6\n        ngroups = 10**3\n        df = DataFrame(\n            {\"key\": np.random.randint(0, ngroups, size=N), \"data\": np.random.randn(N)}\n        )\n    \n        @test_parallel(num_threads=threads)\n        def parallel():\n            getattr(df.groupby(\"key\")[\"data\"], method)()\n    \n        self.parallel = parallel\n    \n        def loop():\n            getattr(df.groupby(\"key\")[\"data\"], method)()\n    \n        self.loop = loop", "min_run_count": 2, "name": "gil.ParallelGroupbyMethods.time_parallel", "number": 0, "param_names": ["threads", "method"], "params": [["2", "4", "8"], ["'count'", "'last'", "'max'", "'mean'", "'min'", "'prod'", "'sum'", "'var'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "ee3c7c1d8ffe98d3bbc8c64cb4af33754566e6351c3bb50458012a695887b895", "warmup_time": -1}, "gil.ParallelGroups.time_get_groups": {"code": "class ParallelGroups:\n    def time_get_groups(self, threads):\n        self.get_groups()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ParallelGroups:\n    def setup(self, threads):\n        size = 2**22\n        ngroups = 10**3\n        data = Series(np.random.randint(0, ngroups, size=size))\n    \n        @test_parallel(num_threads=threads)\n        def get_groups():\n            data.groupby(data).groups\n    \n        self.get_groups = get_groups", "min_run_count": 2, "name": "gil.ParallelGroups.time_get_groups", "number": 0, "param_names": ["threads"], "params": [["2", "4", "8"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "171c8e07e2d81baa3dde5f287fa352a1692571b4e8ab6bc86a6f308969c770f0", "warmup_time": -1}, "gil.ParallelKth.time_kth_smallest": {"code": "class ParallelKth:\n    def time_kth_smallest(self):\n        self.parallel_kth_smallest()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ParallelKth:\n    def setup(self):\n        N = 10**7\n        k = 5 * 10**5\n        kwargs_list = [{\"arr\": np.random.randn(N)}, {\"arr\": np.random.randn(N)}]\n    \n        @test_parallel(num_threads=2, kwargs_list=kwargs_list)\n        def parallel_kth_smallest(arr):\n            algos.kth_smallest(arr, k)\n    \n        self.parallel_kth_smallest = parallel_kth_smallest", "min_run_count": 2, "name": "gil.ParallelKth.time_kth_smallest", "number": 1, "param_names": [], "params": [], "repeat": 5, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "728baeaaeac8eda248c8708b2a4bc45d00a0df43c2103cac65cbfc9c8aff7dcd", "warmup_time": -1}, "gil.ParallelReadCSV.time_read_csv": {"code": "class ParallelReadCSV:\n    def time_read_csv(self, dtype):\n        self.parallel_read_csv()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ParallelReadCSV:\n    def setup(self, dtype):\n        rows = 10000\n        cols = 50\n        if dtype == \"float\":\n            df = DataFrame(np.random.randn(rows, cols))\n        elif dtype == \"datetime\":\n            df = DataFrame(\n                np.random.randn(rows, cols), index=date_range(\"1/1/2000\", periods=rows)\n            )\n        elif dtype == \"object\":\n            df = DataFrame(\n                \"foo\", index=range(rows), columns=[\"object%03d\" for _ in range(5)]\n            )\n        else:\n            raise NotImplementedError\n    \n        self.fname = f\"__test_{dtype}__.csv\"\n        df.to_csv(self.fname)\n    \n        @test_parallel(num_threads=2)\n        def parallel_read_csv():\n            read_csv(self.fname)\n    \n        self.parallel_read_csv = parallel_read_csv", "min_run_count": 2, "name": "gil.ParallelReadCSV.time_read_csv", "number": 1, "param_names": ["dtype"], "params": [["'float'", "'object'", "'datetime'"]], "repeat": 5, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "8228e9d157c6aea95c1ffcdea89ba3331e5dec17b88134f572f22bbf274ea99c", "warmup_time": -1}, "gil.ParallelRolling.time_rolling": {"code": "class ParallelRolling:\n    def time_rolling(self, method):\n        self.parallel_rolling()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ParallelRolling:\n    def setup(self, method):\n        win = 100\n        arr = np.random.rand(100000)\n        if hasattr(DataFrame, \"rolling\"):\n            df = DataFrame(arr).rolling(win)\n    \n            @test_parallel(num_threads=2)\n            def parallel_rolling():\n                getattr(df, method)()\n    \n            self.parallel_rolling = parallel_rolling\n        elif have_rolling_methods:\n            rolling = {\n                \"median\": rolling_median,\n                \"mean\": rolling_mean,\n                \"min\": rolling_min,\n                \"max\": rolling_max,\n                \"var\": rolling_var,\n                \"skew\": rolling_skew,\n                \"kurt\": rolling_kurt,\n                \"std\": rolling_std,\n            }\n    \n            @test_parallel(num_threads=2)\n            def parallel_rolling():\n                rolling[method](arr, win)\n    \n            self.parallel_rolling = parallel_rolling\n        else:\n            raise NotImplementedError", "min_run_count": 2, "name": "gil.ParallelRolling.time_rolling", "number": 0, "param_names": ["method"], "params": [["'median'", "'mean'", "'min'", "'max'", "'var'", "'skew'", "'kurt'", "'std'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "982eb24280f1da753438825641a9861564da7d7a000c415ab86a6bc7522c160b", "warmup_time": -1}, "gil.ParallelTake1D.time_take1d": {"code": "class ParallelTake1D:\n    def time_take1d(self, dtype):\n        self.parallel_take1d()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ParallelTake1D:\n    def setup(self, dtype):\n        N = 10**6\n        df = DataFrame({\"col\": np.arange(N, dtype=dtype)})\n        indexer = np.arange(100, len(df) - 100)\n    \n        @test_parallel(num_threads=2)\n        def parallel_take1d():\n            take_nd(df[\"col\"].values, indexer)\n    \n        self.parallel_take1d = parallel_take1d", "min_run_count": 2, "name": "gil.ParallelTake1D.time_take1d", "number": 0, "param_names": ["dtype"], "params": [["'int64'", "'float64'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "fd7379c21f5111cc9ec16f330e4ffc0e029ced1a7cd13e6b78511e7099f53926", "warmup_time": -1}, "groupby.AggEngine.time_dataframe_cython": {"code": "class AggEngine:\n    def time_dataframe_cython(self, parallel):\n        def function(values):\n            total = 0\n            for i, value in enumerate(values):\n                if i % 2:\n                    total += value + 5\n                else:\n                    total += value * 2\n            return total\n    \n        self.grouper.agg(function, engine=\"cython\")\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass AggEngine:\n    def setup(self, parallel):\n        N = 10**3\n        data = DataFrame(\n            {0: [str(i) for i in range(100)] * N, 1: list(range(100)) * N},\n            columns=[0, 1],\n        )\n        self.parallel = parallel\n        self.grouper = data.groupby(0)", "min_run_count": 2, "name": "groupby.AggEngine.time_dataframe_cython", "number": 0, "param_names": ["parallel"], "params": [["True", "False"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "b631e4aa17bbb96c2171d4d72e155061807325d0b39f89014e9ce5de10bfebd2", "warmup_time": -1}, "groupby.AggEngine.time_dataframe_numba": {"code": "class AggEngine:\n    def time_dataframe_numba(self, parallel):\n        def function(values, index):\n            total = 0\n            for i, value in enumerate(values):\n                if i % 2:\n                    total += value + 5\n                else:\n                    total += value * 2\n            return total\n    \n        self.grouper.agg(\n            function, engine=\"numba\", engine_kwargs={\"parallel\": self.parallel}\n        )\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass AggEngine:\n    def setup(self, parallel):\n        N = 10**3\n        data = DataFrame(\n            {0: [str(i) for i in range(100)] * N, 1: list(range(100)) * N},\n            columns=[0, 1],\n        )\n        self.parallel = parallel\n        self.grouper = data.groupby(0)", "min_run_count": 2, "name": "groupby.AggEngine.time_dataframe_numba", "number": 0, "param_names": ["parallel"], "params": [["True", "False"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "ac6601fa086e8c75d228fd781b72c5b02d2053fd155682b074b03fbd6562ccff", "warmup_time": -1}, "groupby.AggEngine.time_series_cython": {"code": "class AggEngine:\n    def time_series_cython(self, parallel):\n        def function(values):\n            total = 0\n            for i, value in enumerate(values):\n                if i % 2:\n                    total += value + 5\n                else:\n                    total += value * 2\n            return total\n    \n        self.grouper[1].agg(function, engine=\"cython\")\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass AggEngine:\n    def setup(self, parallel):\n        N = 10**3\n        data = DataFrame(\n            {0: [str(i) for i in range(100)] * N, 1: list(range(100)) * N},\n            columns=[0, 1],\n        )\n        self.parallel = parallel\n        self.grouper = data.groupby(0)", "min_run_count": 2, "name": "groupby.AggEngine.time_series_cython", "number": 0, "param_names": ["parallel"], "params": [["True", "False"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "e376d34069b9e05138d16b62f5314f36da3d7a957bb6f040793626df9edcb7ee", "warmup_time": -1}, "groupby.AggEngine.time_series_numba": {"code": "class AggEngine:\n    def time_series_numba(self, parallel):\n        def function(values, index):\n            total = 0\n            for i, value in enumerate(values):\n                if i % 2:\n                    total += value + 5\n                else:\n                    total += value * 2\n            return total\n    \n        self.grouper[1].agg(\n            function, engine=\"numba\", engine_kwargs={\"parallel\": self.parallel}\n        )\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass AggEngine:\n    def setup(self, parallel):\n        N = 10**3\n        data = DataFrame(\n            {0: [str(i) for i in range(100)] * N, 1: list(range(100)) * N},\n            columns=[0, 1],\n        )\n        self.parallel = parallel\n        self.grouper = data.groupby(0)", "min_run_count": 2, "name": "groupby.AggEngine.time_series_numba", "number": 0, "param_names": ["parallel"], "params": [["True", "False"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "c1e4164d5e903fe4335a07378a9a567a3e4f7c80cb9960c112d95f8919a292aa", "warmup_time": -1}, "groupby.AggFunctions.time_different_str_functions": {"code": "class AggFunctions:\n    def time_different_str_functions(self, df):\n        df.groupby([\"key1\", \"key2\"]).agg(\n            {\"value1\": \"mean\", \"value2\": \"var\", \"value3\": \"sum\"}\n        )\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass AggFunctions:\n    def setup_cache(self):\n        N = 10**5\n        fac1 = np.array([\"A\", \"B\", \"C\"], dtype=\"O\")\n        fac2 = np.array([\"one\", \"two\"], dtype=\"O\")\n        df = DataFrame(\n            {\n                \"key1\": fac1.take(np.random.randint(0, 3, size=N)),\n                \"key2\": fac2.take(np.random.randint(0, 2, size=N)),\n                \"value1\": np.random.randn(N),\n                \"value2\": np.random.randn(N),\n                \"value3\": np.random.randn(N),\n            }\n        )\n        return df", "min_run_count": 2, "name": "groupby.AggFunctions.time_different_str_functions", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "setup_cache_key": "groupby:316", "timeout": 60.0, "type": "time", "unit": "seconds", "version": "176cde1b06cc31bb98fa33e5c2d0b5b504f18a26bc5160ce4eba434ee86f286c", "warmup_time": -1}, "groupby.AggFunctions.time_different_str_functions_multicol": {"code": "class AggFunctions:\n    def time_different_str_functions_multicol(self, df):\n        df.groupby([\"key1\", \"key2\"]).agg([\"sum\", \"min\", \"max\"])\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass AggFunctions:\n    def setup_cache(self):\n        N = 10**5\n        fac1 = np.array([\"A\", \"B\", \"C\"], dtype=\"O\")\n        fac2 = np.array([\"one\", \"two\"], dtype=\"O\")\n        df = DataFrame(\n            {\n                \"key1\": fac1.take(np.random.randint(0, 3, size=N)),\n                \"key2\": fac2.take(np.random.randint(0, 2, size=N)),\n                \"value1\": np.random.randn(N),\n                \"value2\": np.random.randn(N),\n                \"value3\": np.random.randn(N),\n            }\n        )\n        return df", "min_run_count": 2, "name": "groupby.AggFunctions.time_different_str_functions_multicol", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "setup_cache_key": "groupby:316", "timeout": 60.0, "type": "time", "unit": "seconds", "version": "665a15402546613d3a9f8692562e3df5bb8e802b90bbaab60dc777323d8c2af2", "warmup_time": -1}, "groupby.AggFunctions.time_different_str_functions_singlecol": {"code": "class AggFunctions:\n    def time_different_str_functions_singlecol(self, df):\n        df.groupby(\"key1\").agg({\"value1\": \"mean\", \"value2\": \"var\", \"value3\": \"sum\"})\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass AggFunctions:\n    def setup_cache(self):\n        N = 10**5\n        fac1 = np.array([\"A\", \"B\", \"C\"], dtype=\"O\")\n        fac2 = np.array([\"one\", \"two\"], dtype=\"O\")\n        df = DataFrame(\n            {\n                \"key1\": fac1.take(np.random.randint(0, 3, size=N)),\n                \"key2\": fac2.take(np.random.randint(0, 2, size=N)),\n                \"value1\": np.random.randn(N),\n                \"value2\": np.random.randn(N),\n                \"value3\": np.random.randn(N),\n            }\n        )\n        return df", "min_run_count": 2, "name": "groupby.AggFunctions.time_different_str_functions_singlecol", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "setup_cache_key": "groupby:316", "timeout": 60.0, "type": "time", "unit": "seconds", "version": "f5e3f8571351af65c0ab394b69b2a896e28ad315f97c21d89abd45facf73ae1e", "warmup_time": -1}, "groupby.Apply.time_copy_function_multi_col": {"code": "class Apply:\n    def time_copy_function_multi_col(self, factor):\n        self.df.groupby([\"key\", \"key2\"]).apply(self.df_copy_function)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Apply:\n    def setup(self, factor):\n        N = 10**factor\n        # two cases:\n        # - small groups: small data (N**4) + many labels (2000) -> average group\n        #   size of 5 (-> larger overhead of slicing method)\n        # - larger groups: larger data (N**5) + fewer labels (20) -> average group\n        #   size of 5000\n        labels = np.random.randint(0, 2000 if factor == 4 else 20, size=N)\n        labels2 = np.random.randint(0, 3, size=N)\n        df = DataFrame(\n            {\n                \"key\": labels,\n                \"key2\": labels2,\n                \"value1\": np.random.randn(N),\n                \"value2\": [\"foo\", \"bar\", \"baz\", \"qux\"] * (N // 4),\n            }\n        )\n        self.df = df", "min_run_count": 2, "name": "groupby.Apply.time_copy_function_multi_col", "number": 0, "param_names": ["factor"], "params": [["4", "5"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "508a1bf90ae09cc26585902afd9774deccb6c4fd643ff3f6e3cd66018ca60057", "warmup_time": -1}, "groupby.Apply.time_copy_overhead_single_col": {"code": "class Apply:\n    def time_copy_overhead_single_col(self, factor):\n        self.df.groupby(\"key\").apply(self.df_copy_function)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Apply:\n    def setup(self, factor):\n        N = 10**factor\n        # two cases:\n        # - small groups: small data (N**4) + many labels (2000) -> average group\n        #   size of 5 (-> larger overhead of slicing method)\n        # - larger groups: larger data (N**5) + fewer labels (20) -> average group\n        #   size of 5000\n        labels = np.random.randint(0, 2000 if factor == 4 else 20, size=N)\n        labels2 = np.random.randint(0, 3, size=N)\n        df = DataFrame(\n            {\n                \"key\": labels,\n                \"key2\": labels2,\n                \"value1\": np.random.randn(N),\n                \"value2\": [\"foo\", \"bar\", \"baz\", \"qux\"] * (N // 4),\n            }\n        )\n        self.df = df", "min_run_count": 2, "name": "groupby.Apply.time_copy_overhead_single_col", "number": 0, "param_names": ["factor"], "params": [["4", "5"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "004ee6e703ae1fbf983c0b4353be97cb81fcd0c0dde8175bbac3fe70f25e2eeb", "warmup_time": -1}, "groupby.Apply.time_scalar_function_multi_col": {"code": "class Apply:\n    def time_scalar_function_multi_col(self, factor):\n        self.df.groupby([\"key\", \"key2\"]).apply(lambda x: 1)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Apply:\n    def setup(self, factor):\n        N = 10**factor\n        # two cases:\n        # - small groups: small data (N**4) + many labels (2000) -> average group\n        #   size of 5 (-> larger overhead of slicing method)\n        # - larger groups: larger data (N**5) + fewer labels (20) -> average group\n        #   size of 5000\n        labels = np.random.randint(0, 2000 if factor == 4 else 20, size=N)\n        labels2 = np.random.randint(0, 3, size=N)\n        df = DataFrame(\n            {\n                \"key\": labels,\n                \"key2\": labels2,\n                \"value1\": np.random.randn(N),\n                \"value2\": [\"foo\", \"bar\", \"baz\", \"qux\"] * (N // 4),\n            }\n        )\n        self.df = df", "min_run_count": 2, "name": "groupby.Apply.time_scalar_function_multi_col", "number": 0, "param_names": ["factor"], "params": [["4", "5"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "c2684326af2c29dbc66ddff0ed5b88aa9ec425dbd70bb2874943b0ee3e8f916d", "warmup_time": -1}, "groupby.Apply.time_scalar_function_single_col": {"code": "class Apply:\n    def time_scalar_function_single_col(self, factor):\n        self.df.groupby(\"key\").apply(lambda x: 1)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Apply:\n    def setup(self, factor):\n        N = 10**factor\n        # two cases:\n        # - small groups: small data (N**4) + many labels (2000) -> average group\n        #   size of 5 (-> larger overhead of slicing method)\n        # - larger groups: larger data (N**5) + fewer labels (20) -> average group\n        #   size of 5000\n        labels = np.random.randint(0, 2000 if factor == 4 else 20, size=N)\n        labels2 = np.random.randint(0, 3, size=N)\n        df = DataFrame(\n            {\n                \"key\": labels,\n                \"key2\": labels2,\n                \"value1\": np.random.randn(N),\n                \"value2\": [\"foo\", \"bar\", \"baz\", \"qux\"] * (N // 4),\n            }\n        )\n        self.df = df", "min_run_count": 2, "name": "groupby.Apply.time_scalar_function_single_col", "number": 0, "param_names": ["factor"], "params": [["4", "5"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "69063f137e8f55d96073f5bed6cb8a4784eed89b8accd6d82bd386218d1d1e79", "warmup_time": -1}, "groupby.ApplyDictReturn.time_groupby_apply_dict_return": {"code": "class ApplyDictReturn:\n    def time_groupby_apply_dict_return(self):\n        self.data.groupby(self.labels).apply(\n            lambda x: {\"first\": x.values[0], \"last\": x.values[-1]}\n        )\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ApplyDictReturn:\n    def setup(self):\n        self.labels = np.arange(1000).repeat(10)\n        self.data = Series(np.random.randn(len(self.labels)))", "min_run_count": 2, "name": "groupby.ApplyDictReturn.time_groupby_apply_dict_return", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "5924f4088fcf382ce33f346ce7ddfd12e83ed70b71b93eaec422e9d9eebf6683", "warmup_time": -1}, "groupby.ApplyNonUniqueUnsortedIndex.time_groupby_apply_non_unique_unsorted_index": {"code": "class ApplyNonUniqueUnsortedIndex:\n    def time_groupby_apply_non_unique_unsorted_index(self):\n        self.df.groupby(\"key\", group_keys=False).apply(lambda x: x)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ApplyNonUniqueUnsortedIndex:\n    def setup(self):\n        # GH 46527\n        # unsorted and non-unique index\n        idx = np.arange(100)[::-1]\n        idx = Index(np.repeat(idx, 200), name=\"key\")\n        self.df = DataFrame(np.random.randn(len(idx), 10), index=idx)", "min_run_count": 2, "name": "groupby.ApplyNonUniqueUnsortedIndex.time_groupby_apply_non_unique_unsorted_index", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "f7c3bea0e579df6a33360dfc8c3303ce3a07b11bf0bd48d962a46d5522f4dcfd", "warmup_time": -1}, "groupby.Categories.time_groupby_extra_cat_nosort": {"code": "class Categories:\n    def time_groupby_extra_cat_nosort(self, observed):\n        self.df_extra_cat.groupby(\"a\", observed=observed, sort=False)[\"b\"].count()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Categories:\n    def setup(self, observed):\n        N = 10**5\n        arr = np.random.random(N)\n        data = {\"a\": Categorical(np.random.randint(10000, size=N)), \"b\": arr}\n        self.df = DataFrame(data)\n        data = {\n            \"a\": Categorical(np.random.randint(10000, size=N), ordered=True),\n            \"b\": arr,\n        }\n        self.df_ordered = DataFrame(data)\n        data = {\n            \"a\": Categorical(\n                np.random.randint(100, size=N), categories=np.arange(10000)\n            ),\n            \"b\": arr,\n        }\n        self.df_extra_cat = DataFrame(data)", "min_run_count": 2, "name": "groupby.Categories.time_groupby_extra_cat_nosort", "number": 0, "param_names": ["observed"], "params": [["True", "False"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "62133a9620af8ea979a326f99617e0e3bbddcc3f3fe81c6bdbf1618701267fde", "warmup_time": -1}, "groupby.Categories.time_groupby_extra_cat_sort": {"code": "class Categories:\n    def time_groupby_extra_cat_sort(self, observed):\n        self.df_extra_cat.groupby(\"a\", observed=observed)[\"b\"].count()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Categories:\n    def setup(self, observed):\n        N = 10**5\n        arr = np.random.random(N)\n        data = {\"a\": Categorical(np.random.randint(10000, size=N)), \"b\": arr}\n        self.df = DataFrame(data)\n        data = {\n            \"a\": Categorical(np.random.randint(10000, size=N), ordered=True),\n            \"b\": arr,\n        }\n        self.df_ordered = DataFrame(data)\n        data = {\n            \"a\": Categorical(\n                np.random.randint(100, size=N), categories=np.arange(10000)\n            ),\n            \"b\": arr,\n        }\n        self.df_extra_cat = DataFrame(data)", "min_run_count": 2, "name": "groupby.Categories.time_groupby_extra_cat_sort", "number": 0, "param_names": ["observed"], "params": [["True", "False"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "bfeb5009688d6d10146eaf165cd717a5783a74a5ec7f081c90f52eeb9663f708", "warmup_time": -1}, "groupby.Categories.time_groupby_nosort": {"code": "class Categories:\n    def time_groupby_nosort(self, observed):\n        self.df.groupby(\"a\", observed=observed, sort=False)[\"b\"].count()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Categories:\n    def setup(self, observed):\n        N = 10**5\n        arr = np.random.random(N)\n        data = {\"a\": Categorical(np.random.randint(10000, size=N)), \"b\": arr}\n        self.df = DataFrame(data)\n        data = {\n            \"a\": Categorical(np.random.randint(10000, size=N), ordered=True),\n            \"b\": arr,\n        }\n        self.df_ordered = DataFrame(data)\n        data = {\n            \"a\": Categorical(\n                np.random.randint(100, size=N), categories=np.arange(10000)\n            ),\n            \"b\": arr,\n        }\n        self.df_extra_cat = DataFrame(data)", "min_run_count": 2, "name": "groupby.Categories.time_groupby_nosort", "number": 0, "param_names": ["observed"], "params": [["True", "False"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "e21931e9e69907f384dfe0d9e8a359e13f8b1293c757b0702b3677c3c6d36e3e", "warmup_time": -1}, "groupby.Categories.time_groupby_ordered_nosort": {"code": "class Categories:\n    def time_groupby_ordered_nosort(self, observed):\n        self.df_ordered.groupby(\"a\", observed=observed, sort=False)[\"b\"].count()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Categories:\n    def setup(self, observed):\n        N = 10**5\n        arr = np.random.random(N)\n        data = {\"a\": Categorical(np.random.randint(10000, size=N)), \"b\": arr}\n        self.df = DataFrame(data)\n        data = {\n            \"a\": Categorical(np.random.randint(10000, size=N), ordered=True),\n            \"b\": arr,\n        }\n        self.df_ordered = DataFrame(data)\n        data = {\n            \"a\": Categorical(\n                np.random.randint(100, size=N), categories=np.arange(10000)\n            ),\n            \"b\": arr,\n        }\n        self.df_extra_cat = DataFrame(data)", "min_run_count": 2, "name": "groupby.Categories.time_groupby_ordered_nosort", "number": 0, "param_names": ["observed"], "params": [["True", "False"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "9e1ed16652daf9b539439c46eab3fc29bfd10b5ba12908c936274bc9d8dc6caa", "warmup_time": -1}, "groupby.Categories.time_groupby_ordered_sort": {"code": "class Categories:\n    def time_groupby_ordered_sort(self, observed):\n        self.df_ordered.groupby(\"a\", observed=observed)[\"b\"].count()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Categories:\n    def setup(self, observed):\n        N = 10**5\n        arr = np.random.random(N)\n        data = {\"a\": Categorical(np.random.randint(10000, size=N)), \"b\": arr}\n        self.df = DataFrame(data)\n        data = {\n            \"a\": Categorical(np.random.randint(10000, size=N), ordered=True),\n            \"b\": arr,\n        }\n        self.df_ordered = DataFrame(data)\n        data = {\n            \"a\": Categorical(\n                np.random.randint(100, size=N), categories=np.arange(10000)\n            ),\n            \"b\": arr,\n        }\n        self.df_extra_cat = DataFrame(data)", "min_run_count": 2, "name": "groupby.Categories.time_groupby_ordered_sort", "number": 0, "param_names": ["observed"], "params": [["True", "False"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "e61e682f371daea64397593a361f55b612c4870d5c7d34a214d012e1f2e346f4", "warmup_time": -1}, "groupby.Categories.time_groupby_sort": {"code": "class Categories:\n    def time_groupby_sort(self, observed):\n        self.df.groupby(\"a\", observed=observed)[\"b\"].count()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Categories:\n    def setup(self, observed):\n        N = 10**5\n        arr = np.random.random(N)\n        data = {\"a\": Categorical(np.random.randint(10000, size=N)), \"b\": arr}\n        self.df = DataFrame(data)\n        data = {\n            \"a\": Categorical(np.random.randint(10000, size=N), ordered=True),\n            \"b\": arr,\n        }\n        self.df_ordered = DataFrame(data)\n        data = {\n            \"a\": Categorical(\n                np.random.randint(100, size=N), categories=np.arange(10000)\n            ),\n            \"b\": arr,\n        }\n        self.df_extra_cat = DataFrame(data)", "min_run_count": 2, "name": "groupby.Categories.time_groupby_sort", "number": 0, "param_names": ["observed"], "params": [["True", "False"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "27b91ff09ded66431067f94886fa27b9fafe051869103620cc7baffc8e0be7fb", "warmup_time": -1}, "groupby.CountMultiDtype.time_multi_count": {"code": "class CountMultiDtype:\n    def time_multi_count(self, df):\n        df.groupby([\"key1\", \"key2\"]).count()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass CountMultiDtype:\n    def setup_cache(self):\n        n = 10000\n        offsets = np.random.randint(n, size=n).astype(\"timedelta64[ns]\")\n        dates = np.datetime64(\"now\") + offsets\n        dates[np.random.rand(n) > 0.5] = np.datetime64(\"nat\")\n        offsets[np.random.rand(n) > 0.5] = np.timedelta64(\"nat\")\n        value2 = np.random.randn(n)\n        value2[np.random.rand(n) > 0.5] = np.nan\n        obj = np.random.choice(list(\"ab\"), size=n).astype(object)\n        obj[np.random.randn(n) > 0.5] = np.nan\n        df = DataFrame(\n            {\n                \"key1\": np.random.randint(0, 500, size=n),\n                \"key2\": np.random.randint(0, 100, size=n),\n                \"dates\": dates,\n                \"value2\": value2,\n                \"value3\": np.random.randn(n),\n                \"ints\": np.random.randint(0, 1000, size=n),\n                \"obj\": obj,\n                \"offsets\": offsets,\n            }\n        )\n        return df", "min_run_count": 2, "name": "groupby.CountMultiDtype.time_multi_count", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "setup_cache_key": "groupby:267", "timeout": 60.0, "type": "time", "unit": "seconds", "version": "781eccf167f79b9db2b42e6637dca3e0917b3ee82948078ab34ec1fdd55a8ba7", "warmup_time": -1}, "groupby.CountMultiInt.time_multi_int_count": {"code": "class CountMultiInt:\n    def time_multi_int_count(self, df):\n        df.groupby([\"key1\", \"key2\"]).count()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass CountMultiInt:\n    def setup_cache(self):\n        n = 10000\n        df = DataFrame(\n            {\n                \"key1\": np.random.randint(0, 500, size=n),\n                \"key2\": np.random.randint(0, 100, size=n),\n                \"ints\": np.random.randint(0, 1000, size=n),\n                \"ints2\": np.random.randint(0, 1000, size=n),\n            }\n        )\n        return df", "min_run_count": 2, "name": "groupby.CountMultiInt.time_multi_int_count", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "setup_cache_key": "groupby:296", "timeout": 60.0, "type": "time", "unit": "seconds", "version": "c0c648960106b54be2a606e2093e04045e55e61c502f37ec87315025300cc688", "warmup_time": -1}, "groupby.CountMultiInt.time_multi_int_nunique": {"code": "class CountMultiInt:\n    def time_multi_int_nunique(self, df):\n        df.groupby([\"key1\", \"key2\"]).nunique()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass CountMultiInt:\n    def setup_cache(self):\n        n = 10000\n        df = DataFrame(\n            {\n                \"key1\": np.random.randint(0, 500, size=n),\n                \"key2\": np.random.randint(0, 100, size=n),\n                \"ints\": np.random.randint(0, 1000, size=n),\n                \"ints2\": np.random.randint(0, 1000, size=n),\n            }\n        )\n        return df", "min_run_count": 2, "name": "groupby.CountMultiInt.time_multi_int_nunique", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "setup_cache_key": "groupby:296", "timeout": 60.0, "type": "time", "unit": "seconds", "version": "02179b80a10ef56e163f7134b90b2b3a14e1e783c29bcd78e8c839cc49c2b89a", "warmup_time": -1}, "groupby.Cumulative.time_frame_transform": {"code": "class Cumulative:\n    def time_frame_transform(self, dtype, method, with_nans):\n        self.df.groupby(\"key\").transform(method)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Cumulative:\n    def setup(self, dtype, method, with_nans):\n        if with_nans and dtype == \"int64\":\n            raise NotImplementedError(\"Construction of df would raise\")\n    \n        N = 500_000\n        keys = np.random.randint(0, 100, size=N)\n        vals = np.random.randint(-10, 10, (N, 5))\n    \n        if with_nans:\n            null_vals = vals.astype(float, copy=True)\n            null_vals[::2, :] = np.nan\n            null_vals[::3, :] = np.nan\n            df = DataFrame(null_vals, columns=list(\"abcde\"), dtype=dtype)\n            df[\"key\"] = keys\n            self.df = df\n        else:\n            df = DataFrame(vals, columns=list(\"abcde\")).astype(dtype, copy=False)\n            df[\"key\"] = keys\n            self.df = df", "min_run_count": 2, "name": "groupby.Cumulative.time_frame_transform", "number": 0, "param_names": ["dtype", "method", "with_nans"], "params": [["'float64'", "'int64'", "'Float64'", "'Int64'"], ["'cummin'", "'cummax'", "'cumsum'"], ["True", "False"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "508bbc112e0877babc3aaf14b674b720e942cd27f59280bc4678e5cca617dd6d", "warmup_time": -1}, "groupby.DateAttributes.time_len_groupby_object": {"code": "class DateAttributes:\n    def time_len_groupby_object(self):\n        len(self.ts.groupby([self.year, self.month, self.day]))\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass DateAttributes:\n    def setup(self):\n        rng = date_range(\"1/1/2000\", \"12/31/2005\", freq=\"h\")\n        self.year, self.month, self.day = rng.year, rng.month, rng.day\n        self.ts = Series(np.random.randn(len(rng)), index=rng)", "min_run_count": 2, "name": "groupby.DateAttributes.time_len_groupby_object", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "8afdc2d8ced7d3eae328dd9110607db5fb11b9f1345b32d6f85c95f2a0790f13", "warmup_time": -1}, "groupby.Datelike.time_sum": {"code": "class Datelike:\n    def time_sum(self, grouper):\n        self.df.groupby(self.grouper).sum()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Datelike:\n    def setup(self, grouper):\n        N = 10**4\n        rng_map = {\n            \"period_range\": period_range,\n            \"date_range\": date_range,\n            \"date_range_tz\": partial(date_range, tz=\"US/Central\"),\n        }\n        self.grouper = rng_map[grouper](\"1900-01-01\", freq=\"D\", periods=N)\n        self.df = DataFrame(np.random.randn(10**4, 2))", "min_run_count": 2, "name": "groupby.Datelike.time_sum", "number": 0, "param_names": ["grouper"], "params": [["'period_range'", "'date_range'", "'date_range_tz'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "e8e6e1030bf91e85db8d838621c86faee1e19b8f21d49efe9d147e58d9b54307", "warmup_time": -1}, "groupby.Fillna.time_df_bfill": {"code": "class Fillna:\n    def time_df_bfill(self):\n        self.df.groupby(\"group\").bfill()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Fillna:\n    def setup(self):\n        N = 100\n        self.df = DataFrame(\n            {\"group\": [1] * N + [2] * N, \"value\": [np.nan, 1.0] * N}\n        ).set_index(\"group\")", "min_run_count": 2, "name": "groupby.Fillna.time_df_bfill", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "7ff1f9cf6c6df0928b8c57fd5409cd697220c5294222532ee686299c3410b840", "warmup_time": -1}, "groupby.Fillna.time_df_ffill": {"code": "class Fillna:\n    def time_df_ffill(self):\n        self.df.groupby(\"group\").ffill()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Fillna:\n    def setup(self):\n        N = 100\n        self.df = DataFrame(\n            {\"group\": [1] * N + [2] * N, \"value\": [np.nan, 1.0] * N}\n        ).set_index(\"group\")", "min_run_count": 2, "name": "groupby.Fillna.time_df_ffill", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "40586a88db43958ca78216d046b99f037c1d2538d8ecbb88e73f0f3fec775b8f", "warmup_time": -1}, "groupby.Fillna.time_srs_bfill": {"code": "class Fillna:\n    def time_srs_bfill(self):\n        self.df.groupby(\"group\")[\"value\"].bfill()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Fillna:\n    def setup(self):\n        N = 100\n        self.df = DataFrame(\n            {\"group\": [1] * N + [2] * N, \"value\": [np.nan, 1.0] * N}\n        ).set_index(\"group\")", "min_run_count": 2, "name": "groupby.Fillna.time_srs_bfill", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "579f258a2de5f21f32a2705c8b4de416b0d90092be5b8db9155802b3114e5eba", "warmup_time": -1}, "groupby.Fillna.time_srs_ffill": {"code": "class Fillna:\n    def time_srs_ffill(self):\n        self.df.groupby(\"group\")[\"value\"].ffill()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Fillna:\n    def setup(self):\n        N = 100\n        self.df = DataFrame(\n            {\"group\": [1] * N + [2] * N, \"value\": [np.nan, 1.0] * N}\n        ).set_index(\"group\")", "min_run_count": 2, "name": "groupby.Fillna.time_srs_ffill", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "836866b476636343cf2f78c006849b25914c07fb61542a85b138c258c1bdb0b2", "warmup_time": -1}, "groupby.Float32.time_sum": {"code": "class Float32:\n    def time_sum(self):\n        self.df.groupby([\"a\"])[\"b\"].sum()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Float32:\n    def setup(self):\n        tmp1 = (np.random.random(10000) * 0.1).astype(np.float32)\n        tmp2 = (np.random.random(10000) * 10.0).astype(np.float32)\n        tmp = np.concatenate((tmp1, tmp2))\n        arr = np.repeat(tmp, 10)\n        self.df = DataFrame({\"a\": arr, \"b\": arr})", "min_run_count": 2, "name": "groupby.Float32.time_sum", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "ffe9e34b1eb793ed006421668ab941faed0e6f0e51c5142f0940d4117f1aedb4", "warmup_time": -1}, "groupby.GroupByCythonAgg.time_frame_agg": {"code": "class GroupByCythonAgg:\n    def time_frame_agg(self, dtype, method):\n        self.df.groupby(\"key\").agg(method)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass GroupByCythonAgg:\n    def setup(self, dtype, method):\n        N = 1_000_000\n        df = DataFrame(np.random.randn(N, 10), columns=list(\"abcdefghij\"))\n        df[\"key\"] = np.random.randint(0, 100, size=N)\n        self.df = df", "min_run_count": 2, "name": "groupby.GroupByCythonAgg.time_frame_agg", "number": 0, "param_names": ["dtype", "method"], "params": [["'float64'"], ["'sum'", "'prod'", "'min'", "'max'", "'idxmin'", "'idxmax'", "'mean'", "'median'", "'var'", "'first'", "'last'", "'any'", "'all'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "08ae292d77e9806660d8e3c10232a024c7526f433635c0290aa62b6b313af20f", "warmup_time": -1}, "groupby.GroupByCythonAggEaDtypes.time_frame_agg": {"code": "class GroupByCythonAggEaDtypes:\n    def time_frame_agg(self, dtype, method):\n        self.df.groupby(\"key\").agg(method)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass GroupByCythonAggEaDtypes:\n    def setup(self, dtype, method):\n        N = 1_000_000\n        df = DataFrame(\n            np.random.randint(0, high=100, size=(N, 10)),\n            columns=list(\"abcdefghij\"),\n            dtype=dtype,\n        )\n        df.loc[list(range(1, N, 5)), list(\"abcdefghij\")] = NA\n        df[\"key\"] = np.random.randint(0, 100, size=N)\n        self.df = df", "min_run_count": 2, "name": "groupby.GroupByCythonAggEaDtypes.time_frame_agg", "number": 0, "param_names": ["dtype", "method"], "params": [["'Float64'", "'Int64'", "'Int32'"], ["'sum'", "'prod'", "'min'", "'max'", "'mean'", "'median'", "'var'", "'first'", "'last'", "'any'", "'all'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "9d0957d40f08e9fb265f5ca8f466358e6742a3b6b934d1714c6cfc2f9604ded1", "warmup_time": -1}, "groupby.GroupByMethods.time_dtype_as_field": {"code": "class GroupByMethods:\n    def time_dtype_as_field(self, dtype, method, application, ncols, engine):\n        self.as_field_method()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass GroupByMethods:\n    def setup(self, dtype, method, application, ncols, engine):\n        if method in method_blocklist.get(dtype, {}):\n            raise NotImplementedError  # skip benchmark\n    \n        if ncols != 1 and method in [\"value_counts\", \"unique\"]:\n            # DataFrameGroupBy doesn't have these methods\n            raise NotImplementedError\n    \n        if application == \"transformation\" and method in [\n            \"describe\",\n            \"head\",\n            \"tail\",\n            \"unique\",\n            \"value_counts\",\n            \"size\",\n        ]:\n            # DataFrameGroupBy doesn't have these methods\n            raise NotImplementedError\n    \n        # Numba currently doesn't support\n        # multiple transform functions or strs for transform,\n        # grouping on multiple columns\n        # and we lack kernels for a bunch of methods\n        if (\n            engine == \"numba\"\n            and method in _numba_unsupported_methods\n            or ncols > 1\n            or application == \"transformation\"\n            or dtype == \"datetime\"\n        ):\n            raise NotImplementedError\n    \n        if method == \"describe\":\n            ngroups = 20\n        elif method == \"skew\":\n            ngroups = 100\n        else:\n            ngroups = 1000\n        size = ngroups * 2\n        rng = np.arange(ngroups).reshape(-1, 1)\n        rng = np.broadcast_to(rng, (len(rng), ncols))\n        taker = np.random.randint(0, ngroups, size=size)\n        values = rng.take(taker, axis=0)\n        if dtype == \"int\":\n            key = np.random.randint(0, size, size=size)\n        elif dtype in (\"int16\", \"uint\"):\n            key = np.random.randint(0, size, size=size, dtype=dtype)\n        elif dtype == \"float\":\n            key = np.concatenate(\n                [np.random.random(ngroups) * 0.1, np.random.random(ngroups) * 10.0]\n            )\n        elif dtype == \"object\":\n            key = [\"foo\"] * size\n        elif dtype == \"datetime\":\n            key = date_range(\"1/1/2011\", periods=size, freq=\"s\")\n    \n        cols = [f\"values{n}\" for n in range(ncols)]\n        df = DataFrame(values, columns=cols)\n        df[\"key\"] = key\n    \n        if len(cols) == 1:\n            cols = cols[0]\n    \n        # Not everything supports the engine keyword yet\n        kwargs = {}\n        if engine == \"numba\":\n            kwargs[\"engine\"] = engine\n    \n        if application == \"transformation\":\n            self.as_group_method = lambda: df.groupby(\"key\")[cols].transform(\n                method, **kwargs\n            )\n            self.as_field_method = lambda: df.groupby(cols)[\"key\"].transform(\n                method, **kwargs\n            )\n        else:\n            self.as_group_method = partial(\n                getattr(df.groupby(\"key\")[cols], method), **kwargs\n            )\n            self.as_field_method = partial(\n                getattr(df.groupby(cols)[\"key\"], method), **kwargs\n            )", "min_run_count": 2, "name": "groupby.GroupByMethods.time_dtype_as_field", "number": 0, "param_names": ["dtype", "method", "application", "ncols", "param5"], "params": [["'int'", "'int16'", "'float'", "'object'", "'datetime'", "'uint'"], ["'all'", "'any'", "'bfill'", "'count'", "'cumcount'", "'cummax'", "'cummin'", "'cumprod'", "'cumsum'", "'describe'", "'diff'", "'ffill'", "'first'", "'head'", "'last'", "'max'", "'min'", "'median'", "'mean'", "'nunique'", "'pct_change'", "'prod'", "'quantile'", "'rank'", "'sem'", "'shift'", "'size'", "'skew'", "'std'", "'sum'", "'tail'", "'unique'", "'value_counts'", "'var'"], ["'direct'", "'transformation'"], ["1", "5"], ["'cython'", "'numba'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "f6756187c0bd8623a9ef1a6791275810e0ec9866b6205b044c43a5fcb0f3005d", "warmup_time": -1}, "groupby.GroupByMethods.time_dtype_as_group": {"code": "class GroupByMethods:\n    def time_dtype_as_group(self, dtype, method, application, ncols, engine):\n        self.as_group_method()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass GroupByMethods:\n    def setup(self, dtype, method, application, ncols, engine):\n        if method in method_blocklist.get(dtype, {}):\n            raise NotImplementedError  # skip benchmark\n    \n        if ncols != 1 and method in [\"value_counts\", \"unique\"]:\n            # DataFrameGroupBy doesn't have these methods\n            raise NotImplementedError\n    \n        if application == \"transformation\" and method in [\n            \"describe\",\n            \"head\",\n            \"tail\",\n            \"unique\",\n            \"value_counts\",\n            \"size\",\n        ]:\n            # DataFrameGroupBy doesn't have these methods\n            raise NotImplementedError\n    \n        # Numba currently doesn't support\n        # multiple transform functions or strs for transform,\n        # grouping on multiple columns\n        # and we lack kernels for a bunch of methods\n        if (\n            engine == \"numba\"\n            and method in _numba_unsupported_methods\n            or ncols > 1\n            or application == \"transformation\"\n            or dtype == \"datetime\"\n        ):\n            raise NotImplementedError\n    \n        if method == \"describe\":\n            ngroups = 20\n        elif method == \"skew\":\n            ngroups = 100\n        else:\n            ngroups = 1000\n        size = ngroups * 2\n        rng = np.arange(ngroups).reshape(-1, 1)\n        rng = np.broadcast_to(rng, (len(rng), ncols))\n        taker = np.random.randint(0, ngroups, size=size)\n        values = rng.take(taker, axis=0)\n        if dtype == \"int\":\n            key = np.random.randint(0, size, size=size)\n        elif dtype in (\"int16\", \"uint\"):\n            key = np.random.randint(0, size, size=size, dtype=dtype)\n        elif dtype == \"float\":\n            key = np.concatenate(\n                [np.random.random(ngroups) * 0.1, np.random.random(ngroups) * 10.0]\n            )\n        elif dtype == \"object\":\n            key = [\"foo\"] * size\n        elif dtype == \"datetime\":\n            key = date_range(\"1/1/2011\", periods=size, freq=\"s\")\n    \n        cols = [f\"values{n}\" for n in range(ncols)]\n        df = DataFrame(values, columns=cols)\n        df[\"key\"] = key\n    \n        if len(cols) == 1:\n            cols = cols[0]\n    \n        # Not everything supports the engine keyword yet\n        kwargs = {}\n        if engine == \"numba\":\n            kwargs[\"engine\"] = engine\n    \n        if application == \"transformation\":\n            self.as_group_method = lambda: df.groupby(\"key\")[cols].transform(\n                method, **kwargs\n            )\n            self.as_field_method = lambda: df.groupby(cols)[\"key\"].transform(\n                method, **kwargs\n            )\n        else:\n            self.as_group_method = partial(\n                getattr(df.groupby(\"key\")[cols], method), **kwargs\n            )\n            self.as_field_method = partial(\n                getattr(df.groupby(cols)[\"key\"], method), **kwargs\n            )", "min_run_count": 2, "name": "groupby.GroupByMethods.time_dtype_as_group", "number": 0, "param_names": ["dtype", "method", "application", "ncols", "param5"], "params": [["'int'", "'int16'", "'float'", "'object'", "'datetime'", "'uint'"], ["'all'", "'any'", "'bfill'", "'count'", "'cumcount'", "'cummax'", "'cummin'", "'cumprod'", "'cumsum'", "'describe'", "'diff'", "'ffill'", "'first'", "'head'", "'last'", "'max'", "'min'", "'median'", "'mean'", "'nunique'", "'pct_change'", "'prod'", "'quantile'", "'rank'", "'sem'", "'shift'", "'size'", "'skew'", "'std'", "'sum'", "'tail'", "'unique'", "'value_counts'", "'var'"], ["'direct'", "'transformation'"], ["1", "5"], ["'cython'", "'numba'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "5819db2ef25de74e27b8c2c1fc7cf3a213557e9b5c305e7f9d91e758f4b0b54f", "warmup_time": -1}, "groupby.GroupByNumbaAgg.time_frame_agg": {"code": "class GroupByNumbaAgg:\n    def time_frame_agg(self, dtype, method):\n        self.df.groupby(\"key\").agg(method, engine=\"numba\")\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass GroupByNumbaAgg:\n    def setup(self, dtype, method):\n        if method in _numba_unsupported_methods:\n            raise NotImplementedError\n        super().setup(dtype, method)", "min_run_count": 2, "name": "groupby.GroupByNumbaAgg.time_frame_agg", "number": 0, "param_names": ["dtype", "method"], "params": [["'float64'"], ["'sum'", "'prod'", "'min'", "'max'", "'idxmin'", "'idxmax'", "'mean'", "'median'", "'var'", "'first'", "'last'", "'any'", "'all'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "485567a7945b89dfbcc8517d268d1572570c908383b9f7fdbc1b173bc67a292a", "warmup_time": -1}, "groupby.GroupManyLabels.time_sum": {"code": "class GroupManyLabels:\n    def time_sum(self, ncols):\n        self.df.groupby(self.labels).sum()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass GroupManyLabels:\n    def setup(self, ncols):\n        N = 1000\n        data = np.random.randn(N, ncols)\n        self.labels = np.random.randint(0, 100, size=N)\n        self.df = DataFrame(data)", "min_run_count": 2, "name": "groupby.GroupManyLabels.time_sum", "number": 0, "param_names": ["ncols"], "params": [["1", "1000"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "66b2e0c8c016da785fe5cc599d0ce7892b1c5657f8af53ff854fed498e28878a", "warmup_time": -1}, "groupby.GroupStrings.time_multi_columns": {"code": "class GroupStrings:\n    def time_multi_columns(self):\n        self.df.groupby(list(\"abcd\")).max()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass GroupStrings:\n    def setup(self):\n        n = 2 * 10**5\n        alpha = list(map(\"\".join, product(ascii_letters, repeat=4)))\n        data = np.random.choice(alpha, (n // 5, 4), replace=False)\n        data = np.repeat(data, 5, axis=0)\n        self.df = DataFrame(data, columns=list(\"abcd\"))\n        self.df[\"joe\"] = (np.random.randn(len(self.df)) * 10).round(3)\n        self.df = self.df.sample(frac=1).reset_index(drop=True)", "min_run_count": 2, "name": "groupby.GroupStrings.time_multi_columns", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "e2cad1f849665339cebeef8f37279cd4824c4fa1e86e39fe618e4052a76b7dd6", "warmup_time": -1}, "groupby.Groups.time_series_groups": {"code": "class Groups:\n    def time_series_groups(self, data, key):\n        self.ser.groupby(self.ser).groups\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Groups:\n    def setup(self, data, key):\n        self.ser = data[key]\n\n    def setup_cache(self):\n        size = 10**6\n        data = {\n            \"int64_small\": Series(np.random.randint(0, 100, size=size)),\n            \"int64_large\": Series(np.random.randint(0, 10000, size=size)),\n            \"object_small\": Series(\n                Index([f\"i-{i}\" for i in range(100)], dtype=object).take(\n                    np.random.randint(0, 100, size=size)\n                )\n            ),\n            \"object_large\": Series(\n                Index([f\"i-{i}\" for i in range(10000)], dtype=object).take(\n                    np.random.randint(0, 10000, size=size)\n                )\n            ),\n        }\n        return data", "min_run_count": 2, "name": "groupby.Groups.time_series_groups", "number": 0, "param_names": ["key"], "params": [["'int64_small'", "'int64_large'", "'object_small'", "'object_large'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "setup_cache_key": "groupby:162", "timeout": 60.0, "type": "time", "unit": "seconds", "version": "dbc6b8b2b071005f9ce14efc5386fc68124c154c0787e714bcf9be17ee3b4bba", "warmup_time": -1}, "groupby.Groups.time_series_indices": {"code": "class Groups:\n    def time_series_indices(self, data, key):\n        self.ser.groupby(self.ser).indices\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Groups:\n    def setup(self, data, key):\n        self.ser = data[key]\n\n    def setup_cache(self):\n        size = 10**6\n        data = {\n            \"int64_small\": Series(np.random.randint(0, 100, size=size)),\n            \"int64_large\": Series(np.random.randint(0, 10000, size=size)),\n            \"object_small\": Series(\n                Index([f\"i-{i}\" for i in range(100)], dtype=object).take(\n                    np.random.randint(0, 100, size=size)\n                )\n            ),\n            \"object_large\": Series(\n                Index([f\"i-{i}\" for i in range(10000)], dtype=object).take(\n                    np.random.randint(0, 10000, size=size)\n                )\n            ),\n        }\n        return data", "min_run_count": 2, "name": "groupby.Groups.time_series_indices", "number": 0, "param_names": ["key"], "params": [["'int64_small'", "'int64_large'", "'object_small'", "'object_large'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "setup_cache_key": "groupby:162", "timeout": 60.0, "type": "time", "unit": "seconds", "version": "36d7245a7a3b2bd56d7270e0d6981e83fed5d32bed580a99567addff40ccbd17", "warmup_time": -1}, "groupby.Int64.time_overflow": {"code": "class Int64:\n    def time_overflow(self):\n        self.df.groupby(self.cols).max()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Int64:\n    def setup(self):\n        arr = np.random.randint(-1 << 12, 1 << 12, (1 << 17, 5))\n        i = np.random.choice(len(arr), len(arr) * 5)\n        arr = np.vstack((arr, arr[i]))\n        i = np.random.permutation(len(arr))\n        arr = arr[i]\n        self.cols = list(\"abcde\")\n        self.df = DataFrame(arr, columns=self.cols)\n        self.df[\"jim\"], self.df[\"joe\"] = np.random.randn(2, len(self.df)) * 10", "min_run_count": 2, "name": "groupby.Int64.time_overflow", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "c59f5b180f618f9de6657c8e0c5a373add1e863a6f3969b4097836f1f4e40929", "warmup_time": -1}, "groupby.MultiColumn.time_col_select_lambda_sum": {"code": "class MultiColumn:\n    def time_col_select_lambda_sum(self, df):\n        df.groupby([\"key1\", \"key2\"])[\"data1\"].agg(lambda x: x.values.sum())\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass MultiColumn:\n    def setup_cache(self):\n        N = 10**5\n        key1 = np.tile(np.arange(100, dtype=object), 1000)\n        key2 = key1.copy()\n        np.random.shuffle(key1)\n        np.random.shuffle(key2)\n        df = DataFrame(\n            {\n                \"key1\": key1,\n                \"key2\": key2,\n                \"data1\": np.random.randn(N),\n                \"data2\": np.random.randn(N),\n            }\n        )\n        return df", "min_run_count": 2, "name": "groupby.MultiColumn.time_col_select_lambda_sum", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "setup_cache_key": "groupby:358", "timeout": 60.0, "type": "time", "unit": "seconds", "version": "cada8d1efcf927c41db4c7b33b88a6816790e5d361e4cf10f3f03f390386a717", "warmup_time": -1}, "groupby.MultiColumn.time_col_select_str_sum": {"code": "class MultiColumn:\n    def time_col_select_str_sum(self, df):\n        df.groupby([\"key1\", \"key2\"])[\"data1\"].agg(\"sum\")\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass MultiColumn:\n    def setup_cache(self):\n        N = 10**5\n        key1 = np.tile(np.arange(100, dtype=object), 1000)\n        key2 = key1.copy()\n        np.random.shuffle(key1)\n        np.random.shuffle(key2)\n        df = DataFrame(\n            {\n                \"key1\": key1,\n                \"key2\": key2,\n                \"data1\": np.random.randn(N),\n                \"data2\": np.random.randn(N),\n            }\n        )\n        return df", "min_run_count": 2, "name": "groupby.MultiColumn.time_col_select_str_sum", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "setup_cache_key": "groupby:358", "timeout": 60.0, "type": "time", "unit": "seconds", "version": "452b0de34f34dcbafb7d59c7c44e17908f0342ebb248d7b61f8ef1ee63c7d175", "warmup_time": -1}, "groupby.MultiColumn.time_cython_sum": {"code": "class MultiColumn:\n    def time_cython_sum(self, df):\n        df.groupby([\"key1\", \"key2\"]).sum()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass MultiColumn:\n    def setup_cache(self):\n        N = 10**5\n        key1 = np.tile(np.arange(100, dtype=object), 1000)\n        key2 = key1.copy()\n        np.random.shuffle(key1)\n        np.random.shuffle(key2)\n        df = DataFrame(\n            {\n                \"key1\": key1,\n                \"key2\": key2,\n                \"data1\": np.random.randn(N),\n                \"data2\": np.random.randn(N),\n            }\n        )\n        return df", "min_run_count": 2, "name": "groupby.MultiColumn.time_cython_sum", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "setup_cache_key": "groupby:358", "timeout": 60.0, "type": "time", "unit": "seconds", "version": "9ba6f25ceb0666279babb6760f71ea64c8a52a817294261fed73699bc7b516f3", "warmup_time": -1}, "groupby.MultiColumn.time_lambda_sum": {"code": "class MultiColumn:\n    def time_lambda_sum(self, df):\n        df.groupby([\"key1\", \"key2\"]).agg(lambda x: x.values.sum())\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass MultiColumn:\n    def setup_cache(self):\n        N = 10**5\n        key1 = np.tile(np.arange(100, dtype=object), 1000)\n        key2 = key1.copy()\n        np.random.shuffle(key1)\n        np.random.shuffle(key2)\n        df = DataFrame(\n            {\n                \"key1\": key1,\n                \"key2\": key2,\n                \"data1\": np.random.randn(N),\n                \"data2\": np.random.randn(N),\n            }\n        )\n        return df", "min_run_count": 2, "name": "groupby.MultiColumn.time_lambda_sum", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "setup_cache_key": "groupby:358", "timeout": 60.0, "type": "time", "unit": "seconds", "version": "38b6452a313f2508f0dfd7fa593d129b13ec9c33f22753679877d5f06818a566", "warmup_time": -1}, "groupby.MultipleCategories.time_groupby_extra_cat_nosort": {"code": "class MultipleCategories:\n    def time_groupby_extra_cat_nosort(self):\n        self.df_extra_cat.groupby([\"a1\", \"a2\"], observed=False, sort=False)[\"b\"].count()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass MultipleCategories:\n    def setup(self):\n        N = 10**3\n        arr = np.random.random(N)\n        data = {\n            \"a1\": Categorical(np.random.randint(10000, size=N)),\n            \"a2\": Categorical(np.random.randint(10000, size=N)),\n            \"b\": arr,\n        }\n        self.df = DataFrame(data)\n        data = {\n            \"a1\": Categorical(np.random.randint(10000, size=N), ordered=True),\n            \"a2\": Categorical(np.random.randint(10000, size=N), ordered=True),\n            \"b\": arr,\n        }\n        self.df_ordered = DataFrame(data)\n        data = {\n            \"a1\": Categorical(np.random.randint(100, size=N), categories=np.arange(N)),\n            \"a2\": Categorical(np.random.randint(100, size=N), categories=np.arange(N)),\n            \"b\": arr,\n        }\n        self.df_extra_cat = DataFrame(data)", "min_run_count": 2, "name": "groupby.MultipleCategories.time_groupby_extra_cat_nosort", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "83cff68f64c01bc265f6f67706237d37c6f96f20ccb947373ea0fbdb9c5c605a", "warmup_time": -1}, "groupby.MultipleCategories.time_groupby_extra_cat_sort": {"code": "class MultipleCategories:\n    def time_groupby_extra_cat_sort(self):\n        self.df_extra_cat.groupby([\"a1\", \"a2\"], observed=False)[\"b\"].count()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass MultipleCategories:\n    def setup(self):\n        N = 10**3\n        arr = np.random.random(N)\n        data = {\n            \"a1\": Categorical(np.random.randint(10000, size=N)),\n            \"a2\": Categorical(np.random.randint(10000, size=N)),\n            \"b\": arr,\n        }\n        self.df = DataFrame(data)\n        data = {\n            \"a1\": Categorical(np.random.randint(10000, size=N), ordered=True),\n            \"a2\": Categorical(np.random.randint(10000, size=N), ordered=True),\n            \"b\": arr,\n        }\n        self.df_ordered = DataFrame(data)\n        data = {\n            \"a1\": Categorical(np.random.randint(100, size=N), categories=np.arange(N)),\n            \"a2\": Categorical(np.random.randint(100, size=N), categories=np.arange(N)),\n            \"b\": arr,\n        }\n        self.df_extra_cat = DataFrame(data)", "min_run_count": 2, "name": "groupby.MultipleCategories.time_groupby_extra_cat_sort", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "96635202ed41a374fefefbfbd2317b32d2475a1d07384a99feb40c69b419e024", "warmup_time": -1}, "groupby.MultipleCategories.time_groupby_nosort": {"code": "class MultipleCategories:\n    def time_groupby_nosort(self):\n        self.df.groupby([\"a1\", \"a2\"], observed=False, sort=False)[\"b\"].count()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass MultipleCategories:\n    def setup(self):\n        N = 10**3\n        arr = np.random.random(N)\n        data = {\n            \"a1\": Categorical(np.random.randint(10000, size=N)),\n            \"a2\": Categorical(np.random.randint(10000, size=N)),\n            \"b\": arr,\n        }\n        self.df = DataFrame(data)\n        data = {\n            \"a1\": Categorical(np.random.randint(10000, size=N), ordered=True),\n            \"a2\": Categorical(np.random.randint(10000, size=N), ordered=True),\n            \"b\": arr,\n        }\n        self.df_ordered = DataFrame(data)\n        data = {\n            \"a1\": Categorical(np.random.randint(100, size=N), categories=np.arange(N)),\n            \"a2\": Categorical(np.random.randint(100, size=N), categories=np.arange(N)),\n            \"b\": arr,\n        }\n        self.df_extra_cat = DataFrame(data)", "min_run_count": 2, "name": "groupby.MultipleCategories.time_groupby_nosort", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "bd1d5b9e0fdabacec5cfdcbec5af5cf24e4a7871654e201e2e36e94e9d50bf9a", "warmup_time": -1}, "groupby.MultipleCategories.time_groupby_ordered_nosort": {"code": "class MultipleCategories:\n    def time_groupby_ordered_nosort(self):\n        self.df_ordered.groupby([\"a1\", \"a2\"], observed=False, sort=False)[\"b\"].count()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass MultipleCategories:\n    def setup(self):\n        N = 10**3\n        arr = np.random.random(N)\n        data = {\n            \"a1\": Categorical(np.random.randint(10000, size=N)),\n            \"a2\": Categorical(np.random.randint(10000, size=N)),\n            \"b\": arr,\n        }\n        self.df = DataFrame(data)\n        data = {\n            \"a1\": Categorical(np.random.randint(10000, size=N), ordered=True),\n            \"a2\": Categorical(np.random.randint(10000, size=N), ordered=True),\n            \"b\": arr,\n        }\n        self.df_ordered = DataFrame(data)\n        data = {\n            \"a1\": Categorical(np.random.randint(100, size=N), categories=np.arange(N)),\n            \"a2\": Categorical(np.random.randint(100, size=N), categories=np.arange(N)),\n            \"b\": arr,\n        }\n        self.df_extra_cat = DataFrame(data)", "min_run_count": 2, "name": "groupby.MultipleCategories.time_groupby_ordered_nosort", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "efc218534283dc987433d4dda645ee117699de0a41f79f59cfcb381a56f55bfa", "warmup_time": -1}, "groupby.MultipleCategories.time_groupby_ordered_sort": {"code": "class MultipleCategories:\n    def time_groupby_ordered_sort(self):\n        self.df_ordered.groupby([\"a1\", \"a2\"], observed=False)[\"b\"].count()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass MultipleCategories:\n    def setup(self):\n        N = 10**3\n        arr = np.random.random(N)\n        data = {\n            \"a1\": Categorical(np.random.randint(10000, size=N)),\n            \"a2\": Categorical(np.random.randint(10000, size=N)),\n            \"b\": arr,\n        }\n        self.df = DataFrame(data)\n        data = {\n            \"a1\": Categorical(np.random.randint(10000, size=N), ordered=True),\n            \"a2\": Categorical(np.random.randint(10000, size=N), ordered=True),\n            \"b\": arr,\n        }\n        self.df_ordered = DataFrame(data)\n        data = {\n            \"a1\": Categorical(np.random.randint(100, size=N), categories=np.arange(N)),\n            \"a2\": Categorical(np.random.randint(100, size=N), categories=np.arange(N)),\n            \"b\": arr,\n        }\n        self.df_extra_cat = DataFrame(data)", "min_run_count": 2, "name": "groupby.MultipleCategories.time_groupby_ordered_sort", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "24d3606f6b66cd0cf252b6566e5c8a44adae7e06ecb2c17a06917ab0f801a0ab", "warmup_time": -1}, "groupby.MultipleCategories.time_groupby_sort": {"code": "class MultipleCategories:\n    def time_groupby_sort(self):\n        self.df.groupby([\"a1\", \"a2\"], observed=False)[\"b\"].count()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass MultipleCategories:\n    def setup(self):\n        N = 10**3\n        arr = np.random.random(N)\n        data = {\n            \"a1\": Categorical(np.random.randint(10000, size=N)),\n            \"a2\": Categorical(np.random.randint(10000, size=N)),\n            \"b\": arr,\n        }\n        self.df = DataFrame(data)\n        data = {\n            \"a1\": Categorical(np.random.randint(10000, size=N), ordered=True),\n            \"a2\": Categorical(np.random.randint(10000, size=N), ordered=True),\n            \"b\": arr,\n        }\n        self.df_ordered = DataFrame(data)\n        data = {\n            \"a1\": Categorical(np.random.randint(100, size=N), categories=np.arange(N)),\n            \"a2\": Categorical(np.random.randint(100, size=N), categories=np.arange(N)),\n            \"b\": arr,\n        }\n        self.df_extra_cat = DataFrame(data)", "min_run_count": 2, "name": "groupby.MultipleCategories.time_groupby_sort", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "869bac12201294cce4dabbed58d29db90d95b9d4060f99ab5acd2d7c3b1426a6", "warmup_time": -1}, "groupby.MultipleCategories.time_groupby_transform": {"code": "class MultipleCategories:\n    def time_groupby_transform(self):\n        self.df_extra_cat.groupby([\"a1\", \"a2\"], observed=False)[\"b\"].cumsum()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass MultipleCategories:\n    def setup(self):\n        N = 10**3\n        arr = np.random.random(N)\n        data = {\n            \"a1\": Categorical(np.random.randint(10000, size=N)),\n            \"a2\": Categorical(np.random.randint(10000, size=N)),\n            \"b\": arr,\n        }\n        self.df = DataFrame(data)\n        data = {\n            \"a1\": Categorical(np.random.randint(10000, size=N), ordered=True),\n            \"a2\": Categorical(np.random.randint(10000, size=N), ordered=True),\n            \"b\": arr,\n        }\n        self.df_ordered = DataFrame(data)\n        data = {\n            \"a1\": Categorical(np.random.randint(100, size=N), categories=np.arange(N)),\n            \"a2\": Categorical(np.random.randint(100, size=N), categories=np.arange(N)),\n            \"b\": arr,\n        }\n        self.df_extra_cat = DataFrame(data)", "min_run_count": 2, "name": "groupby.MultipleCategories.time_groupby_transform", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "9e6ce565eecb66a3cd8ceec5c6d78a2fc6aefeb48742cc69c8ad9a311a77873b", "warmup_time": -1}, "groupby.Nth.time_frame_nth": {"code": "class Nth:\n    def time_frame_nth(self, dtype):\n        self.df.groupby(\"key\").nth(0)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Nth:\n    def setup(self, dtype):\n        N = 10**5\n        # with datetimes (GH7555)\n        if dtype == \"datetime\":\n            values = date_range(\"1/1/2011\", periods=N, freq=\"s\")\n        elif dtype == \"object\":\n            values = [\"foo\"] * N\n        else:\n            values = np.arange(N).astype(dtype)\n    \n        key = np.arange(N)\n        self.df = DataFrame({\"key\": key, \"values\": values})\n        self.df.iloc[1, 1] = np.nan  # insert missing data", "min_run_count": 2, "name": "groupby.Nth.time_frame_nth", "number": 0, "param_names": ["dtype"], "params": [["'float32'", "'float64'", "'datetime'", "'object'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "e1d08a270138a89c0f1723213b6519ab3f5bf1373d8e8d2c2b54a43b065b76be", "warmup_time": -1}, "groupby.Nth.time_frame_nth_any": {"code": "class Nth:\n    def time_frame_nth_any(self, dtype):\n        self.df.groupby(\"key\").nth(0, dropna=\"any\")\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Nth:\n    def setup(self, dtype):\n        N = 10**5\n        # with datetimes (GH7555)\n        if dtype == \"datetime\":\n            values = date_range(\"1/1/2011\", periods=N, freq=\"s\")\n        elif dtype == \"object\":\n            values = [\"foo\"] * N\n        else:\n            values = np.arange(N).astype(dtype)\n    \n        key = np.arange(N)\n        self.df = DataFrame({\"key\": key, \"values\": values})\n        self.df.iloc[1, 1] = np.nan  # insert missing data", "min_run_count": 2, "name": "groupby.Nth.time_frame_nth_any", "number": 0, "param_names": ["dtype"], "params": [["'float32'", "'float64'", "'datetime'", "'object'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "a44829e68092f64486a6572a1a5465f5a0d577ee765ee5ad2e38c472e85346bd", "warmup_time": -1}, "groupby.Nth.time_groupby_nth_all": {"code": "class Nth:\n    def time_groupby_nth_all(self, dtype):\n        self.df.groupby(\"key\").nth(0, dropna=\"all\")\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Nth:\n    def setup(self, dtype):\n        N = 10**5\n        # with datetimes (GH7555)\n        if dtype == \"datetime\":\n            values = date_range(\"1/1/2011\", periods=N, freq=\"s\")\n        elif dtype == \"object\":\n            values = [\"foo\"] * N\n        else:\n            values = np.arange(N).astype(dtype)\n    \n        key = np.arange(N)\n        self.df = DataFrame({\"key\": key, \"values\": values})\n        self.df.iloc[1, 1] = np.nan  # insert missing data", "min_run_count": 2, "name": "groupby.Nth.time_groupby_nth_all", "number": 0, "param_names": ["dtype"], "params": [["'float32'", "'float64'", "'datetime'", "'object'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "866ef9a468514b755b4464d8fd09949132454a4161d7a99770caeec775a2bba6", "warmup_time": -1}, "groupby.Nth.time_series_nth": {"code": "class Nth:\n    def time_series_nth(self, dtype):\n        self.df[\"values\"].groupby(self.df[\"key\"]).nth(0)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Nth:\n    def setup(self, dtype):\n        N = 10**5\n        # with datetimes (GH7555)\n        if dtype == \"datetime\":\n            values = date_range(\"1/1/2011\", periods=N, freq=\"s\")\n        elif dtype == \"object\":\n            values = [\"foo\"] * N\n        else:\n            values = np.arange(N).astype(dtype)\n    \n        key = np.arange(N)\n        self.df = DataFrame({\"key\": key, \"values\": values})\n        self.df.iloc[1, 1] = np.nan  # insert missing data", "min_run_count": 2, "name": "groupby.Nth.time_series_nth", "number": 0, "param_names": ["dtype"], "params": [["'float32'", "'float64'", "'datetime'", "'object'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "c5b1e05da00cd08da75c885c95b13c18db12dc3332aafd79a79049e66f996c1e", "warmup_time": -1}, "groupby.Nth.time_series_nth_all": {"code": "class Nth:\n    def time_series_nth_all(self, dtype):\n        self.df[\"values\"].groupby(self.df[\"key\"]).nth(0, dropna=\"all\")\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Nth:\n    def setup(self, dtype):\n        N = 10**5\n        # with datetimes (GH7555)\n        if dtype == \"datetime\":\n            values = date_range(\"1/1/2011\", periods=N, freq=\"s\")\n        elif dtype == \"object\":\n            values = [\"foo\"] * N\n        else:\n            values = np.arange(N).astype(dtype)\n    \n        key = np.arange(N)\n        self.df = DataFrame({\"key\": key, \"values\": values})\n        self.df.iloc[1, 1] = np.nan  # insert missing data", "min_run_count": 2, "name": "groupby.Nth.time_series_nth_all", "number": 0, "param_names": ["dtype"], "params": [["'float32'", "'float64'", "'datetime'", "'object'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "42ed669cc8c03e7351add656e29a89d0fb07fc43ed2931e70701a559f09f12e1", "warmup_time": -1}, "groupby.Nth.time_series_nth_any": {"code": "class Nth:\n    def time_series_nth_any(self, dtype):\n        self.df[\"values\"].groupby(self.df[\"key\"]).nth(0, dropna=\"any\")\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Nth:\n    def setup(self, dtype):\n        N = 10**5\n        # with datetimes (GH7555)\n        if dtype == \"datetime\":\n            values = date_range(\"1/1/2011\", periods=N, freq=\"s\")\n        elif dtype == \"object\":\n            values = [\"foo\"] * N\n        else:\n            values = np.arange(N).astype(dtype)\n    \n        key = np.arange(N)\n        self.df = DataFrame({\"key\": key, \"values\": values})\n        self.df.iloc[1, 1] = np.nan  # insert missing data", "min_run_count": 2, "name": "groupby.Nth.time_series_nth_any", "number": 0, "param_names": ["dtype"], "params": [["'float32'", "'float64'", "'datetime'", "'object'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "011dc9ba29511d4b5f0b1bb7c6f5a991ef7a1590ce479e354646546de88cfea6", "warmup_time": -1}, "groupby.RankWithTies.time_rank_ties": {"code": "class RankWithTies:\n    def time_rank_ties(self, dtype, tie_method):\n        self.df.groupby(\"key\").rank(method=tie_method)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass RankWithTies:\n    def setup(self, dtype, tie_method):\n        N = 10**4\n        if dtype == \"datetime64\":\n            data = np.array([Timestamp(\"2011/01/01\")] * N, dtype=dtype)\n        else:\n            data = np.ones(N, dtype=dtype)\n        self.df = DataFrame({\"values\": data, \"key\": [\"foo\"] * N})", "min_run_count": 2, "name": "groupby.RankWithTies.time_rank_ties", "number": 0, "param_names": ["dtype", "tie_method"], "params": [["'float64'", "'float32'", "'int64'", "'datetime64'"], ["'first'", "'average'", "'dense'", "'min'", "'max'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "622ded2b5e5432518f83a22d3ed8f82cc9f43e2ca4ab46c97e7aa4dd1daf7f10", "warmup_time": -1}, "groupby.Resample.time_resample": {"code": "class Resample:\n    def time_resample(self):\n        self.df.groupby(level=\"groups\").resample(\"10s\", on=\"timedeltas\").mean()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Resample:\n    def setup(self):\n        num_timedeltas = 20_000\n        num_groups = 3\n    \n        index = MultiIndex.from_product(\n            [\n                np.arange(num_groups),\n                to_timedelta(np.arange(num_timedeltas), unit=\"s\"),\n            ],\n            names=[\"groups\", \"timedeltas\"],\n        )\n        data = np.random.randint(0, 1000, size=(len(index)))\n    \n        self.df = DataFrame(data, index=index).reset_index(\"timedeltas\")\n        self.df_multiindex = DataFrame(data, index=index)", "min_run_count": 2, "name": "groupby.Resample.time_resample", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "2f73c1abc5cfc408cd8604b1badf9ee4f00ceb2a76c77b5b5a78af2d74228f7b", "warmup_time": -1}, "groupby.Resample.time_resample_multiindex": {"code": "class Resample:\n    def time_resample_multiindex(self):\n        self.df_multiindex.groupby(level=\"groups\").resample(\n            \"10s\", level=\"timedeltas\"\n        ).mean()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Resample:\n    def setup(self):\n        num_timedeltas = 20_000\n        num_groups = 3\n    \n        index = MultiIndex.from_product(\n            [\n                np.arange(num_groups),\n                to_timedelta(np.arange(num_timedeltas), unit=\"s\"),\n            ],\n            names=[\"groups\", \"timedeltas\"],\n        )\n        data = np.random.randint(0, 1000, size=(len(index)))\n    \n        self.df = DataFrame(data, index=index).reset_index(\"timedeltas\")\n        self.df_multiindex = DataFrame(data, index=index)", "min_run_count": 2, "name": "groupby.Resample.time_resample_multiindex", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "07304b920f854bdb1422e0b993c60857e6e2d6ad9ce2664f92ee8e113c3df234", "warmup_time": -1}, "groupby.Sample.time_sample": {"code": "class Sample:\n    def time_sample(self):\n        self.df.groupby(self.groups).sample(n=1)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Sample:\n    def setup(self):\n        N = 10**3\n        self.df = DataFrame({\"a\": np.zeros(N)})\n        self.groups = np.arange(0, N)\n        self.weights = np.ones(N)", "min_run_count": 2, "name": "groupby.Sample.time_sample", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "d06fc92a35cfb5f7ef26863259f097f3aabbef9d90438fde13891e042fa2cff9", "warmup_time": -1}, "groupby.Sample.time_sample_weights": {"code": "class Sample:\n    def time_sample_weights(self):\n        self.df.groupby(self.groups).sample(n=1, weights=self.weights)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Sample:\n    def setup(self):\n        N = 10**3\n        self.df = DataFrame({\"a\": np.zeros(N)})\n        self.groups = np.arange(0, N)\n        self.weights = np.ones(N)", "min_run_count": 2, "name": "groupby.Sample.time_sample_weights", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "66bb261674cbd4d0e341aebd067908473e0734bca8091cd8bae8282d7706dd4d", "warmup_time": -1}, "groupby.Shift.time_defaults": {"code": "class Shift:\n    def time_defaults(self):\n        self.df.groupby(\"g\").shift()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Shift:\n    def setup(self):\n        N = 18\n        self.df = DataFrame({\"g\": [\"a\", \"b\"] * 9, \"v\": list(range(N))})", "min_run_count": 2, "name": "groupby.Shift.time_defaults", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "6a3a41956cf53e5cacf8be90a4432268657d065e708f3681cb0da232d8442b7b", "warmup_time": -1}, "groupby.Shift.time_fill_value": {"code": "class Shift:\n    def time_fill_value(self):\n        self.df.groupby(\"g\").shift(fill_value=99)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Shift:\n    def setup(self):\n        N = 18\n        self.df = DataFrame({\"g\": [\"a\", \"b\"] * 9, \"v\": list(range(N))})", "min_run_count": 2, "name": "groupby.Shift.time_fill_value", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "92e908ccaf513773d03d593373379bb94d333da277d2214a08ee1905d58e0c3b", "warmup_time": -1}, "groupby.Size.time_category_size": {"code": "class Size:\n    def time_category_size(self):\n        self.draws.groupby(self.cats, observed=True).size()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Size:\n    def setup(self):\n        n = 10**5\n        offsets = np.random.randint(n, size=n).astype(\"timedelta64[ns]\")\n        dates = np.datetime64(\"now\") + offsets\n        self.df = DataFrame(\n            {\n                \"key1\": np.random.randint(0, 500, size=n),\n                \"key2\": np.random.randint(0, 100, size=n),\n                \"value1\": np.random.randn(n),\n                \"value2\": np.random.randn(n),\n                \"value3\": np.random.randn(n),\n                \"dates\": dates,\n            }\n        )\n        self.draws = Series(np.random.randn(n))\n        labels = Series([\"foo\", \"bar\", \"baz\", \"qux\"] * (n // 4))\n        self.cats = labels.astype(\"category\")", "min_run_count": 2, "name": "groupby.Size.time_category_size", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "5eddb01370059c88e32f412a47746b638593daac39af9c786d43aafdf2e803b3", "warmup_time": -1}, "groupby.Size.time_multi_size": {"code": "class Size:\n    def time_multi_size(self):\n        self.df.groupby([\"key1\", \"key2\"]).size()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Size:\n    def setup(self):\n        n = 10**5\n        offsets = np.random.randint(n, size=n).astype(\"timedelta64[ns]\")\n        dates = np.datetime64(\"now\") + offsets\n        self.df = DataFrame(\n            {\n                \"key1\": np.random.randint(0, 500, size=n),\n                \"key2\": np.random.randint(0, 100, size=n),\n                \"value1\": np.random.randn(n),\n                \"value2\": np.random.randn(n),\n                \"value3\": np.random.randn(n),\n                \"dates\": dates,\n            }\n        )\n        self.draws = Series(np.random.randn(n))\n        labels = Series([\"foo\", \"bar\", \"baz\", \"qux\"] * (n // 4))\n        self.cats = labels.astype(\"category\")", "min_run_count": 2, "name": "groupby.Size.time_multi_size", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "34694723d47ec5028bd8d513e5986c685e58d7219113ca9a4be7e030a9a98aa1", "warmup_time": -1}, "groupby.String.time_str_func": {"code": "class String:\n    def time_str_func(self, dtype, method):\n        self.df.groupby(\"a\")[self.df.columns[1:]].agg(method)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass String:\n    def setup(self, dtype, method):\n        cols = list(\"abcdefghjkl\")\n        self.df = DataFrame(\n            np.random.randint(0, 100, size=(10_000, len(cols))),\n            columns=cols,\n            dtype=dtype,\n        )", "min_run_count": 2, "name": "groupby.String.time_str_func", "number": 0, "param_names": ["dtype", "method"], "params": [["'str'", "'string[python]'"], ["'sum'", "'min'", "'max'", "'first'", "'last'", "'any'", "'all'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "b49dcaf61606c8e3e1fd9bd0ca3f1d1b8833147e2b729e1e363d481f98270ec4", "warmup_time": -1}, "groupby.SumBools.time_groupby_sum_booleans": {"code": "class SumBools:\n    def time_groupby_sum_booleans(self):\n        self.df.groupby(\"ii\").sum()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass SumBools:\n    def setup(self):\n        N = 500\n        self.df = DataFrame({\"ii\": range(N), \"bb\": [True] * N})", "min_run_count": 2, "name": "groupby.SumBools.time_groupby_sum_booleans", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "c3539588ce95b04f6cfe6c310ff1d827826da14d25eafe09e1d58cf28f0f2020", "warmup_time": -1}, "groupby.SumMultiLevel.time_groupby_sum_multiindex": {"code": "class SumMultiLevel:\n    def time_groupby_sum_multiindex(self):\n        self.df.groupby(level=[0, 1]).sum()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass SumMultiLevel:\n    def setup(self):\n        N = 50\n        self.df = DataFrame(\n            {\"A\": list(range(N)) * 2, \"B\": range(N * 2), \"C\": 1}\n        ).set_index([\"A\", \"B\"])", "min_run_count": 2, "name": "groupby.SumMultiLevel.time_groupby_sum_multiindex", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 120.0, "type": "time", "unit": "seconds", "version": "b34947d529ea832ced0c45868dd46b91974ce4d6a23b4212210c255083673ef8", "warmup_time": -1}, "groupby.SumTimeDelta.time_groupby_sum_int": {"code": "class SumTimeDelta:\n    def time_groupby_sum_int(self):\n        self.df_int.groupby(lambda x: x).sum()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass SumTimeDelta:\n    def setup(self):\n        N = 10**4\n        self.df = DataFrame(\n            np.random.randint(1000, 100000, (N, 100)),\n            index=np.random.randint(200, size=(N,)),\n        ).astype(\"timedelta64[ns]\")\n        self.df_int = self.df.copy().astype(\"int64\")", "min_run_count": 2, "name": "groupby.SumTimeDelta.time_groupby_sum_int", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "3ac04c1b47b978a60e2dd36712fe8b5546ca48524e482437ab7dd05d74d70b51", "warmup_time": -1}, "groupby.SumTimeDelta.time_groupby_sum_timedelta": {"code": "class SumTimeDelta:\n    def time_groupby_sum_timedelta(self):\n        self.df.groupby(lambda x: x).sum()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass SumTimeDelta:\n    def setup(self):\n        N = 10**4\n        self.df = DataFrame(\n            np.random.randint(1000, 100000, (N, 100)),\n            index=np.random.randint(200, size=(N,)),\n        ).astype(\"timedelta64[ns]\")\n        self.df_int = self.df.copy().astype(\"int64\")", "min_run_count": 2, "name": "groupby.SumTimeDelta.time_groupby_sum_timedelta", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "2399de64ddcb9b1503469e78a45205ffbc8d6c7780eb674273569e1a06d55607", "warmup_time": -1}, "groupby.Transform.time_transform_lambda_max": {"code": "class Transform:\n    def time_transform_lambda_max(self):\n        self.df.groupby(level=\"lev1\").transform(lambda x: max(x))\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Transform:\n    def setup(self):\n        n1 = 400\n        n2 = 250\n        index = MultiIndex(\n            levels=[np.arange(n1), Index([f\"i-{i}\" for i in range(n2)], dtype=object)],\n            codes=[np.repeat(range(n1), n2).tolist(), list(range(n2)) * n1],\n            names=[\"lev1\", \"lev2\"],\n        )\n        arr = np.random.randn(n1 * n2, 3)\n        arr[::10000, 0] = np.nan\n        arr[1::10000, 1] = np.nan\n        arr[2::10000, 2] = np.nan\n        data = DataFrame(arr, index=index, columns=[\"col1\", \"col20\", \"col3\"])\n        self.df = data\n    \n        n = 1000\n        self.df_wide = DataFrame(\n            np.random.randn(n, n),\n            index=np.random.choice(range(10), n),\n        )\n    \n        n = 1_000_000\n        self.df_tall = DataFrame(\n            np.random.randn(n, 3),\n            index=np.random.randint(0, 5, n),\n        )\n    \n        n = 20000\n        self.df1 = DataFrame(\n            np.random.randint(1, n, (n, 3)), columns=[\"jim\", \"joe\", \"jolie\"]\n        )\n        self.df2 = self.df1.copy()\n        self.df2[\"jim\"] = self.df2[\"joe\"]\n    \n        self.df3 = DataFrame(\n            np.random.randint(1, (n / 10), (n, 3)), columns=[\"jim\", \"joe\", \"jolie\"]\n        )\n        self.df4 = self.df3.copy()\n        self.df4[\"jim\"] = self.df4[\"joe\"]", "min_run_count": 2, "name": "groupby.Transform.time_transform_lambda_max", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "291190f0a573b88f867178ceac1295c04bb53f214b480bc15fced8ee95dd4089", "warmup_time": -1}, "groupby.Transform.time_transform_lambda_max_tall": {"code": "class Transform:\n    def time_transform_lambda_max_tall(self):\n        self.df_tall.groupby(level=0).transform(lambda x: np.max(x, axis=0))\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Transform:\n    def setup(self):\n        n1 = 400\n        n2 = 250\n        index = MultiIndex(\n            levels=[np.arange(n1), Index([f\"i-{i}\" for i in range(n2)], dtype=object)],\n            codes=[np.repeat(range(n1), n2).tolist(), list(range(n2)) * n1],\n            names=[\"lev1\", \"lev2\"],\n        )\n        arr = np.random.randn(n1 * n2, 3)\n        arr[::10000, 0] = np.nan\n        arr[1::10000, 1] = np.nan\n        arr[2::10000, 2] = np.nan\n        data = DataFrame(arr, index=index, columns=[\"col1\", \"col20\", \"col3\"])\n        self.df = data\n    \n        n = 1000\n        self.df_wide = DataFrame(\n            np.random.randn(n, n),\n            index=np.random.choice(range(10), n),\n        )\n    \n        n = 1_000_000\n        self.df_tall = DataFrame(\n            np.random.randn(n, 3),\n            index=np.random.randint(0, 5, n),\n        )\n    \n        n = 20000\n        self.df1 = DataFrame(\n            np.random.randint(1, n, (n, 3)), columns=[\"jim\", \"joe\", \"jolie\"]\n        )\n        self.df2 = self.df1.copy()\n        self.df2[\"jim\"] = self.df2[\"joe\"]\n    \n        self.df3 = DataFrame(\n            np.random.randint(1, (n / 10), (n, 3)), columns=[\"jim\", \"joe\", \"jolie\"]\n        )\n        self.df4 = self.df3.copy()\n        self.df4[\"jim\"] = self.df4[\"joe\"]", "min_run_count": 2, "name": "groupby.Transform.time_transform_lambda_max_tall", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "0715fe48299e582fbe65937e99c6a8d54e797598178532c197eb7628502c9550", "warmup_time": -1}, "groupby.Transform.time_transform_lambda_max_wide": {"code": "class Transform:\n    def time_transform_lambda_max_wide(self):\n        self.df_wide.groupby(level=0).transform(lambda x: np.max(x, axis=0))\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Transform:\n    def setup(self):\n        n1 = 400\n        n2 = 250\n        index = MultiIndex(\n            levels=[np.arange(n1), Index([f\"i-{i}\" for i in range(n2)], dtype=object)],\n            codes=[np.repeat(range(n1), n2).tolist(), list(range(n2)) * n1],\n            names=[\"lev1\", \"lev2\"],\n        )\n        arr = np.random.randn(n1 * n2, 3)\n        arr[::10000, 0] = np.nan\n        arr[1::10000, 1] = np.nan\n        arr[2::10000, 2] = np.nan\n        data = DataFrame(arr, index=index, columns=[\"col1\", \"col20\", \"col3\"])\n        self.df = data\n    \n        n = 1000\n        self.df_wide = DataFrame(\n            np.random.randn(n, n),\n            index=np.random.choice(range(10), n),\n        )\n    \n        n = 1_000_000\n        self.df_tall = DataFrame(\n            np.random.randn(n, 3),\n            index=np.random.randint(0, 5, n),\n        )\n    \n        n = 20000\n        self.df1 = DataFrame(\n            np.random.randint(1, n, (n, 3)), columns=[\"jim\", \"joe\", \"jolie\"]\n        )\n        self.df2 = self.df1.copy()\n        self.df2[\"jim\"] = self.df2[\"joe\"]\n    \n        self.df3 = DataFrame(\n            np.random.randint(1, (n / 10), (n, 3)), columns=[\"jim\", \"joe\", \"jolie\"]\n        )\n        self.df4 = self.df3.copy()\n        self.df4[\"jim\"] = self.df4[\"joe\"]", "min_run_count": 2, "name": "groupby.Transform.time_transform_lambda_max_wide", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "e300e23373f04b050335813db183ab5f4fdc3090aa3c7c010731410139b922a2", "warmup_time": -1}, "groupby.Transform.time_transform_multi_key1": {"code": "class Transform:\n    def time_transform_multi_key1(self):\n        self.df1.groupby([\"jim\", \"joe\"])[\"jolie\"].transform(\"max\")\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Transform:\n    def setup(self):\n        n1 = 400\n        n2 = 250\n        index = MultiIndex(\n            levels=[np.arange(n1), Index([f\"i-{i}\" for i in range(n2)], dtype=object)],\n            codes=[np.repeat(range(n1), n2).tolist(), list(range(n2)) * n1],\n            names=[\"lev1\", \"lev2\"],\n        )\n        arr = np.random.randn(n1 * n2, 3)\n        arr[::10000, 0] = np.nan\n        arr[1::10000, 1] = np.nan\n        arr[2::10000, 2] = np.nan\n        data = DataFrame(arr, index=index, columns=[\"col1\", \"col20\", \"col3\"])\n        self.df = data\n    \n        n = 1000\n        self.df_wide = DataFrame(\n            np.random.randn(n, n),\n            index=np.random.choice(range(10), n),\n        )\n    \n        n = 1_000_000\n        self.df_tall = DataFrame(\n            np.random.randn(n, 3),\n            index=np.random.randint(0, 5, n),\n        )\n    \n        n = 20000\n        self.df1 = DataFrame(\n            np.random.randint(1, n, (n, 3)), columns=[\"jim\", \"joe\", \"jolie\"]\n        )\n        self.df2 = self.df1.copy()\n        self.df2[\"jim\"] = self.df2[\"joe\"]\n    \n        self.df3 = DataFrame(\n            np.random.randint(1, (n / 10), (n, 3)), columns=[\"jim\", \"joe\", \"jolie\"]\n        )\n        self.df4 = self.df3.copy()\n        self.df4[\"jim\"] = self.df4[\"joe\"]", "min_run_count": 2, "name": "groupby.Transform.time_transform_multi_key1", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "366e371c2918778eb64606950f5d97720245d6f5c1d70398a7d693b6806cff22", "warmup_time": -1}, "groupby.Transform.time_transform_multi_key2": {"code": "class Transform:\n    def time_transform_multi_key2(self):\n        self.df2.groupby([\"jim\", \"joe\"])[\"jolie\"].transform(\"max\")\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Transform:\n    def setup(self):\n        n1 = 400\n        n2 = 250\n        index = MultiIndex(\n            levels=[np.arange(n1), Index([f\"i-{i}\" for i in range(n2)], dtype=object)],\n            codes=[np.repeat(range(n1), n2).tolist(), list(range(n2)) * n1],\n            names=[\"lev1\", \"lev2\"],\n        )\n        arr = np.random.randn(n1 * n2, 3)\n        arr[::10000, 0] = np.nan\n        arr[1::10000, 1] = np.nan\n        arr[2::10000, 2] = np.nan\n        data = DataFrame(arr, index=index, columns=[\"col1\", \"col20\", \"col3\"])\n        self.df = data\n    \n        n = 1000\n        self.df_wide = DataFrame(\n            np.random.randn(n, n),\n            index=np.random.choice(range(10), n),\n        )\n    \n        n = 1_000_000\n        self.df_tall = DataFrame(\n            np.random.randn(n, 3),\n            index=np.random.randint(0, 5, n),\n        )\n    \n        n = 20000\n        self.df1 = DataFrame(\n            np.random.randint(1, n, (n, 3)), columns=[\"jim\", \"joe\", \"jolie\"]\n        )\n        self.df2 = self.df1.copy()\n        self.df2[\"jim\"] = self.df2[\"joe\"]\n    \n        self.df3 = DataFrame(\n            np.random.randint(1, (n / 10), (n, 3)), columns=[\"jim\", \"joe\", \"jolie\"]\n        )\n        self.df4 = self.df3.copy()\n        self.df4[\"jim\"] = self.df4[\"joe\"]", "min_run_count": 2, "name": "groupby.Transform.time_transform_multi_key2", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "07ba2bab8a423416e13164dea63101908acca0e0e9c2a38d7276dec381baa054", "warmup_time": -1}, "groupby.Transform.time_transform_multi_key3": {"code": "class Transform:\n    def time_transform_multi_key3(self):\n        self.df3.groupby([\"jim\", \"joe\"])[\"jolie\"].transform(\"max\")\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Transform:\n    def setup(self):\n        n1 = 400\n        n2 = 250\n        index = MultiIndex(\n            levels=[np.arange(n1), Index([f\"i-{i}\" for i in range(n2)], dtype=object)],\n            codes=[np.repeat(range(n1), n2).tolist(), list(range(n2)) * n1],\n            names=[\"lev1\", \"lev2\"],\n        )\n        arr = np.random.randn(n1 * n2, 3)\n        arr[::10000, 0] = np.nan\n        arr[1::10000, 1] = np.nan\n        arr[2::10000, 2] = np.nan\n        data = DataFrame(arr, index=index, columns=[\"col1\", \"col20\", \"col3\"])\n        self.df = data\n    \n        n = 1000\n        self.df_wide = DataFrame(\n            np.random.randn(n, n),\n            index=np.random.choice(range(10), n),\n        )\n    \n        n = 1_000_000\n        self.df_tall = DataFrame(\n            np.random.randn(n, 3),\n            index=np.random.randint(0, 5, n),\n        )\n    \n        n = 20000\n        self.df1 = DataFrame(\n            np.random.randint(1, n, (n, 3)), columns=[\"jim\", \"joe\", \"jolie\"]\n        )\n        self.df2 = self.df1.copy()\n        self.df2[\"jim\"] = self.df2[\"joe\"]\n    \n        self.df3 = DataFrame(\n            np.random.randint(1, (n / 10), (n, 3)), columns=[\"jim\", \"joe\", \"jolie\"]\n        )\n        self.df4 = self.df3.copy()\n        self.df4[\"jim\"] = self.df4[\"joe\"]", "min_run_count": 2, "name": "groupby.Transform.time_transform_multi_key3", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "0535ec60ed264575ec4171ebd7c700b11428d714ccba8793dd6e2f3c2b093233", "warmup_time": -1}, "groupby.Transform.time_transform_multi_key4": {"code": "class Transform:\n    def time_transform_multi_key4(self):\n        self.df4.groupby([\"jim\", \"joe\"])[\"jolie\"].transform(\"max\")\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Transform:\n    def setup(self):\n        n1 = 400\n        n2 = 250\n        index = MultiIndex(\n            levels=[np.arange(n1), Index([f\"i-{i}\" for i in range(n2)], dtype=object)],\n            codes=[np.repeat(range(n1), n2).tolist(), list(range(n2)) * n1],\n            names=[\"lev1\", \"lev2\"],\n        )\n        arr = np.random.randn(n1 * n2, 3)\n        arr[::10000, 0] = np.nan\n        arr[1::10000, 1] = np.nan\n        arr[2::10000, 2] = np.nan\n        data = DataFrame(arr, index=index, columns=[\"col1\", \"col20\", \"col3\"])\n        self.df = data\n    \n        n = 1000\n        self.df_wide = DataFrame(\n            np.random.randn(n, n),\n            index=np.random.choice(range(10), n),\n        )\n    \n        n = 1_000_000\n        self.df_tall = DataFrame(\n            np.random.randn(n, 3),\n            index=np.random.randint(0, 5, n),\n        )\n    \n        n = 20000\n        self.df1 = DataFrame(\n            np.random.randint(1, n, (n, 3)), columns=[\"jim\", \"joe\", \"jolie\"]\n        )\n        self.df2 = self.df1.copy()\n        self.df2[\"jim\"] = self.df2[\"joe\"]\n    \n        self.df3 = DataFrame(\n            np.random.randint(1, (n / 10), (n, 3)), columns=[\"jim\", \"joe\", \"jolie\"]\n        )\n        self.df4 = self.df3.copy()\n        self.df4[\"jim\"] = self.df4[\"joe\"]", "min_run_count": 2, "name": "groupby.Transform.time_transform_multi_key4", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "909a4078e8d6a175f6cada96c1bdf3a92bb698109b6d4b03667bdae77cebbfb0", "warmup_time": -1}, "groupby.Transform.time_transform_str_max": {"code": "class Transform:\n    def time_transform_str_max(self):\n        self.df.groupby(level=\"lev1\").transform(\"max\")\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Transform:\n    def setup(self):\n        n1 = 400\n        n2 = 250\n        index = MultiIndex(\n            levels=[np.arange(n1), Index([f\"i-{i}\" for i in range(n2)], dtype=object)],\n            codes=[np.repeat(range(n1), n2).tolist(), list(range(n2)) * n1],\n            names=[\"lev1\", \"lev2\"],\n        )\n        arr = np.random.randn(n1 * n2, 3)\n        arr[::10000, 0] = np.nan\n        arr[1::10000, 1] = np.nan\n        arr[2::10000, 2] = np.nan\n        data = DataFrame(arr, index=index, columns=[\"col1\", \"col20\", \"col3\"])\n        self.df = data\n    \n        n = 1000\n        self.df_wide = DataFrame(\n            np.random.randn(n, n),\n            index=np.random.choice(range(10), n),\n        )\n    \n        n = 1_000_000\n        self.df_tall = DataFrame(\n            np.random.randn(n, 3),\n            index=np.random.randint(0, 5, n),\n        )\n    \n        n = 20000\n        self.df1 = DataFrame(\n            np.random.randint(1, n, (n, 3)), columns=[\"jim\", \"joe\", \"jolie\"]\n        )\n        self.df2 = self.df1.copy()\n        self.df2[\"jim\"] = self.df2[\"joe\"]\n    \n        self.df3 = DataFrame(\n            np.random.randint(1, (n / 10), (n, 3)), columns=[\"jim\", \"joe\", \"jolie\"]\n        )\n        self.df4 = self.df3.copy()\n        self.df4[\"jim\"] = self.df4[\"joe\"]", "min_run_count": 2, "name": "groupby.Transform.time_transform_str_max", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "f0a9ece43b99ebb197312d9bb8296b5f64c894b31c206c02264bf0bca0f4b27d", "warmup_time": -1}, "groupby.TransformBools.time_transform_mean": {"code": "class TransformBools:\n    def time_transform_mean(self):\n        self.df[\"signal\"].groupby(self.g).transform(\"mean\")\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass TransformBools:\n    def setup(self):\n        N = 120000\n        transition_points = np.sort(np.random.choice(np.arange(N), 1400))\n        transitions = np.zeros(N, dtype=np.bool_)\n        transitions[transition_points] = True\n        self.g = transitions.cumsum()\n        self.df = DataFrame({\"signal\": np.random.rand(N)})", "min_run_count": 2, "name": "groupby.TransformBools.time_transform_mean", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "fbf9d5bd6f37110a204b7a248de7080198abd4d49e10d7e866f785439364bb84", "warmup_time": -1}, "groupby.TransformEngine.time_dataframe_cython": {"code": "class TransformEngine:\n    def time_dataframe_cython(self, parallel):\n        def function(values):\n            return values * 5\n    \n        self.grouper.transform(function, engine=\"cython\")\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass TransformEngine:\n    def setup(self, parallel):\n        N = 10**3\n        data = DataFrame(\n            {0: [str(i) for i in range(100)] * N, 1: list(range(100)) * N},\n            columns=[0, 1],\n        )\n        self.parallel = parallel\n        self.grouper = data.groupby(0)", "min_run_count": 2, "name": "groupby.TransformEngine.time_dataframe_cython", "number": 0, "param_names": ["parallel"], "params": [["True", "False"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "d0c83497327280f78a5062c9717764f36483b50943b5eb9fe60025ca086edb53", "warmup_time": -1}, "groupby.TransformEngine.time_dataframe_numba": {"code": "class TransformEngine:\n    def time_dataframe_numba(self, parallel):\n        def function(values, index):\n            return values * 5\n    \n        self.grouper.transform(\n            function, engine=\"numba\", engine_kwargs={\"parallel\": self.parallel}\n        )\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass TransformEngine:\n    def setup(self, parallel):\n        N = 10**3\n        data = DataFrame(\n            {0: [str(i) for i in range(100)] * N, 1: list(range(100)) * N},\n            columns=[0, 1],\n        )\n        self.parallel = parallel\n        self.grouper = data.groupby(0)", "min_run_count": 2, "name": "groupby.TransformEngine.time_dataframe_numba", "number": 0, "param_names": ["parallel"], "params": [["True", "False"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "146b7844bad06cc92400f5337ad2abbbb2ef4e7262b9ecf7bf2f369e08df9e5c", "warmup_time": -1}, "groupby.TransformEngine.time_series_cython": {"code": "class TransformEngine:\n    def time_series_cython(self, parallel):\n        def function(values):\n            return values * 5\n    \n        self.grouper[1].transform(function, engine=\"cython\")\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass TransformEngine:\n    def setup(self, parallel):\n        N = 10**3\n        data = DataFrame(\n            {0: [str(i) for i in range(100)] * N, 1: list(range(100)) * N},\n            columns=[0, 1],\n        )\n        self.parallel = parallel\n        self.grouper = data.groupby(0)", "min_run_count": 2, "name": "groupby.TransformEngine.time_series_cython", "number": 0, "param_names": ["parallel"], "params": [["True", "False"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "2826562b07220b11d0e02a233f43f754b8f9b1b0dbed50ca3f2b3bf25b71995d", "warmup_time": -1}, "groupby.TransformEngine.time_series_numba": {"code": "class TransformEngine:\n    def time_series_numba(self, parallel):\n        def function(values, index):\n            return values * 5\n    \n        self.grouper[1].transform(\n            function, engine=\"numba\", engine_kwargs={\"parallel\": self.parallel}\n        )\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass TransformEngine:\n    def setup(self, parallel):\n        N = 10**3\n        data = DataFrame(\n            {0: [str(i) for i in range(100)] * N, 1: list(range(100)) * N},\n            columns=[0, 1],\n        )\n        self.parallel = parallel\n        self.grouper = data.groupby(0)", "min_run_count": 2, "name": "groupby.TransformEngine.time_series_numba", "number": 0, "param_names": ["parallel"], "params": [["True", "False"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "b20f5b20c80e1abd068634154b292c0cc05eaed4af84c3f95bdd4fb09e654937", "warmup_time": -1}, "groupby.TransformNaN.time_first": {"code": "class TransformNaN:\n    def time_first(self):\n        self.df_nans.groupby(\"key\").transform(\"first\")\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass TransformNaN:\n    def setup(self):\n        self.df_nans = DataFrame(\n            {\"key\": np.repeat(np.arange(1000), 10), \"B\": np.nan, \"C\": np.nan}\n        )\n        self.df_nans.loc[4::10, \"B\":\"C\"] = 5", "min_run_count": 2, "name": "groupby.TransformNaN.time_first", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "466258ae973db79b6c4ae80572d3424a11b6997e4ab98b9751eb9a5d30f468e8", "warmup_time": -1}, "hash_functions.Float64GroupIndex.time_groupby": {"code": "class Float64GroupIndex:\n    def time_groupby(self):\n        self.df.groupby(self.group_index).last()\n\n    def setup(self):\n        self.df = pd.date_range(\n            start=\"1/1/2018\", end=\"1/2/2018\", periods=10**6\n        ).to_frame()\n        self.group_index = np.round(self.df.index.astype(int) / 10**9)", "min_run_count": 2, "name": "hash_functions.Float64GroupIndex.time_groupby", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "16fa99f7d4871f73a649b4eb9085ebd39124ac1b6451a2321c9fb1e2792d9569", "warmup_time": -1}, "hash_functions.NumericSeriesIndexing.time_loc_slice": {"code": "class NumericSeriesIndexing:\n    def time_loc_slice(self, index, N):\n        # trigger building of mapping\n        self.data.loc[:800]\n\n    def setup(self, dtype, N):\n        vals = np.array(list(range(55)) + [54] + list(range(55, N - 1)), dtype=dtype)\n        indices = pd.Index(vals)\n        self.data = pd.Series(np.arange(N), index=indices)", "min_run_count": 2, "name": "hash_functions.NumericSeriesIndexing.time_loc_slice", "number": 0, "param_names": ["dtype", "N"], "params": [["<class 'numpy.int64'>", "<class 'numpy.uint64'>", "<class 'numpy.float64'>"], ["10000", "100000", "500000", "1000000", "5000000"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "bbd9b15d7f65d1d2a57335626da432a02c7db5e70cbd8098c13b4e3d4b391802", "warmup_time": -1}, "hash_functions.NumericSeriesIndexingShuffled.time_loc_slice": {"code": "class NumericSeriesIndexingShuffled:\n    def time_loc_slice(self, index, N):\n        # trigger building of mapping\n        self.data.loc[:800]\n\n    def setup(self, dtype, N):\n        vals = np.array(list(range(55)) + [54] + list(range(55, N - 1)), dtype=dtype)\n        np.random.shuffle(vals)\n        indices = pd.Index(vals)\n        self.data = pd.Series(np.arange(N), index=indices)", "min_run_count": 2, "name": "hash_functions.NumericSeriesIndexingShuffled.time_loc_slice", "number": 0, "param_names": ["dtype", "N"], "params": [["<class 'numpy.int64'>", "<class 'numpy.uint64'>", "<class 'numpy.float64'>"], ["10000", "100000", "500000", "1000000", "5000000"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "432c7f2c138c103e14be8ce799b1975974eeda009197320865b48b0310220376", "warmup_time": -1}, "hash_functions.Unique.time_unique": {"code": "class Unique:\n    def time_unique(self, exponent):\n        pd.unique(self.ser_unique)\n\n    def setup(self, dtype):\n        self.ser = pd.Series(([1, pd.NA, 2] + list(range(100_000))) * 3, dtype=dtype)\n        self.ser_unique = pd.Series(list(range(300_000)) + [pd.NA], dtype=dtype)", "min_run_count": 2, "name": "hash_functions.Unique.time_unique", "number": 0, "param_names": ["dtype"], "params": [["'Int64'", "'Float64'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "b4e9501a2d788652cf742d899e45ee6697865981d8caebbc02b5c662b0207edf", "warmup_time": -1}, "hash_functions.Unique.time_unique_with_duplicates": {"code": "class Unique:\n    def time_unique_with_duplicates(self, exponent):\n        pd.unique(self.ser)\n\n    def setup(self, dtype):\n        self.ser = pd.Series(([1, pd.NA, 2] + list(range(100_000))) * 3, dtype=dtype)\n        self.ser_unique = pd.Series(list(range(300_000)) + [pd.NA], dtype=dtype)", "min_run_count": 2, "name": "hash_functions.Unique.time_unique_with_duplicates", "number": 0, "param_names": ["dtype"], "params": [["'Int64'", "'Float64'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "167e56c7e4063b7bb8cad24ce741ad07d7714185a453ada8f9296eb9acf885af", "warmup_time": -1}, "hash_functions.UniqueAndFactorizeArange.time_factorize": {"code": "class UniqueAndFactorizeArange:\n    def time_factorize(self, exponent):\n        pd.factorize(self.a2)\n\n    def setup(self, exponent):\n        a = np.arange(10**4, dtype=\"float64\")\n        self.a2 = (a + 10**exponent).repeat(100)", "min_run_count": 2, "name": "hash_functions.UniqueAndFactorizeArange.time_factorize", "number": 0, "param_names": ["exponent"], "params": [["4", "5", "6", "7", "8", "9", "10", "11", "12", "13", "14", "15"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "0f26f4d8f2608aa8c5a85a0f06b3d3035de285c9a423a8f0f98688da07c40443", "warmup_time": -1}, "hash_functions.UniqueAndFactorizeArange.time_unique": {"code": "class UniqueAndFactorizeArange:\n    def time_unique(self, exponent):\n        pd.unique(self.a2)\n\n    def setup(self, exponent):\n        a = np.arange(10**4, dtype=\"float64\")\n        self.a2 = (a + 10**exponent).repeat(100)", "min_run_count": 2, "name": "hash_functions.UniqueAndFactorizeArange.time_unique", "number": 0, "param_names": ["exponent"], "params": [["4", "5", "6", "7", "8", "9", "10", "11", "12", "13", "14", "15"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "871707976cd021a306828a6723cac7ae71087078cf1b78c6d17c352b6b600d9c", "warmup_time": -1}, "hash_functions.UniqueForLargePyObjectInts.time_unique": {"code": "class UniqueForLargePyObjectInts:\n    def time_unique(self):\n        pd.unique(self.arr)\n\n    def setup(self):\n        lst = [x << 32 for x in range(5000)]\n        self.arr = np.array(lst, dtype=np.object_)", "min_run_count": 2, "name": "hash_functions.UniqueForLargePyObjectInts.time_unique", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "2b911217a8295551fd862ba4e9a94107678d903c84a5a197b90acce421e6f8c6", "warmup_time": -1}, "index_cached_properties.IndexCache.time_engine": {"code": "class IndexCache:\n    def time_engine(self, index_type):\n        self.idx._engine\n\n    def setup(self, index_type):\n        N = 10**5\n        if index_type == \"MultiIndex\":\n            self.idx = pd.MultiIndex.from_product(\n                [pd.date_range(\"1/1/2000\", freq=\"min\", periods=N // 2), [\"a\", \"b\"]]\n            )\n        elif index_type == \"DatetimeIndex\":\n            self.idx = pd.date_range(\"1/1/2000\", freq=\"min\", periods=N)\n        elif index_type == \"Int64Index\":\n            self.idx = pd.Index(range(N), dtype=\"int64\")\n        elif index_type == \"PeriodIndex\":\n            self.idx = pd.period_range(\"1/1/2000\", freq=\"min\", periods=N)\n        elif index_type == \"RangeIndex\":\n            self.idx = pd.RangeIndex(start=0, stop=N)\n        elif index_type == \"IntervalIndex\":\n            self.idx = pd.IntervalIndex.from_arrays(range(N), range(1, N + 1))\n        elif index_type == \"TimedeltaIndex\":\n            self.idx = pd.TimedeltaIndex(range(N))\n        elif index_type == \"Float64Index\":\n            self.idx = pd.Index(range(N), dtype=\"float64\")\n        elif index_type == \"UInt64Index\":\n            self.idx = pd.Index(range(N), dtype=\"uint64\")\n        elif index_type == \"CategoricalIndex\":\n            self.idx = pd.CategoricalIndex(range(N), range(N))\n        else:\n            raise ValueError\n        assert len(self.idx) == N\n        self.idx._cache = {}", "min_run_count": 2, "name": "index_cached_properties.IndexCache.time_engine", "number": 1, "param_names": ["index_type"], "params": [["'CategoricalIndex'", "'DatetimeIndex'", "'Float64Index'", "'IntervalIndex'", "'Int64Index'", "'MultiIndex'", "'PeriodIndex'", "'RangeIndex'", "'TimedeltaIndex'", "'UInt64Index'"]], "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "740507bf126b994b6d6ebc6be8ebf07edb76586f565ac510ca9368d909d709d4", "warmup_time": -1}, "index_cached_properties.IndexCache.time_inferred_type": {"code": "class IndexCache:\n    def time_inferred_type(self, index_type):\n        self.idx.inferred_type\n\n    def setup(self, index_type):\n        N = 10**5\n        if index_type == \"MultiIndex\":\n            self.idx = pd.MultiIndex.from_product(\n                [pd.date_range(\"1/1/2000\", freq=\"min\", periods=N // 2), [\"a\", \"b\"]]\n            )\n        elif index_type == \"DatetimeIndex\":\n            self.idx = pd.date_range(\"1/1/2000\", freq=\"min\", periods=N)\n        elif index_type == \"Int64Index\":\n            self.idx = pd.Index(range(N), dtype=\"int64\")\n        elif index_type == \"PeriodIndex\":\n            self.idx = pd.period_range(\"1/1/2000\", freq=\"min\", periods=N)\n        elif index_type == \"RangeIndex\":\n            self.idx = pd.RangeIndex(start=0, stop=N)\n        elif index_type == \"IntervalIndex\":\n            self.idx = pd.IntervalIndex.from_arrays(range(N), range(1, N + 1))\n        elif index_type == \"TimedeltaIndex\":\n            self.idx = pd.TimedeltaIndex(range(N))\n        elif index_type == \"Float64Index\":\n            self.idx = pd.Index(range(N), dtype=\"float64\")\n        elif index_type == \"UInt64Index\":\n            self.idx = pd.Index(range(N), dtype=\"uint64\")\n        elif index_type == \"CategoricalIndex\":\n            self.idx = pd.CategoricalIndex(range(N), range(N))\n        else:\n            raise ValueError\n        assert len(self.idx) == N\n        self.idx._cache = {}", "min_run_count": 2, "name": "index_cached_properties.IndexCache.time_inferred_type", "number": 1, "param_names": ["index_type"], "params": [["'CategoricalIndex'", "'DatetimeIndex'", "'Float64Index'", "'IntervalIndex'", "'Int64Index'", "'MultiIndex'", "'PeriodIndex'", "'RangeIndex'", "'TimedeltaIndex'", "'UInt64Index'"]], "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "f3ebbac92d68a71460a35d139fd438638cdb972b17c7453a5812797d0a732216", "warmup_time": -1}, "index_cached_properties.IndexCache.time_is_monotonic_decreasing": {"code": "class IndexCache:\n    def time_is_monotonic_decreasing(self, index_type):\n        self.idx.is_monotonic_decreasing\n\n    def setup(self, index_type):\n        N = 10**5\n        if index_type == \"MultiIndex\":\n            self.idx = pd.MultiIndex.from_product(\n                [pd.date_range(\"1/1/2000\", freq=\"min\", periods=N // 2), [\"a\", \"b\"]]\n            )\n        elif index_type == \"DatetimeIndex\":\n            self.idx = pd.date_range(\"1/1/2000\", freq=\"min\", periods=N)\n        elif index_type == \"Int64Index\":\n            self.idx = pd.Index(range(N), dtype=\"int64\")\n        elif index_type == \"PeriodIndex\":\n            self.idx = pd.period_range(\"1/1/2000\", freq=\"min\", periods=N)\n        elif index_type == \"RangeIndex\":\n            self.idx = pd.RangeIndex(start=0, stop=N)\n        elif index_type == \"IntervalIndex\":\n            self.idx = pd.IntervalIndex.from_arrays(range(N), range(1, N + 1))\n        elif index_type == \"TimedeltaIndex\":\n            self.idx = pd.TimedeltaIndex(range(N))\n        elif index_type == \"Float64Index\":\n            self.idx = pd.Index(range(N), dtype=\"float64\")\n        elif index_type == \"UInt64Index\":\n            self.idx = pd.Index(range(N), dtype=\"uint64\")\n        elif index_type == \"CategoricalIndex\":\n            self.idx = pd.CategoricalIndex(range(N), range(N))\n        else:\n            raise ValueError\n        assert len(self.idx) == N\n        self.idx._cache = {}", "min_run_count": 2, "name": "index_cached_properties.IndexCache.time_is_monotonic_decreasing", "number": 1, "param_names": ["index_type"], "params": [["'CategoricalIndex'", "'DatetimeIndex'", "'Float64Index'", "'IntervalIndex'", "'Int64Index'", "'MultiIndex'", "'PeriodIndex'", "'RangeIndex'", "'TimedeltaIndex'", "'UInt64Index'"]], "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "0bb371064863d37bb2c6463fec281d4385b45e96f82db5c35dd8465a0914d022", "warmup_time": -1}, "index_cached_properties.IndexCache.time_is_monotonic_increasing": {"code": "class IndexCache:\n    def time_is_monotonic_increasing(self, index_type):\n        self.idx.is_monotonic_increasing\n\n    def setup(self, index_type):\n        N = 10**5\n        if index_type == \"MultiIndex\":\n            self.idx = pd.MultiIndex.from_product(\n                [pd.date_range(\"1/1/2000\", freq=\"min\", periods=N // 2), [\"a\", \"b\"]]\n            )\n        elif index_type == \"DatetimeIndex\":\n            self.idx = pd.date_range(\"1/1/2000\", freq=\"min\", periods=N)\n        elif index_type == \"Int64Index\":\n            self.idx = pd.Index(range(N), dtype=\"int64\")\n        elif index_type == \"PeriodIndex\":\n            self.idx = pd.period_range(\"1/1/2000\", freq=\"min\", periods=N)\n        elif index_type == \"RangeIndex\":\n            self.idx = pd.RangeIndex(start=0, stop=N)\n        elif index_type == \"IntervalIndex\":\n            self.idx = pd.IntervalIndex.from_arrays(range(N), range(1, N + 1))\n        elif index_type == \"TimedeltaIndex\":\n            self.idx = pd.TimedeltaIndex(range(N))\n        elif index_type == \"Float64Index\":\n            self.idx = pd.Index(range(N), dtype=\"float64\")\n        elif index_type == \"UInt64Index\":\n            self.idx = pd.Index(range(N), dtype=\"uint64\")\n        elif index_type == \"CategoricalIndex\":\n            self.idx = pd.CategoricalIndex(range(N), range(N))\n        else:\n            raise ValueError\n        assert len(self.idx) == N\n        self.idx._cache = {}", "min_run_count": 2, "name": "index_cached_properties.IndexCache.time_is_monotonic_increasing", "number": 1, "param_names": ["index_type"], "params": [["'CategoricalIndex'", "'DatetimeIndex'", "'Float64Index'", "'IntervalIndex'", "'Int64Index'", "'MultiIndex'", "'PeriodIndex'", "'RangeIndex'", "'TimedeltaIndex'", "'UInt64Index'"]], "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "de17e7db24a14fda30802ea91555a4f31065f43168acb8e3e31a1e92468b2ab5", "warmup_time": -1}, "index_cached_properties.IndexCache.time_is_unique": {"code": "class IndexCache:\n    def time_is_unique(self, index_type):\n        self.idx.is_unique\n\n    def setup(self, index_type):\n        N = 10**5\n        if index_type == \"MultiIndex\":\n            self.idx = pd.MultiIndex.from_product(\n                [pd.date_range(\"1/1/2000\", freq=\"min\", periods=N // 2), [\"a\", \"b\"]]\n            )\n        elif index_type == \"DatetimeIndex\":\n            self.idx = pd.date_range(\"1/1/2000\", freq=\"min\", periods=N)\n        elif index_type == \"Int64Index\":\n            self.idx = pd.Index(range(N), dtype=\"int64\")\n        elif index_type == \"PeriodIndex\":\n            self.idx = pd.period_range(\"1/1/2000\", freq=\"min\", periods=N)\n        elif index_type == \"RangeIndex\":\n            self.idx = pd.RangeIndex(start=0, stop=N)\n        elif index_type == \"IntervalIndex\":\n            self.idx = pd.IntervalIndex.from_arrays(range(N), range(1, N + 1))\n        elif index_type == \"TimedeltaIndex\":\n            self.idx = pd.TimedeltaIndex(range(N))\n        elif index_type == \"Float64Index\":\n            self.idx = pd.Index(range(N), dtype=\"float64\")\n        elif index_type == \"UInt64Index\":\n            self.idx = pd.Index(range(N), dtype=\"uint64\")\n        elif index_type == \"CategoricalIndex\":\n            self.idx = pd.CategoricalIndex(range(N), range(N))\n        else:\n            raise ValueError\n        assert len(self.idx) == N\n        self.idx._cache = {}", "min_run_count": 2, "name": "index_cached_properties.IndexCache.time_is_unique", "number": 1, "param_names": ["index_type"], "params": [["'CategoricalIndex'", "'DatetimeIndex'", "'Float64Index'", "'IntervalIndex'", "'Int64Index'", "'MultiIndex'", "'PeriodIndex'", "'RangeIndex'", "'TimedeltaIndex'", "'UInt64Index'"]], "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "ee6b34e14ea2eceb624910b4953fddcf15d45041d74a3636af086e47e0523800", "warmup_time": -1}, "index_cached_properties.IndexCache.time_shape": {"code": "class IndexCache:\n    def time_shape(self, index_type):\n        self.idx.shape\n\n    def setup(self, index_type):\n        N = 10**5\n        if index_type == \"MultiIndex\":\n            self.idx = pd.MultiIndex.from_product(\n                [pd.date_range(\"1/1/2000\", freq=\"min\", periods=N // 2), [\"a\", \"b\"]]\n            )\n        elif index_type == \"DatetimeIndex\":\n            self.idx = pd.date_range(\"1/1/2000\", freq=\"min\", periods=N)\n        elif index_type == \"Int64Index\":\n            self.idx = pd.Index(range(N), dtype=\"int64\")\n        elif index_type == \"PeriodIndex\":\n            self.idx = pd.period_range(\"1/1/2000\", freq=\"min\", periods=N)\n        elif index_type == \"RangeIndex\":\n            self.idx = pd.RangeIndex(start=0, stop=N)\n        elif index_type == \"IntervalIndex\":\n            self.idx = pd.IntervalIndex.from_arrays(range(N), range(1, N + 1))\n        elif index_type == \"TimedeltaIndex\":\n            self.idx = pd.TimedeltaIndex(range(N))\n        elif index_type == \"Float64Index\":\n            self.idx = pd.Index(range(N), dtype=\"float64\")\n        elif index_type == \"UInt64Index\":\n            self.idx = pd.Index(range(N), dtype=\"uint64\")\n        elif index_type == \"CategoricalIndex\":\n            self.idx = pd.CategoricalIndex(range(N), range(N))\n        else:\n            raise ValueError\n        assert len(self.idx) == N\n        self.idx._cache = {}", "min_run_count": 2, "name": "index_cached_properties.IndexCache.time_shape", "number": 1, "param_names": ["index_type"], "params": [["'CategoricalIndex'", "'DatetimeIndex'", "'Float64Index'", "'IntervalIndex'", "'Int64Index'", "'MultiIndex'", "'PeriodIndex'", "'RangeIndex'", "'TimedeltaIndex'", "'UInt64Index'"]], "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "8546f1125c3d98d90e592f3e476bbea39ecc261b095952bcf45985ed5b90c619", "warmup_time": -1}, "index_cached_properties.IndexCache.time_values": {"code": "class IndexCache:\n    def time_values(self, index_type):\n        self.idx._values\n\n    def setup(self, index_type):\n        N = 10**5\n        if index_type == \"MultiIndex\":\n            self.idx = pd.MultiIndex.from_product(\n                [pd.date_range(\"1/1/2000\", freq=\"min\", periods=N // 2), [\"a\", \"b\"]]\n            )\n        elif index_type == \"DatetimeIndex\":\n            self.idx = pd.date_range(\"1/1/2000\", freq=\"min\", periods=N)\n        elif index_type == \"Int64Index\":\n            self.idx = pd.Index(range(N), dtype=\"int64\")\n        elif index_type == \"PeriodIndex\":\n            self.idx = pd.period_range(\"1/1/2000\", freq=\"min\", periods=N)\n        elif index_type == \"RangeIndex\":\n            self.idx = pd.RangeIndex(start=0, stop=N)\n        elif index_type == \"IntervalIndex\":\n            self.idx = pd.IntervalIndex.from_arrays(range(N), range(1, N + 1))\n        elif index_type == \"TimedeltaIndex\":\n            self.idx = pd.TimedeltaIndex(range(N))\n        elif index_type == \"Float64Index\":\n            self.idx = pd.Index(range(N), dtype=\"float64\")\n        elif index_type == \"UInt64Index\":\n            self.idx = pd.Index(range(N), dtype=\"uint64\")\n        elif index_type == \"CategoricalIndex\":\n            self.idx = pd.CategoricalIndex(range(N), range(N))\n        else:\n            raise ValueError\n        assert len(self.idx) == N\n        self.idx._cache = {}", "min_run_count": 2, "name": "index_cached_properties.IndexCache.time_values", "number": 1, "param_names": ["index_type"], "params": [["'CategoricalIndex'", "'DatetimeIndex'", "'Float64Index'", "'IntervalIndex'", "'Int64Index'", "'MultiIndex'", "'PeriodIndex'", "'RangeIndex'", "'TimedeltaIndex'", "'UInt64Index'"]], "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "8fc19379f5cae741e4d0deaa9154de9d3ccffef1b639f850c8c2ace4093c3566", "warmup_time": -1}, "index_object.Float64IndexMethod.time_get_loc": {"code": "class Float64IndexMethod:\n    def time_get_loc(self):\n        self.ind.get_loc(0)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Float64IndexMethod:\n    def setup(self):\n        N = 100_000\n        a = np.arange(N, dtype=np.float64)\n        self.ind = Index(a * 4.8000000418824129e-08)", "min_run_count": 2, "name": "index_object.Float64IndexMethod.time_get_loc", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "95061ed30b62c0b9d9cf95faffe63e95be78a617811548ad955f451532cb0fba", "warmup_time": -1}, "index_object.GC.peakmem_gc_instances": {"code": "class GC:\n    def peakmem_gc_instances(self, N):\n        try:\n            gc.disable()\n    \n            for _ in range(N):\n                self.create_use_drop()\n        finally:\n            gc.enable()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)", "name": "index_object.GC.peakmem_gc_instances", "param_names": ["param1"], "params": [["1", "2", "5"]], "timeout": 60.0, "type": "peakmemory", "unit": "bytes", "version": "7b1c36ff9e60323ef8e4df7fa94a4764bdb5c6dce62bfea0095812ca55841ff9"}, "index_object.IndexAppend.time_append_int_list": {"code": "class IndexAppend:\n    def time_append_int_list(self):\n        self.int_idx.append(self.int_idxs)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass IndexAppend:\n    def setup(self):\n        N = 10_000\n        self.range_idx = RangeIndex(0, 100)\n        self.int_idx = self.range_idx.astype(int)\n        self.obj_idx = self.int_idx.astype(str)\n        self.range_idxs = []\n        self.int_idxs = []\n        self.object_idxs = []\n        for i in range(1, N):\n            r_idx = RangeIndex(i * 100, (i + 1) * 100)\n            self.range_idxs.append(r_idx)\n            i_idx = r_idx.astype(int)\n            self.int_idxs.append(i_idx)\n            o_idx = i_idx.astype(str)\n            self.object_idxs.append(o_idx)", "min_run_count": 2, "name": "index_object.IndexAppend.time_append_int_list", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "05fbabe6fe601e117cf15506b123c19243307543aaa4062209fd2b93e36972e4", "warmup_time": -1}, "index_object.IndexAppend.time_append_obj_list": {"code": "class IndexAppend:\n    def time_append_obj_list(self):\n        self.obj_idx.append(self.object_idxs)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass IndexAppend:\n    def setup(self):\n        N = 10_000\n        self.range_idx = RangeIndex(0, 100)\n        self.int_idx = self.range_idx.astype(int)\n        self.obj_idx = self.int_idx.astype(str)\n        self.range_idxs = []\n        self.int_idxs = []\n        self.object_idxs = []\n        for i in range(1, N):\n            r_idx = RangeIndex(i * 100, (i + 1) * 100)\n            self.range_idxs.append(r_idx)\n            i_idx = r_idx.astype(int)\n            self.int_idxs.append(i_idx)\n            o_idx = i_idx.astype(str)\n            self.object_idxs.append(o_idx)", "min_run_count": 2, "name": "index_object.IndexAppend.time_append_obj_list", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "e802d94288d6fa85899782962dad0555c60caee495dcba93d82528d11d820caf", "warmup_time": -1}, "index_object.IndexAppend.time_append_range_list": {"code": "class IndexAppend:\n    def time_append_range_list(self):\n        self.range_idx.append(self.range_idxs)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass IndexAppend:\n    def setup(self):\n        N = 10_000\n        self.range_idx = RangeIndex(0, 100)\n        self.int_idx = self.range_idx.astype(int)\n        self.obj_idx = self.int_idx.astype(str)\n        self.range_idxs = []\n        self.int_idxs = []\n        self.object_idxs = []\n        for i in range(1, N):\n            r_idx = RangeIndex(i * 100, (i + 1) * 100)\n            self.range_idxs.append(r_idx)\n            i_idx = r_idx.astype(int)\n            self.int_idxs.append(i_idx)\n            o_idx = i_idx.astype(str)\n            self.object_idxs.append(o_idx)", "min_run_count": 2, "name": "index_object.IndexAppend.time_append_range_list", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "ce33d2de0a76a2454729de45db0e290dc82287e0866a615650e848ff37e4ba88", "warmup_time": -1}, "index_object.IndexEquals.time_non_object_equals_multiindex": {"code": "class IndexEquals:\n    def time_non_object_equals_multiindex(self):\n        self.idx_non_object.equals(self.mi_large_slow)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass IndexEquals:\n    def setup(self):\n        idx_large_fast = RangeIndex(100_000)\n        idx_small_slow = date_range(start=\"1/1/2012\", periods=1)\n        self.mi_large_slow = MultiIndex.from_product([idx_large_fast, idx_small_slow])\n    \n        self.idx_non_object = RangeIndex(1)", "min_run_count": 2, "name": "index_object.IndexEquals.time_non_object_equals_multiindex", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "bc0a852a1647f5faba1ff3d27b24d6f703432910d3e11571a9d33ab853b195fe", "warmup_time": -1}, "index_object.Indexing.time_boolean_array": {"code": "class Indexing:\n    def time_boolean_array(self, dtype):\n        self.idx[self.array_mask]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Indexing:\n    def setup(self, dtype):\n        N = 10**6\n        if dtype == \"String\":\n            self.idx = Index([f\"i-{i}\" for i in range(N)], dtype=object)\n        elif dtype == \"Float\":\n            self.idx = Index(np.arange(N), dtype=np.float64)\n        elif dtype == \"Int\":\n            self.idx = Index(np.arange(N), dtype=np.int64)\n        self.array_mask = (np.arange(N) % 3) == 0\n        self.series_mask = Series(self.array_mask)\n        self.sorted = self.idx.sort_values()\n        half = N // 2\n        self.non_unique = self.idx[:half].append(self.idx[:half])\n        self.non_unique_sorted = self.sorted[:half].repeat(2)\n        self.key = self.sorted[N // 4]", "min_run_count": 2, "name": "index_object.Indexing.time_boolean_array", "number": 0, "param_names": ["dtype"], "params": [["'String'", "'Float'", "'Int'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "2872d6ea2933595acc8996735ecb7a9132a4426fb1407ccec9aa7efdd4ad85ad", "warmup_time": -1}, "index_object.Indexing.time_boolean_series": {"code": "class Indexing:\n    def time_boolean_series(self, dtype):\n        self.idx[self.series_mask]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Indexing:\n    def setup(self, dtype):\n        N = 10**6\n        if dtype == \"String\":\n            self.idx = Index([f\"i-{i}\" for i in range(N)], dtype=object)\n        elif dtype == \"Float\":\n            self.idx = Index(np.arange(N), dtype=np.float64)\n        elif dtype == \"Int\":\n            self.idx = Index(np.arange(N), dtype=np.int64)\n        self.array_mask = (np.arange(N) % 3) == 0\n        self.series_mask = Series(self.array_mask)\n        self.sorted = self.idx.sort_values()\n        half = N // 2\n        self.non_unique = self.idx[:half].append(self.idx[:half])\n        self.non_unique_sorted = self.sorted[:half].repeat(2)\n        self.key = self.sorted[N // 4]", "min_run_count": 2, "name": "index_object.Indexing.time_boolean_series", "number": 0, "param_names": ["dtype"], "params": [["'String'", "'Float'", "'Int'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "171ff47df045dded77e36fb401cca8017353337080c278f199fb8dcb639b5464", "warmup_time": -1}, "index_object.Indexing.time_get": {"code": "class Indexing:\n    def time_get(self, dtype):\n        self.idx[1]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Indexing:\n    def setup(self, dtype):\n        N = 10**6\n        if dtype == \"String\":\n            self.idx = Index([f\"i-{i}\" for i in range(N)], dtype=object)\n        elif dtype == \"Float\":\n            self.idx = Index(np.arange(N), dtype=np.float64)\n        elif dtype == \"Int\":\n            self.idx = Index(np.arange(N), dtype=np.int64)\n        self.array_mask = (np.arange(N) % 3) == 0\n        self.series_mask = Series(self.array_mask)\n        self.sorted = self.idx.sort_values()\n        half = N // 2\n        self.non_unique = self.idx[:half].append(self.idx[:half])\n        self.non_unique_sorted = self.sorted[:half].repeat(2)\n        self.key = self.sorted[N // 4]", "min_run_count": 2, "name": "index_object.Indexing.time_get", "number": 0, "param_names": ["dtype"], "params": [["'String'", "'Float'", "'Int'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "c57b57260524bc53aea830758c7b5709073ec090659a1d47c36095f2fb15dff7", "warmup_time": -1}, "index_object.Indexing.time_get_loc": {"code": "class Indexing:\n    def time_get_loc(self, dtype):\n        self.idx.get_loc(self.key)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Indexing:\n    def setup(self, dtype):\n        N = 10**6\n        if dtype == \"String\":\n            self.idx = Index([f\"i-{i}\" for i in range(N)], dtype=object)\n        elif dtype == \"Float\":\n            self.idx = Index(np.arange(N), dtype=np.float64)\n        elif dtype == \"Int\":\n            self.idx = Index(np.arange(N), dtype=np.int64)\n        self.array_mask = (np.arange(N) % 3) == 0\n        self.series_mask = Series(self.array_mask)\n        self.sorted = self.idx.sort_values()\n        half = N // 2\n        self.non_unique = self.idx[:half].append(self.idx[:half])\n        self.non_unique_sorted = self.sorted[:half].repeat(2)\n        self.key = self.sorted[N // 4]", "min_run_count": 2, "name": "index_object.Indexing.time_get_loc", "number": 0, "param_names": ["dtype"], "params": [["'String'", "'Float'", "'Int'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "69319b49f855f411ba4637d014498c805bf3ed2a7094c32bd645b68fc1cd4f0e", "warmup_time": -1}, "index_object.Indexing.time_get_loc_non_unique": {"code": "class Indexing:\n    def time_get_loc_non_unique(self, dtype):\n        self.non_unique.get_loc(self.key)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Indexing:\n    def setup(self, dtype):\n        N = 10**6\n        if dtype == \"String\":\n            self.idx = Index([f\"i-{i}\" for i in range(N)], dtype=object)\n        elif dtype == \"Float\":\n            self.idx = Index(np.arange(N), dtype=np.float64)\n        elif dtype == \"Int\":\n            self.idx = Index(np.arange(N), dtype=np.int64)\n        self.array_mask = (np.arange(N) % 3) == 0\n        self.series_mask = Series(self.array_mask)\n        self.sorted = self.idx.sort_values()\n        half = N // 2\n        self.non_unique = self.idx[:half].append(self.idx[:half])\n        self.non_unique_sorted = self.sorted[:half].repeat(2)\n        self.key = self.sorted[N // 4]", "min_run_count": 2, "name": "index_object.Indexing.time_get_loc_non_unique", "number": 0, "param_names": ["dtype"], "params": [["'String'", "'Float'", "'Int'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "c8473ef7870230376ca8a19b46b05af3eca2e5e512dc4b793c2815ca20baf1d4", "warmup_time": -1}, "index_object.Indexing.time_get_loc_non_unique_sorted": {"code": "class Indexing:\n    def time_get_loc_non_unique_sorted(self, dtype):\n        self.non_unique_sorted.get_loc(self.key)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Indexing:\n    def setup(self, dtype):\n        N = 10**6\n        if dtype == \"String\":\n            self.idx = Index([f\"i-{i}\" for i in range(N)], dtype=object)\n        elif dtype == \"Float\":\n            self.idx = Index(np.arange(N), dtype=np.float64)\n        elif dtype == \"Int\":\n            self.idx = Index(np.arange(N), dtype=np.int64)\n        self.array_mask = (np.arange(N) % 3) == 0\n        self.series_mask = Series(self.array_mask)\n        self.sorted = self.idx.sort_values()\n        half = N // 2\n        self.non_unique = self.idx[:half].append(self.idx[:half])\n        self.non_unique_sorted = self.sorted[:half].repeat(2)\n        self.key = self.sorted[N // 4]", "min_run_count": 2, "name": "index_object.Indexing.time_get_loc_non_unique_sorted", "number": 0, "param_names": ["dtype"], "params": [["'String'", "'Float'", "'Int'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "d3b10e0134711d5f0ab40869cd8d2c7bdb5c3036812bcd69d10d62fb1747b2d9", "warmup_time": -1}, "index_object.Indexing.time_get_loc_sorted": {"code": "class Indexing:\n    def time_get_loc_sorted(self, dtype):\n        self.sorted.get_loc(self.key)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Indexing:\n    def setup(self, dtype):\n        N = 10**6\n        if dtype == \"String\":\n            self.idx = Index([f\"i-{i}\" for i in range(N)], dtype=object)\n        elif dtype == \"Float\":\n            self.idx = Index(np.arange(N), dtype=np.float64)\n        elif dtype == \"Int\":\n            self.idx = Index(np.arange(N), dtype=np.int64)\n        self.array_mask = (np.arange(N) % 3) == 0\n        self.series_mask = Series(self.array_mask)\n        self.sorted = self.idx.sort_values()\n        half = N // 2\n        self.non_unique = self.idx[:half].append(self.idx[:half])\n        self.non_unique_sorted = self.sorted[:half].repeat(2)\n        self.key = self.sorted[N // 4]", "min_run_count": 2, "name": "index_object.Indexing.time_get_loc_sorted", "number": 0, "param_names": ["dtype"], "params": [["'String'", "'Float'", "'Int'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "739af3c9409d4e9d6c8df759ed8f56c0fd3d26f455934fbf3bb864fae82ad7df", "warmup_time": -1}, "index_object.Indexing.time_slice": {"code": "class Indexing:\n    def time_slice(self, dtype):\n        self.idx[:-1]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Indexing:\n    def setup(self, dtype):\n        N = 10**6\n        if dtype == \"String\":\n            self.idx = Index([f\"i-{i}\" for i in range(N)], dtype=object)\n        elif dtype == \"Float\":\n            self.idx = Index(np.arange(N), dtype=np.float64)\n        elif dtype == \"Int\":\n            self.idx = Index(np.arange(N), dtype=np.int64)\n        self.array_mask = (np.arange(N) % 3) == 0\n        self.series_mask = Series(self.array_mask)\n        self.sorted = self.idx.sort_values()\n        half = N // 2\n        self.non_unique = self.idx[:half].append(self.idx[:half])\n        self.non_unique_sorted = self.sorted[:half].repeat(2)\n        self.key = self.sorted[N // 4]", "min_run_count": 2, "name": "index_object.Indexing.time_slice", "number": 0, "param_names": ["dtype"], "params": [["'String'", "'Float'", "'Int'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "11119f3458bfba6b765f0d88bdf470a536cb9627fe0038c74fff6a0713250654", "warmup_time": -1}, "index_object.Indexing.time_slice_step": {"code": "class Indexing:\n    def time_slice_step(self, dtype):\n        self.idx[::2]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Indexing:\n    def setup(self, dtype):\n        N = 10**6\n        if dtype == \"String\":\n            self.idx = Index([f\"i-{i}\" for i in range(N)], dtype=object)\n        elif dtype == \"Float\":\n            self.idx = Index(np.arange(N), dtype=np.float64)\n        elif dtype == \"Int\":\n            self.idx = Index(np.arange(N), dtype=np.int64)\n        self.array_mask = (np.arange(N) % 3) == 0\n        self.series_mask = Series(self.array_mask)\n        self.sorted = self.idx.sort_values()\n        half = N // 2\n        self.non_unique = self.idx[:half].append(self.idx[:half])\n        self.non_unique_sorted = self.sorted[:half].repeat(2)\n        self.key = self.sorted[N // 4]", "min_run_count": 2, "name": "index_object.Indexing.time_slice_step", "number": 0, "param_names": ["dtype"], "params": [["'String'", "'Float'", "'Int'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "c9173d384d9c83e3f8d59ac1ffc9ef13805aa187d563490d88c3fe8968f7bc68", "warmup_time": -1}, "index_object.IntervalIndexMethod.time_intersection": {"code": "class IntervalIndexMethod:\n    def time_intersection(self, N):\n        self.left.intersection(self.right)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass IntervalIndexMethod:\n    def setup(self, N):\n        left = np.append(np.arange(N), np.array(0))\n        right = np.append(np.arange(1, N + 1), np.array(1))\n        self.intv = IntervalIndex.from_arrays(left, right)\n        self.intv._engine\n    \n        self.intv2 = IntervalIndex.from_arrays(left + 1, right + 1)\n        self.intv2._engine\n    \n        self.left = IntervalIndex.from_breaks(np.arange(N))\n        self.right = IntervalIndex.from_breaks(np.arange(N - 3, 2 * N - 3))", "min_run_count": 2, "name": "index_object.IntervalIndexMethod.time_intersection", "number": 0, "param_names": ["param1"], "params": [["1000", "100000"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "4211da5ac938e20dc8e3ebad85e3fd809e9b9485898f7bc9fa4b78bf51836ba1", "warmup_time": -1}, "index_object.IntervalIndexMethod.time_intersection_both_duplicate": {"code": "class IntervalIndexMethod:\n    def time_intersection_both_duplicate(self, N):\n        self.intv.intersection(self.intv2)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass IntervalIndexMethod:\n    def setup(self, N):\n        left = np.append(np.arange(N), np.array(0))\n        right = np.append(np.arange(1, N + 1), np.array(1))\n        self.intv = IntervalIndex.from_arrays(left, right)\n        self.intv._engine\n    \n        self.intv2 = IntervalIndex.from_arrays(left + 1, right + 1)\n        self.intv2._engine\n    \n        self.left = IntervalIndex.from_breaks(np.arange(N))\n        self.right = IntervalIndex.from_breaks(np.arange(N - 3, 2 * N - 3))", "min_run_count": 2, "name": "index_object.IntervalIndexMethod.time_intersection_both_duplicate", "number": 0, "param_names": ["param1"], "params": [["1000", "100000"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "51c27b25f860d486d8b165a9a8fff37e4de68c2b0a193957783434e9151daaaa", "warmup_time": -1}, "index_object.IntervalIndexMethod.time_intersection_one_duplicate": {"code": "class IntervalIndexMethod:\n    def time_intersection_one_duplicate(self, N):\n        self.intv.intersection(self.right)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass IntervalIndexMethod:\n    def setup(self, N):\n        left = np.append(np.arange(N), np.array(0))\n        right = np.append(np.arange(1, N + 1), np.array(1))\n        self.intv = IntervalIndex.from_arrays(left, right)\n        self.intv._engine\n    \n        self.intv2 = IntervalIndex.from_arrays(left + 1, right + 1)\n        self.intv2._engine\n    \n        self.left = IntervalIndex.from_breaks(np.arange(N))\n        self.right = IntervalIndex.from_breaks(np.arange(N - 3, 2 * N - 3))", "min_run_count": 2, "name": "index_object.IntervalIndexMethod.time_intersection_one_duplicate", "number": 0, "param_names": ["param1"], "params": [["1000", "100000"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "d690ff28419653e49b71207cafa08bd0c7e2901de3773c422f3c20c5659c70da", "warmup_time": -1}, "index_object.IntervalIndexMethod.time_is_unique": {"code": "class IntervalIndexMethod:\n    def time_is_unique(self, N):\n        self.intv.is_unique\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass IntervalIndexMethod:\n    def setup(self, N):\n        left = np.append(np.arange(N), np.array(0))\n        right = np.append(np.arange(1, N + 1), np.array(1))\n        self.intv = IntervalIndex.from_arrays(left, right)\n        self.intv._engine\n    \n        self.intv2 = IntervalIndex.from_arrays(left + 1, right + 1)\n        self.intv2._engine\n    \n        self.left = IntervalIndex.from_breaks(np.arange(N))\n        self.right = IntervalIndex.from_breaks(np.arange(N - 3, 2 * N - 3))", "min_run_count": 2, "name": "index_object.IntervalIndexMethod.time_is_unique", "number": 0, "param_names": ["param1"], "params": [["1000", "100000"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "b17a38c55c09eaaebc6e2a4010627e28285f0f0b8e734cf754a82d09ba25a090", "warmup_time": -1}, "index_object.IntervalIndexMethod.time_monotonic_inc": {"code": "class IntervalIndexMethod:\n    def time_monotonic_inc(self, N):\n        self.intv.is_monotonic_increasing\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass IntervalIndexMethod:\n    def setup(self, N):\n        left = np.append(np.arange(N), np.array(0))\n        right = np.append(np.arange(1, N + 1), np.array(1))\n        self.intv = IntervalIndex.from_arrays(left, right)\n        self.intv._engine\n    \n        self.intv2 = IntervalIndex.from_arrays(left + 1, right + 1)\n        self.intv2._engine\n    \n        self.left = IntervalIndex.from_breaks(np.arange(N))\n        self.right = IntervalIndex.from_breaks(np.arange(N - 3, 2 * N - 3))", "min_run_count": 2, "name": "index_object.IntervalIndexMethod.time_monotonic_inc", "number": 0, "param_names": ["param1"], "params": [["1000", "100000"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "2f556c42b4ba4b668eb1eb25dfddbcc31dc3735f52e12303ef99ae8a4b9243e0", "warmup_time": -1}, "index_object.Range.time_get_loc_dec": {"code": "class Range:\n    def time_get_loc_dec(self):\n        self.idx_dec.get_loc(100_000)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Range:\n    def setup(self):\n        self.idx_inc = RangeIndex(start=0, stop=10**6, step=3)\n        self.idx_dec = RangeIndex(start=10**6, stop=-1, step=-3)", "min_run_count": 2, "name": "index_object.Range.time_get_loc_dec", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "cf79b8ebe5bba662336f38ac055b59d39696daca21fa516ec6f3d586ef77fbeb", "warmup_time": -1}, "index_object.Range.time_get_loc_inc": {"code": "class Range:\n    def time_get_loc_inc(self):\n        self.idx_inc.get_loc(900_000)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Range:\n    def setup(self):\n        self.idx_inc = RangeIndex(start=0, stop=10**6, step=3)\n        self.idx_dec = RangeIndex(start=10**6, stop=-1, step=-3)", "min_run_count": 2, "name": "index_object.Range.time_get_loc_inc", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "e65b3c2e45ffd07fe90c70762651887bf917e0004b33efeabc1a1513961834af", "warmup_time": -1}, "index_object.Range.time_iter_dec": {"code": "class Range:\n    def time_iter_dec(self):\n        for _ in self.idx_dec:\n            pass\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Range:\n    def setup(self):\n        self.idx_inc = RangeIndex(start=0, stop=10**6, step=3)\n        self.idx_dec = RangeIndex(start=10**6, stop=-1, step=-3)", "min_run_count": 2, "name": "index_object.Range.time_iter_dec", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "0a8939329588ad2b3dccc5769b034e1cc2e6af1940fac168fcfa5dc2b425573c", "warmup_time": -1}, "index_object.Range.time_iter_inc": {"code": "class Range:\n    def time_iter_inc(self):\n        for _ in self.idx_inc:\n            pass\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Range:\n    def setup(self):\n        self.idx_inc = RangeIndex(start=0, stop=10**6, step=3)\n        self.idx_dec = RangeIndex(start=10**6, stop=-1, step=-3)", "min_run_count": 2, "name": "index_object.Range.time_iter_inc", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "83fc9b98da37845cad00c4fbdc28fc193a5ba6fe4036f48c28387979e66deb80", "warmup_time": -1}, "index_object.Range.time_max": {"code": "class Range:\n    def time_max(self):\n        self.idx_inc.max()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Range:\n    def setup(self):\n        self.idx_inc = RangeIndex(start=0, stop=10**6, step=3)\n        self.idx_dec = RangeIndex(start=10**6, stop=-1, step=-3)", "min_run_count": 2, "name": "index_object.Range.time_max", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "3fe3d3e0faeaa6aca9e99b56ed9428c2909cf685bc2777ad15b8b139f7f9b6fc", "warmup_time": -1}, "index_object.Range.time_max_trivial": {"code": "class Range:\n    def time_max_trivial(self):\n        self.idx_dec.max()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Range:\n    def setup(self):\n        self.idx_inc = RangeIndex(start=0, stop=10**6, step=3)\n        self.idx_dec = RangeIndex(start=10**6, stop=-1, step=-3)", "min_run_count": 2, "name": "index_object.Range.time_max_trivial", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "4e25e4137da187681125aee125ed76c646d75254e914e5a610454f0dab1bdbf2", "warmup_time": -1}, "index_object.Range.time_min": {"code": "class Range:\n    def time_min(self):\n        self.idx_dec.min()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Range:\n    def setup(self):\n        self.idx_inc = RangeIndex(start=0, stop=10**6, step=3)\n        self.idx_dec = RangeIndex(start=10**6, stop=-1, step=-3)", "min_run_count": 2, "name": "index_object.Range.time_min", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "5d8be4d1e9900d49eb6d2838b94ceaf7b5b6044f15d46b44772fd09d2ed706ed", "warmup_time": -1}, "index_object.Range.time_min_trivial": {"code": "class Range:\n    def time_min_trivial(self):\n        self.idx_inc.min()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Range:\n    def setup(self):\n        self.idx_inc = RangeIndex(start=0, stop=10**6, step=3)\n        self.idx_dec = RangeIndex(start=10**6, stop=-1, step=-3)", "min_run_count": 2, "name": "index_object.Range.time_min_trivial", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "9406fe8e0431d861ebb9af746fdd854868498b66f1a43f0b7184b8a5955f901b", "warmup_time": -1}, "index_object.Range.time_sort_values_asc": {"code": "class Range:\n    def time_sort_values_asc(self):\n        self.idx_inc.sort_values()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Range:\n    def setup(self):\n        self.idx_inc = RangeIndex(start=0, stop=10**6, step=3)\n        self.idx_dec = RangeIndex(start=10**6, stop=-1, step=-3)", "min_run_count": 2, "name": "index_object.Range.time_sort_values_asc", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "ad0ef7f510dcd8d00149b95616b19281a15359db8f2989bf9b4db306fdf0153f", "warmup_time": -1}, "index_object.Range.time_sort_values_des": {"code": "class Range:\n    def time_sort_values_des(self):\n        self.idx_inc.sort_values(ascending=False)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Range:\n    def setup(self):\n        self.idx_inc = RangeIndex(start=0, stop=10**6, step=3)\n        self.idx_dec = RangeIndex(start=10**6, stop=-1, step=-3)", "min_run_count": 2, "name": "index_object.Range.time_sort_values_des", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "c7ce6ea7bb8b8649240594fbbc1a612d9d42aa3b0e41c90f92cfb40283cbbd45", "warmup_time": -1}, "index_object.SetDisjoint.time_datetime_difference_disjoint": {"code": "class SetDisjoint:\n    def time_datetime_difference_disjoint(self):\n        self.datetime_left.difference(self.datetime_right)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass SetDisjoint:\n    def setup(self):\n        N = 10**5\n        B = N + 20000\n        self.datetime_left = DatetimeIndex(range(N))\n        self.datetime_right = DatetimeIndex(range(N, B))", "min_run_count": 2, "name": "index_object.SetDisjoint.time_datetime_difference_disjoint", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "5f314bb98034f50776d52507597278df13b4f23a7942559fc0dedf93d1c11c62", "warmup_time": -1}, "index_object.SetOperations.time_operation": {"code": "class SetOperations:\n    def time_operation(self, index_structure, dtype, method):\n        getattr(self.left, method)(self.right)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass SetOperations:\n    def setup(self, index_structure, dtype, method):\n        N = 10**5\n        dates_left = date_range(\"1/1/2000\", periods=N, freq=\"min\")\n        fmt = \"%Y-%m-%d %H:%M:%S\"\n        date_str_left = Index(dates_left.strftime(fmt))\n        int_left = Index(np.arange(N))\n        ea_int_left = Index(np.arange(N), dtype=\"Int64\")\n        str_left = Index([f\"i-{i}\" for i in range(N)], dtype=object)\n    \n        data = {\n            \"datetime\": dates_left,\n            \"date_string\": date_str_left,\n            \"int\": int_left,\n            \"strings\": str_left,\n            \"ea_int\": ea_int_left,\n        }\n    \n        if index_structure == \"non_monotonic\":\n            data = {k: mi[::-1] for k, mi in data.items()}\n    \n        data = {k: {\"left\": idx, \"right\": idx[:-1]} for k, idx in data.items()}\n    \n        self.left = data[dtype][\"left\"]\n        self.right = data[dtype][\"right\"]", "min_run_count": 2, "name": "index_object.SetOperations.time_operation", "number": 0, "param_names": ["index_structure", "dtype", "method"], "params": [["'monotonic'", "'non_monotonic'"], ["'datetime'", "'date_string'", "'int'", "'strings'", "'ea_int'"], ["'intersection'", "'union'", "'symmetric_difference'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "705854d266f8227ee3d9b1eebe268d69ac27a014c6ad4691945dfab9b8c3707b", "warmup_time": -1}, "index_object.UnionWithDuplicates.time_union_with_duplicates": {"code": "class UnionWithDuplicates:\n    def time_union_with_duplicates(self):\n        self.left.union(self.right)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass UnionWithDuplicates:\n    def setup(self):\n        self.left = Index(np.repeat(np.arange(1000), 100))\n        self.right = Index(np.tile(np.arange(500, 1500), 50))", "min_run_count": 2, "name": "index_object.UnionWithDuplicates.time_union_with_duplicates", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "0420e720a40b09b5a83ef4ace67c704a238d521a86a8cb00c673aae12cfa2f25", "warmup_time": -1}, "indexing.AssignTimeseriesIndex.time_frame_assign_timeseries_index": {"code": "class AssignTimeseriesIndex:\n    def time_frame_assign_timeseries_index(self):\n        self.df[\"date\"] = self.df.index\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass AssignTimeseriesIndex:\n    def setup(self):\n        N = 100000\n        idx = date_range(\"1/1/2000\", periods=N, freq=\"h\")\n        self.df = DataFrame(np.random.randn(N, 1), columns=[\"A\"], index=idx)", "min_run_count": 2, "name": "indexing.AssignTimeseriesIndex.time_frame_assign_timeseries_index", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "8a46e2b72c84ebbe38a56cb3270fe056a22bae89403a8b5abbba563b26d08524", "warmup_time": -1}, "indexing.Block.time_test": {"code": "class Block:\n    def time_test(self, true_value, mode):\n        start = datetime(2010, 5, 1)\n        end = datetime(2010, 9, 1)\n        self.df.loc[start:end, :] = true_value\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Block:\n    def setup(self, true_value, mode):\n        self.df = DataFrame(\n            False,\n            columns=np.arange(500).astype(str),\n            index=date_range(\"2010-01-01\", \"2011-01-01\"),\n        )\n    \n        self.true_value = true_value", "min_run_count": 2, "name": "indexing.Block.time_test", "number": 0, "param_names": ["param1", "param2"], "params": [["True", "'True'"], ["array(True)", "'np.array(True)'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "ae3119c5959265c6c46681f6292d6c006f60b008666add07669ba9a943b1a9a5", "warmup_time": -1}, "indexing.CategoricalIndexIndexing.time_get_indexer_list": {"code": "class CategoricalIndexIndexing:\n    def time_get_indexer_list(self, index):\n        self.data_unique.get_indexer(self.cat_list)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass CategoricalIndexIndexing:\n    def setup(self, index):\n        N = 10**5\n        values = list(\"a\" * N + \"b\" * N + \"c\" * N)\n        indices = {\n            \"monotonic_incr\": CategoricalIndex(values),\n            \"monotonic_decr\": CategoricalIndex(reversed(values)),\n            \"non_monotonic\": CategoricalIndex(list(\"abc\" * N)),\n        }\n        self.data = indices[index]\n        self.data_unique = CategoricalIndex([str(i) for i in range(N * 3)])\n    \n        self.int_scalar = 10000\n        self.int_list = list(range(10000))\n    \n        self.cat_scalar = \"b\"\n        self.cat_list = [\"1\", \"3\"]", "min_run_count": 2, "name": "indexing.CategoricalIndexIndexing.time_get_indexer_list", "number": 0, "param_names": ["index"], "params": [["'monotonic_incr'", "'monotonic_decr'", "'non_monotonic'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "62150e3781f883d8f6823c45067fcac0fefeb8ec685a47ce8057bed4cbaf3de7", "warmup_time": -1}, "indexing.CategoricalIndexIndexing.time_get_loc_scalar": {"code": "class CategoricalIndexIndexing:\n    def time_get_loc_scalar(self, index):\n        self.data.get_loc(self.cat_scalar)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass CategoricalIndexIndexing:\n    def setup(self, index):\n        N = 10**5\n        values = list(\"a\" * N + \"b\" * N + \"c\" * N)\n        indices = {\n            \"monotonic_incr\": CategoricalIndex(values),\n            \"monotonic_decr\": CategoricalIndex(reversed(values)),\n            \"non_monotonic\": CategoricalIndex(list(\"abc\" * N)),\n        }\n        self.data = indices[index]\n        self.data_unique = CategoricalIndex([str(i) for i in range(N * 3)])\n    \n        self.int_scalar = 10000\n        self.int_list = list(range(10000))\n    \n        self.cat_scalar = \"b\"\n        self.cat_list = [\"1\", \"3\"]", "min_run_count": 2, "name": "indexing.CategoricalIndexIndexing.time_get_loc_scalar", "number": 0, "param_names": ["index"], "params": [["'monotonic_incr'", "'monotonic_decr'", "'non_monotonic'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "f37f9a77340871ef67cae5bac921473a106ea7e1c707babd9a5d708a28df0d9a", "warmup_time": -1}, "indexing.CategoricalIndexIndexing.time_getitem_bool_array": {"code": "class CategoricalIndexIndexing:\n    def time_getitem_bool_array(self, index):\n        self.data[self.data == self.cat_scalar]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass CategoricalIndexIndexing:\n    def setup(self, index):\n        N = 10**5\n        values = list(\"a\" * N + \"b\" * N + \"c\" * N)\n        indices = {\n            \"monotonic_incr\": CategoricalIndex(values),\n            \"monotonic_decr\": CategoricalIndex(reversed(values)),\n            \"non_monotonic\": CategoricalIndex(list(\"abc\" * N)),\n        }\n        self.data = indices[index]\n        self.data_unique = CategoricalIndex([str(i) for i in range(N * 3)])\n    \n        self.int_scalar = 10000\n        self.int_list = list(range(10000))\n    \n        self.cat_scalar = \"b\"\n        self.cat_list = [\"1\", \"3\"]", "min_run_count": 2, "name": "indexing.CategoricalIndexIndexing.time_getitem_bool_array", "number": 0, "param_names": ["index"], "params": [["'monotonic_incr'", "'monotonic_decr'", "'non_monotonic'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "b4c1625b9c78f360819094fa2e243d9c3671eccf5396bd00cc7d4298824b370d", "warmup_time": -1}, "indexing.CategoricalIndexIndexing.time_getitem_list": {"code": "class CategoricalIndexIndexing:\n    def time_getitem_list(self, index):\n        self.data[self.int_list]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass CategoricalIndexIndexing:\n    def setup(self, index):\n        N = 10**5\n        values = list(\"a\" * N + \"b\" * N + \"c\" * N)\n        indices = {\n            \"monotonic_incr\": CategoricalIndex(values),\n            \"monotonic_decr\": CategoricalIndex(reversed(values)),\n            \"non_monotonic\": CategoricalIndex(list(\"abc\" * N)),\n        }\n        self.data = indices[index]\n        self.data_unique = CategoricalIndex([str(i) for i in range(N * 3)])\n    \n        self.int_scalar = 10000\n        self.int_list = list(range(10000))\n    \n        self.cat_scalar = \"b\"\n        self.cat_list = [\"1\", \"3\"]", "min_run_count": 2, "name": "indexing.CategoricalIndexIndexing.time_getitem_list", "number": 0, "param_names": ["index"], "params": [["'monotonic_incr'", "'monotonic_decr'", "'non_monotonic'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "25f5a440360e857bbf13b393292f058291a0fe0e335aa56339d4690c25ac147c", "warmup_time": -1}, "indexing.CategoricalIndexIndexing.time_getitem_list_like": {"code": "class CategoricalIndexIndexing:\n    def time_getitem_list_like(self, index):\n        self.data[[self.int_scalar]]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass CategoricalIndexIndexing:\n    def setup(self, index):\n        N = 10**5\n        values = list(\"a\" * N + \"b\" * N + \"c\" * N)\n        indices = {\n            \"monotonic_incr\": CategoricalIndex(values),\n            \"monotonic_decr\": CategoricalIndex(reversed(values)),\n            \"non_monotonic\": CategoricalIndex(list(\"abc\" * N)),\n        }\n        self.data = indices[index]\n        self.data_unique = CategoricalIndex([str(i) for i in range(N * 3)])\n    \n        self.int_scalar = 10000\n        self.int_list = list(range(10000))\n    \n        self.cat_scalar = \"b\"\n        self.cat_list = [\"1\", \"3\"]", "min_run_count": 2, "name": "indexing.CategoricalIndexIndexing.time_getitem_list_like", "number": 0, "param_names": ["index"], "params": [["'monotonic_incr'", "'monotonic_decr'", "'non_monotonic'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "d616c85b999476b17108e8f7e22f95a195640eb4a2d59226df18c1f7eb5fbc26", "warmup_time": -1}, "indexing.CategoricalIndexIndexing.time_getitem_scalar": {"code": "class CategoricalIndexIndexing:\n    def time_getitem_scalar(self, index):\n        self.data[self.int_scalar]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass CategoricalIndexIndexing:\n    def setup(self, index):\n        N = 10**5\n        values = list(\"a\" * N + \"b\" * N + \"c\" * N)\n        indices = {\n            \"monotonic_incr\": CategoricalIndex(values),\n            \"monotonic_decr\": CategoricalIndex(reversed(values)),\n            \"non_monotonic\": CategoricalIndex(list(\"abc\" * N)),\n        }\n        self.data = indices[index]\n        self.data_unique = CategoricalIndex([str(i) for i in range(N * 3)])\n    \n        self.int_scalar = 10000\n        self.int_list = list(range(10000))\n    \n        self.cat_scalar = \"b\"\n        self.cat_list = [\"1\", \"3\"]", "min_run_count": 2, "name": "indexing.CategoricalIndexIndexing.time_getitem_scalar", "number": 0, "param_names": ["index"], "params": [["'monotonic_incr'", "'monotonic_decr'", "'non_monotonic'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "a18201ebf2cfad696d0e413b9cbc8eb4884b1f5b7447ca8f974fe3f765766278", "warmup_time": -1}, "indexing.CategoricalIndexIndexing.time_getitem_slice": {"code": "class CategoricalIndexIndexing:\n    def time_getitem_slice(self, index):\n        self.data[: self.int_scalar]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass CategoricalIndexIndexing:\n    def setup(self, index):\n        N = 10**5\n        values = list(\"a\" * N + \"b\" * N + \"c\" * N)\n        indices = {\n            \"monotonic_incr\": CategoricalIndex(values),\n            \"monotonic_decr\": CategoricalIndex(reversed(values)),\n            \"non_monotonic\": CategoricalIndex(list(\"abc\" * N)),\n        }\n        self.data = indices[index]\n        self.data_unique = CategoricalIndex([str(i) for i in range(N * 3)])\n    \n        self.int_scalar = 10000\n        self.int_list = list(range(10000))\n    \n        self.cat_scalar = \"b\"\n        self.cat_list = [\"1\", \"3\"]", "min_run_count": 2, "name": "indexing.CategoricalIndexIndexing.time_getitem_slice", "number": 0, "param_names": ["index"], "params": [["'monotonic_incr'", "'monotonic_decr'", "'non_monotonic'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "4c7a1c61821c96671e21fd7ce147081487558bee846c82a1db1d2a696acb4761", "warmup_time": -1}, "indexing.ChainIndexing.time_chained_indexing": {"code": "class ChainIndexing:\n    def time_chained_indexing(self, mode):\n        df = self.df\n        N = self.N\n        with warnings.catch_warnings(record=True):\n            with option_context(\"mode.chained_assignment\", mode):\n                df2 = df[df.A > N // 2]\n                df2[\"C\"] = 1.0\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ChainIndexing:\n    def setup(self, mode):\n        self.N = 1000000\n        self.df = DataFrame({\"A\": np.arange(self.N), \"B\": \"foo\"})", "min_run_count": 2, "name": "indexing.ChainIndexing.time_chained_indexing", "number": 0, "param_names": ["mode"], "params": [["None", "'warn'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "16258f12b7c725f7ffc21ffed9c69bd9751f02f6a459f86e81c20750c1fc1bba", "warmup_time": -1}, "indexing.DataFrameNumericIndexing.time_bool_indexer": {"code": "class DataFrameNumericIndexing:\n    def time_bool_indexer(self, index, index_structure):\n        self.df[self.bool_indexer]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass DataFrameNumericIndexing:\n    def setup(self, dtype, index_structure):\n        N = 10**5\n        indices = {\n            \"unique_monotonic_inc\": Index(range(N), dtype=dtype),\n            \"nonunique_monotonic_inc\": Index(\n                list(range(55)) + [54] + list(range(55, N - 1)), dtype=dtype\n            ),\n        }\n        self.idx_dupe = np.array(range(30)) * 99\n        self.df = DataFrame(np.random.randn(N, 5), index=indices[index_structure])\n        self.df_dup = concat([self.df, 2 * self.df, 3 * self.df])\n        self.bool_indexer = [True] * (N // 2) + [False] * (N - N // 2)", "min_run_count": 2, "name": "indexing.DataFrameNumericIndexing.time_bool_indexer", "number": 0, "param_names": ["dtype", "index_structure"], "params": [["<class 'numpy.int64'>", "<class 'numpy.uint64'>", "<class 'numpy.float64'>"], ["'unique_monotonic_inc'", "'nonunique_monotonic_inc'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "5b49ac8c1fc01d2dc2c19c3edcf588116fa02ee673f47dde99584eb435361fed", "warmup_time": -1}, "indexing.DataFrameNumericIndexing.time_iloc": {"code": "class DataFrameNumericIndexing:\n    def time_iloc(self, index, index_structure):\n        self.df.iloc[:100, 0]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass DataFrameNumericIndexing:\n    def setup(self, dtype, index_structure):\n        N = 10**5\n        indices = {\n            \"unique_monotonic_inc\": Index(range(N), dtype=dtype),\n            \"nonunique_monotonic_inc\": Index(\n                list(range(55)) + [54] + list(range(55, N - 1)), dtype=dtype\n            ),\n        }\n        self.idx_dupe = np.array(range(30)) * 99\n        self.df = DataFrame(np.random.randn(N, 5), index=indices[index_structure])\n        self.df_dup = concat([self.df, 2 * self.df, 3 * self.df])\n        self.bool_indexer = [True] * (N // 2) + [False] * (N - N // 2)", "min_run_count": 2, "name": "indexing.DataFrameNumericIndexing.time_iloc", "number": 0, "param_names": ["dtype", "index_structure"], "params": [["<class 'numpy.int64'>", "<class 'numpy.uint64'>", "<class 'numpy.float64'>"], ["'unique_monotonic_inc'", "'nonunique_monotonic_inc'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "d4f1ee902bd3f0617b7fe7bfbca605d0c34d424476e2ea162e220ee701e530eb", "warmup_time": -1}, "indexing.DataFrameNumericIndexing.time_iloc_dups": {"code": "class DataFrameNumericIndexing:\n    def time_iloc_dups(self, index, index_structure):\n        self.df_dup.iloc[self.idx_dupe]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass DataFrameNumericIndexing:\n    def setup(self, dtype, index_structure):\n        N = 10**5\n        indices = {\n            \"unique_monotonic_inc\": Index(range(N), dtype=dtype),\n            \"nonunique_monotonic_inc\": Index(\n                list(range(55)) + [54] + list(range(55, N - 1)), dtype=dtype\n            ),\n        }\n        self.idx_dupe = np.array(range(30)) * 99\n        self.df = DataFrame(np.random.randn(N, 5), index=indices[index_structure])\n        self.df_dup = concat([self.df, 2 * self.df, 3 * self.df])\n        self.bool_indexer = [True] * (N // 2) + [False] * (N - N // 2)", "min_run_count": 2, "name": "indexing.DataFrameNumericIndexing.time_iloc_dups", "number": 0, "param_names": ["dtype", "index_structure"], "params": [["<class 'numpy.int64'>", "<class 'numpy.uint64'>", "<class 'numpy.float64'>"], ["'unique_monotonic_inc'", "'nonunique_monotonic_inc'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "4390803cba45b26841ac1b3f27cffcaed921e6083822e3d13e9eff994ee542e5", "warmup_time": -1}, "indexing.DataFrameNumericIndexing.time_loc": {"code": "class DataFrameNumericIndexing:\n    def time_loc(self, index, index_structure):\n        self.df.loc[:100, 0]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass DataFrameNumericIndexing:\n    def setup(self, dtype, index_structure):\n        N = 10**5\n        indices = {\n            \"unique_monotonic_inc\": Index(range(N), dtype=dtype),\n            \"nonunique_monotonic_inc\": Index(\n                list(range(55)) + [54] + list(range(55, N - 1)), dtype=dtype\n            ),\n        }\n        self.idx_dupe = np.array(range(30)) * 99\n        self.df = DataFrame(np.random.randn(N, 5), index=indices[index_structure])\n        self.df_dup = concat([self.df, 2 * self.df, 3 * self.df])\n        self.bool_indexer = [True] * (N // 2) + [False] * (N - N // 2)", "min_run_count": 2, "name": "indexing.DataFrameNumericIndexing.time_loc", "number": 0, "param_names": ["dtype", "index_structure"], "params": [["<class 'numpy.int64'>", "<class 'numpy.uint64'>", "<class 'numpy.float64'>"], ["'unique_monotonic_inc'", "'nonunique_monotonic_inc'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "a85621866c240f052375710c72ffe0cc190d797923084092e4984bff4240dfdf", "warmup_time": -1}, "indexing.DataFrameNumericIndexing.time_loc_dups": {"code": "class DataFrameNumericIndexing:\n    def time_loc_dups(self, index, index_structure):\n        self.df_dup.loc[self.idx_dupe]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass DataFrameNumericIndexing:\n    def setup(self, dtype, index_structure):\n        N = 10**5\n        indices = {\n            \"unique_monotonic_inc\": Index(range(N), dtype=dtype),\n            \"nonunique_monotonic_inc\": Index(\n                list(range(55)) + [54] + list(range(55, N - 1)), dtype=dtype\n            ),\n        }\n        self.idx_dupe = np.array(range(30)) * 99\n        self.df = DataFrame(np.random.randn(N, 5), index=indices[index_structure])\n        self.df_dup = concat([self.df, 2 * self.df, 3 * self.df])\n        self.bool_indexer = [True] * (N // 2) + [False] * (N - N // 2)", "min_run_count": 2, "name": "indexing.DataFrameNumericIndexing.time_loc_dups", "number": 0, "param_names": ["dtype", "index_structure"], "params": [["<class 'numpy.int64'>", "<class 'numpy.uint64'>", "<class 'numpy.float64'>"], ["'unique_monotonic_inc'", "'nonunique_monotonic_inc'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "9789412267c4eba4099218c01b54dc8d5055978255c8cae7cd1d3f96cf362b7e", "warmup_time": -1}, "indexing.DataFrameStringIndexing.time_at": {"code": "class DataFrameStringIndexing:\n    def time_at(self):\n        self.df.at[self.idx_scalar, self.col_scalar]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass DataFrameStringIndexing:\n    def setup(self):\n        index = Index([f\"i-{i}\" for i in range(1000)], dtype=object)\n        columns = Index([f\"i-{i}\" for i in range(30)], dtype=object)\n        with warnings.catch_warnings(record=True):\n            self.df = DataFrame(np.random.randn(1000, 30), index=index, columns=columns)\n        self.idx_scalar = index[100]\n        self.col_scalar = columns[10]\n        self.bool_indexer = self.df[self.col_scalar] > 0\n        self.bool_obj_indexer = self.bool_indexer.astype(object)\n        self.boolean_indexer = (self.df[self.col_scalar] > 0).astype(\"boolean\")", "min_run_count": 2, "name": "indexing.DataFrameStringIndexing.time_at", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "04739f5bfcf96a2f809bfa8f746b3114f7e77b97abc35344668e4ca4a11170d4", "warmup_time": -1}, "indexing.DataFrameStringIndexing.time_at_setitem": {"code": "class DataFrameStringIndexing:\n    def time_at_setitem(self):\n        self.df.at[self.idx_scalar, self.col_scalar] = 0.0\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass DataFrameStringIndexing:\n    def setup(self):\n        index = Index([f\"i-{i}\" for i in range(1000)], dtype=object)\n        columns = Index([f\"i-{i}\" for i in range(30)], dtype=object)\n        with warnings.catch_warnings(record=True):\n            self.df = DataFrame(np.random.randn(1000, 30), index=index, columns=columns)\n        self.idx_scalar = index[100]\n        self.col_scalar = columns[10]\n        self.bool_indexer = self.df[self.col_scalar] > 0\n        self.bool_obj_indexer = self.bool_indexer.astype(object)\n        self.boolean_indexer = (self.df[self.col_scalar] > 0).astype(\"boolean\")", "min_run_count": 2, "name": "indexing.DataFrameStringIndexing.time_at_setitem", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "16329486e02da43d62eec0a291532ad60f0896602155cbceaedcad8754660605", "warmup_time": -1}, "indexing.DataFrameStringIndexing.time_boolean_rows": {"code": "class DataFrameStringIndexing:\n    def time_boolean_rows(self):\n        self.df[self.bool_indexer]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass DataFrameStringIndexing:\n    def setup(self):\n        index = Index([f\"i-{i}\" for i in range(1000)], dtype=object)\n        columns = Index([f\"i-{i}\" for i in range(30)], dtype=object)\n        with warnings.catch_warnings(record=True):\n            self.df = DataFrame(np.random.randn(1000, 30), index=index, columns=columns)\n        self.idx_scalar = index[100]\n        self.col_scalar = columns[10]\n        self.bool_indexer = self.df[self.col_scalar] > 0\n        self.bool_obj_indexer = self.bool_indexer.astype(object)\n        self.boolean_indexer = (self.df[self.col_scalar] > 0).astype(\"boolean\")", "min_run_count": 2, "name": "indexing.DataFrameStringIndexing.time_boolean_rows", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "8c68634926f34e2c9bc0f70108b33cfe3e2b04a295ea8cd25fc43f47be736790", "warmup_time": -1}, "indexing.DataFrameStringIndexing.time_boolean_rows_boolean": {"code": "class DataFrameStringIndexing:\n    def time_boolean_rows_boolean(self):\n        self.df[self.boolean_indexer]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass DataFrameStringIndexing:\n    def setup(self):\n        index = Index([f\"i-{i}\" for i in range(1000)], dtype=object)\n        columns = Index([f\"i-{i}\" for i in range(30)], dtype=object)\n        with warnings.catch_warnings(record=True):\n            self.df = DataFrame(np.random.randn(1000, 30), index=index, columns=columns)\n        self.idx_scalar = index[100]\n        self.col_scalar = columns[10]\n        self.bool_indexer = self.df[self.col_scalar] > 0\n        self.bool_obj_indexer = self.bool_indexer.astype(object)\n        self.boolean_indexer = (self.df[self.col_scalar] > 0).astype(\"boolean\")", "min_run_count": 2, "name": "indexing.DataFrameStringIndexing.time_boolean_rows_boolean", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "6dab0adc8de5d2f64428f7448f101efc6b11cbcc807586ed900490d1d9afb74d", "warmup_time": -1}, "indexing.DataFrameStringIndexing.time_boolean_rows_object": {"code": "class DataFrameStringIndexing:\n    def time_boolean_rows_object(self):\n        self.df[self.bool_obj_indexer]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass DataFrameStringIndexing:\n    def setup(self):\n        index = Index([f\"i-{i}\" for i in range(1000)], dtype=object)\n        columns = Index([f\"i-{i}\" for i in range(30)], dtype=object)\n        with warnings.catch_warnings(record=True):\n            self.df = DataFrame(np.random.randn(1000, 30), index=index, columns=columns)\n        self.idx_scalar = index[100]\n        self.col_scalar = columns[10]\n        self.bool_indexer = self.df[self.col_scalar] > 0\n        self.bool_obj_indexer = self.bool_indexer.astype(object)\n        self.boolean_indexer = (self.df[self.col_scalar] > 0).astype(\"boolean\")", "min_run_count": 2, "name": "indexing.DataFrameStringIndexing.time_boolean_rows_object", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "17f00e8889b2275c34fb7afa8d331fedfd9d5e12704117ffc4055d512bd2bd60", "warmup_time": -1}, "indexing.DataFrameStringIndexing.time_getitem_scalar": {"code": "class DataFrameStringIndexing:\n    def time_getitem_scalar(self):\n        self.df[self.col_scalar][self.idx_scalar]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass DataFrameStringIndexing:\n    def setup(self):\n        index = Index([f\"i-{i}\" for i in range(1000)], dtype=object)\n        columns = Index([f\"i-{i}\" for i in range(30)], dtype=object)\n        with warnings.catch_warnings(record=True):\n            self.df = DataFrame(np.random.randn(1000, 30), index=index, columns=columns)\n        self.idx_scalar = index[100]\n        self.col_scalar = columns[10]\n        self.bool_indexer = self.df[self.col_scalar] > 0\n        self.bool_obj_indexer = self.bool_indexer.astype(object)\n        self.boolean_indexer = (self.df[self.col_scalar] > 0).astype(\"boolean\")", "min_run_count": 2, "name": "indexing.DataFrameStringIndexing.time_getitem_scalar", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "fcea3e53ee2d996215560d161151b94b0177c7b2d2cbbc4580f324f6dc2de27a", "warmup_time": -1}, "indexing.DataFrameStringIndexing.time_loc": {"code": "class DataFrameStringIndexing:\n    def time_loc(self):\n        self.df.loc[self.idx_scalar, self.col_scalar]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass DataFrameStringIndexing:\n    def setup(self):\n        index = Index([f\"i-{i}\" for i in range(1000)], dtype=object)\n        columns = Index([f\"i-{i}\" for i in range(30)], dtype=object)\n        with warnings.catch_warnings(record=True):\n            self.df = DataFrame(np.random.randn(1000, 30), index=index, columns=columns)\n        self.idx_scalar = index[100]\n        self.col_scalar = columns[10]\n        self.bool_indexer = self.df[self.col_scalar] > 0\n        self.bool_obj_indexer = self.bool_indexer.astype(object)\n        self.boolean_indexer = (self.df[self.col_scalar] > 0).astype(\"boolean\")", "min_run_count": 2, "name": "indexing.DataFrameStringIndexing.time_loc", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "12b067d7b3c3ffe25275292b557ba18517ad4d2c5b6e1b41fdfb018f4889d00c", "warmup_time": -1}, "indexing.DatetimeIndexIndexing.time_get_indexer_mismatched_tz": {"code": "class DatetimeIndexIndexing:\n    def time_get_indexer_mismatched_tz(self):\n        # reached via e.g.\n        #  ser = Series(range(len(dti)), index=dti)\n        #  ser[dti2]\n        self.dti.get_indexer(self.dti2)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass DatetimeIndexIndexing:\n    def setup(self):\n        dti = date_range(\"2016-01-01\", periods=10000, tz=\"US/Pacific\")\n        dti2 = dti.tz_convert(\"UTC\")\n        self.dti = dti\n        self.dti2 = dti2", "min_run_count": 2, "name": "indexing.DatetimeIndexIndexing.time_get_indexer_mismatched_tz", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "c9cf20755eb4a51e544f3173086738738b06c2840acdc00a8c905a951594ce03", "warmup_time": -1}, "indexing.GetItemSingleColumn.time_frame_getitem_single_column_int": {"code": "class GetItemSingleColumn:\n    def time_frame_getitem_single_column_int(self):\n        self.df_int_col[0]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass GetItemSingleColumn:\n    def setup(self):\n        self.df_string_col = DataFrame(np.random.randn(3000, 1), columns=[\"A\"])\n        self.df_int_col = DataFrame(np.random.randn(3000, 1))", "min_run_count": 2, "name": "indexing.GetItemSingleColumn.time_frame_getitem_single_column_int", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "8516566e6a549f1f7c5a48623aa1378d299f882af8c200a8ab04eb7d321f0a23", "warmup_time": -1}, "indexing.GetItemSingleColumn.time_frame_getitem_single_column_label": {"code": "class GetItemSingleColumn:\n    def time_frame_getitem_single_column_label(self):\n        self.df_string_col[\"A\"]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass GetItemSingleColumn:\n    def setup(self):\n        self.df_string_col = DataFrame(np.random.randn(3000, 1), columns=[\"A\"])\n        self.df_int_col = DataFrame(np.random.randn(3000, 1))", "min_run_count": 2, "name": "indexing.GetItemSingleColumn.time_frame_getitem_single_column_label", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "a03a82b5117e7c2d6cccfe8ac22ef652a2ac9b039e27f15814a7bfab97c94f00", "warmup_time": -1}, "indexing.IndexSingleRow.time_iloc_row": {"code": "class IndexSingleRow:\n    def time_iloc_row(self, unique_cols):\n        self.df.iloc[10000]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass IndexSingleRow:\n    def setup(self, unique_cols):\n        arr = np.arange(10**7).reshape(-1, 10)\n        df = DataFrame(arr)\n        dtypes = [\"u1\", \"u2\", \"u4\", \"u8\", \"i1\", \"i2\", \"i4\", \"i8\", \"f8\", \"f4\"]\n        for i, d in enumerate(dtypes):\n            df[i] = df[i].astype(d)\n    \n        if not unique_cols:\n            # GH#33032 single-row lookups with non-unique columns were\n            #  15x slower than with unique columns\n            df.columns = [\"A\", \"A\"] + list(df.columns[2:])\n    \n        self.df = df", "min_run_count": 2, "name": "indexing.IndexSingleRow.time_iloc_row", "number": 0, "param_names": ["unique_cols"], "params": [["True", "False"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "4e20d2ce44a18740b78a7eae0eab3b3352a211486335db125fa22f685c9c5c68", "warmup_time": -1}, "indexing.IndexSingleRow.time_loc_row": {"code": "class IndexSingleRow:\n    def time_loc_row(self, unique_cols):\n        self.df.loc[10000]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass IndexSingleRow:\n    def setup(self, unique_cols):\n        arr = np.arange(10**7).reshape(-1, 10)\n        df = DataFrame(arr)\n        dtypes = [\"u1\", \"u2\", \"u4\", \"u8\", \"i1\", \"i2\", \"i4\", \"i8\", \"f8\", \"f4\"]\n        for i, d in enumerate(dtypes):\n            df[i] = df[i].astype(d)\n    \n        if not unique_cols:\n            # GH#33032 single-row lookups with non-unique columns were\n            #  15x slower than with unique columns\n            df.columns = [\"A\", \"A\"] + list(df.columns[2:])\n    \n        self.df = df", "min_run_count": 2, "name": "indexing.IndexSingleRow.time_loc_row", "number": 0, "param_names": ["unique_cols"], "params": [["True", "False"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "b1ae71b2de36f0424ee21d6b377c7e4370496ce8ed29f92ce82786280ff4c9db", "warmup_time": -1}, "indexing.InsertColumns.time_assign_list_like_with_setitem": {"code": "class InsertColumns:\n    def time_assign_list_like_with_setitem(self):\n        self.df[list(range(100))] = np.random.randn(self.N, 100)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass InsertColumns:\n    def setup(self):\n        self.N = 10**3\n        self.df = DataFrame(index=range(self.N))\n        self.df2 = DataFrame(np.random.randn(self.N, 2))", "min_run_count": 2, "name": "indexing.InsertColumns.time_assign_list_like_with_setitem", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "3bb24f36b40d94be98724ac3ffea9a7afbc390d394fa5fa9475cc77a13ffdf7b", "warmup_time": -1}, "indexing.InsertColumns.time_assign_list_of_columns_concat": {"code": "class InsertColumns:\n    def time_assign_list_of_columns_concat(self):\n        df = DataFrame(np.random.randn(self.N, 100))\n        concat([self.df, df], axis=1)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass InsertColumns:\n    def setup(self):\n        self.N = 10**3\n        self.df = DataFrame(index=range(self.N))\n        self.df2 = DataFrame(np.random.randn(self.N, 2))", "min_run_count": 2, "name": "indexing.InsertColumns.time_assign_list_of_columns_concat", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "41cef472b41bd56488365882e9724052692d13ec0abf67f3fa395e44af3a045d", "warmup_time": -1}, "indexing.InsertColumns.time_assign_with_setitem": {"code": "class InsertColumns:\n    def time_assign_with_setitem(self):\n        for i in range(100):\n            self.df[i] = np.random.randn(self.N)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass InsertColumns:\n    def setup(self):\n        self.N = 10**3\n        self.df = DataFrame(index=range(self.N))\n        self.df2 = DataFrame(np.random.randn(self.N, 2))", "min_run_count": 2, "name": "indexing.InsertColumns.time_assign_with_setitem", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "594d490a7116f20753d8366d82e417220b8035ce74080b41de66a9f64d7b2abd", "warmup_time": -1}, "indexing.InsertColumns.time_insert": {"code": "class InsertColumns:\n    def time_insert(self):\n        for i in range(100):\n            self.df.insert(0, i, np.random.randn(self.N), allow_duplicates=True)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass InsertColumns:\n    def setup(self):\n        self.N = 10**3\n        self.df = DataFrame(index=range(self.N))\n        self.df2 = DataFrame(np.random.randn(self.N, 2))", "min_run_count": 2, "name": "indexing.InsertColumns.time_insert", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "0021e91e2211b243fded9954bae458921f73a3e5ded206d0817555b44c945c0d", "warmup_time": -1}, "indexing.InsertColumns.time_insert_middle": {"code": "class InsertColumns:\n    def time_insert_middle(self):\n        # same as time_insert but inserting to a middle column rather than\n        #  front or back (which have fast-paths)\n        for i in range(100):\n            self.df2.insert(\n                1, \"colname\", np.random.randn(self.N), allow_duplicates=True\n            )\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass InsertColumns:\n    def setup(self):\n        self.N = 10**3\n        self.df = DataFrame(index=range(self.N))\n        self.df2 = DataFrame(np.random.randn(self.N, 2))", "min_run_count": 2, "name": "indexing.InsertColumns.time_insert_middle", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "c08ac878c8c7f19edcae9cddb8525e726ef5328f5fb06d9932ca3e83158e4a7d", "warmup_time": -1}, "indexing.IntervalIndexing.time_getitem_list": {"code": "class IntervalIndexing:\n    def time_getitem_list(self, monotonic):\n        monotonic[80000:]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass IntervalIndexing:\n    def setup_cache(self):\n        idx = IntervalIndex.from_breaks(np.arange(1000001))\n        monotonic = Series(np.arange(1000000), index=idx)\n        return monotonic", "min_run_count": 2, "name": "indexing.IntervalIndexing.time_getitem_list", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "setup_cache_key": "indexing:325", "timeout": 60.0, "type": "time", "unit": "seconds", "version": "ae80a330a1a4becae8c369fe9bcb0c8f430beb2d8ac3986f5e2f82490c50e071", "warmup_time": -1}, "indexing.IntervalIndexing.time_getitem_scalar": {"code": "class IntervalIndexing:\n    def time_getitem_scalar(self, monotonic):\n        monotonic[80000]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass IntervalIndexing:\n    def setup_cache(self):\n        idx = IntervalIndex.from_breaks(np.arange(1000001))\n        monotonic = Series(np.arange(1000000), index=idx)\n        return monotonic", "min_run_count": 2, "name": "indexing.IntervalIndexing.time_getitem_scalar", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "setup_cache_key": "indexing:325", "timeout": 60.0, "type": "time", "unit": "seconds", "version": "f160eaae3bf3bcbcc3fd20357b12c28670839282da6644be0e8024f97b21204b", "warmup_time": -1}, "indexing.IntervalIndexing.time_loc_list": {"code": "class IntervalIndexing:\n    def time_loc_list(self, monotonic):\n        monotonic.loc[80000:]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass IntervalIndexing:\n    def setup_cache(self):\n        idx = IntervalIndex.from_breaks(np.arange(1000001))\n        monotonic = Series(np.arange(1000000), index=idx)\n        return monotonic", "min_run_count": 2, "name": "indexing.IntervalIndexing.time_loc_list", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "setup_cache_key": "indexing:325", "timeout": 60.0, "type": "time", "unit": "seconds", "version": "634735f3995a5c9be2542706652ca9d8a024f91ded9a8e3ec8653b176bb9c556", "warmup_time": -1}, "indexing.IntervalIndexing.time_loc_scalar": {"code": "class IntervalIndexing:\n    def time_loc_scalar(self, monotonic):\n        monotonic.loc[80000]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass IntervalIndexing:\n    def setup_cache(self):\n        idx = IntervalIndex.from_breaks(np.arange(1000001))\n        monotonic = Series(np.arange(1000000), index=idx)\n        return monotonic", "min_run_count": 2, "name": "indexing.IntervalIndexing.time_loc_scalar", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "setup_cache_key": "indexing:325", "timeout": 60.0, "type": "time", "unit": "seconds", "version": "9682c17d993a421023a33cdfbf1ae6a67d4f2b1a8a9eb98fb60445f56f4d892e", "warmup_time": -1}, "indexing.MethodLookup.time_lookup_iloc": {"code": "class MethodLookup:\n    def time_lookup_iloc(self, s):\n        s.iloc\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass MethodLookup:\n    def setup_cache(self):\n        s = Series()\n        return s", "min_run_count": 2, "name": "indexing.MethodLookup.time_lookup_iloc", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "setup_cache_key": "indexing:419", "timeout": 60.0, "type": "time", "unit": "seconds", "version": "de130c1315ebaff60daa5132a0ffba11a1513d688c4d7465c4f0b75fa3b40d4d", "warmup_time": -1}, "indexing.MethodLookup.time_lookup_loc": {"code": "class MethodLookup:\n    def time_lookup_loc(self, s):\n        s.loc\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass MethodLookup:\n    def setup_cache(self):\n        s = Series()\n        return s", "min_run_count": 2, "name": "indexing.MethodLookup.time_lookup_loc", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "setup_cache_key": "indexing:419", "timeout": 60.0, "type": "time", "unit": "seconds", "version": "8f3e9ba1fa6ae32795b77d4fb0a2cb3a36108a494ac5a33197076f41a75cee6c", "warmup_time": -1}, "indexing.MultiIndexing.time_loc_all_bool_indexers": {"code": "class MultiIndexing:\n    def time_loc_all_bool_indexers(self, unique_levels):\n        target = tuple([self.tgt_bool_indexer] * self.nlevels)\n        self.df.loc[target, :]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass MultiIndexing:\n    def setup(self, unique_levels):\n        self.nlevels = 2\n        if unique_levels:\n            mi = MultiIndex.from_arrays([range(1000000)] * self.nlevels)\n        else:\n            mi = MultiIndex.from_product([range(1000)] * self.nlevels)\n        self.df = DataFrame(np.random.randn(len(mi)), index=mi)\n    \n        self.tgt_slice = slice(200, 800)\n        self.tgt_null_slice = slice(None)\n        self.tgt_list = list(range(0, 1000, 10))\n        self.tgt_scalar = 500\n    \n        bool_indexer = np.zeros(len(mi), dtype=np.bool_)\n        bool_indexer[slice(0, len(mi), 100)] = True\n        self.tgt_bool_indexer = bool_indexer", "min_run_count": 2, "name": "indexing.MultiIndexing.time_loc_all_bool_indexers", "number": 0, "param_names": ["unique_levels"], "params": [["True", "False"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "1771918b3fe0b5cbe067324593f312813f66ac1576a3387207feb5abfb7ca806", "warmup_time": -1}, "indexing.MultiIndexing.time_loc_all_lists": {"code": "class MultiIndexing:\n    def time_loc_all_lists(self, unique_levels):\n        target = tuple([self.tgt_list] * self.nlevels)\n        self.df.loc[target, :]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass MultiIndexing:\n    def setup(self, unique_levels):\n        self.nlevels = 2\n        if unique_levels:\n            mi = MultiIndex.from_arrays([range(1000000)] * self.nlevels)\n        else:\n            mi = MultiIndex.from_product([range(1000)] * self.nlevels)\n        self.df = DataFrame(np.random.randn(len(mi)), index=mi)\n    \n        self.tgt_slice = slice(200, 800)\n        self.tgt_null_slice = slice(None)\n        self.tgt_list = list(range(0, 1000, 10))\n        self.tgt_scalar = 500\n    \n        bool_indexer = np.zeros(len(mi), dtype=np.bool_)\n        bool_indexer[slice(0, len(mi), 100)] = True\n        self.tgt_bool_indexer = bool_indexer", "min_run_count": 2, "name": "indexing.MultiIndexing.time_loc_all_lists", "number": 0, "param_names": ["unique_levels"], "params": [["True", "False"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "472ab8a43bc8d905a0c7bfecd2190e954a7da13e4e29ddbaf54d1ffa9c50a846", "warmup_time": -1}, "indexing.MultiIndexing.time_loc_all_null_slices": {"code": "class MultiIndexing:\n    def time_loc_all_null_slices(self, unique_levels):\n        target = tuple([self.tgt_null_slice] * self.nlevels)\n        self.df.loc[target, :]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass MultiIndexing:\n    def setup(self, unique_levels):\n        self.nlevels = 2\n        if unique_levels:\n            mi = MultiIndex.from_arrays([range(1000000)] * self.nlevels)\n        else:\n            mi = MultiIndex.from_product([range(1000)] * self.nlevels)\n        self.df = DataFrame(np.random.randn(len(mi)), index=mi)\n    \n        self.tgt_slice = slice(200, 800)\n        self.tgt_null_slice = slice(None)\n        self.tgt_list = list(range(0, 1000, 10))\n        self.tgt_scalar = 500\n    \n        bool_indexer = np.zeros(len(mi), dtype=np.bool_)\n        bool_indexer[slice(0, len(mi), 100)] = True\n        self.tgt_bool_indexer = bool_indexer", "min_run_count": 2, "name": "indexing.MultiIndexing.time_loc_all_null_slices", "number": 0, "param_names": ["unique_levels"], "params": [["True", "False"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "ee13de44701c0630572b0428b6d08740c41bc7278df47aae6f015bed57f20896", "warmup_time": -1}, "indexing.MultiIndexing.time_loc_all_scalars": {"code": "class MultiIndexing:\n    def time_loc_all_scalars(self, unique_levels):\n        target = tuple([self.tgt_scalar] * self.nlevels)\n        self.df.loc[target, :]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass MultiIndexing:\n    def setup(self, unique_levels):\n        self.nlevels = 2\n        if unique_levels:\n            mi = MultiIndex.from_arrays([range(1000000)] * self.nlevels)\n        else:\n            mi = MultiIndex.from_product([range(1000)] * self.nlevels)\n        self.df = DataFrame(np.random.randn(len(mi)), index=mi)\n    \n        self.tgt_slice = slice(200, 800)\n        self.tgt_null_slice = slice(None)\n        self.tgt_list = list(range(0, 1000, 10))\n        self.tgt_scalar = 500\n    \n        bool_indexer = np.zeros(len(mi), dtype=np.bool_)\n        bool_indexer[slice(0, len(mi), 100)] = True\n        self.tgt_bool_indexer = bool_indexer", "min_run_count": 2, "name": "indexing.MultiIndexing.time_loc_all_scalars", "number": 0, "param_names": ["unique_levels"], "params": [["True", "False"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "52fba5b8883c06b2ad277a711b4ac49603c38321be1afb8a2daf975deff153af", "warmup_time": -1}, "indexing.MultiIndexing.time_loc_all_slices": {"code": "class MultiIndexing:\n    def time_loc_all_slices(self, unique_levels):\n        target = tuple([self.tgt_slice] * self.nlevels)\n        self.df.loc[target, :]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass MultiIndexing:\n    def setup(self, unique_levels):\n        self.nlevels = 2\n        if unique_levels:\n            mi = MultiIndex.from_arrays([range(1000000)] * self.nlevels)\n        else:\n            mi = MultiIndex.from_product([range(1000)] * self.nlevels)\n        self.df = DataFrame(np.random.randn(len(mi)), index=mi)\n    \n        self.tgt_slice = slice(200, 800)\n        self.tgt_null_slice = slice(None)\n        self.tgt_list = list(range(0, 1000, 10))\n        self.tgt_scalar = 500\n    \n        bool_indexer = np.zeros(len(mi), dtype=np.bool_)\n        bool_indexer[slice(0, len(mi), 100)] = True\n        self.tgt_bool_indexer = bool_indexer", "min_run_count": 2, "name": "indexing.MultiIndexing.time_loc_all_slices", "number": 0, "param_names": ["unique_levels"], "params": [["True", "False"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "7ee6845e7a946179e2f28eb51291bf1e8dc5aa663346c5e70b7db58cf6a415d4", "warmup_time": -1}, "indexing.MultiIndexing.time_loc_multiindex": {"code": "class MultiIndexing:\n    def time_loc_multiindex(self, unique_levels):\n        target = self.df.index[::10]\n        self.df.loc[target]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass MultiIndexing:\n    def setup(self, unique_levels):\n        self.nlevels = 2\n        if unique_levels:\n            mi = MultiIndex.from_arrays([range(1000000)] * self.nlevels)\n        else:\n            mi = MultiIndex.from_product([range(1000)] * self.nlevels)\n        self.df = DataFrame(np.random.randn(len(mi)), index=mi)\n    \n        self.tgt_slice = slice(200, 800)\n        self.tgt_null_slice = slice(None)\n        self.tgt_list = list(range(0, 1000, 10))\n        self.tgt_scalar = 500\n    \n        bool_indexer = np.zeros(len(mi), dtype=np.bool_)\n        bool_indexer[slice(0, len(mi), 100)] = True\n        self.tgt_bool_indexer = bool_indexer", "min_run_count": 2, "name": "indexing.MultiIndexing.time_loc_multiindex", "number": 0, "param_names": ["unique_levels"], "params": [["True", "False"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "845e85441994edf43d432790182cf5f3f1c8a8d11260d19322d4f9c26e9ea82e", "warmup_time": -1}, "indexing.MultiIndexing.time_loc_null_slice_plus_slice": {"code": "class MultiIndexing:\n    def time_loc_null_slice_plus_slice(self, unique_levels):\n        target = (self.tgt_null_slice, self.tgt_slice)\n        self.df.loc[target, :]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass MultiIndexing:\n    def setup(self, unique_levels):\n        self.nlevels = 2\n        if unique_levels:\n            mi = MultiIndex.from_arrays([range(1000000)] * self.nlevels)\n        else:\n            mi = MultiIndex.from_product([range(1000)] * self.nlevels)\n        self.df = DataFrame(np.random.randn(len(mi)), index=mi)\n    \n        self.tgt_slice = slice(200, 800)\n        self.tgt_null_slice = slice(None)\n        self.tgt_list = list(range(0, 1000, 10))\n        self.tgt_scalar = 500\n    \n        bool_indexer = np.zeros(len(mi), dtype=np.bool_)\n        bool_indexer[slice(0, len(mi), 100)] = True\n        self.tgt_bool_indexer = bool_indexer", "min_run_count": 2, "name": "indexing.MultiIndexing.time_loc_null_slice_plus_slice", "number": 0, "param_names": ["unique_levels"], "params": [["True", "False"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "f8a8667e507761ed75e543d5d59a9b99abf35fbbd88506af79bba513db537b1d", "warmup_time": -1}, "indexing.MultiIndexing.time_loc_partial_key_bool_indexer": {"code": "class MultiIndexing:\n    def time_loc_partial_key_bool_indexer(self, unique_levels):\n        self.df.loc[self.tgt_bool_indexer, :]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass MultiIndexing:\n    def setup(self, unique_levels):\n        self.nlevels = 2\n        if unique_levels:\n            mi = MultiIndex.from_arrays([range(1000000)] * self.nlevels)\n        else:\n            mi = MultiIndex.from_product([range(1000)] * self.nlevels)\n        self.df = DataFrame(np.random.randn(len(mi)), index=mi)\n    \n        self.tgt_slice = slice(200, 800)\n        self.tgt_null_slice = slice(None)\n        self.tgt_list = list(range(0, 1000, 10))\n        self.tgt_scalar = 500\n    \n        bool_indexer = np.zeros(len(mi), dtype=np.bool_)\n        bool_indexer[slice(0, len(mi), 100)] = True\n        self.tgt_bool_indexer = bool_indexer", "min_run_count": 2, "name": "indexing.MultiIndexing.time_loc_partial_key_bool_indexer", "number": 0, "param_names": ["unique_levels"], "params": [["True", "False"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "f4163b15e26adc988dcb7d895e5ced6f1fa85495a29d44c6f1df7010fff0d379", "warmup_time": -1}, "indexing.MultiIndexing.time_loc_partial_key_list": {"code": "class MultiIndexing:\n    def time_loc_partial_key_list(self, unique_levels):\n        self.df.loc[self.tgt_list, :]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass MultiIndexing:\n    def setup(self, unique_levels):\n        self.nlevels = 2\n        if unique_levels:\n            mi = MultiIndex.from_arrays([range(1000000)] * self.nlevels)\n        else:\n            mi = MultiIndex.from_product([range(1000)] * self.nlevels)\n        self.df = DataFrame(np.random.randn(len(mi)), index=mi)\n    \n        self.tgt_slice = slice(200, 800)\n        self.tgt_null_slice = slice(None)\n        self.tgt_list = list(range(0, 1000, 10))\n        self.tgt_scalar = 500\n    \n        bool_indexer = np.zeros(len(mi), dtype=np.bool_)\n        bool_indexer[slice(0, len(mi), 100)] = True\n        self.tgt_bool_indexer = bool_indexer", "min_run_count": 2, "name": "indexing.MultiIndexing.time_loc_partial_key_list", "number": 0, "param_names": ["unique_levels"], "params": [["True", "False"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "3d998427658ce79d9730202287dfc27f39d7b70b94481fc82cc28c58bb10fc2c", "warmup_time": -1}, "indexing.MultiIndexing.time_loc_partial_key_null_slice": {"code": "class MultiIndexing:\n    def time_loc_partial_key_null_slice(self, unique_levels):\n        self.df.loc[self.tgt_null_slice, :]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass MultiIndexing:\n    def setup(self, unique_levels):\n        self.nlevels = 2\n        if unique_levels:\n            mi = MultiIndex.from_arrays([range(1000000)] * self.nlevels)\n        else:\n            mi = MultiIndex.from_product([range(1000)] * self.nlevels)\n        self.df = DataFrame(np.random.randn(len(mi)), index=mi)\n    \n        self.tgt_slice = slice(200, 800)\n        self.tgt_null_slice = slice(None)\n        self.tgt_list = list(range(0, 1000, 10))\n        self.tgt_scalar = 500\n    \n        bool_indexer = np.zeros(len(mi), dtype=np.bool_)\n        bool_indexer[slice(0, len(mi), 100)] = True\n        self.tgt_bool_indexer = bool_indexer", "min_run_count": 2, "name": "indexing.MultiIndexing.time_loc_partial_key_null_slice", "number": 0, "param_names": ["unique_levels"], "params": [["True", "False"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "777e2da95dafebe327dcbfc63277290e5760e3bb51661ddfe6a5fd3c7e0702bc", "warmup_time": -1}, "indexing.MultiIndexing.time_loc_partial_key_scalar": {"code": "class MultiIndexing:\n    def time_loc_partial_key_scalar(self, unique_levels):\n        self.df.loc[self.tgt_scalar, :]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass MultiIndexing:\n    def setup(self, unique_levels):\n        self.nlevels = 2\n        if unique_levels:\n            mi = MultiIndex.from_arrays([range(1000000)] * self.nlevels)\n        else:\n            mi = MultiIndex.from_product([range(1000)] * self.nlevels)\n        self.df = DataFrame(np.random.randn(len(mi)), index=mi)\n    \n        self.tgt_slice = slice(200, 800)\n        self.tgt_null_slice = slice(None)\n        self.tgt_list = list(range(0, 1000, 10))\n        self.tgt_scalar = 500\n    \n        bool_indexer = np.zeros(len(mi), dtype=np.bool_)\n        bool_indexer[slice(0, len(mi), 100)] = True\n        self.tgt_bool_indexer = bool_indexer", "min_run_count": 2, "name": "indexing.MultiIndexing.time_loc_partial_key_scalar", "number": 0, "param_names": ["unique_levels"], "params": [["True", "False"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "7fff81ab0ee84cd8d0d1cbb857a086f21277e9956a9dd836bbe17b4070bf4188", "warmup_time": -1}, "indexing.MultiIndexing.time_loc_partial_key_slice": {"code": "class MultiIndexing:\n    def time_loc_partial_key_slice(self, unique_levels):\n        self.df.loc[self.tgt_slice, :]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass MultiIndexing:\n    def setup(self, unique_levels):\n        self.nlevels = 2\n        if unique_levels:\n            mi = MultiIndex.from_arrays([range(1000000)] * self.nlevels)\n        else:\n            mi = MultiIndex.from_product([range(1000)] * self.nlevels)\n        self.df = DataFrame(np.random.randn(len(mi)), index=mi)\n    \n        self.tgt_slice = slice(200, 800)\n        self.tgt_null_slice = slice(None)\n        self.tgt_list = list(range(0, 1000, 10))\n        self.tgt_scalar = 500\n    \n        bool_indexer = np.zeros(len(mi), dtype=np.bool_)\n        bool_indexer[slice(0, len(mi), 100)] = True\n        self.tgt_bool_indexer = bool_indexer", "min_run_count": 2, "name": "indexing.MultiIndexing.time_loc_partial_key_slice", "number": 0, "param_names": ["unique_levels"], "params": [["True", "False"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "7e493377f1a856eeb73c21aae1208537b26a4a29edb1afaa8ac89e4ffa29ef49", "warmup_time": -1}, "indexing.MultiIndexing.time_loc_slice_plus_null_slice": {"code": "class MultiIndexing:\n    def time_loc_slice_plus_null_slice(self, unique_levels):\n        target = (self.tgt_slice, self.tgt_null_slice)\n        self.df.loc[target, :]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass MultiIndexing:\n    def setup(self, unique_levels):\n        self.nlevels = 2\n        if unique_levels:\n            mi = MultiIndex.from_arrays([range(1000000)] * self.nlevels)\n        else:\n            mi = MultiIndex.from_product([range(1000)] * self.nlevels)\n        self.df = DataFrame(np.random.randn(len(mi)), index=mi)\n    \n        self.tgt_slice = slice(200, 800)\n        self.tgt_null_slice = slice(None)\n        self.tgt_list = list(range(0, 1000, 10))\n        self.tgt_scalar = 500\n    \n        bool_indexer = np.zeros(len(mi), dtype=np.bool_)\n        bool_indexer[slice(0, len(mi), 100)] = True\n        self.tgt_bool_indexer = bool_indexer", "min_run_count": 2, "name": "indexing.MultiIndexing.time_loc_slice_plus_null_slice", "number": 0, "param_names": ["unique_levels"], "params": [["True", "False"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "e35e95d2686e9edb9c298e881d73f80b937d8cc77b9c363ce78a9e6f079157f9", "warmup_time": -1}, "indexing.MultiIndexing.time_xs_full_key": {"code": "class MultiIndexing:\n    def time_xs_full_key(self, unique_levels):\n        target = tuple([self.tgt_scalar] * self.nlevels)\n        self.df.xs(target)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass MultiIndexing:\n    def setup(self, unique_levels):\n        self.nlevels = 2\n        if unique_levels:\n            mi = MultiIndex.from_arrays([range(1000000)] * self.nlevels)\n        else:\n            mi = MultiIndex.from_product([range(1000)] * self.nlevels)\n        self.df = DataFrame(np.random.randn(len(mi)), index=mi)\n    \n        self.tgt_slice = slice(200, 800)\n        self.tgt_null_slice = slice(None)\n        self.tgt_list = list(range(0, 1000, 10))\n        self.tgt_scalar = 500\n    \n        bool_indexer = np.zeros(len(mi), dtype=np.bool_)\n        bool_indexer[slice(0, len(mi), 100)] = True\n        self.tgt_bool_indexer = bool_indexer", "min_run_count": 2, "name": "indexing.MultiIndexing.time_xs_full_key", "number": 0, "param_names": ["unique_levels"], "params": [["True", "False"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "d9bbac09a6803b7e0d554f99cfbfa0517a1d7320e6a6af606bce52ec78fe89d5", "warmup_time": -1}, "indexing.MultiIndexing.time_xs_level_0": {"code": "class MultiIndexing:\n    def time_xs_level_0(self, unique_levels):\n        target = self.tgt_scalar\n        self.df.xs(target, level=0)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass MultiIndexing:\n    def setup(self, unique_levels):\n        self.nlevels = 2\n        if unique_levels:\n            mi = MultiIndex.from_arrays([range(1000000)] * self.nlevels)\n        else:\n            mi = MultiIndex.from_product([range(1000)] * self.nlevels)\n        self.df = DataFrame(np.random.randn(len(mi)), index=mi)\n    \n        self.tgt_slice = slice(200, 800)\n        self.tgt_null_slice = slice(None)\n        self.tgt_list = list(range(0, 1000, 10))\n        self.tgt_scalar = 500\n    \n        bool_indexer = np.zeros(len(mi), dtype=np.bool_)\n        bool_indexer[slice(0, len(mi), 100)] = True\n        self.tgt_bool_indexer = bool_indexer", "min_run_count": 2, "name": "indexing.MultiIndexing.time_xs_level_0", "number": 0, "param_names": ["unique_levels"], "params": [["True", "False"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "daaf4beb33874670dbba4df791aff72a906678fd1058938bc990e56cd7b733e3", "warmup_time": -1}, "indexing.MultiIndexing.time_xs_level_1": {"code": "class MultiIndexing:\n    def time_xs_level_1(self, unique_levels):\n        target = self.tgt_scalar\n        self.df.xs(target, level=1)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass MultiIndexing:\n    def setup(self, unique_levels):\n        self.nlevels = 2\n        if unique_levels:\n            mi = MultiIndex.from_arrays([range(1000000)] * self.nlevels)\n        else:\n            mi = MultiIndex.from_product([range(1000)] * self.nlevels)\n        self.df = DataFrame(np.random.randn(len(mi)), index=mi)\n    \n        self.tgt_slice = slice(200, 800)\n        self.tgt_null_slice = slice(None)\n        self.tgt_list = list(range(0, 1000, 10))\n        self.tgt_scalar = 500\n    \n        bool_indexer = np.zeros(len(mi), dtype=np.bool_)\n        bool_indexer[slice(0, len(mi), 100)] = True\n        self.tgt_bool_indexer = bool_indexer", "min_run_count": 2, "name": "indexing.MultiIndexing.time_xs_level_1", "number": 0, "param_names": ["unique_levels"], "params": [["True", "False"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "464f6f9822548adbb0a5afc6fd74b0fa4a5077d6215ac2a85daf48a6454b74b8", "warmup_time": -1}, "indexing.NonNumericSeriesIndexing.time_getitem_label_slice": {"code": "class NonNumericSeriesIndexing:\n    def time_getitem_label_slice(self, index, index_structure):\n        self.s[: self.lbl]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass NonNumericSeriesIndexing:\n    def setup(self, index, index_structure):\n        N = 10**6\n        if index == \"string\":\n            index = Index([f\"i-{i}\" for i in range(N)], dtype=object)\n        elif index == \"datetime\":\n            index = date_range(\"1900\", periods=N, freq=\"s\")\n        elif index == \"period\":\n            index = period_range(\"1900\", periods=N, freq=\"s\")\n        index = index.sort_values()\n        assert index.is_unique and index.is_monotonic_increasing\n        if index_structure == \"nonunique_monotonic_inc\":\n            index = index.insert(item=index[2], loc=2)[:-1]\n        elif index_structure == \"non_monotonic\":\n            index = index[::2].append(index[1::2])\n            assert len(index) == N\n        self.s = Series(np.random.rand(N), index=index)\n        self.lbl = index[80000]\n        # warm up index mapping\n        self.s[self.lbl]", "min_run_count": 2, "name": "indexing.NonNumericSeriesIndexing.time_getitem_label_slice", "number": 0, "param_names": ["index_dtype", "index_structure"], "params": [["'string'", "'datetime'", "'period'"], ["'unique_monotonic_inc'", "'nonunique_monotonic_inc'", "'non_monotonic'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "b7149a98ec037ac1cf628a59eae2af60f74f9e88aa8a8184591977e3c6053734", "warmup_time": -1}, "indexing.NonNumericSeriesIndexing.time_getitem_list_like": {"code": "class NonNumericSeriesIndexing:\n    def time_getitem_list_like(self, index, index_structure):\n        self.s[[self.lbl]]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass NonNumericSeriesIndexing:\n    def setup(self, index, index_structure):\n        N = 10**6\n        if index == \"string\":\n            index = Index([f\"i-{i}\" for i in range(N)], dtype=object)\n        elif index == \"datetime\":\n            index = date_range(\"1900\", periods=N, freq=\"s\")\n        elif index == \"period\":\n            index = period_range(\"1900\", periods=N, freq=\"s\")\n        index = index.sort_values()\n        assert index.is_unique and index.is_monotonic_increasing\n        if index_structure == \"nonunique_monotonic_inc\":\n            index = index.insert(item=index[2], loc=2)[:-1]\n        elif index_structure == \"non_monotonic\":\n            index = index[::2].append(index[1::2])\n            assert len(index) == N\n        self.s = Series(np.random.rand(N), index=index)\n        self.lbl = index[80000]\n        # warm up index mapping\n        self.s[self.lbl]", "min_run_count": 2, "name": "indexing.NonNumericSeriesIndexing.time_getitem_list_like", "number": 0, "param_names": ["index_dtype", "index_structure"], "params": [["'string'", "'datetime'", "'period'"], ["'unique_monotonic_inc'", "'nonunique_monotonic_inc'", "'non_monotonic'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "6a98622cf697e3e9ee3a5279589dc8280e8ed223e48a847e90691ad95248b8fe", "warmup_time": -1}, "indexing.NonNumericSeriesIndexing.time_getitem_pos_slice": {"code": "class NonNumericSeriesIndexing:\n    def time_getitem_pos_slice(self, index, index_structure):\n        self.s[:80000]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass NonNumericSeriesIndexing:\n    def setup(self, index, index_structure):\n        N = 10**6\n        if index == \"string\":\n            index = Index([f\"i-{i}\" for i in range(N)], dtype=object)\n        elif index == \"datetime\":\n            index = date_range(\"1900\", periods=N, freq=\"s\")\n        elif index == \"period\":\n            index = period_range(\"1900\", periods=N, freq=\"s\")\n        index = index.sort_values()\n        assert index.is_unique and index.is_monotonic_increasing\n        if index_structure == \"nonunique_monotonic_inc\":\n            index = index.insert(item=index[2], loc=2)[:-1]\n        elif index_structure == \"non_monotonic\":\n            index = index[::2].append(index[1::2])\n            assert len(index) == N\n        self.s = Series(np.random.rand(N), index=index)\n        self.lbl = index[80000]\n        # warm up index mapping\n        self.s[self.lbl]", "min_run_count": 2, "name": "indexing.NonNumericSeriesIndexing.time_getitem_pos_slice", "number": 0, "param_names": ["index_dtype", "index_structure"], "params": [["'string'", "'datetime'", "'period'"], ["'unique_monotonic_inc'", "'nonunique_monotonic_inc'", "'non_monotonic'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "06c57330892af61624a8f99c03e8af71fe978ac9049882d56369cf5f4b0ab7a7", "warmup_time": -1}, "indexing.NonNumericSeriesIndexing.time_getitem_scalar": {"code": "class NonNumericSeriesIndexing:\n    def time_getitem_scalar(self, index, index_structure):\n        self.s[self.lbl]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass NonNumericSeriesIndexing:\n    def setup(self, index, index_structure):\n        N = 10**6\n        if index == \"string\":\n            index = Index([f\"i-{i}\" for i in range(N)], dtype=object)\n        elif index == \"datetime\":\n            index = date_range(\"1900\", periods=N, freq=\"s\")\n        elif index == \"period\":\n            index = period_range(\"1900\", periods=N, freq=\"s\")\n        index = index.sort_values()\n        assert index.is_unique and index.is_monotonic_increasing\n        if index_structure == \"nonunique_monotonic_inc\":\n            index = index.insert(item=index[2], loc=2)[:-1]\n        elif index_structure == \"non_monotonic\":\n            index = index[::2].append(index[1::2])\n            assert len(index) == N\n        self.s = Series(np.random.rand(N), index=index)\n        self.lbl = index[80000]\n        # warm up index mapping\n        self.s[self.lbl]", "min_run_count": 2, "name": "indexing.NonNumericSeriesIndexing.time_getitem_scalar", "number": 0, "param_names": ["index_dtype", "index_structure"], "params": [["'string'", "'datetime'", "'period'"], ["'unique_monotonic_inc'", "'nonunique_monotonic_inc'", "'non_monotonic'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "9eff631ecc5e93c0bc45f0d7cfa28a9241c82461e4e1af909e9e0f1bcae15268", "warmup_time": -1}, "indexing.NumericMaskedIndexing.time_get_indexer": {"code": "class NumericMaskedIndexing:\n    def time_get_indexer(self, dtype, monotonic):\n        self.data.get_indexer(self.indexer)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass NumericMaskedIndexing:\n    def setup(self, dtype, monotonic):\n        indices = {\n            True: Index(self.monotonic_list, dtype=dtype),\n            False: Index(self.non_monotonic_list, dtype=dtype).append(\n                Index([NA], dtype=dtype)\n            ),\n        }\n        self.data = indices[monotonic]\n        self.indexer = np.arange(300, 1_000)\n        self.data_dups = self.data.append(self.data)", "min_run_count": 2, "name": "indexing.NumericMaskedIndexing.time_get_indexer", "number": 0, "param_names": ["dtype", "monotonic"], "params": [["'Int64'", "'UInt64'", "'Float64'"], ["True", "False"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "c9f9a8ac9f8595fa973302687b629db6bf6b9924be4c3431f56d1b61c68570d2", "warmup_time": -1}, "indexing.NumericMaskedIndexing.time_get_indexer_dups": {"code": "class NumericMaskedIndexing:\n    def time_get_indexer_dups(self, dtype, monotonic):\n        self.data.get_indexer_for(self.indexer)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass NumericMaskedIndexing:\n    def setup(self, dtype, monotonic):\n        indices = {\n            True: Index(self.monotonic_list, dtype=dtype),\n            False: Index(self.non_monotonic_list, dtype=dtype).append(\n                Index([NA], dtype=dtype)\n            ),\n        }\n        self.data = indices[monotonic]\n        self.indexer = np.arange(300, 1_000)\n        self.data_dups = self.data.append(self.data)", "min_run_count": 2, "name": "indexing.NumericMaskedIndexing.time_get_indexer_dups", "number": 0, "param_names": ["dtype", "monotonic"], "params": [["'Int64'", "'UInt64'", "'Float64'"], ["True", "False"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "650c0af5a8f5231315bb45ae613c0b6e4fe1a990510b7c6ef5cb41e20818e616", "warmup_time": -1}, "indexing.NumericSeriesIndexing.time_getitem_array": {"code": "class NumericSeriesIndexing:\n    def time_getitem_array(self, index, index_structure):\n        self.data[self.array]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass NumericSeriesIndexing:\n    def setup(self, dtype, index_structure):\n        N = 10**6\n        indices = {\n            \"unique_monotonic_inc\": Index(range(N), dtype=dtype),\n            \"nonunique_monotonic_inc\": Index(\n                list(range(55)) + [54] + list(range(55, N - 1)), dtype=dtype\n            ),\n        }\n        self.data = Series(np.random.rand(N), index=indices[index_structure])\n        self.array = np.arange(10000)\n        self.array_list = self.array.tolist()", "min_run_count": 2, "name": "indexing.NumericSeriesIndexing.time_getitem_array", "number": 0, "param_names": ["dtype", "index_structure"], "params": [["<class 'numpy.int64'>", "<class 'numpy.uint64'>", "<class 'numpy.float64'>"], ["'unique_monotonic_inc'", "'nonunique_monotonic_inc'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "f8dbc1486bd95bff70285ace102a5d9ae45c39e61501c81985e19c24fef1d788", "warmup_time": -1}, "indexing.NumericSeriesIndexing.time_getitem_list_like": {"code": "class NumericSeriesIndexing:\n    def time_getitem_list_like(self, index, index_structure):\n        self.data[[800000]]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass NumericSeriesIndexing:\n    def setup(self, dtype, index_structure):\n        N = 10**6\n        indices = {\n            \"unique_monotonic_inc\": Index(range(N), dtype=dtype),\n            \"nonunique_monotonic_inc\": Index(\n                list(range(55)) + [54] + list(range(55, N - 1)), dtype=dtype\n            ),\n        }\n        self.data = Series(np.random.rand(N), index=indices[index_structure])\n        self.array = np.arange(10000)\n        self.array_list = self.array.tolist()", "min_run_count": 2, "name": "indexing.NumericSeriesIndexing.time_getitem_list_like", "number": 0, "param_names": ["dtype", "index_structure"], "params": [["<class 'numpy.int64'>", "<class 'numpy.uint64'>", "<class 'numpy.float64'>"], ["'unique_monotonic_inc'", "'nonunique_monotonic_inc'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "767f017c9055f888f75b6eed2e15a080b0b64319d1095620556c015c88fa110d", "warmup_time": -1}, "indexing.NumericSeriesIndexing.time_getitem_lists": {"code": "class NumericSeriesIndexing:\n    def time_getitem_lists(self, index, index_structure):\n        self.data[self.array_list]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass NumericSeriesIndexing:\n    def setup(self, dtype, index_structure):\n        N = 10**6\n        indices = {\n            \"unique_monotonic_inc\": Index(range(N), dtype=dtype),\n            \"nonunique_monotonic_inc\": Index(\n                list(range(55)) + [54] + list(range(55, N - 1)), dtype=dtype\n            ),\n        }\n        self.data = Series(np.random.rand(N), index=indices[index_structure])\n        self.array = np.arange(10000)\n        self.array_list = self.array.tolist()", "min_run_count": 2, "name": "indexing.NumericSeriesIndexing.time_getitem_lists", "number": 0, "param_names": ["dtype", "index_structure"], "params": [["<class 'numpy.int64'>", "<class 'numpy.uint64'>", "<class 'numpy.float64'>"], ["'unique_monotonic_inc'", "'nonunique_monotonic_inc'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "443e55142dfd34591a735feb3d4d744e6958acb9018b753424bb95601e47a666", "warmup_time": -1}, "indexing.NumericSeriesIndexing.time_getitem_scalar": {"code": "class NumericSeriesIndexing:\n    def time_getitem_scalar(self, index, index_structure):\n        self.data[800000]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass NumericSeriesIndexing:\n    def setup(self, dtype, index_structure):\n        N = 10**6\n        indices = {\n            \"unique_monotonic_inc\": Index(range(N), dtype=dtype),\n            \"nonunique_monotonic_inc\": Index(\n                list(range(55)) + [54] + list(range(55, N - 1)), dtype=dtype\n            ),\n        }\n        self.data = Series(np.random.rand(N), index=indices[index_structure])\n        self.array = np.arange(10000)\n        self.array_list = self.array.tolist()", "min_run_count": 2, "name": "indexing.NumericSeriesIndexing.time_getitem_scalar", "number": 0, "param_names": ["dtype", "index_structure"], "params": [["<class 'numpy.int64'>", "<class 'numpy.uint64'>", "<class 'numpy.float64'>"], ["'unique_monotonic_inc'", "'nonunique_monotonic_inc'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "73c063a362862485753efeb9a6fbc07336e18a6c35add26bec792086df47b674", "warmup_time": -1}, "indexing.NumericSeriesIndexing.time_getitem_slice": {"code": "class NumericSeriesIndexing:\n    def time_getitem_slice(self, index, index_structure):\n        self.data[:800000]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass NumericSeriesIndexing:\n    def setup(self, dtype, index_structure):\n        N = 10**6\n        indices = {\n            \"unique_monotonic_inc\": Index(range(N), dtype=dtype),\n            \"nonunique_monotonic_inc\": Index(\n                list(range(55)) + [54] + list(range(55, N - 1)), dtype=dtype\n            ),\n        }\n        self.data = Series(np.random.rand(N), index=indices[index_structure])\n        self.array = np.arange(10000)\n        self.array_list = self.array.tolist()", "min_run_count": 2, "name": "indexing.NumericSeriesIndexing.time_getitem_slice", "number": 0, "param_names": ["dtype", "index_structure"], "params": [["<class 'numpy.int64'>", "<class 'numpy.uint64'>", "<class 'numpy.float64'>"], ["'unique_monotonic_inc'", "'nonunique_monotonic_inc'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "53dd251b95b13c6d4735cc1d1ad7f926e4ec0328748779a56fa1c63f4fa359a0", "warmup_time": -1}, "indexing.NumericSeriesIndexing.time_iloc_array": {"code": "class NumericSeriesIndexing:\n    def time_iloc_array(self, index, index_structure):\n        self.data.iloc[self.array]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass NumericSeriesIndexing:\n    def setup(self, dtype, index_structure):\n        N = 10**6\n        indices = {\n            \"unique_monotonic_inc\": Index(range(N), dtype=dtype),\n            \"nonunique_monotonic_inc\": Index(\n                list(range(55)) + [54] + list(range(55, N - 1)), dtype=dtype\n            ),\n        }\n        self.data = Series(np.random.rand(N), index=indices[index_structure])\n        self.array = np.arange(10000)\n        self.array_list = self.array.tolist()", "min_run_count": 2, "name": "indexing.NumericSeriesIndexing.time_iloc_array", "number": 0, "param_names": ["dtype", "index_structure"], "params": [["<class 'numpy.int64'>", "<class 'numpy.uint64'>", "<class 'numpy.float64'>"], ["'unique_monotonic_inc'", "'nonunique_monotonic_inc'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "7ca4d36d48a371195da509750de2d5dbb5fe15f466c419bd88a3d832c7339921", "warmup_time": -1}, "indexing.NumericSeriesIndexing.time_iloc_list_like": {"code": "class NumericSeriesIndexing:\n    def time_iloc_list_like(self, index, index_structure):\n        self.data.iloc[[800000]]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass NumericSeriesIndexing:\n    def setup(self, dtype, index_structure):\n        N = 10**6\n        indices = {\n            \"unique_monotonic_inc\": Index(range(N), dtype=dtype),\n            \"nonunique_monotonic_inc\": Index(\n                list(range(55)) + [54] + list(range(55, N - 1)), dtype=dtype\n            ),\n        }\n        self.data = Series(np.random.rand(N), index=indices[index_structure])\n        self.array = np.arange(10000)\n        self.array_list = self.array.tolist()", "min_run_count": 2, "name": "indexing.NumericSeriesIndexing.time_iloc_list_like", "number": 0, "param_names": ["dtype", "index_structure"], "params": [["<class 'numpy.int64'>", "<class 'numpy.uint64'>", "<class 'numpy.float64'>"], ["'unique_monotonic_inc'", "'nonunique_monotonic_inc'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "e6eb0977e121dbf9c0f8fed57bba4cbd0712e219c303813a323edfbeb879ca5f", "warmup_time": -1}, "indexing.NumericSeriesIndexing.time_iloc_scalar": {"code": "class NumericSeriesIndexing:\n    def time_iloc_scalar(self, index, index_structure):\n        self.data.iloc[800000]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass NumericSeriesIndexing:\n    def setup(self, dtype, index_structure):\n        N = 10**6\n        indices = {\n            \"unique_monotonic_inc\": Index(range(N), dtype=dtype),\n            \"nonunique_monotonic_inc\": Index(\n                list(range(55)) + [54] + list(range(55, N - 1)), dtype=dtype\n            ),\n        }\n        self.data = Series(np.random.rand(N), index=indices[index_structure])\n        self.array = np.arange(10000)\n        self.array_list = self.array.tolist()", "min_run_count": 2, "name": "indexing.NumericSeriesIndexing.time_iloc_scalar", "number": 0, "param_names": ["dtype", "index_structure"], "params": [["<class 'numpy.int64'>", "<class 'numpy.uint64'>", "<class 'numpy.float64'>"], ["'unique_monotonic_inc'", "'nonunique_monotonic_inc'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "d5a3df9b91de4f27357390975b96e77f6fe4ed9eced3a16044211134bc38617b", "warmup_time": -1}, "indexing.NumericSeriesIndexing.time_iloc_slice": {"code": "class NumericSeriesIndexing:\n    def time_iloc_slice(self, index, index_structure):\n        self.data.iloc[:800000]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass NumericSeriesIndexing:\n    def setup(self, dtype, index_structure):\n        N = 10**6\n        indices = {\n            \"unique_monotonic_inc\": Index(range(N), dtype=dtype),\n            \"nonunique_monotonic_inc\": Index(\n                list(range(55)) + [54] + list(range(55, N - 1)), dtype=dtype\n            ),\n        }\n        self.data = Series(np.random.rand(N), index=indices[index_structure])\n        self.array = np.arange(10000)\n        self.array_list = self.array.tolist()", "min_run_count": 2, "name": "indexing.NumericSeriesIndexing.time_iloc_slice", "number": 0, "param_names": ["dtype", "index_structure"], "params": [["<class 'numpy.int64'>", "<class 'numpy.uint64'>", "<class 'numpy.float64'>"], ["'unique_monotonic_inc'", "'nonunique_monotonic_inc'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "6dd75593c3e3cf6040fc6b6152cae16559fec377ae607105dc5867d7257d6e6b", "warmup_time": -1}, "indexing.NumericSeriesIndexing.time_loc_array": {"code": "class NumericSeriesIndexing:\n    def time_loc_array(self, index, index_structure):\n        self.data.loc[self.array]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass NumericSeriesIndexing:\n    def setup(self, dtype, index_structure):\n        N = 10**6\n        indices = {\n            \"unique_monotonic_inc\": Index(range(N), dtype=dtype),\n            \"nonunique_monotonic_inc\": Index(\n                list(range(55)) + [54] + list(range(55, N - 1)), dtype=dtype\n            ),\n        }\n        self.data = Series(np.random.rand(N), index=indices[index_structure])\n        self.array = np.arange(10000)\n        self.array_list = self.array.tolist()", "min_run_count": 2, "name": "indexing.NumericSeriesIndexing.time_loc_array", "number": 0, "param_names": ["dtype", "index_structure"], "params": [["<class 'numpy.int64'>", "<class 'numpy.uint64'>", "<class 'numpy.float64'>"], ["'unique_monotonic_inc'", "'nonunique_monotonic_inc'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "3165bdce66ae50b67ee74bf5b720ddc68ab182ec7445bc812e1c0a6282bdf773", "warmup_time": -1}, "indexing.NumericSeriesIndexing.time_loc_list_like": {"code": "class NumericSeriesIndexing:\n    def time_loc_list_like(self, index, index_structure):\n        self.data.loc[[800000]]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass NumericSeriesIndexing:\n    def setup(self, dtype, index_structure):\n        N = 10**6\n        indices = {\n            \"unique_monotonic_inc\": Index(range(N), dtype=dtype),\n            \"nonunique_monotonic_inc\": Index(\n                list(range(55)) + [54] + list(range(55, N - 1)), dtype=dtype\n            ),\n        }\n        self.data = Series(np.random.rand(N), index=indices[index_structure])\n        self.array = np.arange(10000)\n        self.array_list = self.array.tolist()", "min_run_count": 2, "name": "indexing.NumericSeriesIndexing.time_loc_list_like", "number": 0, "param_names": ["dtype", "index_structure"], "params": [["<class 'numpy.int64'>", "<class 'numpy.uint64'>", "<class 'numpy.float64'>"], ["'unique_monotonic_inc'", "'nonunique_monotonic_inc'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "9bd41a8e0e77f49c1815e6441bfed382f1642a7ffd8d470af8ae822095871ce7", "warmup_time": -1}, "indexing.NumericSeriesIndexing.time_loc_scalar": {"code": "class NumericSeriesIndexing:\n    def time_loc_scalar(self, index, index_structure):\n        self.data.loc[800000]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass NumericSeriesIndexing:\n    def setup(self, dtype, index_structure):\n        N = 10**6\n        indices = {\n            \"unique_monotonic_inc\": Index(range(N), dtype=dtype),\n            \"nonunique_monotonic_inc\": Index(\n                list(range(55)) + [54] + list(range(55, N - 1)), dtype=dtype\n            ),\n        }\n        self.data = Series(np.random.rand(N), index=indices[index_structure])\n        self.array = np.arange(10000)\n        self.array_list = self.array.tolist()", "min_run_count": 2, "name": "indexing.NumericSeriesIndexing.time_loc_scalar", "number": 0, "param_names": ["dtype", "index_structure"], "params": [["<class 'numpy.int64'>", "<class 'numpy.uint64'>", "<class 'numpy.float64'>"], ["'unique_monotonic_inc'", "'nonunique_monotonic_inc'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "ca036299851e1902e2e167658690aabd8b3c4a23c4565717eaed87565bac7725", "warmup_time": -1}, "indexing.NumericSeriesIndexing.time_loc_slice": {"code": "class NumericSeriesIndexing:\n    def time_loc_slice(self, index, index_structure):\n        self.data.loc[:800000]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass NumericSeriesIndexing:\n    def setup(self, dtype, index_structure):\n        N = 10**6\n        indices = {\n            \"unique_monotonic_inc\": Index(range(N), dtype=dtype),\n            \"nonunique_monotonic_inc\": Index(\n                list(range(55)) + [54] + list(range(55, N - 1)), dtype=dtype\n            ),\n        }\n        self.data = Series(np.random.rand(N), index=indices[index_structure])\n        self.array = np.arange(10000)\n        self.array_list = self.array.tolist()", "min_run_count": 2, "name": "indexing.NumericSeriesIndexing.time_loc_slice", "number": 0, "param_names": ["dtype", "index_structure"], "params": [["<class 'numpy.int64'>", "<class 'numpy.uint64'>", "<class 'numpy.float64'>"], ["'unique_monotonic_inc'", "'nonunique_monotonic_inc'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "7ec9524466f40bb446af6342c1220299a782e5c6c08e8a074782d963360ff732", "warmup_time": -1}, "indexing.Setitem.time_setitem": {"code": "class Setitem:\n    def time_setitem(self):\n        self.df[100] = 100\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Setitem:\n    def setup(self):\n        N = 500_000\n        cols = 500\n        self.df = DataFrame(np.random.rand(N, cols))", "min_run_count": 2, "name": "indexing.Setitem.time_setitem", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "05f726f7641992ec4777d8bd735c1ae3ec9b5046bec013ae0c155fe1b3e37560", "warmup_time": -1}, "indexing.Setitem.time_setitem_list": {"code": "class Setitem:\n    def time_setitem_list(self):\n        self.df[[100, 200, 300]] = 100\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Setitem:\n    def setup(self):\n        N = 500_000\n        cols = 500\n        self.df = DataFrame(np.random.rand(N, cols))", "min_run_count": 2, "name": "indexing.Setitem.time_setitem_list", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "6ae63a2e6c513edbdfdf8c6e2acfeca129311e22230ada6b94c26bda50916b2b", "warmup_time": -1}, "indexing.SetitemObjectDtype.time_setitem_object_dtype": {"code": "class SetitemObjectDtype:\n    def time_setitem_object_dtype(self):\n        self.df.loc[0, 1] = 1.0\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass SetitemObjectDtype:\n    def setup(self):\n        N = 1000\n        cols = 500\n        self.df = DataFrame(index=range(N), columns=range(cols), dtype=object)", "min_run_count": 2, "name": "indexing.SetitemObjectDtype.time_setitem_object_dtype", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "8097d4d139957ec4def40f768092a69c123eb5734fd79de749c28d017fcf96d8", "warmup_time": -1}, "indexing.SortedAndUnsortedDatetimeIndexLoc.time_loc_sorted": {"code": "class SortedAndUnsortedDatetimeIndexLoc:\n    def time_loc_sorted(self):\n        self.df_sort.loc[\"2016-6-11\"]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass SortedAndUnsortedDatetimeIndexLoc:\n    def setup(self):\n        dti = date_range(\"2016-01-01\", periods=10000, tz=\"US/Pacific\")\n        index = np.array(dti)\n    \n        unsorted_index = index.copy()\n        unsorted_index[10] = unsorted_index[20]\n    \n        self.df_unsorted = DataFrame(index=unsorted_index, data={\"a\": 1})\n        self.df_sort = DataFrame(index=index, data={\"a\": 1})", "min_run_count": 2, "name": "indexing.SortedAndUnsortedDatetimeIndexLoc.time_loc_sorted", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "0f65be8fdfcef229110b3366c9eeec8b227559f9db6dbbae3de7e915928496c4", "warmup_time": -1}, "indexing.SortedAndUnsortedDatetimeIndexLoc.time_loc_unsorted": {"code": "class SortedAndUnsortedDatetimeIndexLoc:\n    def time_loc_unsorted(self):\n        self.df_unsorted.loc[\"2016-6-11\"]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass SortedAndUnsortedDatetimeIndexLoc:\n    def setup(self):\n        dti = date_range(\"2016-01-01\", periods=10000, tz=\"US/Pacific\")\n        index = np.array(dti)\n    \n        unsorted_index = index.copy()\n        unsorted_index[10] = unsorted_index[20]\n    \n        self.df_unsorted = DataFrame(index=unsorted_index, data={\"a\": 1})\n        self.df_sort = DataFrame(index=index, data={\"a\": 1})", "min_run_count": 2, "name": "indexing.SortedAndUnsortedDatetimeIndexLoc.time_loc_unsorted", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "7f7406b54217c050b92bb548cd77d9e99371a9102aed4a513cc83b2677d7dd3d", "warmup_time": -1}, "indexing.Take.time_take": {"code": "class Take:\n    def time_take(self, index):\n        self.s.take(self.indexer)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Take:\n    def setup(self, index):\n        N = 100000\n        indexes = {\n            \"int\": Index(np.arange(N), dtype=np.int64),\n            \"datetime\": date_range(\"2011-01-01\", freq=\"s\", periods=N),\n        }\n        index = indexes[index]\n        self.s = Series(np.random.rand(N), index=index)\n        self.indexer = np.random.randint(0, N, size=N)", "min_run_count": 2, "name": "indexing.Take.time_take", "number": 0, "param_names": ["index"], "params": [["'int'", "'datetime'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "aaab1dd97f72161e6764c891742376656b295e9c0af44239f220454e583034c4", "warmup_time": -1}, "indexing_engines.MaskedNumericEngineIndexing.time_get_loc": {"code": "class MaskedNumericEngineIndexing:\n    def time_get_loc(self, engine_and_dtype, index_type, unique, N):\n        self.data.get_loc(self.key_early)\n\n    def setup(self, engine_and_dtype, index_type, unique, N):\n        engine, dtype = engine_and_dtype\n        dtype = dtype.lower()\n    \n        if index_type == \"monotonic_incr\":\n            if unique:\n                arr = np.arange(N * 3, dtype=dtype)\n            else:\n                arr = np.array([1, 2, 3], dtype=dtype).repeat(N)\n            mask = np.zeros(N * 3, dtype=np.bool_)\n        elif index_type == \"monotonic_decr\":\n            if unique:\n                arr = np.arange(N * 3, dtype=dtype)[::-1]\n            else:\n                arr = np.array([3, 2, 1], dtype=dtype).repeat(N)\n            mask = np.zeros(N * 3, dtype=np.bool_)\n        else:\n            assert index_type == \"non_monotonic\"\n            if unique:\n                arr = np.zeros(N * 3, dtype=dtype)\n                arr[:N] = np.arange(N * 2, N * 3, dtype=dtype)\n                arr[N:] = np.arange(N * 2, dtype=dtype)\n    \n            else:\n                arr = np.array([1, 2, 3], dtype=dtype).repeat(N)\n            mask = np.zeros(N * 3, dtype=np.bool_)\n            mask[-1] = True\n    \n        self.data = engine(BaseMaskedArray(arr, mask))\n        # code belows avoids populating the mapping etc. while timing.\n        self.data.get_loc(2)\n    \n        self.key_middle = arr[len(arr) // 2]\n        self.key_early = arr[2]", "min_run_count": 2, "name": "indexing_engines.MaskedNumericEngineIndexing.time_get_loc", "number": 0, "param_names": ["engine_and_dtype", "index_type", "unique", "N"], "params": [["(<class 'pandas._libs.index.MaskedInt64Engine'>, 'Int64')", "(<class 'pandas._libs.index.MaskedInt32Engine'>, 'Int32')", "(<class 'pandas._libs.index.MaskedInt16Engine'>, 'Int16')", "(<class 'pandas._libs.index.MaskedInt8Engine'>, 'Int8')", "(<class 'pandas._libs.index.MaskedUInt64Engine'>, 'UInt64')", "(<class 'pandas._libs.index.MaskedUInt32Engine'>, 'UInt32')", "(<class 'pandas._libs.index.MaskedUInt8Engine'>, 'UInt8')", "(<class 'pandas._libs.index.MaskedFloat64Engine'>, 'Float64')", "(<class 'pandas._libs.index.MaskedFloat32Engine'>, 'Float32')"], ["'monotonic_incr'", "'monotonic_decr'", "'non_monotonic'"], ["True", "False"], ["100000", "2000000"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "7f7b33642121e2bf9384ba174818a80c958132853320733e3d21dbbbc2057252", "warmup_time": -1}, "indexing_engines.MaskedNumericEngineIndexing.time_get_loc_near_middle": {"code": "class MaskedNumericEngineIndexing:\n    def time_get_loc_near_middle(self, engine_and_dtype, index_type, unique, N):\n        # searchsorted performance may be different near the middle of a range\n        #  vs near an endpoint\n        self.data.get_loc(self.key_middle)\n\n    def setup(self, engine_and_dtype, index_type, unique, N):\n        engine, dtype = engine_and_dtype\n        dtype = dtype.lower()\n    \n        if index_type == \"monotonic_incr\":\n            if unique:\n                arr = np.arange(N * 3, dtype=dtype)\n            else:\n                arr = np.array([1, 2, 3], dtype=dtype).repeat(N)\n            mask = np.zeros(N * 3, dtype=np.bool_)\n        elif index_type == \"monotonic_decr\":\n            if unique:\n                arr = np.arange(N * 3, dtype=dtype)[::-1]\n            else:\n                arr = np.array([3, 2, 1], dtype=dtype).repeat(N)\n            mask = np.zeros(N * 3, dtype=np.bool_)\n        else:\n            assert index_type == \"non_monotonic\"\n            if unique:\n                arr = np.zeros(N * 3, dtype=dtype)\n                arr[:N] = np.arange(N * 2, N * 3, dtype=dtype)\n                arr[N:] = np.arange(N * 2, dtype=dtype)\n    \n            else:\n                arr = np.array([1, 2, 3], dtype=dtype).repeat(N)\n            mask = np.zeros(N * 3, dtype=np.bool_)\n            mask[-1] = True\n    \n        self.data = engine(BaseMaskedArray(arr, mask))\n        # code belows avoids populating the mapping etc. while timing.\n        self.data.get_loc(2)\n    \n        self.key_middle = arr[len(arr) // 2]\n        self.key_early = arr[2]", "min_run_count": 2, "name": "indexing_engines.MaskedNumericEngineIndexing.time_get_loc_near_middle", "number": 0, "param_names": ["engine_and_dtype", "index_type", "unique", "N"], "params": [["(<class 'pandas._libs.index.MaskedInt64Engine'>, 'Int64')", "(<class 'pandas._libs.index.MaskedInt32Engine'>, 'Int32')", "(<class 'pandas._libs.index.MaskedInt16Engine'>, 'Int16')", "(<class 'pandas._libs.index.MaskedInt8Engine'>, 'Int8')", "(<class 'pandas._libs.index.MaskedUInt64Engine'>, 'UInt64')", "(<class 'pandas._libs.index.MaskedUInt32Engine'>, 'UInt32')", "(<class 'pandas._libs.index.MaskedUInt8Engine'>, 'UInt8')", "(<class 'pandas._libs.index.MaskedFloat64Engine'>, 'Float64')", "(<class 'pandas._libs.index.MaskedFloat32Engine'>, 'Float32')"], ["'monotonic_incr'", "'monotonic_decr'", "'non_monotonic'"], ["True", "False"], ["100000", "2000000"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "e8d4e1f556c6199573b3a7e40431bfe838e4b917ab6f36f60f02124dc509cc70", "warmup_time": -1}, "indexing_engines.NumericEngineIndexing.time_get_loc": {"code": "class NumericEngineIndexing:\n    def time_get_loc(self, engine_and_dtype, index_type, unique, N):\n        self.data.get_loc(self.key_early)\n\n    def setup(self, engine_and_dtype, index_type, unique, N):\n        engine, dtype = engine_and_dtype\n    \n        if index_type == \"monotonic_incr\":\n            if unique:\n                arr = np.arange(N * 3, dtype=dtype)\n            else:\n                arr = np.array([1, 2, 3], dtype=dtype).repeat(N)\n        elif index_type == \"monotonic_decr\":\n            if unique:\n                arr = np.arange(N * 3, dtype=dtype)[::-1]\n            else:\n                arr = np.array([3, 2, 1], dtype=dtype).repeat(N)\n        else:\n            assert index_type == \"non_monotonic\"\n            if unique:\n                arr = np.empty(N * 3, dtype=dtype)\n                arr[:N] = np.arange(N * 2, N * 3, dtype=dtype)\n                arr[N:] = np.arange(N * 2, dtype=dtype)\n            else:\n                arr = np.array([1, 2, 3], dtype=dtype).repeat(N)\n    \n        self.data = engine(arr)\n        # code belows avoids populating the mapping etc. while timing.\n        self.data.get_loc(2)\n    \n        self.key_middle = arr[len(arr) // 2]\n        self.key_early = arr[2]", "min_run_count": 2, "name": "indexing_engines.NumericEngineIndexing.time_get_loc", "number": 0, "param_names": ["engine_and_dtype", "index_type", "unique", "N"], "params": [["(<class 'pandas._libs.index.Int64Engine'>, <class 'numpy.int64'>)", "(<class 'pandas._libs.index.Int32Engine'>, <class 'numpy.int32'>)", "(<class 'pandas._libs.index.Int16Engine'>, <class 'numpy.int16'>)", "(<class 'pandas._libs.index.Int8Engine'>, <class 'numpy.int8'>)", "(<class 'pandas._libs.index.UInt64Engine'>, <class 'numpy.uint64'>)", "(<class 'pandas._libs.index.UInt32Engine'>, <class 'numpy.uint32'>)", "(<class 'pandas._libs.index.UInt8Engine'>, <class 'numpy.uint8'>)", "(<class 'pandas._libs.index.Float64Engine'>, <class 'numpy.float64'>)", "(<class 'pandas._libs.index.Float32Engine'>, <class 'numpy.float32'>)"], ["'monotonic_incr'", "'monotonic_decr'", "'non_monotonic'"], ["True", "False"], ["100000", "2000000"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "4c197e5d67e9ab70f54d781b315a2320298cf94bf97e74a10e6c3316fef965dd", "warmup_time": -1}, "indexing_engines.NumericEngineIndexing.time_get_loc_near_middle": {"code": "class NumericEngineIndexing:\n    def time_get_loc_near_middle(self, engine_and_dtype, index_type, unique, N):\n        # searchsorted performance may be different near the middle of a range\n        #  vs near an endpoint\n        self.data.get_loc(self.key_middle)\n\n    def setup(self, engine_and_dtype, index_type, unique, N):\n        engine, dtype = engine_and_dtype\n    \n        if index_type == \"monotonic_incr\":\n            if unique:\n                arr = np.arange(N * 3, dtype=dtype)\n            else:\n                arr = np.array([1, 2, 3], dtype=dtype).repeat(N)\n        elif index_type == \"monotonic_decr\":\n            if unique:\n                arr = np.arange(N * 3, dtype=dtype)[::-1]\n            else:\n                arr = np.array([3, 2, 1], dtype=dtype).repeat(N)\n        else:\n            assert index_type == \"non_monotonic\"\n            if unique:\n                arr = np.empty(N * 3, dtype=dtype)\n                arr[:N] = np.arange(N * 2, N * 3, dtype=dtype)\n                arr[N:] = np.arange(N * 2, dtype=dtype)\n            else:\n                arr = np.array([1, 2, 3], dtype=dtype).repeat(N)\n    \n        self.data = engine(arr)\n        # code belows avoids populating the mapping etc. while timing.\n        self.data.get_loc(2)\n    \n        self.key_middle = arr[len(arr) // 2]\n        self.key_early = arr[2]", "min_run_count": 2, "name": "indexing_engines.NumericEngineIndexing.time_get_loc_near_middle", "number": 0, "param_names": ["engine_and_dtype", "index_type", "unique", "N"], "params": [["(<class 'pandas._libs.index.Int64Engine'>, <class 'numpy.int64'>)", "(<class 'pandas._libs.index.Int32Engine'>, <class 'numpy.int32'>)", "(<class 'pandas._libs.index.Int16Engine'>, <class 'numpy.int16'>)", "(<class 'pandas._libs.index.Int8Engine'>, <class 'numpy.int8'>)", "(<class 'pandas._libs.index.UInt64Engine'>, <class 'numpy.uint64'>)", "(<class 'pandas._libs.index.UInt32Engine'>, <class 'numpy.uint32'>)", "(<class 'pandas._libs.index.UInt8Engine'>, <class 'numpy.uint8'>)", "(<class 'pandas._libs.index.Float64Engine'>, <class 'numpy.float64'>)", "(<class 'pandas._libs.index.Float32Engine'>, <class 'numpy.float32'>)"], ["'monotonic_incr'", "'monotonic_decr'", "'non_monotonic'"], ["True", "False"], ["100000", "2000000"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "93ec3dac855a502170e2dcf8d6117cc83aed3b3e00d60b8b9c702a68c8fff8b1", "warmup_time": -1}, "indexing_engines.ObjectEngineIndexing.time_get_loc": {"code": "class ObjectEngineIndexing:\n    def time_get_loc(self, index_type):\n        self.data.get_loc(\"b\")\n\n    def setup(self, index_type):\n        N = 10**5\n        values = list(\"a\" * N + \"b\" * N + \"c\" * N)\n        arr = {\n            \"monotonic_incr\": np.array(values, dtype=object),\n            \"monotonic_decr\": np.array(list(reversed(values)), dtype=object),\n            \"non_monotonic\": np.array(list(\"abc\") * N, dtype=object),\n        }[index_type]\n    \n        self.data = libindex.ObjectEngine(arr)\n        # code belows avoids populating the mapping etc. while timing.\n        self.data.get_loc(\"b\")", "min_run_count": 2, "name": "indexing_engines.ObjectEngineIndexing.time_get_loc", "number": 0, "param_names": ["index_type"], "params": [["'monotonic_incr'", "'monotonic_decr'", "'non_monotonic'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "147e59ebd8ed373d14dbc9abdbd3d300ac731c931df74b2c8286bb2495bf8f7f", "warmup_time": -1}, "inference.MaybeConvertNumeric.time_convert": {"code": "class MaybeConvertNumeric:\n    def time_convert(self, data):\n        lib.maybe_convert_numeric(data, set(), coerce_numeric=False)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass MaybeConvertNumeric:\n    def setup_cache(self):\n        N = 10**6\n        arr = np.repeat([2**63], N) + np.arange(N).astype(\"uint64\")\n        data = arr.astype(object)\n        data[1::2] = arr[1::2].astype(str)\n        data[-1] = -1\n        return data", "min_run_count": 2, "name": "inference.MaybeConvertNumeric.time_convert", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "setup_cache_key": "inference:83", "timeout": 60.0, "type": "time", "unit": "seconds", "version": "cf27dbc37431d8df629b71882573a765fb8244c558a5874dc6c8d279f80c581e", "warmup_time": -1}, "inference.MaybeConvertObjects.time_maybe_convert_objects": {"code": "class MaybeConvertObjects:\n    def time_maybe_convert_objects(self):\n        lib.maybe_convert_objects(self.data)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass MaybeConvertObjects:\n    def setup(self):\n        N = 10**5\n    \n        data = list(range(N))\n        data[0] = NaT\n        data = np.array(data)\n        self.data = data", "min_run_count": 2, "name": "inference.MaybeConvertObjects.time_maybe_convert_objects", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "5e7742ec3e74701df6d7944b29f2a86f87a571e7c29cdd82373fbc1264620fcf", "warmup_time": -1}, "inference.ToDatetimeCache.time_dup_seconds_and_unit": {"code": "class ToDatetimeCache:\n    def time_dup_seconds_and_unit(self, cache):\n        to_datetime(self.dup_numeric_seconds, unit=\"s\", cache=cache)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToDatetimeCache:\n    def setup(self, cache):\n        N = 10000\n        self.unique_numeric_seconds = list(range(N))\n        self.dup_numeric_seconds = [1000] * N\n        self.dup_string_dates = [\"2000-02-11\"] * N\n        self.dup_string_with_tz = [\"2000-02-11 15:00:00-0800\"] * N", "min_run_count": 2, "name": "inference.ToDatetimeCache.time_dup_seconds_and_unit", "number": 0, "param_names": ["cache"], "params": [["True", "False"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "115495d011e90c1e84334a047f0989bfb9edee09d9a3180f0c98d9d55a4f5d9e", "warmup_time": -1}, "inference.ToDatetimeCache.time_dup_string_dates": {"code": "class ToDatetimeCache:\n    def time_dup_string_dates(self, cache):\n        to_datetime(self.dup_string_dates, cache=cache)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToDatetimeCache:\n    def setup(self, cache):\n        N = 10000\n        self.unique_numeric_seconds = list(range(N))\n        self.dup_numeric_seconds = [1000] * N\n        self.dup_string_dates = [\"2000-02-11\"] * N\n        self.dup_string_with_tz = [\"2000-02-11 15:00:00-0800\"] * N", "min_run_count": 2, "name": "inference.ToDatetimeCache.time_dup_string_dates", "number": 0, "param_names": ["cache"], "params": [["True", "False"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "98daac9ccb43e22cad7edf108a8f9ef3f7dfbf2eb8deb23ea7df594845b8af4c", "warmup_time": -1}, "inference.ToDatetimeCache.time_dup_string_dates_and_format": {"code": "class ToDatetimeCache:\n    def time_dup_string_dates_and_format(self, cache):\n        to_datetime(self.dup_string_dates, format=\"%Y-%m-%d\", cache=cache)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToDatetimeCache:\n    def setup(self, cache):\n        N = 10000\n        self.unique_numeric_seconds = list(range(N))\n        self.dup_numeric_seconds = [1000] * N\n        self.dup_string_dates = [\"2000-02-11\"] * N\n        self.dup_string_with_tz = [\"2000-02-11 15:00:00-0800\"] * N", "min_run_count": 2, "name": "inference.ToDatetimeCache.time_dup_string_dates_and_format", "number": 0, "param_names": ["cache"], "params": [["True", "False"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "ee70077e5420259875c0f2299f011187d7baaef6f1cdeb4826b8ef8b1552dbce", "warmup_time": -1}, "inference.ToDatetimeCache.time_dup_string_tzoffset_dates": {"code": "class ToDatetimeCache:\n    def time_dup_string_tzoffset_dates(self, cache):\n        to_datetime(self.dup_string_with_tz, cache=cache)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToDatetimeCache:\n    def setup(self, cache):\n        N = 10000\n        self.unique_numeric_seconds = list(range(N))\n        self.dup_numeric_seconds = [1000] * N\n        self.dup_string_dates = [\"2000-02-11\"] * N\n        self.dup_string_with_tz = [\"2000-02-11 15:00:00-0800\"] * N", "min_run_count": 2, "name": "inference.ToDatetimeCache.time_dup_string_tzoffset_dates", "number": 0, "param_names": ["cache"], "params": [["True", "False"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "9e31f01ac2515ecaf953530ced77a145692dd110a116641738e36e284fe36dd6", "warmup_time": -1}, "inference.ToDatetimeCache.time_unique_seconds_and_unit": {"code": "class ToDatetimeCache:\n    def time_unique_seconds_and_unit(self, cache):\n        to_datetime(self.unique_numeric_seconds, unit=\"s\", cache=cache)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToDatetimeCache:\n    def setup(self, cache):\n        N = 10000\n        self.unique_numeric_seconds = list(range(N))\n        self.dup_numeric_seconds = [1000] * N\n        self.dup_string_dates = [\"2000-02-11\"] * N\n        self.dup_string_with_tz = [\"2000-02-11 15:00:00-0800\"] * N", "min_run_count": 2, "name": "inference.ToDatetimeCache.time_unique_seconds_and_unit", "number": 0, "param_names": ["cache"], "params": [["True", "False"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "0cd72e287b8884f32a7696a5bae419aa06c002232f3f3e5644000bec0a231d7c", "warmup_time": -1}, "inference.ToDatetimeCacheSmallCount.time_unique_date_strings": {"code": "class ToDatetimeCacheSmallCount:\n    def time_unique_date_strings(self, cache, count):\n        to_datetime(self.unique_date_strings, cache=cache)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToDatetimeCacheSmallCount:\n    def setup(self, cache, count):\n        rng = date_range(start=\"1/1/1971\", periods=count)\n        self.unique_date_strings = rng.strftime(\"%Y-%m-%d\").tolist()", "min_run_count": 2, "name": "inference.ToDatetimeCacheSmallCount.time_unique_date_strings", "number": 0, "param_names": ["cache", "count"], "params": [["True", "False"], ["50", "500", "5000", "100000"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "a56323da170a0fe1ab82a8aa298f38bf720a11efd9c5e53816e754fbfa0d2c10", "warmup_time": -1}, "inference.ToDatetimeFormat.time_different_offset": {"code": "class ToDatetimeFormat:\n    def time_different_offset(self):\n        to_datetime(self.diff_offset, format=\"%m/%d/%Y %H:%M:%S.%f%z\")\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToDatetimeFormat:\n    def setup(self):\n        N = 100000\n        self.s = Series([\"19MAY11\", \"19MAY11:00:00:00\"] * N)\n        self.s2 = self.s.str.replace(\":\\\\S+$\", \"\", regex=True)\n    \n        self.same_offset = [\"10/11/2018 00:00:00.045-07:00\"] * N\n        self.diff_offset = [\n            f\"10/11/2018 00:00:00.045-0{offset}:00\" for offset in range(10)\n        ] * (N // 10)", "min_run_count": 2, "name": "inference.ToDatetimeFormat.time_different_offset", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "7635604221c85fc5fcf2ef9c49c0e010d35795728991a4871bc9395a87e64568", "warmup_time": -1}, "inference.ToDatetimeFormat.time_different_offset_to_utc": {"code": "class ToDatetimeFormat:\n    def time_different_offset_to_utc(self):\n        to_datetime(self.diff_offset, format=\"%m/%d/%Y %H:%M:%S.%f%z\", utc=True)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToDatetimeFormat:\n    def setup(self):\n        N = 100000\n        self.s = Series([\"19MAY11\", \"19MAY11:00:00:00\"] * N)\n        self.s2 = self.s.str.replace(\":\\\\S+$\", \"\", regex=True)\n    \n        self.same_offset = [\"10/11/2018 00:00:00.045-07:00\"] * N\n        self.diff_offset = [\n            f\"10/11/2018 00:00:00.045-0{offset}:00\" for offset in range(10)\n        ] * (N // 10)", "min_run_count": 2, "name": "inference.ToDatetimeFormat.time_different_offset_to_utc", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "1134fb9d2267ce314aafafd3994e3faf459b0ffb6f88a729c01ab4ea6bb44302", "warmup_time": -1}, "inference.ToDatetimeFormat.time_exact": {"code": "class ToDatetimeFormat:\n    def time_exact(self):\n        to_datetime(self.s2, format=\"%d%b%y\")\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToDatetimeFormat:\n    def setup(self):\n        N = 100000\n        self.s = Series([\"19MAY11\", \"19MAY11:00:00:00\"] * N)\n        self.s2 = self.s.str.replace(\":\\\\S+$\", \"\", regex=True)\n    \n        self.same_offset = [\"10/11/2018 00:00:00.045-07:00\"] * N\n        self.diff_offset = [\n            f\"10/11/2018 00:00:00.045-0{offset}:00\" for offset in range(10)\n        ] * (N // 10)", "min_run_count": 2, "name": "inference.ToDatetimeFormat.time_exact", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "76d9d38bf86802c26b9548453bc209c70d50d02a2d30f7ae0469155f0576cb0a", "warmup_time": -1}, "inference.ToDatetimeFormat.time_no_exact": {"code": "class ToDatetimeFormat:\n    def time_no_exact(self):\n        to_datetime(self.s, format=\"%d%b%y\", exact=False)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToDatetimeFormat:\n    def setup(self):\n        N = 100000\n        self.s = Series([\"19MAY11\", \"19MAY11:00:00:00\"] * N)\n        self.s2 = self.s.str.replace(\":\\\\S+$\", \"\", regex=True)\n    \n        self.same_offset = [\"10/11/2018 00:00:00.045-07:00\"] * N\n        self.diff_offset = [\n            f\"10/11/2018 00:00:00.045-0{offset}:00\" for offset in range(10)\n        ] * (N // 10)", "min_run_count": 2, "name": "inference.ToDatetimeFormat.time_no_exact", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "1cbd72079d4edb0010f0b4016b0fd8ef613e37fb9f6c47a4de28327121902b19", "warmup_time": -1}, "inference.ToDatetimeFormat.time_same_offset": {"code": "class ToDatetimeFormat:\n    def time_same_offset(self):\n        to_datetime(self.same_offset, format=\"%m/%d/%Y %H:%M:%S.%f%z\")\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToDatetimeFormat:\n    def setup(self):\n        N = 100000\n        self.s = Series([\"19MAY11\", \"19MAY11:00:00:00\"] * N)\n        self.s2 = self.s.str.replace(\":\\\\S+$\", \"\", regex=True)\n    \n        self.same_offset = [\"10/11/2018 00:00:00.045-07:00\"] * N\n        self.diff_offset = [\n            f\"10/11/2018 00:00:00.045-0{offset}:00\" for offset in range(10)\n        ] * (N // 10)", "min_run_count": 2, "name": "inference.ToDatetimeFormat.time_same_offset", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "081651f9c7ef04560ccff0b7e01f00e729a8f50007024b8be6ae5df6d8252682", "warmup_time": -1}, "inference.ToDatetimeFormat.time_same_offset_to_utc": {"code": "class ToDatetimeFormat:\n    def time_same_offset_to_utc(self):\n        to_datetime(self.same_offset, format=\"%m/%d/%Y %H:%M:%S.%f%z\", utc=True)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToDatetimeFormat:\n    def setup(self):\n        N = 100000\n        self.s = Series([\"19MAY11\", \"19MAY11:00:00:00\"] * N)\n        self.s2 = self.s.str.replace(\":\\\\S+$\", \"\", regex=True)\n    \n        self.same_offset = [\"10/11/2018 00:00:00.045-07:00\"] * N\n        self.diff_offset = [\n            f\"10/11/2018 00:00:00.045-0{offset}:00\" for offset in range(10)\n        ] * (N // 10)", "min_run_count": 2, "name": "inference.ToDatetimeFormat.time_same_offset_to_utc", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "19b041862541f6a61d1616096316f0f2de3452b56a3bf5c720c671b4f0bad85f", "warmup_time": -1}, "inference.ToDatetimeFormatQuarters.time_infer_quarter": {"code": "class ToDatetimeFormatQuarters:\n    def time_infer_quarter(self):\n        to_datetime(self.s)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToDatetimeFormatQuarters:\n    def setup(self):\n        self.s = Series([\"2Q2005\", \"2Q05\", \"2005Q1\", \"05Q1\"] * 10000)", "min_run_count": 2, "name": "inference.ToDatetimeFormatQuarters.time_infer_quarter", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "87bb6a74eb91c588ca3c6a25551ece61b8b7585eb61f04410973d650e0964120", "warmup_time": -1}, "inference.ToDatetimeFromIntsFloats.time_nanosec_float64": {"code": "class ToDatetimeFromIntsFloats:\n    def time_nanosec_float64(self):\n        to_datetime(self.ts_nanosec_float, unit=\"ns\")\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToDatetimeFromIntsFloats:\n    def setup(self):\n        self.ts_sec = Series(range(1521080307, 1521685107), dtype=\"int64\")\n        self.ts_sec_uint = Series(range(1521080307, 1521685107), dtype=\"uint64\")\n        self.ts_sec_float = self.ts_sec.astype(\"float64\")\n    \n        self.ts_nanosec = 1_000_000 * self.ts_sec\n        self.ts_nanosec_uint = 1_000_000 * self.ts_sec_uint\n        self.ts_nanosec_float = self.ts_nanosec.astype(\"float64\")", "min_run_count": 2, "name": "inference.ToDatetimeFromIntsFloats.time_nanosec_float64", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "2a6fbb3b51b828848e8d7f73b076d8fae1161c6e4d53f48a8c4524fb4bd1820e", "warmup_time": -1}, "inference.ToDatetimeFromIntsFloats.time_nanosec_int64": {"code": "class ToDatetimeFromIntsFloats:\n    def time_nanosec_int64(self):\n        to_datetime(self.ts_nanosec, unit=\"ns\")\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToDatetimeFromIntsFloats:\n    def setup(self):\n        self.ts_sec = Series(range(1521080307, 1521685107), dtype=\"int64\")\n        self.ts_sec_uint = Series(range(1521080307, 1521685107), dtype=\"uint64\")\n        self.ts_sec_float = self.ts_sec.astype(\"float64\")\n    \n        self.ts_nanosec = 1_000_000 * self.ts_sec\n        self.ts_nanosec_uint = 1_000_000 * self.ts_sec_uint\n        self.ts_nanosec_float = self.ts_nanosec.astype(\"float64\")", "min_run_count": 2, "name": "inference.ToDatetimeFromIntsFloats.time_nanosec_int64", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "8970f8a6a15aef3813dcea5bb9bf3a7c39853f92d88c59907ac2830fd16daef2", "warmup_time": -1}, "inference.ToDatetimeFromIntsFloats.time_nanosec_uint64": {"code": "class ToDatetimeFromIntsFloats:\n    def time_nanosec_uint64(self):\n        to_datetime(self.ts_nanosec_uint, unit=\"ns\")\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToDatetimeFromIntsFloats:\n    def setup(self):\n        self.ts_sec = Series(range(1521080307, 1521685107), dtype=\"int64\")\n        self.ts_sec_uint = Series(range(1521080307, 1521685107), dtype=\"uint64\")\n        self.ts_sec_float = self.ts_sec.astype(\"float64\")\n    \n        self.ts_nanosec = 1_000_000 * self.ts_sec\n        self.ts_nanosec_uint = 1_000_000 * self.ts_sec_uint\n        self.ts_nanosec_float = self.ts_nanosec.astype(\"float64\")", "min_run_count": 2, "name": "inference.ToDatetimeFromIntsFloats.time_nanosec_uint64", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "55b37560ce70ea683ab6134ede09ee43de470162b68416ec0ef8b0f469e90e97", "warmup_time": -1}, "inference.ToDatetimeFromIntsFloats.time_sec_float64": {"code": "class ToDatetimeFromIntsFloats:\n    def time_sec_float64(self):\n        to_datetime(self.ts_sec_float, unit=\"s\")\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToDatetimeFromIntsFloats:\n    def setup(self):\n        self.ts_sec = Series(range(1521080307, 1521685107), dtype=\"int64\")\n        self.ts_sec_uint = Series(range(1521080307, 1521685107), dtype=\"uint64\")\n        self.ts_sec_float = self.ts_sec.astype(\"float64\")\n    \n        self.ts_nanosec = 1_000_000 * self.ts_sec\n        self.ts_nanosec_uint = 1_000_000 * self.ts_sec_uint\n        self.ts_nanosec_float = self.ts_nanosec.astype(\"float64\")", "min_run_count": 2, "name": "inference.ToDatetimeFromIntsFloats.time_sec_float64", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "412960192629b47bdb51536bd1acc465c6644d94331ec0b060809f15f2270d21", "warmup_time": -1}, "inference.ToDatetimeFromIntsFloats.time_sec_int64": {"code": "class ToDatetimeFromIntsFloats:\n    def time_sec_int64(self):\n        to_datetime(self.ts_sec, unit=\"s\")\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToDatetimeFromIntsFloats:\n    def setup(self):\n        self.ts_sec = Series(range(1521080307, 1521685107), dtype=\"int64\")\n        self.ts_sec_uint = Series(range(1521080307, 1521685107), dtype=\"uint64\")\n        self.ts_sec_float = self.ts_sec.astype(\"float64\")\n    \n        self.ts_nanosec = 1_000_000 * self.ts_sec\n        self.ts_nanosec_uint = 1_000_000 * self.ts_sec_uint\n        self.ts_nanosec_float = self.ts_nanosec.astype(\"float64\")", "min_run_count": 2, "name": "inference.ToDatetimeFromIntsFloats.time_sec_int64", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "723bef42790ad2535ae6772086a189690bbc81c0dc720a9ae78f79b14541e1ed", "warmup_time": -1}, "inference.ToDatetimeFromIntsFloats.time_sec_uint64": {"code": "class ToDatetimeFromIntsFloats:\n    def time_sec_uint64(self):\n        to_datetime(self.ts_sec_uint, unit=\"s\")\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToDatetimeFromIntsFloats:\n    def setup(self):\n        self.ts_sec = Series(range(1521080307, 1521685107), dtype=\"int64\")\n        self.ts_sec_uint = Series(range(1521080307, 1521685107), dtype=\"uint64\")\n        self.ts_sec_float = self.ts_sec.astype(\"float64\")\n    \n        self.ts_nanosec = 1_000_000 * self.ts_sec\n        self.ts_nanosec_uint = 1_000_000 * self.ts_sec_uint\n        self.ts_nanosec_float = self.ts_nanosec.astype(\"float64\")", "min_run_count": 2, "name": "inference.ToDatetimeFromIntsFloats.time_sec_uint64", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "ca17f492874efa6d87297d7a5eb649d9b0235ba934649a093f70ea48bc399454", "warmup_time": -1}, "inference.ToDatetimeISO8601.time_iso8601": {"code": "class ToDatetimeISO8601:\n    def time_iso8601(self):\n        to_datetime(self.strings)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToDatetimeISO8601:\n    def setup(self):\n        rng = date_range(start=\"1/1/2000\", periods=20000, freq=\"h\")\n        self.strings = rng.strftime(\"%Y-%m-%d %H:%M:%S\").tolist()\n        self.strings_nosep = rng.strftime(\"%Y%m%d %H:%M:%S\").tolist()\n        self.strings_tz_space = [\n            x.strftime(\"%Y-%m-%d %H:%M:%S\") + \" -0800\" for x in rng\n        ]\n        self.strings_zero_tz = [x.strftime(\"%Y-%m-%d %H:%M:%S\") + \"Z\" for x in rng]", "min_run_count": 2, "name": "inference.ToDatetimeISO8601.time_iso8601", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "c01e071dec3afc28fb8a6bcd6b0d157e5a0fb6281c3ae6da7ee509aa2dfe980a", "warmup_time": -1}, "inference.ToDatetimeISO8601.time_iso8601_format": {"code": "class ToDatetimeISO8601:\n    def time_iso8601_format(self):\n        to_datetime(self.strings, format=\"%Y-%m-%d %H:%M:%S\")\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToDatetimeISO8601:\n    def setup(self):\n        rng = date_range(start=\"1/1/2000\", periods=20000, freq=\"h\")\n        self.strings = rng.strftime(\"%Y-%m-%d %H:%M:%S\").tolist()\n        self.strings_nosep = rng.strftime(\"%Y%m%d %H:%M:%S\").tolist()\n        self.strings_tz_space = [\n            x.strftime(\"%Y-%m-%d %H:%M:%S\") + \" -0800\" for x in rng\n        ]\n        self.strings_zero_tz = [x.strftime(\"%Y-%m-%d %H:%M:%S\") + \"Z\" for x in rng]", "min_run_count": 2, "name": "inference.ToDatetimeISO8601.time_iso8601_format", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "bed05451c81f560e10f4add4bbd244599ac8758951990f8804a6c0e8ecde2f59", "warmup_time": -1}, "inference.ToDatetimeISO8601.time_iso8601_format_no_sep": {"code": "class ToDatetimeISO8601:\n    def time_iso8601_format_no_sep(self):\n        to_datetime(self.strings_nosep, format=\"%Y%m%d %H:%M:%S\")\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToDatetimeISO8601:\n    def setup(self):\n        rng = date_range(start=\"1/1/2000\", periods=20000, freq=\"h\")\n        self.strings = rng.strftime(\"%Y-%m-%d %H:%M:%S\").tolist()\n        self.strings_nosep = rng.strftime(\"%Y%m%d %H:%M:%S\").tolist()\n        self.strings_tz_space = [\n            x.strftime(\"%Y-%m-%d %H:%M:%S\") + \" -0800\" for x in rng\n        ]\n        self.strings_zero_tz = [x.strftime(\"%Y-%m-%d %H:%M:%S\") + \"Z\" for x in rng]", "min_run_count": 2, "name": "inference.ToDatetimeISO8601.time_iso8601_format_no_sep", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "97f94b8084cbb68f27ace40b4638b64544d81de4239a98b0ea7a5171624c9547", "warmup_time": -1}, "inference.ToDatetimeISO8601.time_iso8601_infer_zero_tz_fromat": {"code": "class ToDatetimeISO8601:\n    def time_iso8601_infer_zero_tz_fromat(self):\n        # GH 41047\n        to_datetime(self.strings_zero_tz, infer_datetime_format=True)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToDatetimeISO8601:\n    def setup(self):\n        rng = date_range(start=\"1/1/2000\", periods=20000, freq=\"h\")\n        self.strings = rng.strftime(\"%Y-%m-%d %H:%M:%S\").tolist()\n        self.strings_nosep = rng.strftime(\"%Y%m%d %H:%M:%S\").tolist()\n        self.strings_tz_space = [\n            x.strftime(\"%Y-%m-%d %H:%M:%S\") + \" -0800\" for x in rng\n        ]\n        self.strings_zero_tz = [x.strftime(\"%Y-%m-%d %H:%M:%S\") + \"Z\" for x in rng]", "min_run_count": 2, "name": "inference.ToDatetimeISO8601.time_iso8601_infer_zero_tz_fromat", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "ff73c34b9abee4afb32fb8661438fc78f3206b64d55bbf3bd01d74169a7eae95", "warmup_time": -1}, "inference.ToDatetimeISO8601.time_iso8601_nosep": {"code": "class ToDatetimeISO8601:\n    def time_iso8601_nosep(self):\n        to_datetime(self.strings_nosep)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToDatetimeISO8601:\n    def setup(self):\n        rng = date_range(start=\"1/1/2000\", periods=20000, freq=\"h\")\n        self.strings = rng.strftime(\"%Y-%m-%d %H:%M:%S\").tolist()\n        self.strings_nosep = rng.strftime(\"%Y%m%d %H:%M:%S\").tolist()\n        self.strings_tz_space = [\n            x.strftime(\"%Y-%m-%d %H:%M:%S\") + \" -0800\" for x in rng\n        ]\n        self.strings_zero_tz = [x.strftime(\"%Y-%m-%d %H:%M:%S\") + \"Z\" for x in rng]", "min_run_count": 2, "name": "inference.ToDatetimeISO8601.time_iso8601_nosep", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "30412f207bfd54b6590f2cdb46e9d487f1c49b618946150f4befc00b60adfa74", "warmup_time": -1}, "inference.ToDatetimeISO8601.time_iso8601_tz_spaceformat": {"code": "class ToDatetimeISO8601:\n    def time_iso8601_tz_spaceformat(self):\n        to_datetime(self.strings_tz_space)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToDatetimeISO8601:\n    def setup(self):\n        rng = date_range(start=\"1/1/2000\", periods=20000, freq=\"h\")\n        self.strings = rng.strftime(\"%Y-%m-%d %H:%M:%S\").tolist()\n        self.strings_nosep = rng.strftime(\"%Y%m%d %H:%M:%S\").tolist()\n        self.strings_tz_space = [\n            x.strftime(\"%Y-%m-%d %H:%M:%S\") + \" -0800\" for x in rng\n        ]\n        self.strings_zero_tz = [x.strftime(\"%Y-%m-%d %H:%M:%S\") + \"Z\" for x in rng]", "min_run_count": 2, "name": "inference.ToDatetimeISO8601.time_iso8601_tz_spaceformat", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "4c99d43165a9bb12c372d05ec434c5809826524a4733adfa440a3308cc4d8325", "warmup_time": -1}, "inference.ToDatetimeInferDatetimeFormat.time_infer_datetime_format": {"code": "class ToDatetimeInferDatetimeFormat:\n    def time_infer_datetime_format(self):\n        to_datetime(self.strings, infer_datetime_format=True)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToDatetimeInferDatetimeFormat:\n    def setup(self):\n        rng = date_range(start=\"1/1/2000\", periods=100000, freq=\"h\")\n        self.strings = rng.strftime(\"%Y-%m-%d %H:%M:%S\").tolist()", "min_run_count": 2, "name": "inference.ToDatetimeInferDatetimeFormat.time_infer_datetime_format", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "51230dad34e04742c51ab806009dd0987a16738969201362340c6f73729023d8", "warmup_time": -1}, "inference.ToDatetimeNONISO8601.time_different_offset": {"code": "class ToDatetimeNONISO8601:\n    def time_different_offset(self):\n        to_datetime(self.diff_offset)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToDatetimeNONISO8601:\n    def setup(self):\n        N = 10000\n        half = N // 2\n        ts_string_1 = \"March 1, 2018 12:00:00+0400\"\n        ts_string_2 = \"March 1, 2018 12:00:00+0500\"\n        self.same_offset = [ts_string_1] * N\n        self.diff_offset = [ts_string_1] * half + [ts_string_2] * half", "min_run_count": 2, "name": "inference.ToDatetimeNONISO8601.time_different_offset", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "2e0c92a1d5e9a354637aa8cc2832b3bc010f1197d796dc79ef3f026a0281060f", "warmup_time": -1}, "inference.ToDatetimeNONISO8601.time_same_offset": {"code": "class ToDatetimeNONISO8601:\n    def time_same_offset(self):\n        to_datetime(self.same_offset)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToDatetimeNONISO8601:\n    def setup(self):\n        N = 10000\n        half = N // 2\n        ts_string_1 = \"March 1, 2018 12:00:00+0400\"\n        ts_string_2 = \"March 1, 2018 12:00:00+0500\"\n        self.same_offset = [ts_string_1] * N\n        self.diff_offset = [ts_string_1] * half + [ts_string_2] * half", "min_run_count": 2, "name": "inference.ToDatetimeNONISO8601.time_same_offset", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "f4cfe5cc89ed121e911be978f375ccb3976e7f6b8bc0e40ffd649e75abf676dc", "warmup_time": -1}, "inference.ToDatetimeYYYYMMDD.time_format_YYYYMMDD": {"code": "class ToDatetimeYYYYMMDD:\n    def time_format_YYYYMMDD(self):\n        to_datetime(self.stringsD, format=\"%Y%m%d\")\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToDatetimeYYYYMMDD:\n    def setup(self):\n        rng = date_range(start=\"1/1/2000\", periods=10000, freq=\"D\")\n        self.stringsD = Series(rng.strftime(\"%Y%m%d\"))", "min_run_count": 2, "name": "inference.ToDatetimeYYYYMMDD.time_format_YYYYMMDD", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "1231af2c8acd673f7622a4a5cda34d3f69371a14c6d712e970653093e409349a", "warmup_time": -1}, "inference.ToNumeric.time_from_float": {"code": "class ToNumeric:\n    def time_from_float(self, errors):\n        to_numeric(self.float, errors=errors)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToNumeric:\n    def setup(self, errors):\n        N = 10000\n        self.float = Series(np.random.randn(N))\n        self.numstr = self.float.astype(\"str\")\n        self.str = Series(Index([f\"i-{i}\" for i in range(N)], dtype=object))", "min_run_count": 2, "name": "inference.ToNumeric.time_from_float", "number": 0, "param_names": ["errors"], "params": [["'ignore'", "'coerce'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "3018bceae25100a080272038e631bac6404179a468b4898e4c566f700b774817", "warmup_time": -1}, "inference.ToNumeric.time_from_numeric_str": {"code": "class ToNumeric:\n    def time_from_numeric_str(self, errors):\n        to_numeric(self.numstr, errors=errors)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToNumeric:\n    def setup(self, errors):\n        N = 10000\n        self.float = Series(np.random.randn(N))\n        self.numstr = self.float.astype(\"str\")\n        self.str = Series(Index([f\"i-{i}\" for i in range(N)], dtype=object))", "min_run_count": 2, "name": "inference.ToNumeric.time_from_numeric_str", "number": 0, "param_names": ["errors"], "params": [["'ignore'", "'coerce'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "7d94dad7883fd868cebd134c27f8d28972563020f052a001cc845b9253459e00", "warmup_time": -1}, "inference.ToNumeric.time_from_str": {"code": "class ToNumeric:\n    def time_from_str(self, errors):\n        to_numeric(self.str, errors=errors)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToNumeric:\n    def setup(self, errors):\n        N = 10000\n        self.float = Series(np.random.randn(N))\n        self.numstr = self.float.astype(\"str\")\n        self.str = Series(Index([f\"i-{i}\" for i in range(N)], dtype=object))", "min_run_count": 2, "name": "inference.ToNumeric.time_from_str", "number": 0, "param_names": ["errors"], "params": [["'ignore'", "'coerce'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "de75855151f0848ae519ca1bcfe87afd4695df8f8c11f28db0696c2c0ff33f58", "warmup_time": -1}, "inference.ToNumericDowncast.time_downcast": {"code": "class ToNumericDowncast:\n    def time_downcast(self, dtype, downcast):\n        to_numeric(self.data, downcast=downcast)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToNumericDowncast:\n    def setup(self, dtype, downcast):\n        self.data = self.data_dict[dtype]", "min_run_count": 2, "name": "inference.ToNumericDowncast.time_downcast", "number": 0, "param_names": ["dtype", "downcast"], "params": [["'string-float'", "'string-int'", "'string-nint'", "'datetime64'", "'int-list'", "'int32'"], ["None", "'integer'", "'signed'", "'unsigned'", "'float'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "0c056f48d7870e4188d6e5d83b2fae5d416f447632d4ee4e9e8c1ccec4b933bc", "warmup_time": -1}, "inference.ToTimedelta.time_convert_int": {"code": "class ToTimedelta:\n    def time_convert_int(self):\n        to_timedelta(self.ints, unit=\"s\")\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToTimedelta:\n    def setup(self):\n        self.ints = np.random.randint(0, 60, size=10000)\n        self.str_days = []\n        self.str_seconds = []\n        for i in self.ints:\n            self.str_days.append(f\"{i} days\")\n            self.str_seconds.append(f\"00:00:{i:02d}\")", "min_run_count": 2, "name": "inference.ToTimedelta.time_convert_int", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "e3d32b170c7865f14153be4d1dfe4cedbbfa407716af9b931a20cbf2be09aa76", "warmup_time": -1}, "inference.ToTimedelta.time_convert_string_days": {"code": "class ToTimedelta:\n    def time_convert_string_days(self):\n        to_timedelta(self.str_days)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToTimedelta:\n    def setup(self):\n        self.ints = np.random.randint(0, 60, size=10000)\n        self.str_days = []\n        self.str_seconds = []\n        for i in self.ints:\n            self.str_days.append(f\"{i} days\")\n            self.str_seconds.append(f\"00:00:{i:02d}\")", "min_run_count": 2, "name": "inference.ToTimedelta.time_convert_string_days", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "b10b9c32557f6894a8d5cdad6099b33d92453d78580ed6ac9bce54eeda6ac731", "warmup_time": -1}, "inference.ToTimedelta.time_convert_string_seconds": {"code": "class ToTimedelta:\n    def time_convert_string_seconds(self):\n        to_timedelta(self.str_seconds)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToTimedelta:\n    def setup(self):\n        self.ints = np.random.randint(0, 60, size=10000)\n        self.str_days = []\n        self.str_seconds = []\n        for i in self.ints:\n            self.str_days.append(f\"{i} days\")\n            self.str_seconds.append(f\"00:00:{i:02d}\")", "min_run_count": 2, "name": "inference.ToTimedelta.time_convert_string_seconds", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "ab0555d598557f0386f6743a49658aed686a61742a1a10086b99506a9dc533ba", "warmup_time": -1}, "inference.ToTimedeltaErrors.time_convert": {"code": "class ToTimedeltaErrors:\n    def time_convert(self, errors):\n        to_timedelta(self.arr, errors=errors)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToTimedeltaErrors:\n    def setup(self, errors):\n        ints = np.random.randint(0, 60, size=10000)\n        self.arr = [f\"{i} days\" for i in ints]\n        self.arr[-1] = \"apple\"", "min_run_count": 2, "name": "inference.ToTimedeltaErrors.time_convert", "number": 0, "param_names": ["errors"], "params": [["'coerce'", "'ignore'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "8a1b83205aea85d9e2d96e4303cdb083f3815f1959f3dee5f921a8668cb54c13", "warmup_time": -1}, "io.csv.ParseDateComparison.time_read_csv_dayfirst": {"code": "class ParseDateComparison:\n    def time_read_csv_dayfirst(self, cache_dates):\n        try:\n            read_csv(\n                self.data(self.StringIO_input),\n                sep=\",\",\n                header=None,\n                names=[\"Date\"],\n                parse_dates=[\"Date\"],\n                cache_dates=cache_dates,\n                dayfirst=True,\n            )\n        except TypeError:\n            # cache_dates is a new keyword in 0.25\n            pass\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ParseDateComparison:\n    def setup(self, cache_dates):\n        count_elem = 10000\n        data = \"12-02-2010\\n\" * count_elem\n        self.StringIO_input = StringIO(data)", "min_run_count": 2, "name": "io.csv.ParseDateComparison.time_read_csv_dayfirst", "number": 0, "param_names": ["cache_dates"], "params": [["False", "True"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "b531fbcabfa9f50a40159c707fc3c7f6e7b08d581c7b1d7a345041defb16e66f", "warmup_time": -1}, "io.csv.ParseDateComparison.time_to_datetime_dayfirst": {"code": "class ParseDateComparison:\n    def time_to_datetime_dayfirst(self, cache_dates):\n        df = read_csv(\n            self.data(self.StringIO_input), dtype={\"date\": str}, names=[\"date\"]\n        )\n        to_datetime(df[\"date\"], cache=cache_dates, dayfirst=True)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ParseDateComparison:\n    def setup(self, cache_dates):\n        count_elem = 10000\n        data = \"12-02-2010\\n\" * count_elem\n        self.StringIO_input = StringIO(data)", "min_run_count": 2, "name": "io.csv.ParseDateComparison.time_to_datetime_dayfirst", "number": 0, "param_names": ["cache_dates"], "params": [["False", "True"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "50d96a36fe567c997d3c1a6fbd696fe9705f2ea698a08554aa84d41cd77fcd4d", "warmup_time": -1}, "io.csv.ParseDateComparison.time_to_datetime_format_DD_MM_YYYY": {"code": "class ParseDateComparison:\n    def time_to_datetime_format_DD_MM_YYYY(self, cache_dates):\n        df = read_csv(\n            self.data(self.StringIO_input), dtype={\"date\": str}, names=[\"date\"]\n        )\n        to_datetime(df[\"date\"], cache=cache_dates, format=\"%d-%m-%Y\")\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ParseDateComparison:\n    def setup(self, cache_dates):\n        count_elem = 10000\n        data = \"12-02-2010\\n\" * count_elem\n        self.StringIO_input = StringIO(data)", "min_run_count": 2, "name": "io.csv.ParseDateComparison.time_to_datetime_format_DD_MM_YYYY", "number": 0, "param_names": ["cache_dates"], "params": [["False", "True"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "22583c40b98481bf789be587a51186ee7ff145dc4fb7e8e302872d06333449c9", "warmup_time": -1}, "io.csv.ReadCSVCParserLowMemory.peakmem_over_2gb_input": {"code": "class ReadCSVCParserLowMemory:\n    def peakmem_over_2gb_input(self):\n        read_csv(self.csv, engine=\"c\", low_memory=False)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ReadCSVCParserLowMemory:\n    def setup(self):\n        self.csv = StringIO(\n            \"strings\\n\" + \"\\n\".join([\"x\" * (1 << 20) for _ in range(2100)])\n        )", "name": "io.csv.ReadCSVCParserLowMemory.peakmem_over_2gb_input", "param_names": [], "params": [], "timeout": 60.0, "type": "peakmemory", "unit": "bytes", "version": "a48446a53498bc61ad769b708252358aea4b14b242699d3724820c38150f87ab"}, "io.csv.ReadCSVCachedParseDates.time_read_csv_cached": {"code": "class ReadCSVCachedParseDates:\n    def time_read_csv_cached(self, do_cache, engine):\n        try:\n            read_csv(\n                self.data(self.StringIO_input),\n                engine=engine,\n                header=None,\n                parse_dates=[0],\n                cache_dates=do_cache,\n            )\n        except TypeError:\n            # cache_dates is a new keyword in 0.25\n            pass\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ReadCSVCachedParseDates:\n    def setup(self, do_cache, engine):\n        data = (\"\\n\".join([f\"10/{year}\" for year in range(2000, 2100)]) + \"\\n\") * 10\n        self.StringIO_input = StringIO(data)", "min_run_count": 2, "name": "io.csv.ReadCSVCachedParseDates.time_read_csv_cached", "number": 0, "param_names": ["do_cache", "engine"], "params": [["True", "False"], ["'c'", "'python'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "bd18017d7e35c75b5b8e7641eba13970add0683431db08d765c8d0c218e4a37d", "warmup_time": -1}, "io.csv.ReadCSVCategorical.time_convert_direct": {"code": "class ReadCSVCategorical:\n    def time_convert_direct(self, engine):\n        read_csv(self.fname, engine=engine, dtype=\"category\")\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ReadCSVCategorical:\n    def setup(self, engine):\n        N = 100000\n        group1 = [\"aaaaaaaa\", \"bbbbbbb\", \"cccccccc\", \"dddddddd\", \"eeeeeeee\"]\n        df = DataFrame(np.random.choice(group1, (N, 3)), columns=list(\"abc\"))\n        df.to_csv(self.fname, index=False)", "min_run_count": 2, "name": "io.csv.ReadCSVCategorical.time_convert_direct", "number": 0, "param_names": ["engine"], "params": [["'c'", "'python'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "b2e9577b100c6272d45c9326e6ae5cc423be2a61cded554dcded5c3f443ab3d3", "warmup_time": -1}, "io.csv.ReadCSVCategorical.time_convert_post": {"code": "class ReadCSVCategorical:\n    def time_convert_post(self, engine):\n        read_csv(self.fname, engine=engine).apply(Categorical)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ReadCSVCategorical:\n    def setup(self, engine):\n        N = 100000\n        group1 = [\"aaaaaaaa\", \"bbbbbbb\", \"cccccccc\", \"dddddddd\", \"eeeeeeee\"]\n        df = DataFrame(np.random.choice(group1, (N, 3)), columns=list(\"abc\"))\n        df.to_csv(self.fname, index=False)", "min_run_count": 2, "name": "io.csv.ReadCSVCategorical.time_convert_post", "number": 0, "param_names": ["engine"], "params": [["'c'", "'python'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "b7f42a0fff0e3f819147a800861b2f3c3bfe6ed2893ab8f978bbc88396a2df45", "warmup_time": -1}, "io.csv.ReadCSVComment.time_comment": {"code": "class ReadCSVComment:\n    def time_comment(self, engine):\n        read_csv(\n            self.data(self.StringIO_input), comment=\"#\", header=None, names=list(\"abc\")\n        )\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ReadCSVComment:\n    def setup(self, engine):\n        data = [\"A,B,C\"] + ([\"1,2,3 # comment\"] * 100000)\n        self.StringIO_input = StringIO(\"\\n\".join(data))", "min_run_count": 2, "name": "io.csv.ReadCSVComment.time_comment", "number": 0, "param_names": ["engine"], "params": [["'c'", "'python'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "a90bbb38eb91ba9eeed032776bd52d7fd80b20ac0f6bc97853a821d08e98cf4b", "warmup_time": -1}, "io.csv.ReadCSVConcatDatetime.time_read_csv": {"code": "class ReadCSVConcatDatetime:\n    def time_read_csv(self):\n        read_csv(\n            self.data(self.StringIO_input),\n            header=None,\n            names=[\"foo\"],\n            parse_dates=[\"foo\"],\n        )\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ReadCSVConcatDatetime:\n    def setup(self):\n        rng = date_range(\"1/1/2000\", periods=50000, freq=\"s\")\n        self.StringIO_input = StringIO(\"\\n\".join(rng.strftime(self.iso8601).tolist()))", "min_run_count": 2, "name": "io.csv.ReadCSVConcatDatetime.time_read_csv", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "e9dddefec004c49888fad8124ac5f7f21e37497376bb8d3366b4c79d8aadebb6", "warmup_time": -1}, "io.csv.ReadCSVConcatDatetimeBadDateValue.time_read_csv": {"code": "class ReadCSVConcatDatetimeBadDateValue:\n    def time_read_csv(self, bad_date_value):\n        read_csv(\n            self.data(self.StringIO_input),\n            header=None,\n            names=[\"foo\", \"bar\"],\n            parse_dates=[\"foo\"],\n        )\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ReadCSVConcatDatetimeBadDateValue:\n    def setup(self, bad_date_value):\n        self.StringIO_input = StringIO((f\"{bad_date_value},\\n\") * 50000)", "min_run_count": 2, "name": "io.csv.ReadCSVConcatDatetimeBadDateValue.time_read_csv", "number": 0, "param_names": ["bad_date_value"], "params": [["'nan'", "'0'", "''"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "bbf5c349092a736709a8ab77f99aac07e8537b14babc5371d15b985c262ba233", "warmup_time": -1}, "io.csv.ReadCSVDInferDatetimeFormat.time_read_csv": {"code": "class ReadCSVDInferDatetimeFormat:\n    def time_read_csv(self, format):\n        read_csv(\n            self.data(self.StringIO_input),\n            header=None,\n            names=[\"foo\"],\n            parse_dates=[\"foo\"],\n        )\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ReadCSVDInferDatetimeFormat:\n    def setup(self, format):\n        rng = date_range(\"1/1/2000\", periods=1000)\n        formats = {\n            None: None,\n            \"custom\": \"%m/%d/%Y %H:%M:%S.%f\",\n            \"iso8601\": \"%Y-%m-%d %H:%M:%S\",\n            \"ymd\": \"%Y%m%d\",\n        }\n        dt_format = formats[format]\n        self.StringIO_input = StringIO(\"\\n\".join(rng.strftime(dt_format).tolist()))", "min_run_count": 2, "name": "io.csv.ReadCSVDInferDatetimeFormat.time_read_csv", "number": 0, "param_names": ["format"], "params": [["None", "'custom'", "'iso8601'", "'ymd'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "24fbc7cd7577a0d332b069a46fd6569ee2f6763c413b3881ae61d2f2076a8a2e", "warmup_time": -1}, "io.csv.ReadCSVDatePyarrowEngine.time_read_csv_index_col": {"code": "class ReadCSVDatePyarrowEngine:\n    def time_read_csv_index_col(self):\n        read_csv(\n            self.StringIO_input,\n            parse_dates=[\"a\"],\n            engine=\"pyarrow\",\n            dtype_backend=\"pyarrow\",\n        )\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ReadCSVDatePyarrowEngine:\n    def setup(self):\n        count_elem = 100_000\n        data = \"a\\n\" + \"2019-12-31\\n\" * count_elem\n        self.StringIO_input = StringIO(data)", "min_run_count": 2, "name": "io.csv.ReadCSVDatePyarrowEngine.time_read_csv_index_col", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "984d38229ea165c811952867799942026b2ec82f4ced14c519faa325c3df4a72", "warmup_time": -1}, "io.csv.ReadCSVEngine.time_read_bytescsv": {"code": "class ReadCSVEngine:\n    def time_read_bytescsv(self, engine):\n        read_csv(self.data(self.BytesIO_input), engine=engine)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ReadCSVEngine:\n    def setup(self, engine):\n        data = [\"A,B,C,D,E\"] + ([\"1,2,3,4,5\"] * 100000)\n        self.StringIO_input = StringIO(\"\\n\".join(data))\n        # simulate reading from file\n        self.BytesIO_input = BytesIO(self.StringIO_input.read().encode(\"utf-8\"))", "min_run_count": 2, "name": "io.csv.ReadCSVEngine.time_read_bytescsv", "number": 0, "param_names": ["engine"], "params": [["'c'", "'python'", "'pyarrow'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "c55db1629ca6d2b9c2cc35edb1684bf28f0a642354365378b739990b2beb3b36", "warmup_time": -1}, "io.csv.ReadCSVEngine.time_read_stringcsv": {"code": "class ReadCSVEngine:\n    def time_read_stringcsv(self, engine):\n        read_csv(self.data(self.StringIO_input), engine=engine)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ReadCSVEngine:\n    def setup(self, engine):\n        data = [\"A,B,C,D,E\"] + ([\"1,2,3,4,5\"] * 100000)\n        self.StringIO_input = StringIO(\"\\n\".join(data))\n        # simulate reading from file\n        self.BytesIO_input = BytesIO(self.StringIO_input.read().encode(\"utf-8\"))", "min_run_count": 2, "name": "io.csv.ReadCSVEngine.time_read_stringcsv", "number": 0, "param_names": ["engine"], "params": [["'c'", "'python'", "'pyarrow'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "bcd2541e7d01564732b9ee7d1a6eb25bc0640eba5345d2109c242f2887344d0b", "warmup_time": -1}, "io.csv.ReadCSVFloatPrecision.time_read_csv": {"code": "class ReadCSVFloatPrecision:\n    def time_read_csv(self, sep, decimal, float_precision):\n        read_csv(\n            self.data(self.StringIO_input),\n            sep=sep,\n            header=None,\n            names=list(\"abc\"),\n            float_precision=float_precision,\n        )\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ReadCSVFloatPrecision:\n    def setup(self, sep, decimal, float_precision):\n        floats = [\n            \"\".join([random.choice(string.digits) for _ in range(28)])\n            for _ in range(15)\n        ]\n        rows = sep.join([f\"0{decimal}{{}}\"] * 3) + \"\\n\"\n        data = rows * 5\n        data = data.format(*floats) * 200  # 1000 x 3 strings csv\n        self.StringIO_input = StringIO(data)", "min_run_count": 2, "name": "io.csv.ReadCSVFloatPrecision.time_read_csv", "number": 0, "param_names": ["sep", "decimal", "float_precision"], "params": [["','", "';'"], ["'.'", "'_'"], ["None", "'high'", "'round_trip'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "663280822afc0347b49d14d5e3295794e4e85cd460cf06e6afe197b7a034a74d", "warmup_time": -1}, "io.csv.ReadCSVFloatPrecision.time_read_csv_python_engine": {"code": "class ReadCSVFloatPrecision:\n    def time_read_csv_python_engine(self, sep, decimal, float_precision):\n        read_csv(\n            self.data(self.StringIO_input),\n            sep=sep,\n            header=None,\n            engine=\"python\",\n            float_precision=None,\n            names=list(\"abc\"),\n        )\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ReadCSVFloatPrecision:\n    def setup(self, sep, decimal, float_precision):\n        floats = [\n            \"\".join([random.choice(string.digits) for _ in range(28)])\n            for _ in range(15)\n        ]\n        rows = sep.join([f\"0{decimal}{{}}\"] * 3) + \"\\n\"\n        data = rows * 5\n        data = data.format(*floats) * 200  # 1000 x 3 strings csv\n        self.StringIO_input = StringIO(data)", "min_run_count": 2, "name": "io.csv.ReadCSVFloatPrecision.time_read_csv_python_engine", "number": 0, "param_names": ["sep", "decimal", "float_precision"], "params": [["','", "';'"], ["'.'", "'_'"], ["None", "'high'", "'round_trip'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "8904e1f9bcabd952d3ac2b41f754258e2e24205b0106b3bde4ba9fe99d668d64", "warmup_time": -1}, "io.csv.ReadCSVIndexCol.time_read_csv_index_col": {"code": "class ReadCSVIndexCol:\n    def time_read_csv_index_col(self):\n        read_csv(self.StringIO_input, index_col=\"a\")\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ReadCSVIndexCol:\n    def setup(self):\n        count_elem = 100_000\n        data = \"a,b\\n\" + \"1,2\\n\" * count_elem\n        self.StringIO_input = StringIO(data)", "min_run_count": 2, "name": "io.csv.ReadCSVIndexCol.time_read_csv_index_col", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "f6b24f24cf759e64c0087a252f48f6776c5e68abea602439336c61fb7db08a91", "warmup_time": -1}, "io.csv.ReadCSVMemMapUTF8.time_read_memmapped_utf8": {"code": "class ReadCSVMemMapUTF8:\n    def time_read_memmapped_utf8(self):\n        read_csv(self.fname, header=None, memory_map=True, encoding=\"utf-8\", engine=\"c\")\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ReadCSVMemMapUTF8:\n    def setup(self):\n        lines = []\n        line_length = 128\n        start_char = \" \"\n        end_char = \"\\U00010080\"\n        # This for loop creates a list of 128-char strings\n        # consisting of consecutive Unicode chars\n        for lnum in range(ord(start_char), ord(end_char), line_length):\n            line = \"\".join([chr(c) for c in range(lnum, lnum + 0x80)]) + \"\\n\"\n            try:\n                line.encode(\"utf-8\")\n            except UnicodeEncodeError:\n                # Some 16-bit words are not valid Unicode chars and must be skipped\n                continue\n            lines.append(line)\n        df = DataFrame(lines)\n        df = concat([df for n in range(100)], ignore_index=True)\n        df.to_csv(self.fname, index=False, header=False, encoding=\"utf-8\")", "min_run_count": 2, "name": "io.csv.ReadCSVMemMapUTF8.time_read_memmapped_utf8", "number": 5, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "28f7fd520f718e3d43c75304bfe758d8db2e0e48f9ecbcc93c96af3d09bb34c5", "warmup_time": -1}, "io.csv.ReadCSVMemoryGrowth.mem_parser_chunks": {"code": "class ReadCSVMemoryGrowth:\n    def mem_parser_chunks(self, engine):\n        # see gh-24805.\n        result = read_csv(self.fname, chunksize=self.chunksize, engine=engine)\n    \n        for _ in result:\n            pass\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ReadCSVMemoryGrowth:\n    def setup(self, engine):\n        with open(self.fname, \"w\", encoding=\"utf-8\") as f:\n            for i in range(self.num_rows):\n                f.write(f\"{i}\\n\")", "name": "io.csv.ReadCSVMemoryGrowth.mem_parser_chunks", "param_names": ["engine"], "params": [["'c'", "'python'"]], "timeout": 60.0, "type": "memory", "unit": "bytes", "version": "387998c7983127f8fd0c8355a485887a7bbb6b50be4b44fb222cf04d96bd4298"}, "io.csv.ReadCSVParseDates.time_baseline": {"code": "class ReadCSVParseDates:\n    def time_baseline(self, engine):\n        read_csv(\n            self.data(self.StringIO_input),\n            engine=engine,\n            sep=\",\",\n            header=None,\n            parse_dates=[1],\n            names=list(string.digits[:9]),\n        )\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ReadCSVParseDates:\n    def setup(self, engine):\n        data = \"\"\"{},19:00:00,18:56:00,0.8100,2.8100,7.2000,0.0000,280.0000\\n\n                  {},20:00:00,19:56:00,0.0100,2.2100,7.2000,0.0000,260.0000\\n\n                  {},21:00:00,20:56:00,-0.5900,2.2100,5.7000,0.0000,280.0000\\n\n                  {},21:00:00,21:18:00,-0.9900,2.0100,3.6000,0.0000,270.0000\\n\n                  {},22:00:00,21:56:00,-0.5900,1.7100,5.1000,0.0000,290.0000\\n\n               \"\"\"\n        two_cols = [\"KORD,19990127\"] * 5\n        data = data.format(*two_cols)\n        self.StringIO_input = StringIO(data)", "min_run_count": 2, "name": "io.csv.ReadCSVParseDates.time_baseline", "number": 0, "param_names": ["engine"], "params": [["'c'", "'python'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "221a4700fd1f02faac09f891ec2ff4bf841f4f8838d4912b40bd070ce1747d0d", "warmup_time": -1}, "io.csv.ReadCSVParseDates.time_multiple_date": {"code": "class ReadCSVParseDates:\n    def time_multiple_date(self, engine):\n        read_csv(\n            self.data(self.StringIO_input),\n            engine=engine,\n            sep=\",\",\n            header=None,\n            names=list(string.digits[:9]),\n            parse_dates=[[1, 2], [1, 3]],\n        )\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ReadCSVParseDates:\n    def setup(self, engine):\n        data = \"\"\"{},19:00:00,18:56:00,0.8100,2.8100,7.2000,0.0000,280.0000\\n\n                  {},20:00:00,19:56:00,0.0100,2.2100,7.2000,0.0000,260.0000\\n\n                  {},21:00:00,20:56:00,-0.5900,2.2100,5.7000,0.0000,280.0000\\n\n                  {},21:00:00,21:18:00,-0.9900,2.0100,3.6000,0.0000,270.0000\\n\n                  {},22:00:00,21:56:00,-0.5900,1.7100,5.1000,0.0000,290.0000\\n\n               \"\"\"\n        two_cols = [\"KORD,19990127\"] * 5\n        data = data.format(*two_cols)\n        self.StringIO_input = StringIO(data)", "min_run_count": 2, "name": "io.csv.ReadCSVParseDates.time_multiple_date", "number": 0, "param_names": ["engine"], "params": [["'c'", "'python'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "ddee417fe3a4e78483aae8d5f9fdc3e5fc75fd2257354f3445f110295eca8b93", "warmup_time": -1}, "io.csv.ReadCSVParseSpecialDate.time_read_special_date": {"code": "class ReadCSVParseSpecialDate:\n    def time_read_special_date(self, value, engine):\n        read_csv(\n            self.data(self.StringIO_input),\n            engine=engine,\n            sep=\",\",\n            header=None,\n            names=[\"Date\"],\n            parse_dates=[\"Date\"],\n        )\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ReadCSVParseSpecialDate:\n    def setup(self, value, engine):\n        count_elem = 10000\n        data = self.objects[value] * count_elem\n        self.StringIO_input = StringIO(data)", "min_run_count": 2, "name": "io.csv.ReadCSVParseSpecialDate.time_read_special_date", "number": 0, "param_names": ["value", "engine"], "params": [["'mY'", "'mdY'", "'hm'"], ["'c'", "'python'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "4adfa495cb5b837ceef161540601f8b0378f4433acbcd79ec36d1936f32b0276", "warmup_time": -1}, "io.csv.ReadCSVSkipRows.time_skipprows": {"code": "class ReadCSVSkipRows:\n    def time_skipprows(self, skiprows, engine):\n        read_csv(self.fname, skiprows=skiprows, engine=engine)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ReadCSVSkipRows:\n    def setup(self, skiprows, engine):\n        N = 20000\n        index = Index([f\"i-{i}\" for i in range(N)], dtype=object)\n        df = DataFrame(\n            {\n                \"float1\": np.random.randn(N),\n                \"float2\": np.random.randn(N),\n                \"string1\": [\"foo\"] * N,\n                \"bool1\": [True] * N,\n                \"int1\": np.random.randint(0, N, size=N),\n            },\n            index=index,\n        )\n        df.to_csv(self.fname)", "min_run_count": 2, "name": "io.csv.ReadCSVSkipRows.time_skipprows", "number": 0, "param_names": ["skiprows", "engine"], "params": [["None", "10000"], ["'c'", "'python'", "'pyarrow'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "fbe9957f14169d7708d3647b72449031d3ce2d6804cdb3dd942f15ce72a7fb63", "warmup_time": -1}, "io.csv.ReadCSVThousands.time_thousands": {"code": "class ReadCSVThousands:\n    def time_thousands(self, sep, thousands, engine):\n        read_csv(self.fname, sep=sep, thousands=thousands, engine=engine)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ReadCSVThousands:\n    def setup(self, sep, thousands, engine):\n        N = 10000\n        K = 8\n        data = np.random.randn(N, K) * np.random.randint(100, 10000, (N, K))\n        df = DataFrame(data)\n        if thousands is not None:\n            fmt = f\":{thousands}\"\n            fmt = \"{\" + fmt + \"}\"\n            df = df.map(lambda x: fmt.format(x))\n        df.to_csv(self.fname, sep=sep)", "min_run_count": 2, "name": "io.csv.ReadCSVThousands.time_thousands", "number": 0, "param_names": ["sep", "thousands", "engine"], "params": [["','", "'|'"], ["None", "','"], ["'c'", "'python'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "28174298e72aa540f2c967d0ae4c27033f3635114bea61298cf59ac2e8364ef5", "warmup_time": -1}, "io.csv.ReadUint64Integers.time_read_uint64": {"code": "class ReadUint64Integers:\n    def time_read_uint64(self):\n        read_csv(self.data(self.data1), header=None, names=[\"foo\"])\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ReadUint64Integers:\n    def setup(self):\n        self.na_values = [2**63 + 500]\n        arr = np.arange(10000).astype(\"uint64\") + 2**63\n        self.data1 = StringIO(\"\\n\".join(arr.astype(str).tolist()))\n        arr = arr.astype(object)\n        arr[500] = -1\n        self.data2 = StringIO(\"\\n\".join(arr.astype(str).tolist()))", "min_run_count": 2, "name": "io.csv.ReadUint64Integers.time_read_uint64", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "d4d93b300cdd080ede9b4b6103d9f29b7d9a87955c39dab1b41661f3b1836158", "warmup_time": -1}, "io.csv.ReadUint64Integers.time_read_uint64_na_values": {"code": "class ReadUint64Integers:\n    def time_read_uint64_na_values(self):\n        read_csv(\n            self.data(self.data1), header=None, names=[\"foo\"], na_values=self.na_values\n        )\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ReadUint64Integers:\n    def setup(self):\n        self.na_values = [2**63 + 500]\n        arr = np.arange(10000).astype(\"uint64\") + 2**63\n        self.data1 = StringIO(\"\\n\".join(arr.astype(str).tolist()))\n        arr = arr.astype(object)\n        arr[500] = -1\n        self.data2 = StringIO(\"\\n\".join(arr.astype(str).tolist()))", "min_run_count": 2, "name": "io.csv.ReadUint64Integers.time_read_uint64_na_values", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "36be6bf3e25ad59106e12794881da1b2cb92dfed243163b4c6802ee873fff567", "warmup_time": -1}, "io.csv.ReadUint64Integers.time_read_uint64_neg_values": {"code": "class ReadUint64Integers:\n    def time_read_uint64_neg_values(self):\n        read_csv(self.data(self.data2), header=None, names=[\"foo\"])\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ReadUint64Integers:\n    def setup(self):\n        self.na_values = [2**63 + 500]\n        arr = np.arange(10000).astype(\"uint64\") + 2**63\n        self.data1 = StringIO(\"\\n\".join(arr.astype(str).tolist()))\n        arr = arr.astype(object)\n        arr[500] = -1\n        self.data2 = StringIO(\"\\n\".join(arr.astype(str).tolist()))", "min_run_count": 2, "name": "io.csv.ReadUint64Integers.time_read_uint64_neg_values", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "2ff84e494ccdcd98ac1f99314c9865a5af568a2a806ace6dd69261d3ff23bd17", "warmup_time": -1}, "io.csv.ToCSV.time_frame": {"code": "class ToCSV:\n    def time_frame(self, kind):\n        self.df.to_csv(self.fname)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToCSV:\n    def setup(self, kind):\n        wide_frame = DataFrame(np.random.randn(3000, 30))\n        long_frame = DataFrame(\n            {\n                \"A\": np.arange(50000),\n                \"B\": np.arange(50000) + 1.0,\n                \"C\": np.arange(50000) + 2.0,\n                \"D\": np.arange(50000) + 3.0,\n            }\n        )\n        mixed_frame = DataFrame(\n            {\n                \"float\": np.random.randn(5000),\n                \"int\": np.random.randn(5000).astype(int),\n                \"bool\": (np.arange(5000) % 2) == 0,\n                \"datetime\": date_range(\"2001\", freq=\"s\", periods=5000),\n                \"object\": [\"foo\"] * 5000,\n            }\n        )\n        mixed_frame.loc[30:500, \"float\"] = np.nan\n        data = {\"wide\": wide_frame, \"long\": long_frame, \"mixed\": mixed_frame}\n        self.df = data[kind]", "min_run_count": 2, "name": "io.csv.ToCSV.time_frame", "number": 0, "param_names": ["kind"], "params": [["'wide'", "'long'", "'mixed'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "b207acadf1f9b5992775d04050e8e1c95f5b672a69adc5ea1bb47fac8c558b49", "warmup_time": -1}, "io.csv.ToCSVDatetime.time_frame_date_formatting": {"code": "class ToCSVDatetime:\n    def time_frame_date_formatting(self):\n        self.data.to_csv(self.fname, date_format=\"%Y%m%d\")\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToCSVDatetime:\n    def setup(self):\n        rng = date_range(\"1/1/2000\", periods=1000)\n        self.data = DataFrame(rng, index=rng)", "min_run_count": 2, "name": "io.csv.ToCSVDatetime.time_frame_date_formatting", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "48aec9f413466587de05eec973105aa3ca66fba9830fc6165228f306cfa384d0", "warmup_time": -1}, "io.csv.ToCSVDatetimeBig.time_frame": {"code": "class ToCSVDatetimeBig:\n    def time_frame(self, nobs):\n        self.data.to_csv(self.fname)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToCSVDatetimeBig:\n    def setup(self, nobs):\n        d = \"2018-11-29\"\n        dt = \"2018-11-26 11:18:27.0\"\n        self.data = DataFrame(\n            {\n                \"dt\": [np.datetime64(dt)] * nobs,\n                \"d\": [np.datetime64(d)] * nobs,\n                \"r\": [np.random.uniform()] * nobs,\n            }\n        )", "min_run_count": 2, "name": "io.csv.ToCSVDatetimeBig.time_frame", "number": 0, "param_names": ["nobs"], "params": [["1000", "10000", "100000"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 1500, "type": "time", "unit": "seconds", "version": "fa395b3a3f41934aecbec3ec06ce6f479c37e6f98c7e1bae1bc958330e6dcfdb", "warmup_time": -1}, "io.csv.ToCSVDatetimeIndex.time_frame_date_formatting_index": {"code": "class ToCSVDatetimeIndex:\n    def time_frame_date_formatting_index(self):\n        self.data.to_csv(self.fname, date_format=\"%Y-%m-%d %H:%M:%S\")\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToCSVDatetimeIndex:\n    def setup(self):\n        rng = date_range(\"2000\", periods=100_000, freq=\"s\")\n        self.data = DataFrame({\"a\": 1}, index=rng)", "min_run_count": 2, "name": "io.csv.ToCSVDatetimeIndex.time_frame_date_formatting_index", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "be53e0ea21b907c9caf3497a41461ca870f2b3189772b5c4ed6008a199faff36", "warmup_time": -1}, "io.csv.ToCSVDatetimeIndex.time_frame_date_no_format_index": {"code": "class ToCSVDatetimeIndex:\n    def time_frame_date_no_format_index(self):\n        self.data.to_csv(self.fname)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToCSVDatetimeIndex:\n    def setup(self):\n        rng = date_range(\"2000\", periods=100_000, freq=\"s\")\n        self.data = DataFrame({\"a\": 1}, index=rng)", "min_run_count": 2, "name": "io.csv.ToCSVDatetimeIndex.time_frame_date_no_format_index", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "a29d8f3cec0c25a7cbfc00d1da20a757fd4c53994cb8622eb1ebfd0e0cb2d5ba", "warmup_time": -1}, "io.csv.ToCSVIndexes.time_head_of_multiindex": {"code": "class ToCSVIndexes:\n    def time_head_of_multiindex(self):\n        self.df_custom_index_then_head.to_csv(self.fname)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToCSVIndexes:\n    def setup(self):\n        ROWS = 100000\n        COLS = 5\n        # For tests using .head(), create an initial dataframe with this many times\n        # more rows\n        HEAD_ROW_MULTIPLIER = 10\n    \n        self.df_standard_index = self._create_df(ROWS, COLS)\n    \n        self.df_custom_index_then_head = (\n            self._create_df(ROWS * HEAD_ROW_MULTIPLIER, COLS)\n            .set_index([\"index1\", \"index2\", \"index3\"])\n            .head(ROWS)\n        )\n    \n        self.df_head_then_custom_index = (\n            self._create_df(ROWS * HEAD_ROW_MULTIPLIER, COLS)\n            .head(ROWS)\n            .set_index([\"index1\", \"index2\", \"index3\"])\n        )", "min_run_count": 2, "name": "io.csv.ToCSVIndexes.time_head_of_multiindex", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "b19bd98ca4e016f0e4a61cb075ab765fe428f49a7a406dd786bf37617833558c", "warmup_time": -1}, "io.csv.ToCSVIndexes.time_multiindex": {"code": "class ToCSVIndexes:\n    def time_multiindex(self):\n        self.df_head_then_custom_index.to_csv(self.fname)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToCSVIndexes:\n    def setup(self):\n        ROWS = 100000\n        COLS = 5\n        # For tests using .head(), create an initial dataframe with this many times\n        # more rows\n        HEAD_ROW_MULTIPLIER = 10\n    \n        self.df_standard_index = self._create_df(ROWS, COLS)\n    \n        self.df_custom_index_then_head = (\n            self._create_df(ROWS * HEAD_ROW_MULTIPLIER, COLS)\n            .set_index([\"index1\", \"index2\", \"index3\"])\n            .head(ROWS)\n        )\n    \n        self.df_head_then_custom_index = (\n            self._create_df(ROWS * HEAD_ROW_MULTIPLIER, COLS)\n            .head(ROWS)\n            .set_index([\"index1\", \"index2\", \"index3\"])\n        )", "min_run_count": 2, "name": "io.csv.ToCSVIndexes.time_multiindex", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "e6c356ab53559b97134b83598c7406d7849f7d72f0cd33999f3ed3a1388ae70b", "warmup_time": -1}, "io.csv.ToCSVIndexes.time_standard_index": {"code": "class ToCSVIndexes:\n    def time_standard_index(self):\n        self.df_standard_index.to_csv(self.fname)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToCSVIndexes:\n    def setup(self):\n        ROWS = 100000\n        COLS = 5\n        # For tests using .head(), create an initial dataframe with this many times\n        # more rows\n        HEAD_ROW_MULTIPLIER = 10\n    \n        self.df_standard_index = self._create_df(ROWS, COLS)\n    \n        self.df_custom_index_then_head = (\n            self._create_df(ROWS * HEAD_ROW_MULTIPLIER, COLS)\n            .set_index([\"index1\", \"index2\", \"index3\"])\n            .head(ROWS)\n        )\n    \n        self.df_head_then_custom_index = (\n            self._create_df(ROWS * HEAD_ROW_MULTIPLIER, COLS)\n            .head(ROWS)\n            .set_index([\"index1\", \"index2\", \"index3\"])\n        )", "min_run_count": 2, "name": "io.csv.ToCSVIndexes.time_standard_index", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "4d8e112a392acdd1a4bdd4008abb8a96e5e23ac65da30366feda0363459f118b", "warmup_time": -1}, "io.csv.ToCSVMultiIndexUnusedLevels.time_full_frame": {"code": "class ToCSVMultiIndexUnusedLevels:\n    def time_full_frame(self):\n        self.df.to_csv(self.fname)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToCSVMultiIndexUnusedLevels:\n    def setup(self):\n        df = DataFrame({\"a\": np.random.randn(100_000), \"b\": 1, \"c\": 1})\n        self.df = df.set_index([\"a\", \"b\"])\n        self.df_unused_levels = self.df.iloc[:10_000]\n        self.df_single_index = df.set_index([\"a\"]).iloc[:10_000]", "min_run_count": 2, "name": "io.csv.ToCSVMultiIndexUnusedLevels.time_full_frame", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "724d348ca5334e593a849378524d8ed762f78bff3cdf32b12389521b5d4296d6", "warmup_time": -1}, "io.csv.ToCSVMultiIndexUnusedLevels.time_single_index_frame": {"code": "class ToCSVMultiIndexUnusedLevels:\n    def time_single_index_frame(self):\n        self.df_single_index.to_csv(self.fname)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToCSVMultiIndexUnusedLevels:\n    def setup(self):\n        df = DataFrame({\"a\": np.random.randn(100_000), \"b\": 1, \"c\": 1})\n        self.df = df.set_index([\"a\", \"b\"])\n        self.df_unused_levels = self.df.iloc[:10_000]\n        self.df_single_index = df.set_index([\"a\"]).iloc[:10_000]", "min_run_count": 2, "name": "io.csv.ToCSVMultiIndexUnusedLevels.time_single_index_frame", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "fddcb69899294d5fe6894ce1add6d4d9dd6b6c889218886482b796f7df3f0718", "warmup_time": -1}, "io.csv.ToCSVMultiIndexUnusedLevels.time_sliced_frame": {"code": "class ToCSVMultiIndexUnusedLevels:\n    def time_sliced_frame(self):\n        self.df_unused_levels.to_csv(self.fname)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToCSVMultiIndexUnusedLevels:\n    def setup(self):\n        df = DataFrame({\"a\": np.random.randn(100_000), \"b\": 1, \"c\": 1})\n        self.df = df.set_index([\"a\", \"b\"])\n        self.df_unused_levels = self.df.iloc[:10_000]\n        self.df_single_index = df.set_index([\"a\"]).iloc[:10_000]", "min_run_count": 2, "name": "io.csv.ToCSVMultiIndexUnusedLevels.time_sliced_frame", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "c52b3c8ffc9d375d7d7fe89c76149484b884cdab2db3b786aa976b2a571dc669", "warmup_time": -1}, "io.csv.ToCSVPeriod.time_frame_period_formatting": {"code": "class ToCSVPeriod:\n    def time_frame_period_formatting(self, nobs, freq):\n        # Nb: `date_format` is not actually taken into account here today, so the\n        # performance is currently identical to `time_frame_period_formatting_default`\n        # above. This timer is therefore expected to degrade when GH#51621 is fixed.\n        # (Remove this comment when GH#51621 is fixed.)\n        self.data.to_csv(self.fname, date_format=\"%Y-%m-%d___%H:%M:%S\")\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToCSVPeriod:\n    def setup(self, nobs, freq):\n        rng = period_range(start=\"2000-01-01\", periods=nobs, freq=freq)\n        self.data = DataFrame(rng)\n        if freq == \"D\":\n            self.default_fmt = \"%Y-%m-%d\"\n        elif freq == \"h\":\n            self.default_fmt = \"%Y-%m-%d %H:00\"", "min_run_count": 2, "name": "io.csv.ToCSVPeriod.time_frame_period_formatting", "number": 0, "param_names": ["nobs", "freq"], "params": [["1000", "10000"], ["'D'", "'h'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "5170753217ef6733879fd3238ebf2cc66780345d552f0cd80797bc50fbfa8f9a", "warmup_time": -1}, "io.csv.ToCSVPeriod.time_frame_period_formatting_default": {"code": "class ToCSVPeriod:\n    def time_frame_period_formatting_default(self, nobs, freq):\n        self.data.to_csv(self.fname)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToCSVPeriod:\n    def setup(self, nobs, freq):\n        rng = period_range(start=\"2000-01-01\", periods=nobs, freq=freq)\n        self.data = DataFrame(rng)\n        if freq == \"D\":\n            self.default_fmt = \"%Y-%m-%d\"\n        elif freq == \"h\":\n            self.default_fmt = \"%Y-%m-%d %H:00\"", "min_run_count": 2, "name": "io.csv.ToCSVPeriod.time_frame_period_formatting_default", "number": 0, "param_names": ["nobs", "freq"], "params": [["1000", "10000"], ["'D'", "'h'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "97fe0df229e93c48eb91efabbb13c673ea37727315d159564845c312e2b6d0bb", "warmup_time": -1}, "io.csv.ToCSVPeriod.time_frame_period_formatting_default_explicit": {"code": "class ToCSVPeriod:\n    def time_frame_period_formatting_default_explicit(self, nobs, freq):\n        self.data.to_csv(self.fname, date_format=self.default_fmt)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToCSVPeriod:\n    def setup(self, nobs, freq):\n        rng = period_range(start=\"2000-01-01\", periods=nobs, freq=freq)\n        self.data = DataFrame(rng)\n        if freq == \"D\":\n            self.default_fmt = \"%Y-%m-%d\"\n        elif freq == \"h\":\n            self.default_fmt = \"%Y-%m-%d %H:00\"", "min_run_count": 2, "name": "io.csv.ToCSVPeriod.time_frame_period_formatting_default_explicit", "number": 0, "param_names": ["nobs", "freq"], "params": [["1000", "10000"], ["'D'", "'h'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "70a4e40c81c34918091a014201d45867a489c6949e7de705876a37f9a70981f7", "warmup_time": -1}, "io.csv.ToCSVPeriodIndex.time_frame_period_formatting_index": {"code": "class ToCSVPeriodIndex:\n    def time_frame_period_formatting_index(self, nobs, freq):\n        self.data.to_csv(self.fname, date_format=\"%Y-%m-%d___%H:%M:%S\")\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToCSVPeriodIndex:\n    def setup(self, nobs, freq):\n        rng = period_range(start=\"2000-01-01\", periods=nobs, freq=freq)\n        self.data = DataFrame({\"a\": 1}, index=rng)\n        if freq == \"D\":\n            self.default_fmt = \"%Y-%m-%d\"\n        elif freq == \"h\":\n            self.default_fmt = \"%Y-%m-%d %H:00\"", "min_run_count": 2, "name": "io.csv.ToCSVPeriodIndex.time_frame_period_formatting_index", "number": 0, "param_names": ["nobs", "freq"], "params": [["1000", "10000"], ["'D'", "'h'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "0331c31f8b48949b743fcd0aaae50203e37d79f16702b6c3e627c8c8f72d4a7d", "warmup_time": -1}, "io.csv.ToCSVPeriodIndex.time_frame_period_formatting_index_default": {"code": "class ToCSVPeriodIndex:\n    def time_frame_period_formatting_index_default(self, nobs, freq):\n        self.data.to_csv(self.fname)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToCSVPeriodIndex:\n    def setup(self, nobs, freq):\n        rng = period_range(start=\"2000-01-01\", periods=nobs, freq=freq)\n        self.data = DataFrame({\"a\": 1}, index=rng)\n        if freq == \"D\":\n            self.default_fmt = \"%Y-%m-%d\"\n        elif freq == \"h\":\n            self.default_fmt = \"%Y-%m-%d %H:00\"", "min_run_count": 2, "name": "io.csv.ToCSVPeriodIndex.time_frame_period_formatting_index_default", "number": 0, "param_names": ["nobs", "freq"], "params": [["1000", "10000"], ["'D'", "'h'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "deb79b68a5a3d0c5dee09ca8f3e00032d4cdbe53e595d7a4633bae09e0998e4e", "warmup_time": -1}, "io.csv.ToCSVPeriodIndex.time_frame_period_formatting_index_default_explicit": {"code": "class ToCSVPeriodIndex:\n    def time_frame_period_formatting_index_default_explicit(self, nobs, freq):\n        self.data.to_csv(self.fname, date_format=self.default_fmt)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToCSVPeriodIndex:\n    def setup(self, nobs, freq):\n        rng = period_range(start=\"2000-01-01\", periods=nobs, freq=freq)\n        self.data = DataFrame({\"a\": 1}, index=rng)\n        if freq == \"D\":\n            self.default_fmt = \"%Y-%m-%d\"\n        elif freq == \"h\":\n            self.default_fmt = \"%Y-%m-%d %H:00\"", "min_run_count": 2, "name": "io.csv.ToCSVPeriodIndex.time_frame_period_formatting_index_default_explicit", "number": 0, "param_names": ["nobs", "freq"], "params": [["1000", "10000"], ["'D'", "'h'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "438b06aa750f7ccc6158ee25ad424220362457cc9ea8d2413071ae2a3570c671", "warmup_time": -1}, "io.excel.ReadExcel.time_read_excel": {"code": "class ReadExcel:\n    def time_read_excel(self, engine):\n        if engine == \"odf\":\n            fname = self.fname_odf\n        else:\n            fname = self.fname_excel\n        read_excel(fname, engine=engine)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ReadExcel:\n    def setup_cache(self):\n        self.df = _generate_dataframe()\n    \n        self.df.to_excel(self.fname_excel, sheet_name=\"Sheet1\")\n        self._create_odf()", "min_run_count": 2, "name": "io.excel.ReadExcel.time_read_excel", "number": 0, "param_names": ["engine"], "params": [["'openpyxl'", "'odf'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "setup_cache_key": "io.excel:85", "timeout": 60.0, "type": "time", "unit": "seconds", "version": "5b4c727b29b6c7a2c1a6679ecdebdf57f4082a33d80b1b263e51a694d738c7f8", "warmup_time": -1}, "io.excel.ReadExcelNRows.time_read_excel": {"code": "class ReadExcelNRows:\n    def time_read_excel(self, engine):\n        if engine == \"odf\":\n            fname = self.fname_odf\n        else:\n            fname = self.fname_excel\n        read_excel(fname, engine=engine, nrows=10)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ReadExcel:\n    def setup_cache(self):\n        self.df = _generate_dataframe()\n    \n        self.df.to_excel(self.fname_excel, sheet_name=\"Sheet1\")\n        self._create_odf()", "min_run_count": 2, "name": "io.excel.ReadExcelNRows.time_read_excel", "number": 0, "param_names": ["engine"], "params": [["'openpyxl'", "'odf'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "setup_cache_key": "io.excel:85", "timeout": 60.0, "type": "time", "unit": "seconds", "version": "3e5f8dfb13ec7132e6defe6d8e37342d4d227165982cfc87986a70725225b237", "warmup_time": -1}, "io.excel.WriteExcel.time_write_excel": {"code": "class WriteExcel:\n    def time_write_excel(self, engine):\n        bio = BytesIO()\n        bio.seek(0)\n        with ExcelWriter(bio, engine=engine) as writer:\n            self.df.to_excel(writer, sheet_name=\"Sheet1\")\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass WriteExcel:\n    def setup(self, engine):\n        self.df = _generate_dataframe()", "min_run_count": 2, "name": "io.excel.WriteExcel.time_write_excel", "number": 0, "param_names": ["engine"], "params": [["'openpyxl'", "'xlsxwriter'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "7578b2403493bd3778db1aadd2c8d24328372b68145f847a4e479265ddccd155", "warmup_time": -1}, "io.excel.WriteExcelStyled.time_write_excel_style": {"code": "class WriteExcelStyled:\n    def time_write_excel_style(self, engine):\n        bio = BytesIO()\n        bio.seek(0)\n        with ExcelWriter(bio, engine=engine) as writer:\n            df_style = self.df.style\n            df_style.map(lambda x: \"border: red 1px solid;\")\n            df_style.map(lambda x: \"color: blue\")\n            df_style.map(lambda x: \"border-color: green black\", subset=[\"float1\"])\n            df_style.to_excel(writer, sheet_name=\"Sheet1\")\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass WriteExcelStyled:\n    def setup(self, engine):\n        self.df = _generate_dataframe()", "min_run_count": 2, "name": "io.excel.WriteExcelStyled.time_write_excel_style", "number": 0, "param_names": ["engine"], "params": [["'openpyxl'", "'xlsxwriter'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "35f39ed22d0a5c540ef5e9f7b05a346a1e0d747b934181b07307d760f10dca5c", "warmup_time": -1}, "io.hdf.HDF.peakmem_read_hdf": {"code": "class HDF:\n    def peakmem_read_hdf(self, format):\n        read_hdf(self.fname, \"df\")\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass HDF:\n    def setup(self, format):\n        self.fname = \"__test__.h5\"\n        N = 100000\n        C = 5\n        self.df = DataFrame(\n            np.random.randn(N, C),\n            columns=[f\"float{i}\" for i in range(C)],\n            index=date_range(\"20000101\", periods=N, freq=\"h\"),\n        )\n        self.df[\"object\"] = Index([f\"i-{i}\" for i in range(N)], dtype=object)\n        self.df.to_hdf(self.fname, \"df\", format=format)\n    \n        # Numeric df\n        self.df1 = self.df.copy()\n        self.df1 = self.df1.reset_index()\n        self.df1.to_hdf(self.fname, \"df1\", format=format)", "name": "io.hdf.HDF.peakmem_read_hdf", "param_names": ["format"], "params": [["'table'", "'fixed'"]], "timeout": 60.0, "type": "peakmemory", "unit": "bytes", "version": "884ca433850bfdc201fb0d96a9802915ef01813587ac0af1cedd87ee0a9b25e7"}, "io.hdf.HDF.time_read_hdf": {"code": "class HDF:\n    def time_read_hdf(self, format):\n        read_hdf(self.fname, \"df\")\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass HDF:\n    def setup(self, format):\n        self.fname = \"__test__.h5\"\n        N = 100000\n        C = 5\n        self.df = DataFrame(\n            np.random.randn(N, C),\n            columns=[f\"float{i}\" for i in range(C)],\n            index=date_range(\"20000101\", periods=N, freq=\"h\"),\n        )\n        self.df[\"object\"] = Index([f\"i-{i}\" for i in range(N)], dtype=object)\n        self.df.to_hdf(self.fname, \"df\", format=format)\n    \n        # Numeric df\n        self.df1 = self.df.copy()\n        self.df1 = self.df1.reset_index()\n        self.df1.to_hdf(self.fname, \"df1\", format=format)", "min_run_count": 2, "name": "io.hdf.HDF.time_read_hdf", "number": 0, "param_names": ["format"], "params": [["'table'", "'fixed'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "e91662bf51283e4c1b6b769f593c4f5ed7f6de1187bef1cb08c37fa276cc9765", "warmup_time": -1}, "io.hdf.HDF.time_write_hdf": {"code": "class HDF:\n    def time_write_hdf(self, format):\n        self.df.to_hdf(self.fname, \"df\", format=format)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass HDF:\n    def setup(self, format):\n        self.fname = \"__test__.h5\"\n        N = 100000\n        C = 5\n        self.df = DataFrame(\n            np.random.randn(N, C),\n            columns=[f\"float{i}\" for i in range(C)],\n            index=date_range(\"20000101\", periods=N, freq=\"h\"),\n        )\n        self.df[\"object\"] = Index([f\"i-{i}\" for i in range(N)], dtype=object)\n        self.df.to_hdf(self.fname, \"df\", format=format)\n    \n        # Numeric df\n        self.df1 = self.df.copy()\n        self.df1 = self.df1.reset_index()\n        self.df1.to_hdf(self.fname, \"df1\", format=format)", "min_run_count": 2, "name": "io.hdf.HDF.time_write_hdf", "number": 0, "param_names": ["format"], "params": [["'table'", "'fixed'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "2d96f2cecaceae950ce47db184a5a2f407909c972fad6e3e2a1eb902fb2dcb10", "warmup_time": -1}, "io.hdf.HDFStoreDataFrame.time_query_store_table": {"code": "class HDFStoreDataFrame:\n    def time_query_store_table(self):\n        self.store.select(\"table\", where=\"index > self.start and index < self.stop\")\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass HDFStoreDataFrame:\n    def setup(self):\n        N = 25000\n        index = Index([f\"i-{i}\" for i in range(N)], dtype=object)\n        self.df = DataFrame(\n            {\"float1\": np.random.randn(N), \"float2\": np.random.randn(N)}, index=index\n        )\n        self.df_mixed = DataFrame(\n            {\n                \"float1\": np.random.randn(N),\n                \"float2\": np.random.randn(N),\n                \"string1\": [\"foo\"] * N,\n                \"bool1\": [True] * N,\n                \"int1\": np.random.randint(0, N, size=N),\n            },\n            index=index,\n        )\n        self.df_wide = DataFrame(np.random.randn(N, 100))\n        self.start_wide = self.df_wide.index[10000]\n        self.stop_wide = self.df_wide.index[15000]\n        self.df2 = DataFrame(\n            {\"float1\": np.random.randn(N), \"float2\": np.random.randn(N)},\n            index=date_range(\"1/1/2000\", periods=N),\n        )\n        self.start = self.df2.index[10000]\n        self.stop = self.df2.index[15000]\n        self.df_wide2 = DataFrame(\n            np.random.randn(N, 100), index=date_range(\"1/1/2000\", periods=N)\n        )\n        self.df_dc = DataFrame(\n            np.random.randn(N, 10), columns=[f\"C{i:03d}\" for i in range(10)]\n        )\n    \n        self.fname = \"__test__.h5\"\n    \n        self.store = HDFStore(self.fname)\n        self.store.put(\"fixed\", self.df)\n        self.store.put(\"fixed_mixed\", self.df_mixed)\n        self.store.append(\"table\", self.df2)\n        self.store.append(\"table_mixed\", self.df_mixed)\n        self.store.append(\"table_wide\", self.df_wide)\n        self.store.append(\"table_wide2\", self.df_wide2)", "min_run_count": 2, "name": "io.hdf.HDFStoreDataFrame.time_query_store_table", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "40b2068f3fa64a0e6a20da79476d70035884e866d3b4994f9da2e7828cd555c2", "warmup_time": -1}, "io.hdf.HDFStoreDataFrame.time_query_store_table_wide": {"code": "class HDFStoreDataFrame:\n    def time_query_store_table_wide(self):\n        self.store.select(\n            \"table_wide\", where=\"index > self.start_wide and index < self.stop_wide\"\n        )\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass HDFStoreDataFrame:\n    def setup(self):\n        N = 25000\n        index = Index([f\"i-{i}\" for i in range(N)], dtype=object)\n        self.df = DataFrame(\n            {\"float1\": np.random.randn(N), \"float2\": np.random.randn(N)}, index=index\n        )\n        self.df_mixed = DataFrame(\n            {\n                \"float1\": np.random.randn(N),\n                \"float2\": np.random.randn(N),\n                \"string1\": [\"foo\"] * N,\n                \"bool1\": [True] * N,\n                \"int1\": np.random.randint(0, N, size=N),\n            },\n            index=index,\n        )\n        self.df_wide = DataFrame(np.random.randn(N, 100))\n        self.start_wide = self.df_wide.index[10000]\n        self.stop_wide = self.df_wide.index[15000]\n        self.df2 = DataFrame(\n            {\"float1\": np.random.randn(N), \"float2\": np.random.randn(N)},\n            index=date_range(\"1/1/2000\", periods=N),\n        )\n        self.start = self.df2.index[10000]\n        self.stop = self.df2.index[15000]\n        self.df_wide2 = DataFrame(\n            np.random.randn(N, 100), index=date_range(\"1/1/2000\", periods=N)\n        )\n        self.df_dc = DataFrame(\n            np.random.randn(N, 10), columns=[f\"C{i:03d}\" for i in range(10)]\n        )\n    \n        self.fname = \"__test__.h5\"\n    \n        self.store = HDFStore(self.fname)\n        self.store.put(\"fixed\", self.df)\n        self.store.put(\"fixed_mixed\", self.df_mixed)\n        self.store.append(\"table\", self.df2)\n        self.store.append(\"table_mixed\", self.df_mixed)\n        self.store.append(\"table_wide\", self.df_wide)\n        self.store.append(\"table_wide2\", self.df_wide2)", "min_run_count": 2, "name": "io.hdf.HDFStoreDataFrame.time_query_store_table_wide", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "205842891832cc3189d2d8c107fb32a32951b545c2567df596beea6814ece721", "warmup_time": -1}, "io.hdf.HDFStoreDataFrame.time_read_store": {"code": "class HDFStoreDataFrame:\n    def time_read_store(self):\n        self.store.get(\"fixed\")\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass HDFStoreDataFrame:\n    def setup(self):\n        N = 25000\n        index = Index([f\"i-{i}\" for i in range(N)], dtype=object)\n        self.df = DataFrame(\n            {\"float1\": np.random.randn(N), \"float2\": np.random.randn(N)}, index=index\n        )\n        self.df_mixed = DataFrame(\n            {\n                \"float1\": np.random.randn(N),\n                \"float2\": np.random.randn(N),\n                \"string1\": [\"foo\"] * N,\n                \"bool1\": [True] * N,\n                \"int1\": np.random.randint(0, N, size=N),\n            },\n            index=index,\n        )\n        self.df_wide = DataFrame(np.random.randn(N, 100))\n        self.start_wide = self.df_wide.index[10000]\n        self.stop_wide = self.df_wide.index[15000]\n        self.df2 = DataFrame(\n            {\"float1\": np.random.randn(N), \"float2\": np.random.randn(N)},\n            index=date_range(\"1/1/2000\", periods=N),\n        )\n        self.start = self.df2.index[10000]\n        self.stop = self.df2.index[15000]\n        self.df_wide2 = DataFrame(\n            np.random.randn(N, 100), index=date_range(\"1/1/2000\", periods=N)\n        )\n        self.df_dc = DataFrame(\n            np.random.randn(N, 10), columns=[f\"C{i:03d}\" for i in range(10)]\n        )\n    \n        self.fname = \"__test__.h5\"\n    \n        self.store = HDFStore(self.fname)\n        self.store.put(\"fixed\", self.df)\n        self.store.put(\"fixed_mixed\", self.df_mixed)\n        self.store.append(\"table\", self.df2)\n        self.store.append(\"table_mixed\", self.df_mixed)\n        self.store.append(\"table_wide\", self.df_wide)\n        self.store.append(\"table_wide2\", self.df_wide2)", "min_run_count": 2, "name": "io.hdf.HDFStoreDataFrame.time_read_store", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "b81c7b37b744fb0fe641d2b6d817db00b609a32efd08df6d7d7071fdae8ba8a0", "warmup_time": -1}, "io.hdf.HDFStoreDataFrame.time_read_store_mixed": {"code": "class HDFStoreDataFrame:\n    def time_read_store_mixed(self):\n        self.store.get(\"fixed_mixed\")\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass HDFStoreDataFrame:\n    def setup(self):\n        N = 25000\n        index = Index([f\"i-{i}\" for i in range(N)], dtype=object)\n        self.df = DataFrame(\n            {\"float1\": np.random.randn(N), \"float2\": np.random.randn(N)}, index=index\n        )\n        self.df_mixed = DataFrame(\n            {\n                \"float1\": np.random.randn(N),\n                \"float2\": np.random.randn(N),\n                \"string1\": [\"foo\"] * N,\n                \"bool1\": [True] * N,\n                \"int1\": np.random.randint(0, N, size=N),\n            },\n            index=index,\n        )\n        self.df_wide = DataFrame(np.random.randn(N, 100))\n        self.start_wide = self.df_wide.index[10000]\n        self.stop_wide = self.df_wide.index[15000]\n        self.df2 = DataFrame(\n            {\"float1\": np.random.randn(N), \"float2\": np.random.randn(N)},\n            index=date_range(\"1/1/2000\", periods=N),\n        )\n        self.start = self.df2.index[10000]\n        self.stop = self.df2.index[15000]\n        self.df_wide2 = DataFrame(\n            np.random.randn(N, 100), index=date_range(\"1/1/2000\", periods=N)\n        )\n        self.df_dc = DataFrame(\n            np.random.randn(N, 10), columns=[f\"C{i:03d}\" for i in range(10)]\n        )\n    \n        self.fname = \"__test__.h5\"\n    \n        self.store = HDFStore(self.fname)\n        self.store.put(\"fixed\", self.df)\n        self.store.put(\"fixed_mixed\", self.df_mixed)\n        self.store.append(\"table\", self.df2)\n        self.store.append(\"table_mixed\", self.df_mixed)\n        self.store.append(\"table_wide\", self.df_wide)\n        self.store.append(\"table_wide2\", self.df_wide2)", "min_run_count": 2, "name": "io.hdf.HDFStoreDataFrame.time_read_store_mixed", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "80585e918467a2bc34f9d22dfec4aea16e3ca27199eb3eada198f0a8d01db954", "warmup_time": -1}, "io.hdf.HDFStoreDataFrame.time_read_store_table": {"code": "class HDFStoreDataFrame:\n    def time_read_store_table(self):\n        self.store.select(\"table\")\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass HDFStoreDataFrame:\n    def setup(self):\n        N = 25000\n        index = Index([f\"i-{i}\" for i in range(N)], dtype=object)\n        self.df = DataFrame(\n            {\"float1\": np.random.randn(N), \"float2\": np.random.randn(N)}, index=index\n        )\n        self.df_mixed = DataFrame(\n            {\n                \"float1\": np.random.randn(N),\n                \"float2\": np.random.randn(N),\n                \"string1\": [\"foo\"] * N,\n                \"bool1\": [True] * N,\n                \"int1\": np.random.randint(0, N, size=N),\n            },\n            index=index,\n        )\n        self.df_wide = DataFrame(np.random.randn(N, 100))\n        self.start_wide = self.df_wide.index[10000]\n        self.stop_wide = self.df_wide.index[15000]\n        self.df2 = DataFrame(\n            {\"float1\": np.random.randn(N), \"float2\": np.random.randn(N)},\n            index=date_range(\"1/1/2000\", periods=N),\n        )\n        self.start = self.df2.index[10000]\n        self.stop = self.df2.index[15000]\n        self.df_wide2 = DataFrame(\n            np.random.randn(N, 100), index=date_range(\"1/1/2000\", periods=N)\n        )\n        self.df_dc = DataFrame(\n            np.random.randn(N, 10), columns=[f\"C{i:03d}\" for i in range(10)]\n        )\n    \n        self.fname = \"__test__.h5\"\n    \n        self.store = HDFStore(self.fname)\n        self.store.put(\"fixed\", self.df)\n        self.store.put(\"fixed_mixed\", self.df_mixed)\n        self.store.append(\"table\", self.df2)\n        self.store.append(\"table_mixed\", self.df_mixed)\n        self.store.append(\"table_wide\", self.df_wide)\n        self.store.append(\"table_wide2\", self.df_wide2)", "min_run_count": 2, "name": "io.hdf.HDFStoreDataFrame.time_read_store_table", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "a0b2d2c3b5db0383751a7133216ac82e5c8e2f2460d14a9743250eeca3476216", "warmup_time": -1}, "io.hdf.HDFStoreDataFrame.time_read_store_table_mixed": {"code": "class HDFStoreDataFrame:\n    def time_read_store_table_mixed(self):\n        self.store.select(\"table_mixed\")\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass HDFStoreDataFrame:\n    def setup(self):\n        N = 25000\n        index = Index([f\"i-{i}\" for i in range(N)], dtype=object)\n        self.df = DataFrame(\n            {\"float1\": np.random.randn(N), \"float2\": np.random.randn(N)}, index=index\n        )\n        self.df_mixed = DataFrame(\n            {\n                \"float1\": np.random.randn(N),\n                \"float2\": np.random.randn(N),\n                \"string1\": [\"foo\"] * N,\n                \"bool1\": [True] * N,\n                \"int1\": np.random.randint(0, N, size=N),\n            },\n            index=index,\n        )\n        self.df_wide = DataFrame(np.random.randn(N, 100))\n        self.start_wide = self.df_wide.index[10000]\n        self.stop_wide = self.df_wide.index[15000]\n        self.df2 = DataFrame(\n            {\"float1\": np.random.randn(N), \"float2\": np.random.randn(N)},\n            index=date_range(\"1/1/2000\", periods=N),\n        )\n        self.start = self.df2.index[10000]\n        self.stop = self.df2.index[15000]\n        self.df_wide2 = DataFrame(\n            np.random.randn(N, 100), index=date_range(\"1/1/2000\", periods=N)\n        )\n        self.df_dc = DataFrame(\n            np.random.randn(N, 10), columns=[f\"C{i:03d}\" for i in range(10)]\n        )\n    \n        self.fname = \"__test__.h5\"\n    \n        self.store = HDFStore(self.fname)\n        self.store.put(\"fixed\", self.df)\n        self.store.put(\"fixed_mixed\", self.df_mixed)\n        self.store.append(\"table\", self.df2)\n        self.store.append(\"table_mixed\", self.df_mixed)\n        self.store.append(\"table_wide\", self.df_wide)\n        self.store.append(\"table_wide2\", self.df_wide2)", "min_run_count": 2, "name": "io.hdf.HDFStoreDataFrame.time_read_store_table_mixed", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "654b809e344f0e10c8a3baac21f45bab7ad0ee525970e4f37cc667bf431c09a9", "warmup_time": -1}, "io.hdf.HDFStoreDataFrame.time_read_store_table_wide": {"code": "class HDFStoreDataFrame:\n    def time_read_store_table_wide(self):\n        self.store.select(\"table_wide\")\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass HDFStoreDataFrame:\n    def setup(self):\n        N = 25000\n        index = Index([f\"i-{i}\" for i in range(N)], dtype=object)\n        self.df = DataFrame(\n            {\"float1\": np.random.randn(N), \"float2\": np.random.randn(N)}, index=index\n        )\n        self.df_mixed = DataFrame(\n            {\n                \"float1\": np.random.randn(N),\n                \"float2\": np.random.randn(N),\n                \"string1\": [\"foo\"] * N,\n                \"bool1\": [True] * N,\n                \"int1\": np.random.randint(0, N, size=N),\n            },\n            index=index,\n        )\n        self.df_wide = DataFrame(np.random.randn(N, 100))\n        self.start_wide = self.df_wide.index[10000]\n        self.stop_wide = self.df_wide.index[15000]\n        self.df2 = DataFrame(\n            {\"float1\": np.random.randn(N), \"float2\": np.random.randn(N)},\n            index=date_range(\"1/1/2000\", periods=N),\n        )\n        self.start = self.df2.index[10000]\n        self.stop = self.df2.index[15000]\n        self.df_wide2 = DataFrame(\n            np.random.randn(N, 100), index=date_range(\"1/1/2000\", periods=N)\n        )\n        self.df_dc = DataFrame(\n            np.random.randn(N, 10), columns=[f\"C{i:03d}\" for i in range(10)]\n        )\n    \n        self.fname = \"__test__.h5\"\n    \n        self.store = HDFStore(self.fname)\n        self.store.put(\"fixed\", self.df)\n        self.store.put(\"fixed_mixed\", self.df_mixed)\n        self.store.append(\"table\", self.df2)\n        self.store.append(\"table_mixed\", self.df_mixed)\n        self.store.append(\"table_wide\", self.df_wide)\n        self.store.append(\"table_wide2\", self.df_wide2)", "min_run_count": 2, "name": "io.hdf.HDFStoreDataFrame.time_read_store_table_wide", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "68e77ec6a80f61239b61938e5edcde665dcb40aabeecd31c67093d3e89dc0224", "warmup_time": -1}, "io.hdf.HDFStoreDataFrame.time_store_info": {"code": "class HDFStoreDataFrame:\n    def time_store_info(self):\n        self.store.info()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass HDFStoreDataFrame:\n    def setup(self):\n        N = 25000\n        index = Index([f\"i-{i}\" for i in range(N)], dtype=object)\n        self.df = DataFrame(\n            {\"float1\": np.random.randn(N), \"float2\": np.random.randn(N)}, index=index\n        )\n        self.df_mixed = DataFrame(\n            {\n                \"float1\": np.random.randn(N),\n                \"float2\": np.random.randn(N),\n                \"string1\": [\"foo\"] * N,\n                \"bool1\": [True] * N,\n                \"int1\": np.random.randint(0, N, size=N),\n            },\n            index=index,\n        )\n        self.df_wide = DataFrame(np.random.randn(N, 100))\n        self.start_wide = self.df_wide.index[10000]\n        self.stop_wide = self.df_wide.index[15000]\n        self.df2 = DataFrame(\n            {\"float1\": np.random.randn(N), \"float2\": np.random.randn(N)},\n            index=date_range(\"1/1/2000\", periods=N),\n        )\n        self.start = self.df2.index[10000]\n        self.stop = self.df2.index[15000]\n        self.df_wide2 = DataFrame(\n            np.random.randn(N, 100), index=date_range(\"1/1/2000\", periods=N)\n        )\n        self.df_dc = DataFrame(\n            np.random.randn(N, 10), columns=[f\"C{i:03d}\" for i in range(10)]\n        )\n    \n        self.fname = \"__test__.h5\"\n    \n        self.store = HDFStore(self.fname)\n        self.store.put(\"fixed\", self.df)\n        self.store.put(\"fixed_mixed\", self.df_mixed)\n        self.store.append(\"table\", self.df2)\n        self.store.append(\"table_mixed\", self.df_mixed)\n        self.store.append(\"table_wide\", self.df_wide)\n        self.store.append(\"table_wide2\", self.df_wide2)", "min_run_count": 2, "name": "io.hdf.HDFStoreDataFrame.time_store_info", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "49715b28d77dba64c85fec14ce3fe1d467fb262c9f60bdb37036c71df679a8dc", "warmup_time": -1}, "io.hdf.HDFStoreDataFrame.time_store_repr": {"code": "class HDFStoreDataFrame:\n    def time_store_repr(self):\n        repr(self.store)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass HDFStoreDataFrame:\n    def setup(self):\n        N = 25000\n        index = Index([f\"i-{i}\" for i in range(N)], dtype=object)\n        self.df = DataFrame(\n            {\"float1\": np.random.randn(N), \"float2\": np.random.randn(N)}, index=index\n        )\n        self.df_mixed = DataFrame(\n            {\n                \"float1\": np.random.randn(N),\n                \"float2\": np.random.randn(N),\n                \"string1\": [\"foo\"] * N,\n                \"bool1\": [True] * N,\n                \"int1\": np.random.randint(0, N, size=N),\n            },\n            index=index,\n        )\n        self.df_wide = DataFrame(np.random.randn(N, 100))\n        self.start_wide = self.df_wide.index[10000]\n        self.stop_wide = self.df_wide.index[15000]\n        self.df2 = DataFrame(\n            {\"float1\": np.random.randn(N), \"float2\": np.random.randn(N)},\n            index=date_range(\"1/1/2000\", periods=N),\n        )\n        self.start = self.df2.index[10000]\n        self.stop = self.df2.index[15000]\n        self.df_wide2 = DataFrame(\n            np.random.randn(N, 100), index=date_range(\"1/1/2000\", periods=N)\n        )\n        self.df_dc = DataFrame(\n            np.random.randn(N, 10), columns=[f\"C{i:03d}\" for i in range(10)]\n        )\n    \n        self.fname = \"__test__.h5\"\n    \n        self.store = HDFStore(self.fname)\n        self.store.put(\"fixed\", self.df)\n        self.store.put(\"fixed_mixed\", self.df_mixed)\n        self.store.append(\"table\", self.df2)\n        self.store.append(\"table_mixed\", self.df_mixed)\n        self.store.append(\"table_wide\", self.df_wide)\n        self.store.append(\"table_wide2\", self.df_wide2)", "min_run_count": 2, "name": "io.hdf.HDFStoreDataFrame.time_store_repr", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "56bf271ad7094e3cd93786522fded365bab13a2eb8463232c31dd7d346f35024", "warmup_time": -1}, "io.hdf.HDFStoreDataFrame.time_store_str": {"code": "class HDFStoreDataFrame:\n    def time_store_str(self):\n        str(self.store)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass HDFStoreDataFrame:\n    def setup(self):\n        N = 25000\n        index = Index([f\"i-{i}\" for i in range(N)], dtype=object)\n        self.df = DataFrame(\n            {\"float1\": np.random.randn(N), \"float2\": np.random.randn(N)}, index=index\n        )\n        self.df_mixed = DataFrame(\n            {\n                \"float1\": np.random.randn(N),\n                \"float2\": np.random.randn(N),\n                \"string1\": [\"foo\"] * N,\n                \"bool1\": [True] * N,\n                \"int1\": np.random.randint(0, N, size=N),\n            },\n            index=index,\n        )\n        self.df_wide = DataFrame(np.random.randn(N, 100))\n        self.start_wide = self.df_wide.index[10000]\n        self.stop_wide = self.df_wide.index[15000]\n        self.df2 = DataFrame(\n            {\"float1\": np.random.randn(N), \"float2\": np.random.randn(N)},\n            index=date_range(\"1/1/2000\", periods=N),\n        )\n        self.start = self.df2.index[10000]\n        self.stop = self.df2.index[15000]\n        self.df_wide2 = DataFrame(\n            np.random.randn(N, 100), index=date_range(\"1/1/2000\", periods=N)\n        )\n        self.df_dc = DataFrame(\n            np.random.randn(N, 10), columns=[f\"C{i:03d}\" for i in range(10)]\n        )\n    \n        self.fname = \"__test__.h5\"\n    \n        self.store = HDFStore(self.fname)\n        self.store.put(\"fixed\", self.df)\n        self.store.put(\"fixed_mixed\", self.df_mixed)\n        self.store.append(\"table\", self.df2)\n        self.store.append(\"table_mixed\", self.df_mixed)\n        self.store.append(\"table_wide\", self.df_wide)\n        self.store.append(\"table_wide2\", self.df_wide2)", "min_run_count": 2, "name": "io.hdf.HDFStoreDataFrame.time_store_str", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "d579449dfe09044c2900a1f5cbeaf78ea5bbedab0e10f8949912bc68b36591f0", "warmup_time": -1}, "io.hdf.HDFStoreDataFrame.time_write_store": {"code": "class HDFStoreDataFrame:\n    def time_write_store(self):\n        self.store.put(\"fixed_write\", self.df)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass HDFStoreDataFrame:\n    def setup(self):\n        N = 25000\n        index = Index([f\"i-{i}\" for i in range(N)], dtype=object)\n        self.df = DataFrame(\n            {\"float1\": np.random.randn(N), \"float2\": np.random.randn(N)}, index=index\n        )\n        self.df_mixed = DataFrame(\n            {\n                \"float1\": np.random.randn(N),\n                \"float2\": np.random.randn(N),\n                \"string1\": [\"foo\"] * N,\n                \"bool1\": [True] * N,\n                \"int1\": np.random.randint(0, N, size=N),\n            },\n            index=index,\n        )\n        self.df_wide = DataFrame(np.random.randn(N, 100))\n        self.start_wide = self.df_wide.index[10000]\n        self.stop_wide = self.df_wide.index[15000]\n        self.df2 = DataFrame(\n            {\"float1\": np.random.randn(N), \"float2\": np.random.randn(N)},\n            index=date_range(\"1/1/2000\", periods=N),\n        )\n        self.start = self.df2.index[10000]\n        self.stop = self.df2.index[15000]\n        self.df_wide2 = DataFrame(\n            np.random.randn(N, 100), index=date_range(\"1/1/2000\", periods=N)\n        )\n        self.df_dc = DataFrame(\n            np.random.randn(N, 10), columns=[f\"C{i:03d}\" for i in range(10)]\n        )\n    \n        self.fname = \"__test__.h5\"\n    \n        self.store = HDFStore(self.fname)\n        self.store.put(\"fixed\", self.df)\n        self.store.put(\"fixed_mixed\", self.df_mixed)\n        self.store.append(\"table\", self.df2)\n        self.store.append(\"table_mixed\", self.df_mixed)\n        self.store.append(\"table_wide\", self.df_wide)\n        self.store.append(\"table_wide2\", self.df_wide2)", "min_run_count": 2, "name": "io.hdf.HDFStoreDataFrame.time_write_store", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "ee8346e909168ac76078a6746c4bb841bbd325a8e9a633a593ba4e3be629591b", "warmup_time": -1}, "io.hdf.HDFStoreDataFrame.time_write_store_mixed": {"code": "class HDFStoreDataFrame:\n    def time_write_store_mixed(self):\n        self.store.put(\"fixed_mixed_write\", self.df_mixed)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass HDFStoreDataFrame:\n    def setup(self):\n        N = 25000\n        index = Index([f\"i-{i}\" for i in range(N)], dtype=object)\n        self.df = DataFrame(\n            {\"float1\": np.random.randn(N), \"float2\": np.random.randn(N)}, index=index\n        )\n        self.df_mixed = DataFrame(\n            {\n                \"float1\": np.random.randn(N),\n                \"float2\": np.random.randn(N),\n                \"string1\": [\"foo\"] * N,\n                \"bool1\": [True] * N,\n                \"int1\": np.random.randint(0, N, size=N),\n            },\n            index=index,\n        )\n        self.df_wide = DataFrame(np.random.randn(N, 100))\n        self.start_wide = self.df_wide.index[10000]\n        self.stop_wide = self.df_wide.index[15000]\n        self.df2 = DataFrame(\n            {\"float1\": np.random.randn(N), \"float2\": np.random.randn(N)},\n            index=date_range(\"1/1/2000\", periods=N),\n        )\n        self.start = self.df2.index[10000]\n        self.stop = self.df2.index[15000]\n        self.df_wide2 = DataFrame(\n            np.random.randn(N, 100), index=date_range(\"1/1/2000\", periods=N)\n        )\n        self.df_dc = DataFrame(\n            np.random.randn(N, 10), columns=[f\"C{i:03d}\" for i in range(10)]\n        )\n    \n        self.fname = \"__test__.h5\"\n    \n        self.store = HDFStore(self.fname)\n        self.store.put(\"fixed\", self.df)\n        self.store.put(\"fixed_mixed\", self.df_mixed)\n        self.store.append(\"table\", self.df2)\n        self.store.append(\"table_mixed\", self.df_mixed)\n        self.store.append(\"table_wide\", self.df_wide)\n        self.store.append(\"table_wide2\", self.df_wide2)", "min_run_count": 2, "name": "io.hdf.HDFStoreDataFrame.time_write_store_mixed", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "d9a86e316a21f2f06f6a5510d44c49901d77f3ff3e328dc05884b09657635842", "warmup_time": -1}, "io.hdf.HDFStoreDataFrame.time_write_store_table": {"code": "class HDFStoreDataFrame:\n    def time_write_store_table(self):\n        self.store.append(\"table_write\", self.df)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass HDFStoreDataFrame:\n    def setup(self):\n        N = 25000\n        index = Index([f\"i-{i}\" for i in range(N)], dtype=object)\n        self.df = DataFrame(\n            {\"float1\": np.random.randn(N), \"float2\": np.random.randn(N)}, index=index\n        )\n        self.df_mixed = DataFrame(\n            {\n                \"float1\": np.random.randn(N),\n                \"float2\": np.random.randn(N),\n                \"string1\": [\"foo\"] * N,\n                \"bool1\": [True] * N,\n                \"int1\": np.random.randint(0, N, size=N),\n            },\n            index=index,\n        )\n        self.df_wide = DataFrame(np.random.randn(N, 100))\n        self.start_wide = self.df_wide.index[10000]\n        self.stop_wide = self.df_wide.index[15000]\n        self.df2 = DataFrame(\n            {\"float1\": np.random.randn(N), \"float2\": np.random.randn(N)},\n            index=date_range(\"1/1/2000\", periods=N),\n        )\n        self.start = self.df2.index[10000]\n        self.stop = self.df2.index[15000]\n        self.df_wide2 = DataFrame(\n            np.random.randn(N, 100), index=date_range(\"1/1/2000\", periods=N)\n        )\n        self.df_dc = DataFrame(\n            np.random.randn(N, 10), columns=[f\"C{i:03d}\" for i in range(10)]\n        )\n    \n        self.fname = \"__test__.h5\"\n    \n        self.store = HDFStore(self.fname)\n        self.store.put(\"fixed\", self.df)\n        self.store.put(\"fixed_mixed\", self.df_mixed)\n        self.store.append(\"table\", self.df2)\n        self.store.append(\"table_mixed\", self.df_mixed)\n        self.store.append(\"table_wide\", self.df_wide)\n        self.store.append(\"table_wide2\", self.df_wide2)", "min_run_count": 2, "name": "io.hdf.HDFStoreDataFrame.time_write_store_table", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "d47058fa561771efea619eea183eab7a6d5b7802df94c96d7e940bb000111118", "warmup_time": -1}, "io.hdf.HDFStoreDataFrame.time_write_store_table_dc": {"code": "class HDFStoreDataFrame:\n    def time_write_store_table_dc(self):\n        self.store.append(\"table_dc_write\", self.df_dc, data_columns=True)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass HDFStoreDataFrame:\n    def setup(self):\n        N = 25000\n        index = Index([f\"i-{i}\" for i in range(N)], dtype=object)\n        self.df = DataFrame(\n            {\"float1\": np.random.randn(N), \"float2\": np.random.randn(N)}, index=index\n        )\n        self.df_mixed = DataFrame(\n            {\n                \"float1\": np.random.randn(N),\n                \"float2\": np.random.randn(N),\n                \"string1\": [\"foo\"] * N,\n                \"bool1\": [True] * N,\n                \"int1\": np.random.randint(0, N, size=N),\n            },\n            index=index,\n        )\n        self.df_wide = DataFrame(np.random.randn(N, 100))\n        self.start_wide = self.df_wide.index[10000]\n        self.stop_wide = self.df_wide.index[15000]\n        self.df2 = DataFrame(\n            {\"float1\": np.random.randn(N), \"float2\": np.random.randn(N)},\n            index=date_range(\"1/1/2000\", periods=N),\n        )\n        self.start = self.df2.index[10000]\n        self.stop = self.df2.index[15000]\n        self.df_wide2 = DataFrame(\n            np.random.randn(N, 100), index=date_range(\"1/1/2000\", periods=N)\n        )\n        self.df_dc = DataFrame(\n            np.random.randn(N, 10), columns=[f\"C{i:03d}\" for i in range(10)]\n        )\n    \n        self.fname = \"__test__.h5\"\n    \n        self.store = HDFStore(self.fname)\n        self.store.put(\"fixed\", self.df)\n        self.store.put(\"fixed_mixed\", self.df_mixed)\n        self.store.append(\"table\", self.df2)\n        self.store.append(\"table_mixed\", self.df_mixed)\n        self.store.append(\"table_wide\", self.df_wide)\n        self.store.append(\"table_wide2\", self.df_wide2)", "min_run_count": 2, "name": "io.hdf.HDFStoreDataFrame.time_write_store_table_dc", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "3835d70e0f39619d661465373c95f90fdcb126a771138196ed2761ef7b7a8bcd", "warmup_time": -1}, "io.hdf.HDFStoreDataFrame.time_write_store_table_mixed": {"code": "class HDFStoreDataFrame:\n    def time_write_store_table_mixed(self):\n        self.store.append(\"table_mixed_write\", self.df_mixed)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass HDFStoreDataFrame:\n    def setup(self):\n        N = 25000\n        index = Index([f\"i-{i}\" for i in range(N)], dtype=object)\n        self.df = DataFrame(\n            {\"float1\": np.random.randn(N), \"float2\": np.random.randn(N)}, index=index\n        )\n        self.df_mixed = DataFrame(\n            {\n                \"float1\": np.random.randn(N),\n                \"float2\": np.random.randn(N),\n                \"string1\": [\"foo\"] * N,\n                \"bool1\": [True] * N,\n                \"int1\": np.random.randint(0, N, size=N),\n            },\n            index=index,\n        )\n        self.df_wide = DataFrame(np.random.randn(N, 100))\n        self.start_wide = self.df_wide.index[10000]\n        self.stop_wide = self.df_wide.index[15000]\n        self.df2 = DataFrame(\n            {\"float1\": np.random.randn(N), \"float2\": np.random.randn(N)},\n            index=date_range(\"1/1/2000\", periods=N),\n        )\n        self.start = self.df2.index[10000]\n        self.stop = self.df2.index[15000]\n        self.df_wide2 = DataFrame(\n            np.random.randn(N, 100), index=date_range(\"1/1/2000\", periods=N)\n        )\n        self.df_dc = DataFrame(\n            np.random.randn(N, 10), columns=[f\"C{i:03d}\" for i in range(10)]\n        )\n    \n        self.fname = \"__test__.h5\"\n    \n        self.store = HDFStore(self.fname)\n        self.store.put(\"fixed\", self.df)\n        self.store.put(\"fixed_mixed\", self.df_mixed)\n        self.store.append(\"table\", self.df2)\n        self.store.append(\"table_mixed\", self.df_mixed)\n        self.store.append(\"table_wide\", self.df_wide)\n        self.store.append(\"table_wide2\", self.df_wide2)", "min_run_count": 2, "name": "io.hdf.HDFStoreDataFrame.time_write_store_table_mixed", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "cfc399c3925c502380baf60452f942cc9fccdc9f9fe9a3d13c6bc9f9bc06b710", "warmup_time": -1}, "io.hdf.HDFStoreDataFrame.time_write_store_table_wide": {"code": "class HDFStoreDataFrame:\n    def time_write_store_table_wide(self):\n        self.store.append(\"table_wide_write\", self.df_wide)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass HDFStoreDataFrame:\n    def setup(self):\n        N = 25000\n        index = Index([f\"i-{i}\" for i in range(N)], dtype=object)\n        self.df = DataFrame(\n            {\"float1\": np.random.randn(N), \"float2\": np.random.randn(N)}, index=index\n        )\n        self.df_mixed = DataFrame(\n            {\n                \"float1\": np.random.randn(N),\n                \"float2\": np.random.randn(N),\n                \"string1\": [\"foo\"] * N,\n                \"bool1\": [True] * N,\n                \"int1\": np.random.randint(0, N, size=N),\n            },\n            index=index,\n        )\n        self.df_wide = DataFrame(np.random.randn(N, 100))\n        self.start_wide = self.df_wide.index[10000]\n        self.stop_wide = self.df_wide.index[15000]\n        self.df2 = DataFrame(\n            {\"float1\": np.random.randn(N), \"float2\": np.random.randn(N)},\n            index=date_range(\"1/1/2000\", periods=N),\n        )\n        self.start = self.df2.index[10000]\n        self.stop = self.df2.index[15000]\n        self.df_wide2 = DataFrame(\n            np.random.randn(N, 100), index=date_range(\"1/1/2000\", periods=N)\n        )\n        self.df_dc = DataFrame(\n            np.random.randn(N, 10), columns=[f\"C{i:03d}\" for i in range(10)]\n        )\n    \n        self.fname = \"__test__.h5\"\n    \n        self.store = HDFStore(self.fname)\n        self.store.put(\"fixed\", self.df)\n        self.store.put(\"fixed_mixed\", self.df_mixed)\n        self.store.append(\"table\", self.df2)\n        self.store.append(\"table_mixed\", self.df_mixed)\n        self.store.append(\"table_wide\", self.df_wide)\n        self.store.append(\"table_wide2\", self.df_wide2)", "min_run_count": 2, "name": "io.hdf.HDFStoreDataFrame.time_write_store_table_wide", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "d4ab189fff466312714744b38e13c09f0a3eb767a53878d0309b322701e5ab04", "warmup_time": -1}, "io.json.NormalizeJSON.time_normalize_json": {"code": "class NormalizeJSON:\n    def time_normalize_json(self, orient, frame):\n        json_normalize(self.data)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass NormalizeJSON:\n    def setup(self, orient, frame):\n        data = {\n            \"hello\": [\"thisisatest\", 999898, \"mixed types\"],\n            \"nest1\": {\"nest2\": {\"nest3\": \"nest3_value\", \"nest3_int\": 3445}},\n            \"nest1_list\": {\"nest2\": [\"blah\", 32423, 546456.876, 92030234]},\n            \"hello2\": \"string\",\n        }\n        self.data = [data for i in range(10000)]", "min_run_count": 2, "name": "io.json.NormalizeJSON.time_normalize_json", "number": 0, "param_names": ["orient", "frame"], "params": [["'split'", "'columns'", "'index'", "'values'", "'records'"], ["'df'", "'df_date_idx'", "'df_td_int_ts'", "'df_int_floats'", "'df_int_float_str'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "318fc7d7f7bff26fc7a49a190be4dc0e2690469149e9fda19e3a8074d89cde6c", "warmup_time": -1}, "io.json.ReadJSON.time_read_json": {"code": "class ReadJSON:\n    def time_read_json(self, orient, index):\n        read_json(self.fname, orient=orient)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ReadJSON:\n    def setup(self, orient, index):\n        N = 100000\n        indexes = {\n            \"int\": np.arange(N),\n            \"datetime\": date_range(\"20000101\", periods=N, freq=\"h\"),\n        }\n        df = DataFrame(\n            np.random.randn(N, 5),\n            columns=[f\"float_{i}\" for i in range(5)],\n            index=indexes[index],\n        )\n        df.to_json(self.fname, orient=orient)", "min_run_count": 2, "name": "io.json.ReadJSON.time_read_json", "number": 0, "param_names": ["orient", "index"], "params": [["'split'", "'index'", "'records'"], ["'int'", "'datetime'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "060ff02601813d99dcb85d35f2248cc6d5ee446b65bd53e44b8047fbff44c093", "warmup_time": -1}, "io.json.ReadJSONLines.peakmem_read_json_lines": {"code": "class ReadJSONLines:\n    def peakmem_read_json_lines(self, index):\n        read_json(self.fname, orient=\"records\", lines=True)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ReadJSONLines:\n    def setup(self, index):\n        N = 100000\n        indexes = {\n            \"int\": np.arange(N),\n            \"datetime\": date_range(\"20000101\", periods=N, freq=\"h\"),\n        }\n        df = DataFrame(\n            np.random.randn(N, 5),\n            columns=[f\"float_{i}\" for i in range(5)],\n            index=indexes[index],\n        )\n        df.to_json(self.fname, orient=\"records\", lines=True)", "name": "io.json.ReadJSONLines.peakmem_read_json_lines", "param_names": ["index"], "params": [["'int'", "'datetime'"]], "timeout": 60.0, "type": "peakmemory", "unit": "bytes", "version": "453a39b717c84b10924b6c7381d2d4ac3ca4b6b34daf8038481adc4c63b37684"}, "io.json.ReadJSONLines.peakmem_read_json_lines_concat": {"code": "class ReadJSONLines:\n    def peakmem_read_json_lines_concat(self, index):\n        concat(read_json(self.fname, orient=\"records\", lines=True, chunksize=25000))\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ReadJSONLines:\n    def setup(self, index):\n        N = 100000\n        indexes = {\n            \"int\": np.arange(N),\n            \"datetime\": date_range(\"20000101\", periods=N, freq=\"h\"),\n        }\n        df = DataFrame(\n            np.random.randn(N, 5),\n            columns=[f\"float_{i}\" for i in range(5)],\n            index=indexes[index],\n        )\n        df.to_json(self.fname, orient=\"records\", lines=True)", "name": "io.json.ReadJSONLines.peakmem_read_json_lines_concat", "param_names": ["index"], "params": [["'int'", "'datetime'"]], "timeout": 60.0, "type": "peakmemory", "unit": "bytes", "version": "8ae93d7aa059d6ca9dbd26187d6b3782176449620b47b2e321dd8f4d891393f3"}, "io.json.ReadJSONLines.peakmem_read_json_lines_nrows": {"code": "class ReadJSONLines:\n    def peakmem_read_json_lines_nrows(self, index):\n        read_json(self.fname, orient=\"records\", lines=True, nrows=15000)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ReadJSONLines:\n    def setup(self, index):\n        N = 100000\n        indexes = {\n            \"int\": np.arange(N),\n            \"datetime\": date_range(\"20000101\", periods=N, freq=\"h\"),\n        }\n        df = DataFrame(\n            np.random.randn(N, 5),\n            columns=[f\"float_{i}\" for i in range(5)],\n            index=indexes[index],\n        )\n        df.to_json(self.fname, orient=\"records\", lines=True)", "name": "io.json.ReadJSONLines.peakmem_read_json_lines_nrows", "param_names": ["index"], "params": [["'int'", "'datetime'"]], "timeout": 60.0, "type": "peakmemory", "unit": "bytes", "version": "ac250f3377bcd575593ac2b371b4c45a47c3ba22cf6904c83289edccf77211ae"}, "io.json.ReadJSONLines.time_read_json_lines": {"code": "class ReadJSONLines:\n    def time_read_json_lines(self, index):\n        read_json(self.fname, orient=\"records\", lines=True)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ReadJSONLines:\n    def setup(self, index):\n        N = 100000\n        indexes = {\n            \"int\": np.arange(N),\n            \"datetime\": date_range(\"20000101\", periods=N, freq=\"h\"),\n        }\n        df = DataFrame(\n            np.random.randn(N, 5),\n            columns=[f\"float_{i}\" for i in range(5)],\n            index=indexes[index],\n        )\n        df.to_json(self.fname, orient=\"records\", lines=True)", "min_run_count": 2, "name": "io.json.ReadJSONLines.time_read_json_lines", "number": 0, "param_names": ["index"], "params": [["'int'", "'datetime'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "279f192d538915c094d4ea8ba8b0fd1ef396291dafe6751c31424148be445ad6", "warmup_time": -1}, "io.json.ReadJSONLines.time_read_json_lines_concat": {"code": "class ReadJSONLines:\n    def time_read_json_lines_concat(self, index):\n        concat(read_json(self.fname, orient=\"records\", lines=True, chunksize=25000))\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ReadJSONLines:\n    def setup(self, index):\n        N = 100000\n        indexes = {\n            \"int\": np.arange(N),\n            \"datetime\": date_range(\"20000101\", periods=N, freq=\"h\"),\n        }\n        df = DataFrame(\n            np.random.randn(N, 5),\n            columns=[f\"float_{i}\" for i in range(5)],\n            index=indexes[index],\n        )\n        df.to_json(self.fname, orient=\"records\", lines=True)", "min_run_count": 2, "name": "io.json.ReadJSONLines.time_read_json_lines_concat", "number": 0, "param_names": ["index"], "params": [["'int'", "'datetime'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "777bcd588c46f7ee722bd31443ac6db78bd8e01de64a0d7e4a09b0f778b1319f", "warmup_time": -1}, "io.json.ReadJSONLines.time_read_json_lines_nrows": {"code": "class ReadJSONLines:\n    def time_read_json_lines_nrows(self, index):\n        read_json(self.fname, orient=\"records\", lines=True, nrows=25000)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ReadJSONLines:\n    def setup(self, index):\n        N = 100000\n        indexes = {\n            \"int\": np.arange(N),\n            \"datetime\": date_range(\"20000101\", periods=N, freq=\"h\"),\n        }\n        df = DataFrame(\n            np.random.randn(N, 5),\n            columns=[f\"float_{i}\" for i in range(5)],\n            index=indexes[index],\n        )\n        df.to_json(self.fname, orient=\"records\", lines=True)", "min_run_count": 2, "name": "io.json.ReadJSONLines.time_read_json_lines_nrows", "number": 0, "param_names": ["index"], "params": [["'int'", "'datetime'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "7f3ac492e006023c74a0a50408cf85b315c2115bbd11ea92acc78c6cc2af2385", "warmup_time": -1}, "io.json.ToJSON.peakmem_to_json": {"code": "class ToJSON:\n    def peakmem_to_json(self, orient, frame):\n        getattr(self, frame).to_json(self.fname, orient=orient)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToJSON:\n    def setup(self, orient, frame):\n        N = 10**5\n        ncols = 5\n        index = date_range(\"20000101\", periods=N, freq=\"h\")\n        timedeltas = timedelta_range(start=1, periods=N, freq=\"s\")\n        datetimes = date_range(start=1, periods=N, freq=\"s\")\n        ints = np.random.randint(100000000, size=N)\n        longints = sys.maxsize * np.random.randint(100000000, size=N)\n        floats = np.random.randn(N)\n        strings = Index([f\"i-{i}\" for i in range(N)], dtype=object)\n        self.df = DataFrame(np.random.randn(N, ncols), index=np.arange(N))\n        self.df_date_idx = DataFrame(np.random.randn(N, ncols), index=index)\n        self.df_td_int_ts = DataFrame(\n            {\n                \"td_1\": timedeltas,\n                \"td_2\": timedeltas,\n                \"int_1\": ints,\n                \"int_2\": ints,\n                \"ts_1\": datetimes,\n                \"ts_2\": datetimes,\n            },\n            index=index,\n        )\n        self.df_int_floats = DataFrame(\n            {\n                \"int_1\": ints,\n                \"int_2\": ints,\n                \"int_3\": ints,\n                \"float_1\": floats,\n                \"float_2\": floats,\n                \"float_3\": floats,\n            },\n            index=index,\n        )\n        self.df_int_float_str = DataFrame(\n            {\n                \"int_1\": ints,\n                \"int_2\": ints,\n                \"float_1\": floats,\n                \"float_2\": floats,\n                \"str_1\": strings,\n                \"str_2\": strings,\n            },\n            index=index,\n        )\n    \n        self.df_longint_float_str = DataFrame(\n            {\n                \"longint_1\": longints,\n                \"longint_2\": longints,\n                \"float_1\": floats,\n                \"float_2\": floats,\n                \"str_1\": strings,\n                \"str_2\": strings,\n            },\n            index=index,\n        )", "name": "io.json.ToJSON.peakmem_to_json", "param_names": ["orient", "frame"], "params": [["'split'", "'columns'", "'index'", "'values'", "'records'"], ["'df'", "'df_date_idx'", "'df_td_int_ts'", "'df_int_floats'", "'df_int_float_str'"]], "timeout": 60.0, "type": "peakmemory", "unit": "bytes", "version": "87eb3ebd846df1b3f04989da149647f27085e365975bb82ce1a093db9bac8f5b"}, "io.json.ToJSON.time_to_json": {"code": "class ToJSON:\n    def time_to_json(self, orient, frame):\n        getattr(self, frame).to_json(self.fname, orient=orient)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToJSON:\n    def setup(self, orient, frame):\n        N = 10**5\n        ncols = 5\n        index = date_range(\"20000101\", periods=N, freq=\"h\")\n        timedeltas = timedelta_range(start=1, periods=N, freq=\"s\")\n        datetimes = date_range(start=1, periods=N, freq=\"s\")\n        ints = np.random.randint(100000000, size=N)\n        longints = sys.maxsize * np.random.randint(100000000, size=N)\n        floats = np.random.randn(N)\n        strings = Index([f\"i-{i}\" for i in range(N)], dtype=object)\n        self.df = DataFrame(np.random.randn(N, ncols), index=np.arange(N))\n        self.df_date_idx = DataFrame(np.random.randn(N, ncols), index=index)\n        self.df_td_int_ts = DataFrame(\n            {\n                \"td_1\": timedeltas,\n                \"td_2\": timedeltas,\n                \"int_1\": ints,\n                \"int_2\": ints,\n                \"ts_1\": datetimes,\n                \"ts_2\": datetimes,\n            },\n            index=index,\n        )\n        self.df_int_floats = DataFrame(\n            {\n                \"int_1\": ints,\n                \"int_2\": ints,\n                \"int_3\": ints,\n                \"float_1\": floats,\n                \"float_2\": floats,\n                \"float_3\": floats,\n            },\n            index=index,\n        )\n        self.df_int_float_str = DataFrame(\n            {\n                \"int_1\": ints,\n                \"int_2\": ints,\n                \"float_1\": floats,\n                \"float_2\": floats,\n                \"str_1\": strings,\n                \"str_2\": strings,\n            },\n            index=index,\n        )\n    \n        self.df_longint_float_str = DataFrame(\n            {\n                \"longint_1\": longints,\n                \"longint_2\": longints,\n                \"float_1\": floats,\n                \"float_2\": floats,\n                \"str_1\": strings,\n                \"str_2\": strings,\n            },\n            index=index,\n        )", "min_run_count": 2, "name": "io.json.ToJSON.time_to_json", "number": 0, "param_names": ["orient", "frame"], "params": [["'split'", "'columns'", "'index'", "'values'", "'records'"], ["'df'", "'df_date_idx'", "'df_td_int_ts'", "'df_int_floats'", "'df_int_float_str'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "9c17efa9080b8d5102c0beaef576f498ed86d1fe6e4fba86df65a39335f72728", "warmup_time": -1}, "io.json.ToJSONISO.time_iso_format": {"code": "class ToJSONISO:\n    def time_iso_format(self, orient):\n        self.df.to_json(orient=orient, date_format=\"iso\")\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToJSONISO:\n    def setup(self, orient):\n        N = 10**5\n        index = date_range(\"20000101\", periods=N, freq=\"h\")\n        timedeltas = timedelta_range(start=1, periods=N, freq=\"s\")\n        datetimes = date_range(start=1, periods=N, freq=\"s\")\n        self.df = DataFrame(\n            {\n                \"td_1\": timedeltas,\n                \"td_2\": timedeltas,\n                \"ts_1\": datetimes,\n                \"ts_2\": datetimes,\n            },\n            index=index,\n        )", "min_run_count": 2, "name": "io.json.ToJSONISO.time_iso_format", "number": 0, "param_names": ["orient"], "params": [["'split'", "'columns'", "'index'", "'values'", "'records'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "de31091c8c9695232ad7a580672fe1150d42e0e74f06119dbe4a85b76c1e6c4a", "warmup_time": -1}, "io.json.ToJSONLines.time_delta_int_tstamp_lines": {"code": "class ToJSONLines:\n    def time_delta_int_tstamp_lines(self):\n        self.df_td_int_ts.to_json(self.fname, orient=\"records\", lines=True)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToJSONLines:\n    def setup(self):\n        N = 10**5\n        ncols = 5\n        index = date_range(\"20000101\", periods=N, freq=\"h\")\n        timedeltas = timedelta_range(start=1, periods=N, freq=\"s\")\n        datetimes = date_range(start=1, periods=N, freq=\"s\")\n        ints = np.random.randint(100000000, size=N)\n        longints = sys.maxsize * np.random.randint(100000000, size=N)\n        floats = np.random.randn(N)\n        strings = Index([f\"i-{i}\" for i in range(N)], dtype=object)\n        self.df = DataFrame(np.random.randn(N, ncols), index=np.arange(N))\n        self.df_date_idx = DataFrame(np.random.randn(N, ncols), index=index)\n        self.df_td_int_ts = DataFrame(\n            {\n                \"td_1\": timedeltas,\n                \"td_2\": timedeltas,\n                \"int_1\": ints,\n                \"int_2\": ints,\n                \"ts_1\": datetimes,\n                \"ts_2\": datetimes,\n            },\n            index=index,\n        )\n        self.df_int_floats = DataFrame(\n            {\n                \"int_1\": ints,\n                \"int_2\": ints,\n                \"int_3\": ints,\n                \"float_1\": floats,\n                \"float_2\": floats,\n                \"float_3\": floats,\n            },\n            index=index,\n        )\n        self.df_int_float_str = DataFrame(\n            {\n                \"int_1\": ints,\n                \"int_2\": ints,\n                \"float_1\": floats,\n                \"float_2\": floats,\n                \"str_1\": strings,\n                \"str_2\": strings,\n            },\n            index=index,\n        )\n        self.df_longint_float_str = DataFrame(\n            {\n                \"longint_1\": longints,\n                \"longint_2\": longints,\n                \"float_1\": floats,\n                \"float_2\": floats,\n                \"str_1\": strings,\n                \"str_2\": strings,\n            },\n            index=index,\n        )", "min_run_count": 2, "name": "io.json.ToJSONLines.time_delta_int_tstamp_lines", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "7a68f6c940cbfe5b7a9d9027dbcf1d2f2156232603726e0c67f7c89c756638fa", "warmup_time": -1}, "io.json.ToJSONLines.time_float_int_lines": {"code": "class ToJSONLines:\n    def time_float_int_lines(self):\n        self.df_int_floats.to_json(self.fname, orient=\"records\", lines=True)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToJSONLines:\n    def setup(self):\n        N = 10**5\n        ncols = 5\n        index = date_range(\"20000101\", periods=N, freq=\"h\")\n        timedeltas = timedelta_range(start=1, periods=N, freq=\"s\")\n        datetimes = date_range(start=1, periods=N, freq=\"s\")\n        ints = np.random.randint(100000000, size=N)\n        longints = sys.maxsize * np.random.randint(100000000, size=N)\n        floats = np.random.randn(N)\n        strings = Index([f\"i-{i}\" for i in range(N)], dtype=object)\n        self.df = DataFrame(np.random.randn(N, ncols), index=np.arange(N))\n        self.df_date_idx = DataFrame(np.random.randn(N, ncols), index=index)\n        self.df_td_int_ts = DataFrame(\n            {\n                \"td_1\": timedeltas,\n                \"td_2\": timedeltas,\n                \"int_1\": ints,\n                \"int_2\": ints,\n                \"ts_1\": datetimes,\n                \"ts_2\": datetimes,\n            },\n            index=index,\n        )\n        self.df_int_floats = DataFrame(\n            {\n                \"int_1\": ints,\n                \"int_2\": ints,\n                \"int_3\": ints,\n                \"float_1\": floats,\n                \"float_2\": floats,\n                \"float_3\": floats,\n            },\n            index=index,\n        )\n        self.df_int_float_str = DataFrame(\n            {\n                \"int_1\": ints,\n                \"int_2\": ints,\n                \"float_1\": floats,\n                \"float_2\": floats,\n                \"str_1\": strings,\n                \"str_2\": strings,\n            },\n            index=index,\n        )\n        self.df_longint_float_str = DataFrame(\n            {\n                \"longint_1\": longints,\n                \"longint_2\": longints,\n                \"float_1\": floats,\n                \"float_2\": floats,\n                \"str_1\": strings,\n                \"str_2\": strings,\n            },\n            index=index,\n        )", "min_run_count": 2, "name": "io.json.ToJSONLines.time_float_int_lines", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "e13146fb82a5dad2ab3bd80cf8af40ebd2cd8d8cbae32a4d4ec10a5dfe13d0ec", "warmup_time": -1}, "io.json.ToJSONLines.time_float_int_str_lines": {"code": "class ToJSONLines:\n    def time_float_int_str_lines(self):\n        self.df_int_float_str.to_json(self.fname, orient=\"records\", lines=True)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToJSONLines:\n    def setup(self):\n        N = 10**5\n        ncols = 5\n        index = date_range(\"20000101\", periods=N, freq=\"h\")\n        timedeltas = timedelta_range(start=1, periods=N, freq=\"s\")\n        datetimes = date_range(start=1, periods=N, freq=\"s\")\n        ints = np.random.randint(100000000, size=N)\n        longints = sys.maxsize * np.random.randint(100000000, size=N)\n        floats = np.random.randn(N)\n        strings = Index([f\"i-{i}\" for i in range(N)], dtype=object)\n        self.df = DataFrame(np.random.randn(N, ncols), index=np.arange(N))\n        self.df_date_idx = DataFrame(np.random.randn(N, ncols), index=index)\n        self.df_td_int_ts = DataFrame(\n            {\n                \"td_1\": timedeltas,\n                \"td_2\": timedeltas,\n                \"int_1\": ints,\n                \"int_2\": ints,\n                \"ts_1\": datetimes,\n                \"ts_2\": datetimes,\n            },\n            index=index,\n        )\n        self.df_int_floats = DataFrame(\n            {\n                \"int_1\": ints,\n                \"int_2\": ints,\n                \"int_3\": ints,\n                \"float_1\": floats,\n                \"float_2\": floats,\n                \"float_3\": floats,\n            },\n            index=index,\n        )\n        self.df_int_float_str = DataFrame(\n            {\n                \"int_1\": ints,\n                \"int_2\": ints,\n                \"float_1\": floats,\n                \"float_2\": floats,\n                \"str_1\": strings,\n                \"str_2\": strings,\n            },\n            index=index,\n        )\n        self.df_longint_float_str = DataFrame(\n            {\n                \"longint_1\": longints,\n                \"longint_2\": longints,\n                \"float_1\": floats,\n                \"float_2\": floats,\n                \"str_1\": strings,\n                \"str_2\": strings,\n            },\n            index=index,\n        )", "min_run_count": 2, "name": "io.json.ToJSONLines.time_float_int_str_lines", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "1517c8c4bbfff332b785506b826f50dcfad142f899a967b7afafdc636cd64789", "warmup_time": -1}, "io.json.ToJSONLines.time_float_longint_str_lines": {"code": "class ToJSONLines:\n    def time_float_longint_str_lines(self):\n        self.df_longint_float_str.to_json(self.fname, orient=\"records\", lines=True)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToJSONLines:\n    def setup(self):\n        N = 10**5\n        ncols = 5\n        index = date_range(\"20000101\", periods=N, freq=\"h\")\n        timedeltas = timedelta_range(start=1, periods=N, freq=\"s\")\n        datetimes = date_range(start=1, periods=N, freq=\"s\")\n        ints = np.random.randint(100000000, size=N)\n        longints = sys.maxsize * np.random.randint(100000000, size=N)\n        floats = np.random.randn(N)\n        strings = Index([f\"i-{i}\" for i in range(N)], dtype=object)\n        self.df = DataFrame(np.random.randn(N, ncols), index=np.arange(N))\n        self.df_date_idx = DataFrame(np.random.randn(N, ncols), index=index)\n        self.df_td_int_ts = DataFrame(\n            {\n                \"td_1\": timedeltas,\n                \"td_2\": timedeltas,\n                \"int_1\": ints,\n                \"int_2\": ints,\n                \"ts_1\": datetimes,\n                \"ts_2\": datetimes,\n            },\n            index=index,\n        )\n        self.df_int_floats = DataFrame(\n            {\n                \"int_1\": ints,\n                \"int_2\": ints,\n                \"int_3\": ints,\n                \"float_1\": floats,\n                \"float_2\": floats,\n                \"float_3\": floats,\n            },\n            index=index,\n        )\n        self.df_int_float_str = DataFrame(\n            {\n                \"int_1\": ints,\n                \"int_2\": ints,\n                \"float_1\": floats,\n                \"float_2\": floats,\n                \"str_1\": strings,\n                \"str_2\": strings,\n            },\n            index=index,\n        )\n        self.df_longint_float_str = DataFrame(\n            {\n                \"longint_1\": longints,\n                \"longint_2\": longints,\n                \"float_1\": floats,\n                \"float_2\": floats,\n                \"str_1\": strings,\n                \"str_2\": strings,\n            },\n            index=index,\n        )", "min_run_count": 2, "name": "io.json.ToJSONLines.time_float_longint_str_lines", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "5a0cc00815b32129927ef8c2875f9c5597779d59ef8b197ab9020ad5aea6df17", "warmup_time": -1}, "io.json.ToJSONLines.time_floats_with_dt_index_lines": {"code": "class ToJSONLines:\n    def time_floats_with_dt_index_lines(self):\n        self.df_date_idx.to_json(self.fname, orient=\"records\", lines=True)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToJSONLines:\n    def setup(self):\n        N = 10**5\n        ncols = 5\n        index = date_range(\"20000101\", periods=N, freq=\"h\")\n        timedeltas = timedelta_range(start=1, periods=N, freq=\"s\")\n        datetimes = date_range(start=1, periods=N, freq=\"s\")\n        ints = np.random.randint(100000000, size=N)\n        longints = sys.maxsize * np.random.randint(100000000, size=N)\n        floats = np.random.randn(N)\n        strings = Index([f\"i-{i}\" for i in range(N)], dtype=object)\n        self.df = DataFrame(np.random.randn(N, ncols), index=np.arange(N))\n        self.df_date_idx = DataFrame(np.random.randn(N, ncols), index=index)\n        self.df_td_int_ts = DataFrame(\n            {\n                \"td_1\": timedeltas,\n                \"td_2\": timedeltas,\n                \"int_1\": ints,\n                \"int_2\": ints,\n                \"ts_1\": datetimes,\n                \"ts_2\": datetimes,\n            },\n            index=index,\n        )\n        self.df_int_floats = DataFrame(\n            {\n                \"int_1\": ints,\n                \"int_2\": ints,\n                \"int_3\": ints,\n                \"float_1\": floats,\n                \"float_2\": floats,\n                \"float_3\": floats,\n            },\n            index=index,\n        )\n        self.df_int_float_str = DataFrame(\n            {\n                \"int_1\": ints,\n                \"int_2\": ints,\n                \"float_1\": floats,\n                \"float_2\": floats,\n                \"str_1\": strings,\n                \"str_2\": strings,\n            },\n            index=index,\n        )\n        self.df_longint_float_str = DataFrame(\n            {\n                \"longint_1\": longints,\n                \"longint_2\": longints,\n                \"float_1\": floats,\n                \"float_2\": floats,\n                \"str_1\": strings,\n                \"str_2\": strings,\n            },\n            index=index,\n        )", "min_run_count": 2, "name": "io.json.ToJSONLines.time_floats_with_dt_index_lines", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "2414d07086e041907667e8b1ba53fa8258be5e0ae02f44cba6c71675e8e82d90", "warmup_time": -1}, "io.json.ToJSONLines.time_floats_with_int_idex_lines": {"code": "class ToJSONLines:\n    def time_floats_with_int_idex_lines(self):\n        self.df.to_json(self.fname, orient=\"records\", lines=True)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToJSONLines:\n    def setup(self):\n        N = 10**5\n        ncols = 5\n        index = date_range(\"20000101\", periods=N, freq=\"h\")\n        timedeltas = timedelta_range(start=1, periods=N, freq=\"s\")\n        datetimes = date_range(start=1, periods=N, freq=\"s\")\n        ints = np.random.randint(100000000, size=N)\n        longints = sys.maxsize * np.random.randint(100000000, size=N)\n        floats = np.random.randn(N)\n        strings = Index([f\"i-{i}\" for i in range(N)], dtype=object)\n        self.df = DataFrame(np.random.randn(N, ncols), index=np.arange(N))\n        self.df_date_idx = DataFrame(np.random.randn(N, ncols), index=index)\n        self.df_td_int_ts = DataFrame(\n            {\n                \"td_1\": timedeltas,\n                \"td_2\": timedeltas,\n                \"int_1\": ints,\n                \"int_2\": ints,\n                \"ts_1\": datetimes,\n                \"ts_2\": datetimes,\n            },\n            index=index,\n        )\n        self.df_int_floats = DataFrame(\n            {\n                \"int_1\": ints,\n                \"int_2\": ints,\n                \"int_3\": ints,\n                \"float_1\": floats,\n                \"float_2\": floats,\n                \"float_3\": floats,\n            },\n            index=index,\n        )\n        self.df_int_float_str = DataFrame(\n            {\n                \"int_1\": ints,\n                \"int_2\": ints,\n                \"float_1\": floats,\n                \"float_2\": floats,\n                \"str_1\": strings,\n                \"str_2\": strings,\n            },\n            index=index,\n        )\n        self.df_longint_float_str = DataFrame(\n            {\n                \"longint_1\": longints,\n                \"longint_2\": longints,\n                \"float_1\": floats,\n                \"float_2\": floats,\n                \"str_1\": strings,\n                \"str_2\": strings,\n            },\n            index=index,\n        )", "min_run_count": 2, "name": "io.json.ToJSONLines.time_floats_with_int_idex_lines", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "1a872bf1a0dbe4c6dacf8368bd57159ad9f6e13729f234362d97480564486430", "warmup_time": -1}, "io.json.ToJSONMem.peakmem_float": {"code": "class ToJSONMem:\n    def peakmem_float(self, frames):\n        df = frames[\"float\"]\n        for _ in range(100_000):\n            df.to_json()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToJSONMem:\n    def setup_cache(self):\n        df = DataFrame([[1]])\n        df2 = DataFrame(range(8), date_range(\"1/1/2000\", periods=8, freq=\"min\"))\n        frames = {\"int\": df, \"float\": df.astype(float), \"datetime\": df2}\n    \n        return frames", "name": "io.json.ToJSONMem.peakmem_float", "param_names": [], "params": [], "setup_cache_key": "io.json:289", "timeout": 60.0, "type": "peakmemory", "unit": "bytes", "version": "00ee9841b98283beeb453d7dfd4cd72008d10a2028768798140f0ad54c56b581"}, "io.json.ToJSONMem.peakmem_int": {"code": "class ToJSONMem:\n    def peakmem_int(self, frames):\n        df = frames[\"int\"]\n        for _ in range(100_000):\n            df.to_json()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToJSONMem:\n    def setup_cache(self):\n        df = DataFrame([[1]])\n        df2 = DataFrame(range(8), date_range(\"1/1/2000\", periods=8, freq=\"min\"))\n        frames = {\"int\": df, \"float\": df.astype(float), \"datetime\": df2}\n    \n        return frames", "name": "io.json.ToJSONMem.peakmem_int", "param_names": [], "params": [], "setup_cache_key": "io.json:289", "timeout": 60.0, "type": "peakmemory", "unit": "bytes", "version": "a0f0fbfe022c1f66c3bb2fb28d8e1a6ecea8488a0a4252439e9a1cb94f397c3e"}, "io.json.ToJSONMem.peakmem_time": {"code": "class ToJSONMem:\n    def peakmem_time(self, frames):\n        df = frames[\"datetime\"]\n        for _ in range(10_000):\n            df.to_json(orient=\"table\")\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToJSONMem:\n    def setup_cache(self):\n        df = DataFrame([[1]])\n        df2 = DataFrame(range(8), date_range(\"1/1/2000\", periods=8, freq=\"min\"))\n        frames = {\"int\": df, \"float\": df.astype(float), \"datetime\": df2}\n    \n        return frames", "name": "io.json.ToJSONMem.peakmem_time", "param_names": [], "params": [], "setup_cache_key": "io.json:289", "timeout": 60.0, "type": "peakmemory", "unit": "bytes", "version": "2260dc5c098f332173c0b87ea1e18f2c50b70b762d04871af1f0c6186d9cfb2f"}, "io.json.ToJSONWide.peakmem_to_json": {"code": "class ToJSON:\n    def peakmem_to_json(self, orient, frame):\n        getattr(self, frame).to_json(self.fname, orient=orient)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToJSONWide:\n    def setup(self, orient, frame):\n        super().setup(orient, frame)\n        base_df = getattr(self, frame).copy()\n        df_wide = concat([base_df.iloc[:100]] * 1000, ignore_index=True, axis=1)\n        self.df_wide = df_wide", "name": "io.json.ToJSONWide.peakmem_to_json", "param_names": ["orient", "frame"], "params": [["'split'", "'columns'", "'index'", "'values'", "'records'"], ["'df'", "'df_date_idx'", "'df_td_int_ts'", "'df_int_floats'", "'df_int_float_str'"]], "timeout": 60.0, "type": "peakmemory", "unit": "bytes", "version": "f179e468594888d4ad11b82d624fc4c3925d4831054986c7642b6a7938e395d8"}, "io.json.ToJSONWide.peakmem_to_json_wide": {"code": "class ToJSONWide:\n    def peakmem_to_json_wide(self, orient, frame):\n        self.df_wide.to_json(self.fname, orient=orient)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToJSONWide:\n    def setup(self, orient, frame):\n        super().setup(orient, frame)\n        base_df = getattr(self, frame).copy()\n        df_wide = concat([base_df.iloc[:100]] * 1000, ignore_index=True, axis=1)\n        self.df_wide = df_wide", "name": "io.json.ToJSONWide.peakmem_to_json_wide", "param_names": ["orient", "frame"], "params": [["'split'", "'columns'", "'index'", "'values'", "'records'"], ["'df'", "'df_date_idx'", "'df_td_int_ts'", "'df_int_floats'", "'df_int_float_str'"]], "timeout": 60.0, "type": "peakmemory", "unit": "bytes", "version": "350c040ee03cb09b3b2af80aacdb6f89f0b64fb12027e7abfcecf1754316da0d"}, "io.json.ToJSONWide.time_to_json": {"code": "class ToJSON:\n    def time_to_json(self, orient, frame):\n        getattr(self, frame).to_json(self.fname, orient=orient)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToJSONWide:\n    def setup(self, orient, frame):\n        super().setup(orient, frame)\n        base_df = getattr(self, frame).copy()\n        df_wide = concat([base_df.iloc[:100]] * 1000, ignore_index=True, axis=1)\n        self.df_wide = df_wide", "min_run_count": 2, "name": "io.json.ToJSONWide.time_to_json", "number": 0, "param_names": ["orient", "frame"], "params": [["'split'", "'columns'", "'index'", "'values'", "'records'"], ["'df'", "'df_date_idx'", "'df_td_int_ts'", "'df_int_floats'", "'df_int_float_str'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "3efe5275ae2f37aaa5320e63422ce5b375719e691728af347d4018c67aef213a", "warmup_time": -1}, "io.json.ToJSONWide.time_to_json_wide": {"code": "class ToJSONWide:\n    def time_to_json_wide(self, orient, frame):\n        self.df_wide.to_json(self.fname, orient=orient)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToJSONWide:\n    def setup(self, orient, frame):\n        super().setup(orient, frame)\n        base_df = getattr(self, frame).copy()\n        df_wide = concat([base_df.iloc[:100]] * 1000, ignore_index=True, axis=1)\n        self.df_wide = df_wide", "min_run_count": 2, "name": "io.json.ToJSONWide.time_to_json_wide", "number": 0, "param_names": ["orient", "frame"], "params": [["'split'", "'columns'", "'index'", "'values'", "'records'"], ["'df'", "'df_date_idx'", "'df_td_int_ts'", "'df_int_floats'", "'df_int_float_str'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "aae5665173eb24e14595380fcf07cfeeab21783b5862479ee4e358e042ba6c38", "warmup_time": -1}, "io.parsers.ConcatDateCols.time_check_concat": {"code": "class ConcatDateCols:\n    def time_check_concat(self, value, dim):\n        concat_date_cols(self.object)\n\n    def setup(self, value, dim):\n        count_elem = 10000\n        if dim == 1:\n            self.object = (np.array([value] * count_elem),)\n        if dim == 2:\n            self.object = (\n                np.array([value] * count_elem),\n                np.array([value] * count_elem),\n            )", "min_run_count": 2, "name": "io.parsers.ConcatDateCols.time_check_concat", "number": 0, "param_names": ["value", "dim"], "params": [["1234567890", "'AAAA'"], ["1", "2"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "9aa4efe73a0a7fdff0a0c0b2ffa389e83a44520cd250bfea1d40fde51c49d9d8", "warmup_time": -1}, "io.parsers.DoesStringLookLikeDatetime.time_check_datetimes": {"code": "class DoesStringLookLikeDatetime:\n    def time_check_datetimes(self, value):\n        for obj in self.objects:\n            _does_string_look_like_datetime(obj)\n\n    def setup(self, value):\n        self.objects = [value] * 1000000", "min_run_count": 2, "name": "io.parsers.DoesStringLookLikeDatetime.time_check_datetimes", "number": 0, "param_names": ["value"], "params": [["'2Q2005'", "'0.0'", "'10000'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "a023015f4dc4ff2fbfce3252f6fd4b6c28970e462a5e405f7c2febd9b2256de7", "warmup_time": -1}, "io.pickle.Pickle.peakmem_read_pickle": {"code": "class Pickle:\n    def peakmem_read_pickle(self):\n        read_pickle(self.fname)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Pickle:\n    def setup(self):\n        self.fname = \"__test__.pkl\"\n        N = 100000\n        C = 5\n        self.df = DataFrame(\n            np.random.randn(N, C),\n            columns=[f\"float{i}\" for i in range(C)],\n            index=date_range(\"20000101\", periods=N, freq=\"h\"),\n        )\n        self.df[\"object\"] = Index([f\"i-{i}\" for i in range(N)], dtype=object)\n        self.df.to_pickle(self.fname)", "name": "io.pickle.Pickle.peakmem_read_pickle", "param_names": [], "params": [], "timeout": 60.0, "type": "peakmemory", "unit": "bytes", "version": "4f88c24f38210faf3621a5f3c8a3f69477ec21a24d2ddc6be2c8470c01aa40e3"}, "io.pickle.Pickle.peakmem_write_pickle": {"code": "class Pickle:\n    def peakmem_write_pickle(self):\n        self.df.to_pickle(self.fname)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Pickle:\n    def setup(self):\n        self.fname = \"__test__.pkl\"\n        N = 100000\n        C = 5\n        self.df = DataFrame(\n            np.random.randn(N, C),\n            columns=[f\"float{i}\" for i in range(C)],\n            index=date_range(\"20000101\", periods=N, freq=\"h\"),\n        )\n        self.df[\"object\"] = Index([f\"i-{i}\" for i in range(N)], dtype=object)\n        self.df.to_pickle(self.fname)", "name": "io.pickle.Pickle.peakmem_write_pickle", "param_names": [], "params": [], "timeout": 60.0, "type": "peakmemory", "unit": "bytes", "version": "d6e455195b782b35e91ceac2d611911bb32493f8c4d4487fc4c4e31f0f4e0ceb"}, "io.pickle.Pickle.time_read_pickle": {"code": "class Pickle:\n    def time_read_pickle(self):\n        read_pickle(self.fname)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Pickle:\n    def setup(self):\n        self.fname = \"__test__.pkl\"\n        N = 100000\n        C = 5\n        self.df = DataFrame(\n            np.random.randn(N, C),\n            columns=[f\"float{i}\" for i in range(C)],\n            index=date_range(\"20000101\", periods=N, freq=\"h\"),\n        )\n        self.df[\"object\"] = Index([f\"i-{i}\" for i in range(N)], dtype=object)\n        self.df.to_pickle(self.fname)", "min_run_count": 2, "name": "io.pickle.Pickle.time_read_pickle", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "b91906f3a4f0e0fc6d0e7c75087708710c17306f6261154037cce4d579f9a168", "warmup_time": -1}, "io.pickle.Pickle.time_write_pickle": {"code": "class Pickle:\n    def time_write_pickle(self):\n        self.df.to_pickle(self.fname)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Pickle:\n    def setup(self):\n        self.fname = \"__test__.pkl\"\n        N = 100000\n        C = 5\n        self.df = DataFrame(\n            np.random.randn(N, C),\n            columns=[f\"float{i}\" for i in range(C)],\n            index=date_range(\"20000101\", periods=N, freq=\"h\"),\n        )\n        self.df[\"object\"] = Index([f\"i-{i}\" for i in range(N)], dtype=object)\n        self.df.to_pickle(self.fname)", "min_run_count": 2, "name": "io.pickle.Pickle.time_write_pickle", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "197a465e7ef1ae675a5470d939c4e2ce2d4f98b1f7d774e82a579024a5626166", "warmup_time": -1}, "io.sas.SAS.time_read_sas7bdat": {"code": "class SAS:\n    def time_read_sas7bdat(self):\n        read_sas(ROOT / \"test1.sas7bdat\")", "min_run_count": 2, "name": "io.sas.SAS.time_read_sas7bdat", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "90750b4b8570b3ae59cde41f15ee1b854b9ab5ce81313090b40ed33623373ac0", "warmup_time": -1}, "io.sas.SAS.time_read_sas7bdat_2": {"code": "class SAS:\n    def time_read_sas7bdat_2(self):\n        next(read_sas(ROOT / \"0x00controlbyte.sas7bdat.bz2\", chunksize=11000))", "min_run_count": 2, "name": "io.sas.SAS.time_read_sas7bdat_2", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "6634a822c4810085a951c2a037c4c61eeb579b792626fe9e9258ee6c42746e28", "warmup_time": -1}, "io.sas.SAS.time_read_sas7bdat_2_chunked": {"code": "class SAS:\n    def time_read_sas7bdat_2_chunked(self):\n        for i, _ in enumerate(\n            read_sas(ROOT / \"0x00controlbyte.sas7bdat.bz2\", chunksize=1000)\n        ):\n            if i == 10:\n                break", "min_run_count": 2, "name": "io.sas.SAS.time_read_sas7bdat_2_chunked", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "d10bf08f751bef710fda95bf4064e7efe3c337d520294711968c04867570b2e1", "warmup_time": -1}, "io.sas.SAS.time_read_xpt": {"code": "class SAS:\n    def time_read_xpt(self):\n        read_sas(ROOT / \"paxraw_d_short.xpt\")", "min_run_count": 2, "name": "io.sas.SAS.time_read_xpt", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "e400235073dafa325dfdd6e6eda51419eff1337191b1178a5f5ab43af9d3bb9a", "warmup_time": -1}, "io.sql.ReadSQLTable.time_read_sql_table_all": {"code": "class ReadSQLTable:\n    def time_read_sql_table_all(self):\n        read_sql_table(self.table_name, self.con)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ReadSQLTable:\n    def setup(self):\n        N = 10000\n        self.table_name = \"test\"\n        self.con = create_engine(\"sqlite:///:memory:\")\n        self.df = DataFrame(\n            {\n                \"float\": np.random.randn(N),\n                \"float_with_nan\": np.random.randn(N),\n                \"string\": [\"foo\"] * N,\n                \"bool\": [True] * N,\n                \"int\": np.random.randint(0, N, size=N),\n                \"datetime\": date_range(\"2000-01-01\", periods=N, freq=\"s\"),\n            },\n            index=Index([f\"i-{i}\" for i in range(N)], dtype=object),\n        )\n        self.df.iloc[1000:3000, 1] = np.nan\n        self.df[\"date\"] = self.df[\"datetime\"].dt.date\n        self.df[\"time\"] = self.df[\"datetime\"].dt.time\n        self.df[\"datetime_string\"] = self.df[\"datetime\"].astype(str)\n        self.df.to_sql(self.table_name, self.con, if_exists=\"replace\")", "min_run_count": 2, "name": "io.sql.ReadSQLTable.time_read_sql_table_all", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "8805189ad353a53259e1140e68baa586a0df8cd9d72c69b5a8cb9423e2338323", "warmup_time": -1}, "io.sql.ReadSQLTable.time_read_sql_table_parse_dates": {"code": "class ReadSQLTable:\n    def time_read_sql_table_parse_dates(self):\n        read_sql_table(\n            self.table_name,\n            self.con,\n            columns=[\"datetime_string\"],\n            parse_dates=[\"datetime_string\"],\n        )\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ReadSQLTable:\n    def setup(self):\n        N = 10000\n        self.table_name = \"test\"\n        self.con = create_engine(\"sqlite:///:memory:\")\n        self.df = DataFrame(\n            {\n                \"float\": np.random.randn(N),\n                \"float_with_nan\": np.random.randn(N),\n                \"string\": [\"foo\"] * N,\n                \"bool\": [True] * N,\n                \"int\": np.random.randint(0, N, size=N),\n                \"datetime\": date_range(\"2000-01-01\", periods=N, freq=\"s\"),\n            },\n            index=Index([f\"i-{i}\" for i in range(N)], dtype=object),\n        )\n        self.df.iloc[1000:3000, 1] = np.nan\n        self.df[\"date\"] = self.df[\"datetime\"].dt.date\n        self.df[\"time\"] = self.df[\"datetime\"].dt.time\n        self.df[\"datetime_string\"] = self.df[\"datetime\"].astype(str)\n        self.df.to_sql(self.table_name, self.con, if_exists=\"replace\")", "min_run_count": 2, "name": "io.sql.ReadSQLTable.time_read_sql_table_parse_dates", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "dd4c0ad3318162e5578f5184117e902602f575122eb690a13703523fafe2ebd4", "warmup_time": -1}, "io.sql.ReadSQLTableDtypes.time_read_sql_table_column": {"code": "class ReadSQLTableDtypes:\n    def time_read_sql_table_column(self, dtype):\n        read_sql_table(self.table_name, self.con, columns=[dtype])\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ReadSQLTableDtypes:\n    def setup(self, dtype):\n        N = 10000\n        self.table_name = \"test\"\n        self.con = create_engine(\"sqlite:///:memory:\")\n        self.df = DataFrame(\n            {\n                \"float\": np.random.randn(N),\n                \"float_with_nan\": np.random.randn(N),\n                \"string\": [\"foo\"] * N,\n                \"bool\": [True] * N,\n                \"int\": np.random.randint(0, N, size=N),\n                \"datetime\": date_range(\"2000-01-01\", periods=N, freq=\"s\"),\n            },\n            index=Index([f\"i-{i}\" for i in range(N)], dtype=object),\n        )\n        self.df.iloc[1000:3000, 1] = np.nan\n        self.df[\"date\"] = self.df[\"datetime\"].dt.date\n        self.df[\"time\"] = self.df[\"datetime\"].dt.time\n        self.df[\"datetime_string\"] = self.df[\"datetime\"].astype(str)\n        self.df.to_sql(self.table_name, self.con, if_exists=\"replace\")", "min_run_count": 2, "name": "io.sql.ReadSQLTableDtypes.time_read_sql_table_column", "number": 0, "param_names": ["dtype"], "params": [["'float'", "'float_with_nan'", "'string'", "'bool'", "'int'", "'date'", "'time'", "'datetime'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "3715243646c52bd93b31afb5ade91a7fb8659472bee04546210dcbfc423b0e34", "warmup_time": -1}, "io.sql.SQL.time_read_sql_query": {"code": "class SQL:\n    def time_read_sql_query(self, connection):\n        read_sql_query(self.query_all, self.con)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass SQL:\n    def setup(self, connection):\n        N = 10000\n        con = {\n            \"sqlalchemy\": create_engine(\"sqlite:///:memory:\"),\n            \"sqlite\": sqlite3.connect(\":memory:\"),\n        }\n        self.table_name = \"test_type\"\n        self.query_all = f\"SELECT * FROM {self.table_name}\"\n        self.con = con[connection]\n        self.df = DataFrame(\n            {\n                \"float\": np.random.randn(N),\n                \"float_with_nan\": np.random.randn(N),\n                \"string\": [\"foo\"] * N,\n                \"bool\": [True] * N,\n                \"int\": np.random.randint(0, N, size=N),\n                \"datetime\": date_range(\"2000-01-01\", periods=N, freq=\"s\"),\n            },\n            index=Index([f\"i-{i}\" for i in range(N)], dtype=object),\n        )\n        self.df.iloc[1000:3000, 1] = np.nan\n        self.df[\"date\"] = self.df[\"datetime\"].dt.date\n        self.df[\"time\"] = self.df[\"datetime\"].dt.time\n        self.df[\"datetime_string\"] = self.df[\"datetime\"].astype(str)\n        self.df.to_sql(self.table_name, self.con, if_exists=\"replace\")", "min_run_count": 2, "name": "io.sql.SQL.time_read_sql_query", "number": 0, "param_names": ["connection"], "params": [["'sqlalchemy'", "'sqlite'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "6e9c468300eee3818a1fdb1388194e0442416d67fe7b467ea3551de7b486cec8", "warmup_time": -1}, "io.sql.SQL.time_to_sql_dataframe": {"code": "class SQL:\n    def time_to_sql_dataframe(self, connection):\n        self.df.to_sql(\"test1\", self.con, if_exists=\"replace\")\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass SQL:\n    def setup(self, connection):\n        N = 10000\n        con = {\n            \"sqlalchemy\": create_engine(\"sqlite:///:memory:\"),\n            \"sqlite\": sqlite3.connect(\":memory:\"),\n        }\n        self.table_name = \"test_type\"\n        self.query_all = f\"SELECT * FROM {self.table_name}\"\n        self.con = con[connection]\n        self.df = DataFrame(\n            {\n                \"float\": np.random.randn(N),\n                \"float_with_nan\": np.random.randn(N),\n                \"string\": [\"foo\"] * N,\n                \"bool\": [True] * N,\n                \"int\": np.random.randint(0, N, size=N),\n                \"datetime\": date_range(\"2000-01-01\", periods=N, freq=\"s\"),\n            },\n            index=Index([f\"i-{i}\" for i in range(N)], dtype=object),\n        )\n        self.df.iloc[1000:3000, 1] = np.nan\n        self.df[\"date\"] = self.df[\"datetime\"].dt.date\n        self.df[\"time\"] = self.df[\"datetime\"].dt.time\n        self.df[\"datetime_string\"] = self.df[\"datetime\"].astype(str)\n        self.df.to_sql(self.table_name, self.con, if_exists=\"replace\")", "min_run_count": 2, "name": "io.sql.SQL.time_to_sql_dataframe", "number": 0, "param_names": ["connection"], "params": [["'sqlalchemy'", "'sqlite'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "e83de9885c2f942c647a56d72031c18606ffbee73b7ee38d1dc227d2b1f69cda", "warmup_time": -1}, "io.sql.WriteSQLDtypes.time_read_sql_query_select_column": {"code": "class WriteSQLDtypes:\n    def time_read_sql_query_select_column(self, connection, dtype):\n        read_sql_query(self.query_col, self.con)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass WriteSQLDtypes:\n    def setup(self, connection, dtype):\n        N = 10000\n        con = {\n            \"sqlalchemy\": create_engine(\"sqlite:///:memory:\"),\n            \"sqlite\": sqlite3.connect(\":memory:\"),\n        }\n        self.table_name = \"test_type\"\n        self.query_col = f\"SELECT {dtype} FROM {self.table_name}\"\n        self.con = con[connection]\n        self.df = DataFrame(\n            {\n                \"float\": np.random.randn(N),\n                \"float_with_nan\": np.random.randn(N),\n                \"string\": [\"foo\"] * N,\n                \"bool\": [True] * N,\n                \"int\": np.random.randint(0, N, size=N),\n                \"datetime\": date_range(\"2000-01-01\", periods=N, freq=\"s\"),\n            },\n            index=Index([f\"i-{i}\" for i in range(N)], dtype=object),\n        )\n        self.df.iloc[1000:3000, 1] = np.nan\n        self.df[\"date\"] = self.df[\"datetime\"].dt.date\n        self.df[\"time\"] = self.df[\"datetime\"].dt.time\n        self.df[\"datetime_string\"] = self.df[\"datetime\"].astype(str)\n        self.df.to_sql(self.table_name, self.con, if_exists=\"replace\")", "min_run_count": 2, "name": "io.sql.WriteSQLDtypes.time_read_sql_query_select_column", "number": 0, "param_names": ["connection", "dtype"], "params": [["'sqlalchemy'", "'sqlite'"], ["'float'", "'float_with_nan'", "'string'", "'bool'", "'int'", "'date'", "'time'", "'datetime'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "6a6d2a3f39d33e0506f5c087cd7c7a253eaacac063a5aa53e54f846897e5c243", "warmup_time": -1}, "io.sql.WriteSQLDtypes.time_to_sql_dataframe_column": {"code": "class WriteSQLDtypes:\n    def time_to_sql_dataframe_column(self, connection, dtype):\n        self.df[[dtype]].to_sql(\"test1\", self.con, if_exists=\"replace\")\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass WriteSQLDtypes:\n    def setup(self, connection, dtype):\n        N = 10000\n        con = {\n            \"sqlalchemy\": create_engine(\"sqlite:///:memory:\"),\n            \"sqlite\": sqlite3.connect(\":memory:\"),\n        }\n        self.table_name = \"test_type\"\n        self.query_col = f\"SELECT {dtype} FROM {self.table_name}\"\n        self.con = con[connection]\n        self.df = DataFrame(\n            {\n                \"float\": np.random.randn(N),\n                \"float_with_nan\": np.random.randn(N),\n                \"string\": [\"foo\"] * N,\n                \"bool\": [True] * N,\n                \"int\": np.random.randint(0, N, size=N),\n                \"datetime\": date_range(\"2000-01-01\", periods=N, freq=\"s\"),\n            },\n            index=Index([f\"i-{i}\" for i in range(N)], dtype=object),\n        )\n        self.df.iloc[1000:3000, 1] = np.nan\n        self.df[\"date\"] = self.df[\"datetime\"].dt.date\n        self.df[\"time\"] = self.df[\"datetime\"].dt.time\n        self.df[\"datetime_string\"] = self.df[\"datetime\"].astype(str)\n        self.df.to_sql(self.table_name, self.con, if_exists=\"replace\")", "min_run_count": 2, "name": "io.sql.WriteSQLDtypes.time_to_sql_dataframe_column", "number": 0, "param_names": ["connection", "dtype"], "params": [["'sqlalchemy'", "'sqlite'"], ["'float'", "'float_with_nan'", "'string'", "'bool'", "'int'", "'date'", "'time'", "'datetime'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "1ef8f5f1c2e6e522fda7b7be0b4b74a02379fca208bdedc44c04133a3168ee4d", "warmup_time": -1}, "io.stata.Stata.time_read_stata": {"code": "class Stata:\n    def time_read_stata(self, convert_dates):\n        read_stata(self.fname)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Stata:\n    def setup(self, convert_dates):\n        self.fname = \"__test__.dta\"\n        N = self.N = 100000\n        C = self.C = 5\n        self.df = DataFrame(\n            np.random.randn(N, C),\n            columns=[f\"float{i}\" for i in range(C)],\n            index=date_range(\"20000101\", periods=N, freq=\"h\"),\n        )\n        self.df[\"object\"] = Index([f\"i-{i}\" for i in range(self.N)], dtype=object)\n        self.df[\"int8_\"] = np.random.randint(\n            np.iinfo(np.int8).min, np.iinfo(np.int8).max - 27, N\n        )\n        self.df[\"int16_\"] = np.random.randint(\n            np.iinfo(np.int16).min, np.iinfo(np.int16).max - 27, N\n        )\n        self.df[\"int32_\"] = np.random.randint(\n            np.iinfo(np.int32).min, np.iinfo(np.int32).max - 27, N\n        )\n        self.df[\"float32_\"] = np.array(np.random.randn(N), dtype=np.float32)\n        self.convert_dates = {\"index\": convert_dates}\n        self.df.to_stata(self.fname, convert_dates=self.convert_dates)", "min_run_count": 2, "name": "io.stata.Stata.time_read_stata", "number": 0, "param_names": ["convert_dates"], "params": [["'tc'", "'td'", "'tm'", "'tw'", "'th'", "'tq'", "'ty'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "373dd72e429ef636629454da90e787c31ecff5cea8dd978c7f0a2d01b864b846", "warmup_time": -1}, "io.stata.Stata.time_write_stata": {"code": "class Stata:\n    def time_write_stata(self, convert_dates):\n        self.df.to_stata(self.fname, convert_dates=self.convert_dates)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Stata:\n    def setup(self, convert_dates):\n        self.fname = \"__test__.dta\"\n        N = self.N = 100000\n        C = self.C = 5\n        self.df = DataFrame(\n            np.random.randn(N, C),\n            columns=[f\"float{i}\" for i in range(C)],\n            index=date_range(\"20000101\", periods=N, freq=\"h\"),\n        )\n        self.df[\"object\"] = Index([f\"i-{i}\" for i in range(self.N)], dtype=object)\n        self.df[\"int8_\"] = np.random.randint(\n            np.iinfo(np.int8).min, np.iinfo(np.int8).max - 27, N\n        )\n        self.df[\"int16_\"] = np.random.randint(\n            np.iinfo(np.int16).min, np.iinfo(np.int16).max - 27, N\n        )\n        self.df[\"int32_\"] = np.random.randint(\n            np.iinfo(np.int32).min, np.iinfo(np.int32).max - 27, N\n        )\n        self.df[\"float32_\"] = np.array(np.random.randn(N), dtype=np.float32)\n        self.convert_dates = {\"index\": convert_dates}\n        self.df.to_stata(self.fname, convert_dates=self.convert_dates)", "min_run_count": 2, "name": "io.stata.Stata.time_write_stata", "number": 0, "param_names": ["convert_dates"], "params": [["'tc'", "'td'", "'tm'", "'tw'", "'th'", "'tq'", "'ty'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "fecc2ef1a45be678d915bdc0d91dfe1927166b223d0f0fb6ff194407d6cdeb18", "warmup_time": -1}, "io.stata.StataMissing.time_read_stata": {"code": "class Stata:\n    def time_read_stata(self, convert_dates):\n        read_stata(self.fname)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass StataMissing:\n    def setup(self, convert_dates):\n        super().setup(convert_dates)\n        for i in range(10):\n            missing_data = np.random.randn(self.N)\n            missing_data[missing_data < 0] = np.nan\n            self.df[f\"missing_{i}\"] = missing_data\n        self.df.to_stata(self.fname, convert_dates=self.convert_dates)", "min_run_count": 2, "name": "io.stata.StataMissing.time_read_stata", "number": 0, "param_names": ["convert_dates"], "params": [["'tc'", "'td'", "'tm'", "'tw'", "'th'", "'tq'", "'ty'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "b28404f018d5ce3e6f6e9f4f573bfc333203130ac26b6ad0a55ab363d4091d56", "warmup_time": -1}, "io.stata.StataMissing.time_write_stata": {"code": "class Stata:\n    def time_write_stata(self, convert_dates):\n        self.df.to_stata(self.fname, convert_dates=self.convert_dates)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass StataMissing:\n    def setup(self, convert_dates):\n        super().setup(convert_dates)\n        for i in range(10):\n            missing_data = np.random.randn(self.N)\n            missing_data[missing_data < 0] = np.nan\n            self.df[f\"missing_{i}\"] = missing_data\n        self.df.to_stata(self.fname, convert_dates=self.convert_dates)", "min_run_count": 2, "name": "io.stata.StataMissing.time_write_stata", "number": 0, "param_names": ["convert_dates"], "params": [["'tc'", "'td'", "'tm'", "'tw'", "'th'", "'tq'", "'ty'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "12dd8e544d5d5dc0ff5c73373ffa7a2338cc235fc3829df79060f21c721b21c1", "warmup_time": -1}, "io.style.Render.peakmem_apply_format_hide_render": {"code": "class Render:\n    def peakmem_apply_format_hide_render(self, cols, rows):\n        self._style_apply_format_hide()\n        self.st._render_html(True, True)\n\n    def setup(self, cols, rows):\n        self.df = DataFrame(\n            np.random.randn(rows, cols),\n            columns=[f\"float_{i+1}\" for i in range(cols)],\n            index=[f\"row_{i+1}\" for i in range(rows)],\n        )", "name": "io.style.Render.peakmem_apply_format_hide_render", "param_names": ["cols", "rows"], "params": [["12", "24", "36"], ["12", "120"]], "timeout": 60.0, "type": "peakmemory", "unit": "bytes", "version": "24efee29e9f4259b3dc32b50ebebd07120a2cc59672b5f07aaf694b3350ffc33"}, "io.style.Render.peakmem_apply_render": {"code": "class Render:\n    def peakmem_apply_render(self, cols, rows):\n        self._style_apply()\n        self.st._render_html(True, True)\n\n    def setup(self, cols, rows):\n        self.df = DataFrame(\n            np.random.randn(rows, cols),\n            columns=[f\"float_{i+1}\" for i in range(cols)],\n            index=[f\"row_{i+1}\" for i in range(rows)],\n        )", "name": "io.style.Render.peakmem_apply_render", "param_names": ["cols", "rows"], "params": [["12", "24", "36"], ["12", "120"]], "timeout": 60.0, "type": "peakmemory", "unit": "bytes", "version": "f1291d9b0cee2ed29164614c2827a58907e0943d031efe0a1f700dd7bb3ea1ef"}, "io.style.Render.peakmem_classes_render": {"code": "class Render:\n    def peakmem_classes_render(self, cols, rows):\n        self._style_classes()\n        self.st._render_html(True, True)\n\n    def setup(self, cols, rows):\n        self.df = DataFrame(\n            np.random.randn(rows, cols),\n            columns=[f\"float_{i+1}\" for i in range(cols)],\n            index=[f\"row_{i+1}\" for i in range(rows)],\n        )", "name": "io.style.Render.peakmem_classes_render", "param_names": ["cols", "rows"], "params": [["12", "24", "36"], ["12", "120"]], "timeout": 60.0, "type": "peakmemory", "unit": "bytes", "version": "1d74d0ee63b8ddbcb67f37a2c6260ebe84c54ec1d2650db12d284630efa672c9"}, "io.style.Render.peakmem_format_render": {"code": "class Render:\n    def peakmem_format_render(self, cols, rows):\n        self._style_format()\n        self.st._render_html(True, True)\n\n    def setup(self, cols, rows):\n        self.df = DataFrame(\n            np.random.randn(rows, cols),\n            columns=[f\"float_{i+1}\" for i in range(cols)],\n            index=[f\"row_{i+1}\" for i in range(rows)],\n        )", "name": "io.style.Render.peakmem_format_render", "param_names": ["cols", "rows"], "params": [["12", "24", "36"], ["12", "120"]], "timeout": 60.0, "type": "peakmemory", "unit": "bytes", "version": "2d2ae2b598964ca4ec2ce6befed05ff0ed2c8833539c314cbc42c2a006d9abcf"}, "io.style.Render.peakmem_tooltips_render": {"code": "class Render:\n    def peakmem_tooltips_render(self, cols, rows):\n        self._style_tooltips()\n        self.st._render_html(True, True)\n\n    def setup(self, cols, rows):\n        self.df = DataFrame(\n            np.random.randn(rows, cols),\n            columns=[f\"float_{i+1}\" for i in range(cols)],\n            index=[f\"row_{i+1}\" for i in range(rows)],\n        )", "name": "io.style.Render.peakmem_tooltips_render", "param_names": ["cols", "rows"], "params": [["12", "24", "36"], ["12", "120"]], "timeout": 60.0, "type": "peakmemory", "unit": "bytes", "version": "f3165d89bad8a5256ce768ec97faaca1dc322cc15dfc6cce5c8f629872c4b625"}, "io.style.Render.time_apply_format_hide_render": {"code": "class Render:\n    def time_apply_format_hide_render(self, cols, rows):\n        self._style_apply_format_hide()\n        self.st._render_html(True, True)\n\n    def setup(self, cols, rows):\n        self.df = DataFrame(\n            np.random.randn(rows, cols),\n            columns=[f\"float_{i+1}\" for i in range(cols)],\n            index=[f\"row_{i+1}\" for i in range(rows)],\n        )", "min_run_count": 2, "name": "io.style.Render.time_apply_format_hide_render", "number": 0, "param_names": ["cols", "rows"], "params": [["12", "24", "36"], ["12", "120"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "4624b648242dbd72367816b07786b7bb20dec67fcf4d8b269046640a281b891b", "warmup_time": -1}, "io.style.Render.time_apply_render": {"code": "class Render:\n    def time_apply_render(self, cols, rows):\n        self._style_apply()\n        self.st._render_html(True, True)\n\n    def setup(self, cols, rows):\n        self.df = DataFrame(\n            np.random.randn(rows, cols),\n            columns=[f\"float_{i+1}\" for i in range(cols)],\n            index=[f\"row_{i+1}\" for i in range(rows)],\n        )", "min_run_count": 2, "name": "io.style.Render.time_apply_render", "number": 0, "param_names": ["cols", "rows"], "params": [["12", "24", "36"], ["12", "120"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "b7713a928f5b63249a63e44399f6d18a893bff35ae8541e666af0885aec0a166", "warmup_time": -1}, "io.style.Render.time_classes_render": {"code": "class Render:\n    def time_classes_render(self, cols, rows):\n        self._style_classes()\n        self.st._render_html(True, True)\n\n    def setup(self, cols, rows):\n        self.df = DataFrame(\n            np.random.randn(rows, cols),\n            columns=[f\"float_{i+1}\" for i in range(cols)],\n            index=[f\"row_{i+1}\" for i in range(rows)],\n        )", "min_run_count": 2, "name": "io.style.Render.time_classes_render", "number": 0, "param_names": ["cols", "rows"], "params": [["12", "24", "36"], ["12", "120"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "e385c7e77a27a0e29b3941e7cf3c0727f5f83d8b6279cd9500e63fb1f630d7d5", "warmup_time": -1}, "io.style.Render.time_format_render": {"code": "class Render:\n    def time_format_render(self, cols, rows):\n        self._style_format()\n        self.st._render_html(True, True)\n\n    def setup(self, cols, rows):\n        self.df = DataFrame(\n            np.random.randn(rows, cols),\n            columns=[f\"float_{i+1}\" for i in range(cols)],\n            index=[f\"row_{i+1}\" for i in range(rows)],\n        )", "min_run_count": 2, "name": "io.style.Render.time_format_render", "number": 0, "param_names": ["cols", "rows"], "params": [["12", "24", "36"], ["12", "120"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "2fe7b97954d549aadb2eb134d3d09b8c1334a640488b36869090ed4c430365ed", "warmup_time": -1}, "io.style.Render.time_tooltips_render": {"code": "class Render:\n    def time_tooltips_render(self, cols, rows):\n        self._style_tooltips()\n        self.st._render_html(True, True)\n\n    def setup(self, cols, rows):\n        self.df = DataFrame(\n            np.random.randn(rows, cols),\n            columns=[f\"float_{i+1}\" for i in range(cols)],\n            index=[f\"row_{i+1}\" for i in range(rows)],\n        )", "min_run_count": 2, "name": "io.style.Render.time_tooltips_render", "number": 0, "param_names": ["cols", "rows"], "params": [["12", "24", "36"], ["12", "120"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "bf6a27f9959b331a6f71cda4f842f4ceb8df92624979f2a522fe57cc98a5e34d", "warmup_time": -1}, "join_merge.Align.time_series_align_int64_index": {"code": "class Align:\n    def time_series_align_int64_index(self):\n        self.ts1 + self.ts2\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Align:\n    def setup(self):\n        size = 5 * 10**5\n        rng = np.arange(0, 10**13, 10**7)\n        stamps = np.datetime64(\"now\").view(\"i8\") + rng\n        idx1 = np.sort(np.random.choice(stamps, size, replace=False))\n        idx2 = np.sort(np.random.choice(stamps, size, replace=False))\n        self.ts1 = Series(np.random.randn(size), idx1)\n        self.ts2 = Series(np.random.randn(size), idx2)", "min_run_count": 2, "name": "join_merge.Align.time_series_align_int64_index", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "59ba8b3aa681ebdec8f5b793e2c2d9f7edd0cc1306163877b74d2788ac7102c0", "warmup_time": -1}, "join_merge.Align.time_series_align_left_monotonic": {"code": "class Align:\n    def time_series_align_left_monotonic(self):\n        self.ts1.align(self.ts2, join=\"left\")\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Align:\n    def setup(self):\n        size = 5 * 10**5\n        rng = np.arange(0, 10**13, 10**7)\n        stamps = np.datetime64(\"now\").view(\"i8\") + rng\n        idx1 = np.sort(np.random.choice(stamps, size, replace=False))\n        idx2 = np.sort(np.random.choice(stamps, size, replace=False))\n        self.ts1 = Series(np.random.randn(size), idx1)\n        self.ts2 = Series(np.random.randn(size), idx2)", "min_run_count": 2, "name": "join_merge.Align.time_series_align_left_monotonic", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "1c381483982c07fac3b6c437f2f740ae055cad4035d9a2bdf325a4acfe440e76", "warmup_time": -1}, "join_merge.Concat.time_concat_empty_left": {"code": "class Concat:\n    def time_concat_empty_left(self, axis):\n        concat(self.empty_left, axis=axis)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Concat:\n    def setup(self, axis):\n        N = 1000\n        s = Series(N, index=Index([f\"i-{i}\" for i in range(N)], dtype=object))\n        self.series = [s[i:-i] for i in range(1, 10)] * 50\n        self.small_frames = [DataFrame(np.random.randn(5, 4))] * 1000\n        df = DataFrame(\n            {\"A\": range(N)}, index=date_range(\"20130101\", periods=N, freq=\"s\")\n        )\n        self.empty_left = [DataFrame(), df]\n        self.empty_right = [df, DataFrame()]\n        self.mixed_ndims = [df, df.head(N // 2)]", "min_run_count": 2, "name": "join_merge.Concat.time_concat_empty_left", "number": 0, "param_names": ["axis"], "params": [["0", "1"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "c24f8d889c69b6fddab68477db7feb9bdd64d0bfc8a437af267480d6244476bc", "warmup_time": -1}, "join_merge.Concat.time_concat_empty_right": {"code": "class Concat:\n    def time_concat_empty_right(self, axis):\n        concat(self.empty_right, axis=axis)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Concat:\n    def setup(self, axis):\n        N = 1000\n        s = Series(N, index=Index([f\"i-{i}\" for i in range(N)], dtype=object))\n        self.series = [s[i:-i] for i in range(1, 10)] * 50\n        self.small_frames = [DataFrame(np.random.randn(5, 4))] * 1000\n        df = DataFrame(\n            {\"A\": range(N)}, index=date_range(\"20130101\", periods=N, freq=\"s\")\n        )\n        self.empty_left = [DataFrame(), df]\n        self.empty_right = [df, DataFrame()]\n        self.mixed_ndims = [df, df.head(N // 2)]", "min_run_count": 2, "name": "join_merge.Concat.time_concat_empty_right", "number": 0, "param_names": ["axis"], "params": [["0", "1"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "50a67de8903652dc050970bc82dc1e728dd0803fb2d35b1eefd98d1b5771497b", "warmup_time": -1}, "join_merge.Concat.time_concat_mixed_ndims": {"code": "class Concat:\n    def time_concat_mixed_ndims(self, axis):\n        concat(self.mixed_ndims, axis=axis)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Concat:\n    def setup(self, axis):\n        N = 1000\n        s = Series(N, index=Index([f\"i-{i}\" for i in range(N)], dtype=object))\n        self.series = [s[i:-i] for i in range(1, 10)] * 50\n        self.small_frames = [DataFrame(np.random.randn(5, 4))] * 1000\n        df = DataFrame(\n            {\"A\": range(N)}, index=date_range(\"20130101\", periods=N, freq=\"s\")\n        )\n        self.empty_left = [DataFrame(), df]\n        self.empty_right = [df, DataFrame()]\n        self.mixed_ndims = [df, df.head(N // 2)]", "min_run_count": 2, "name": "join_merge.Concat.time_concat_mixed_ndims", "number": 0, "param_names": ["axis"], "params": [["0", "1"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "c9ed31fc560eb4af434e4a5f9c1c3f4661613c9c160b2335cbe6555ce327feac", "warmup_time": -1}, "join_merge.Concat.time_concat_series": {"code": "class Concat:\n    def time_concat_series(self, axis):\n        concat(self.series, axis=axis, sort=False)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Concat:\n    def setup(self, axis):\n        N = 1000\n        s = Series(N, index=Index([f\"i-{i}\" for i in range(N)], dtype=object))\n        self.series = [s[i:-i] for i in range(1, 10)] * 50\n        self.small_frames = [DataFrame(np.random.randn(5, 4))] * 1000\n        df = DataFrame(\n            {\"A\": range(N)}, index=date_range(\"20130101\", periods=N, freq=\"s\")\n        )\n        self.empty_left = [DataFrame(), df]\n        self.empty_right = [df, DataFrame()]\n        self.mixed_ndims = [df, df.head(N // 2)]", "min_run_count": 2, "name": "join_merge.Concat.time_concat_series", "number": 0, "param_names": ["axis"], "params": [["0", "1"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "bf170cabb255499f965da712f65e57cd5f3a050cf5c35d2069e104851dd6e5a0", "warmup_time": -1}, "join_merge.Concat.time_concat_small_frames": {"code": "class Concat:\n    def time_concat_small_frames(self, axis):\n        concat(self.small_frames, axis=axis)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Concat:\n    def setup(self, axis):\n        N = 1000\n        s = Series(N, index=Index([f\"i-{i}\" for i in range(N)], dtype=object))\n        self.series = [s[i:-i] for i in range(1, 10)] * 50\n        self.small_frames = [DataFrame(np.random.randn(5, 4))] * 1000\n        df = DataFrame(\n            {\"A\": range(N)}, index=date_range(\"20130101\", periods=N, freq=\"s\")\n        )\n        self.empty_left = [DataFrame(), df]\n        self.empty_right = [df, DataFrame()]\n        self.mixed_ndims = [df, df.head(N // 2)]", "min_run_count": 2, "name": "join_merge.Concat.time_concat_small_frames", "number": 0, "param_names": ["axis"], "params": [["0", "1"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "470adfb2d6977cd7074d1f42533fea5a4d223b74619f161758021c6161815779", "warmup_time": -1}, "join_merge.ConcatDataFrames.time_c_ordered": {"code": "class ConcatDataFrames:\n    def time_c_ordered(self, axis, ignore_index):\n        concat(self.frame_c, axis=axis, ignore_index=ignore_index)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ConcatDataFrames:\n    def setup(self, axis, ignore_index):\n        frame_c = DataFrame(np.zeros((10000, 200), dtype=np.float32, order=\"C\"))\n        self.frame_c = [frame_c] * 20\n        frame_f = DataFrame(np.zeros((10000, 200), dtype=np.float32, order=\"F\"))\n        self.frame_f = [frame_f] * 20", "min_run_count": 2, "name": "join_merge.ConcatDataFrames.time_c_ordered", "number": 0, "param_names": ["axis", "ignore_index"], "params": [["0", "1"], ["True", "False"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "a747cecacb0f57e2d282f77dbc9ba6108bb55d137dcb4cdef4d0cb94bd2ef909", "warmup_time": -1}, "join_merge.ConcatDataFrames.time_f_ordered": {"code": "class ConcatDataFrames:\n    def time_f_ordered(self, axis, ignore_index):\n        concat(self.frame_f, axis=axis, ignore_index=ignore_index)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ConcatDataFrames:\n    def setup(self, axis, ignore_index):\n        frame_c = DataFrame(np.zeros((10000, 200), dtype=np.float32, order=\"C\"))\n        self.frame_c = [frame_c] * 20\n        frame_f = DataFrame(np.zeros((10000, 200), dtype=np.float32, order=\"F\"))\n        self.frame_f = [frame_f] * 20", "min_run_count": 2, "name": "join_merge.ConcatDataFrames.time_f_ordered", "number": 0, "param_names": ["axis", "ignore_index"], "params": [["0", "1"], ["True", "False"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "4ae3b6dda3a99cfd094de14c2550530e69a1ede87ff9911c02706ef1acf501eb", "warmup_time": -1}, "join_merge.ConcatIndexDtype.time_concat_series": {"code": "class ConcatIndexDtype:\n    def time_concat_series(self, dtype, structure, axis, sort):\n        concat(self.series, axis=axis, sort=sort)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ConcatIndexDtype:\n    def setup(self, dtype, structure, axis, sort):\n        N = 10_000\n        if dtype == \"datetime64[ns]\":\n            vals = date_range(\"1970-01-01\", periods=N)\n        elif dtype in (\"int64\", \"Int64\", \"int64[pyarrow]\"):\n            vals = np.arange(N, dtype=np.int64)\n        elif dtype in (\"string[python]\", \"string[pyarrow]\"):\n            vals = Index([f\"i-{i}\" for i in range(N)], dtype=object)\n        else:\n            raise NotImplementedError\n    \n        idx = Index(vals, dtype=dtype)\n    \n        if structure == \"monotonic\":\n            idx = idx.sort_values()\n        elif structure == \"non_monotonic\":\n            idx = idx[::-1]\n        elif structure == \"has_na\":\n            if not idx._can_hold_na:\n                raise NotImplementedError\n            idx = Index([None], dtype=dtype).append(idx)\n        else:\n            raise NotImplementedError\n    \n        self.series = [Series(i, idx[:-i]) for i in range(1, 6)]", "min_run_count": 2, "name": "join_merge.ConcatIndexDtype.time_concat_series", "number": 0, "param_names": ["dtype", "structure", "axis", "sort"], "params": [["'datetime64[ns]'", "'int64'", "'Int64'", "'int64[pyarrow]'", "'string[python]'", "'string[pyarrow]'"], ["'monotonic'", "'non_monotonic'", "'has_na'"], ["0", "1"], ["True", "False"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "3f0be47c3aec82696fed8b66f103fb17e1c8ade9f27aed2205614c881c60a48a", "warmup_time": -1}, "join_merge.I8Merge.time_i8merge": {"code": "class I8Merge:\n    def time_i8merge(self, how):\n        merge(self.left, self.right, how=how)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass I8Merge:\n    def setup(self, how):\n        low, high, n = -1000, 1000, 10**6\n        self.left = DataFrame(\n            np.random.randint(low, high, (n, 7)), columns=list(\"ABCDEFG\")\n        )\n        self.left[\"left\"] = self.left.sum(axis=1)\n        self.right = self.left.sample(frac=1).rename({\"left\": \"right\"}, axis=1)\n        self.right = self.right.reset_index(drop=True)\n        self.right[\"right\"] *= -1", "min_run_count": 2, "name": "join_merge.I8Merge.time_i8merge", "number": 0, "param_names": ["how"], "params": [["'inner'", "'outer'", "'left'", "'right'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "d4abb49d5f599a151d5e78dad2990f16fe5bf60710912a404da24856006a297a", "warmup_time": -1}, "join_merge.Join.time_join_dataframe_index_multi": {"code": "class Join:\n    def time_join_dataframe_index_multi(self, sort):\n        self.df.join(self.df_multi, on=[\"key1\", \"key2\"], sort=sort)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Join:\n    def setup(self, sort):\n        level1 = Index([f\"i-{i}\" for i in range(10)], dtype=object).values\n        level2 = Index([f\"i-{i}\" for i in range(1000)], dtype=object).values\n        codes1 = np.arange(10).repeat(1000)\n        codes2 = np.tile(np.arange(1000), 10)\n        index2 = MultiIndex(levels=[level1, level2], codes=[codes1, codes2])\n        self.df_multi = DataFrame(\n            np.random.randn(len(index2), 4), index=index2, columns=[\"A\", \"B\", \"C\", \"D\"]\n        )\n    \n        self.key1 = np.tile(level1.take(codes1), 10)\n        self.key2 = np.tile(level2.take(codes2), 10)\n        self.df = DataFrame(\n            {\n                \"data1\": np.random.randn(100000),\n                \"data2\": np.random.randn(100000),\n                \"key1\": self.key1,\n                \"key2\": self.key2,\n            }\n        )\n    \n        self.df_key1 = DataFrame(\n            np.random.randn(len(level1), 4), index=level1, columns=[\"A\", \"B\", \"C\", \"D\"]\n        )\n        self.df_key2 = DataFrame(\n            np.random.randn(len(level2), 4), index=level2, columns=[\"A\", \"B\", \"C\", \"D\"]\n        )\n    \n        shuf = np.arange(100000)\n        np.random.shuffle(shuf)\n        self.df_shuf = self.df.reindex(self.df.index[shuf])", "min_run_count": 2, "name": "join_merge.Join.time_join_dataframe_index_multi", "number": 0, "param_names": ["sort"], "params": [["True", "False"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "4333bf6cde7671e71926340c558300735ccf5294d204d4e0c4c81a51d019eb1c", "warmup_time": -1}, "join_merge.Join.time_join_dataframe_index_shuffle_key_bigger_sort": {"code": "class Join:\n    def time_join_dataframe_index_shuffle_key_bigger_sort(self, sort):\n        self.df_shuf.join(self.df_key2, on=\"key2\", sort=sort)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Join:\n    def setup(self, sort):\n        level1 = Index([f\"i-{i}\" for i in range(10)], dtype=object).values\n        level2 = Index([f\"i-{i}\" for i in range(1000)], dtype=object).values\n        codes1 = np.arange(10).repeat(1000)\n        codes2 = np.tile(np.arange(1000), 10)\n        index2 = MultiIndex(levels=[level1, level2], codes=[codes1, codes2])\n        self.df_multi = DataFrame(\n            np.random.randn(len(index2), 4), index=index2, columns=[\"A\", \"B\", \"C\", \"D\"]\n        )\n    \n        self.key1 = np.tile(level1.take(codes1), 10)\n        self.key2 = np.tile(level2.take(codes2), 10)\n        self.df = DataFrame(\n            {\n                \"data1\": np.random.randn(100000),\n                \"data2\": np.random.randn(100000),\n                \"key1\": self.key1,\n                \"key2\": self.key2,\n            }\n        )\n    \n        self.df_key1 = DataFrame(\n            np.random.randn(len(level1), 4), index=level1, columns=[\"A\", \"B\", \"C\", \"D\"]\n        )\n        self.df_key2 = DataFrame(\n            np.random.randn(len(level2), 4), index=level2, columns=[\"A\", \"B\", \"C\", \"D\"]\n        )\n    \n        shuf = np.arange(100000)\n        np.random.shuffle(shuf)\n        self.df_shuf = self.df.reindex(self.df.index[shuf])", "min_run_count": 2, "name": "join_merge.Join.time_join_dataframe_index_shuffle_key_bigger_sort", "number": 0, "param_names": ["sort"], "params": [["True", "False"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "c4db5e399d8b3f5fe10c825360367198fb61e0ea906c2842d56ec531c4cd5f97", "warmup_time": -1}, "join_merge.Join.time_join_dataframe_index_single_key_bigger": {"code": "class Join:\n    def time_join_dataframe_index_single_key_bigger(self, sort):\n        self.df.join(self.df_key2, on=\"key2\", sort=sort)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Join:\n    def setup(self, sort):\n        level1 = Index([f\"i-{i}\" for i in range(10)], dtype=object).values\n        level2 = Index([f\"i-{i}\" for i in range(1000)], dtype=object).values\n        codes1 = np.arange(10).repeat(1000)\n        codes2 = np.tile(np.arange(1000), 10)\n        index2 = MultiIndex(levels=[level1, level2], codes=[codes1, codes2])\n        self.df_multi = DataFrame(\n            np.random.randn(len(index2), 4), index=index2, columns=[\"A\", \"B\", \"C\", \"D\"]\n        )\n    \n        self.key1 = np.tile(level1.take(codes1), 10)\n        self.key2 = np.tile(level2.take(codes2), 10)\n        self.df = DataFrame(\n            {\n                \"data1\": np.random.randn(100000),\n                \"data2\": np.random.randn(100000),\n                \"key1\": self.key1,\n                \"key2\": self.key2,\n            }\n        )\n    \n        self.df_key1 = DataFrame(\n            np.random.randn(len(level1), 4), index=level1, columns=[\"A\", \"B\", \"C\", \"D\"]\n        )\n        self.df_key2 = DataFrame(\n            np.random.randn(len(level2), 4), index=level2, columns=[\"A\", \"B\", \"C\", \"D\"]\n        )\n    \n        shuf = np.arange(100000)\n        np.random.shuffle(shuf)\n        self.df_shuf = self.df.reindex(self.df.index[shuf])", "min_run_count": 2, "name": "join_merge.Join.time_join_dataframe_index_single_key_bigger", "number": 0, "param_names": ["sort"], "params": [["True", "False"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "c91255828f8625e649458aaa81a177dd077c288fe7beb2a8349f154536f30000", "warmup_time": -1}, "join_merge.Join.time_join_dataframe_index_single_key_small": {"code": "class Join:\n    def time_join_dataframe_index_single_key_small(self, sort):\n        self.df.join(self.df_key1, on=\"key1\", sort=sort)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Join:\n    def setup(self, sort):\n        level1 = Index([f\"i-{i}\" for i in range(10)], dtype=object).values\n        level2 = Index([f\"i-{i}\" for i in range(1000)], dtype=object).values\n        codes1 = np.arange(10).repeat(1000)\n        codes2 = np.tile(np.arange(1000), 10)\n        index2 = MultiIndex(levels=[level1, level2], codes=[codes1, codes2])\n        self.df_multi = DataFrame(\n            np.random.randn(len(index2), 4), index=index2, columns=[\"A\", \"B\", \"C\", \"D\"]\n        )\n    \n        self.key1 = np.tile(level1.take(codes1), 10)\n        self.key2 = np.tile(level2.take(codes2), 10)\n        self.df = DataFrame(\n            {\n                \"data1\": np.random.randn(100000),\n                \"data2\": np.random.randn(100000),\n                \"key1\": self.key1,\n                \"key2\": self.key2,\n            }\n        )\n    \n        self.df_key1 = DataFrame(\n            np.random.randn(len(level1), 4), index=level1, columns=[\"A\", \"B\", \"C\", \"D\"]\n        )\n        self.df_key2 = DataFrame(\n            np.random.randn(len(level2), 4), index=level2, columns=[\"A\", \"B\", \"C\", \"D\"]\n        )\n    \n        shuf = np.arange(100000)\n        np.random.shuffle(shuf)\n        self.df_shuf = self.df.reindex(self.df.index[shuf])", "min_run_count": 2, "name": "join_merge.Join.time_join_dataframe_index_single_key_small", "number": 0, "param_names": ["sort"], "params": [["True", "False"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "eec67ca32224c312bdba6f34b701b8fcea4192407ff25bca0a093889a2c86f01", "warmup_time": -1}, "join_merge.Join.time_join_dataframes_cross": {"code": "class Join:\n    def time_join_dataframes_cross(self, sort):\n        self.df.loc[:2000].join(self.df_key1, how=\"cross\", sort=sort)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Join:\n    def setup(self, sort):\n        level1 = Index([f\"i-{i}\" for i in range(10)], dtype=object).values\n        level2 = Index([f\"i-{i}\" for i in range(1000)], dtype=object).values\n        codes1 = np.arange(10).repeat(1000)\n        codes2 = np.tile(np.arange(1000), 10)\n        index2 = MultiIndex(levels=[level1, level2], codes=[codes1, codes2])\n        self.df_multi = DataFrame(\n            np.random.randn(len(index2), 4), index=index2, columns=[\"A\", \"B\", \"C\", \"D\"]\n        )\n    \n        self.key1 = np.tile(level1.take(codes1), 10)\n        self.key2 = np.tile(level2.take(codes2), 10)\n        self.df = DataFrame(\n            {\n                \"data1\": np.random.randn(100000),\n                \"data2\": np.random.randn(100000),\n                \"key1\": self.key1,\n                \"key2\": self.key2,\n            }\n        )\n    \n        self.df_key1 = DataFrame(\n            np.random.randn(len(level1), 4), index=level1, columns=[\"A\", \"B\", \"C\", \"D\"]\n        )\n        self.df_key2 = DataFrame(\n            np.random.randn(len(level2), 4), index=level2, columns=[\"A\", \"B\", \"C\", \"D\"]\n        )\n    \n        shuf = np.arange(100000)\n        np.random.shuffle(shuf)\n        self.df_shuf = self.df.reindex(self.df.index[shuf])", "min_run_count": 2, "name": "join_merge.Join.time_join_dataframes_cross", "number": 0, "param_names": ["sort"], "params": [["True", "False"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "3a48d807904c7c932eb0f8012602129fcf2c528ffbf8a19bb5af2fa0084b6b29", "warmup_time": -1}, "join_merge.JoinEmpty.time_inner_join_left_empty": {"code": "class JoinEmpty:\n    def time_inner_join_left_empty(self):\n        self.df_empty.join(self.df, how=\"inner\")\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass JoinEmpty:\n    def setup(self):\n        N = 100_000\n        self.df = DataFrame({\"A\": np.arange(N)})\n        self.df_empty = DataFrame(columns=[\"B\", \"C\"], dtype=\"int64\")", "min_run_count": 2, "name": "join_merge.JoinEmpty.time_inner_join_left_empty", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "bfdd1b4564785774724d06a1078e1417803a55bc67f678a1cdd417a1aedc2f04", "warmup_time": -1}, "join_merge.JoinEmpty.time_inner_join_right_empty": {"code": "class JoinEmpty:\n    def time_inner_join_right_empty(self):\n        self.df.join(self.df_empty, how=\"inner\")\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass JoinEmpty:\n    def setup(self):\n        N = 100_000\n        self.df = DataFrame({\"A\": np.arange(N)})\n        self.df_empty = DataFrame(columns=[\"B\", \"C\"], dtype=\"int64\")", "min_run_count": 2, "name": "join_merge.JoinEmpty.time_inner_join_right_empty", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "dcfe17741af364f20337e68e1210e4775f3da625571f7a163b7a94dd7ba6ab00", "warmup_time": -1}, "join_merge.JoinIndex.time_left_outer_join_index": {"code": "class JoinIndex:\n    def time_left_outer_join_index(self):\n        self.left.join(self.right, on=\"jim\")\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass JoinIndex:\n    def setup(self):\n        N = 5000\n        self.left = DataFrame(\n            np.random.randint(1, N / 50, (N, 2)), columns=[\"jim\", \"joe\"]\n        )\n        self.right = DataFrame(\n            np.random.randint(1, N / 50, (N, 2)), columns=[\"jolie\", \"jolia\"]\n        ).set_index(\"jolie\")", "min_run_count": 2, "name": "join_merge.JoinIndex.time_left_outer_join_index", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "1745a459c7417d954ba2b1543c89580f2da4fae87754d704488eb8a230577907", "warmup_time": -1}, "join_merge.JoinMultiindexSubset.time_join_multiindex_subset": {"code": "class JoinMultiindexSubset:\n    def time_join_multiindex_subset(self):\n        self.left.join(self.right)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass JoinMultiindexSubset:\n    def setup(self):\n        N = 100_000\n        mi1 = MultiIndex.from_arrays([np.arange(N)] * 4, names=[\"a\", \"b\", \"c\", \"d\"])\n        mi2 = MultiIndex.from_arrays([np.arange(N)] * 2, names=[\"a\", \"b\"])\n        self.left = DataFrame({\"col1\": 1}, index=mi1)\n        self.right = DataFrame({\"col2\": 2}, index=mi2)", "min_run_count": 2, "name": "join_merge.JoinMultiindexSubset.time_join_multiindex_subset", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "27bf46b67e61ae20d7d34733a62c67fd8dd46b37dcd0a578e046d57b6c6a5751", "warmup_time": -1}, "join_merge.JoinNonUnique.time_join_non_unique_equal": {"code": "class JoinNonUnique:\n    def time_join_non_unique_equal(self):\n        self.fracofday * self.temp\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass JoinNonUnique:\n    def setup(self):\n        date_index = date_range(\"01-Jan-2013\", \"23-Jan-2013\", freq=\"min\")\n        daily_dates = date_index.to_period(\"D\").to_timestamp(\"s\", \"s\")\n        self.fracofday = date_index.values - daily_dates.values\n        self.fracofday = self.fracofday.astype(\"timedelta64[ns]\")\n        self.fracofday = self.fracofday.astype(np.float64) / 86_400_000_000_000\n        self.fracofday = Series(self.fracofday, daily_dates)\n        index = date_range(date_index.min(), date_index.max(), freq=\"D\")\n        self.temp = Series(1.0, index)[self.fracofday.index]", "min_run_count": 2, "name": "join_merge.JoinNonUnique.time_join_non_unique_equal", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "0e34c149af187b7f4eaa9c905928f5605dabce492f1114f9878a83fcfa4be311", "warmup_time": -1}, "join_merge.Merge.time_merge_2intkey": {"code": "class Merge:\n    def time_merge_2intkey(self, sort):\n        merge(self.left, self.right, sort=sort)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Merge:\n    def setup(self, sort):\n        N = 10000\n        indices = Index([f\"i-{i}\" for i in range(N)], dtype=object).values\n        indices2 = Index([f\"i-{i}\" for i in range(N)], dtype=object).values\n        key = np.tile(indices[:8000], 10)\n        key2 = np.tile(indices2[:8000], 10)\n        self.left = DataFrame(\n            {\"key\": key, \"key2\": key2, \"value\": np.random.randn(80000)}\n        )\n        self.right = DataFrame(\n            {\n                \"key\": indices[2000:],\n                \"key2\": indices2[2000:],\n                \"value2\": np.random.randn(8000),\n            }\n        )\n    \n        self.df = DataFrame(\n            {\n                \"key1\": np.tile(np.arange(500).repeat(10), 2),\n                \"key2\": np.tile(np.arange(250).repeat(10), 4),\n                \"value\": np.random.randn(10000),\n            }\n        )\n        self.df2 = DataFrame({\"key1\": np.arange(500), \"value2\": np.random.randn(500)})\n        self.df3 = self.df[:5000]", "min_run_count": 2, "name": "join_merge.Merge.time_merge_2intkey", "number": 0, "param_names": ["sort"], "params": [["True", "False"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "02c985ca0f91e858a760146877c62a3ce45e8e49ad16d9cf150e01a8e45d60f8", "warmup_time": -1}, "join_merge.Merge.time_merge_dataframe_empty_left": {"code": "class Merge:\n    def time_merge_dataframe_empty_left(self, sort):\n        merge(self.left.iloc[:0], self.right, sort=sort)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Merge:\n    def setup(self, sort):\n        N = 10000\n        indices = Index([f\"i-{i}\" for i in range(N)], dtype=object).values\n        indices2 = Index([f\"i-{i}\" for i in range(N)], dtype=object).values\n        key = np.tile(indices[:8000], 10)\n        key2 = np.tile(indices2[:8000], 10)\n        self.left = DataFrame(\n            {\"key\": key, \"key2\": key2, \"value\": np.random.randn(80000)}\n        )\n        self.right = DataFrame(\n            {\n                \"key\": indices[2000:],\n                \"key2\": indices2[2000:],\n                \"value2\": np.random.randn(8000),\n            }\n        )\n    \n        self.df = DataFrame(\n            {\n                \"key1\": np.tile(np.arange(500).repeat(10), 2),\n                \"key2\": np.tile(np.arange(250).repeat(10), 4),\n                \"value\": np.random.randn(10000),\n            }\n        )\n        self.df2 = DataFrame({\"key1\": np.arange(500), \"value2\": np.random.randn(500)})\n        self.df3 = self.df[:5000]", "min_run_count": 2, "name": "join_merge.Merge.time_merge_dataframe_empty_left", "number": 0, "param_names": ["sort"], "params": [["True", "False"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "5385d6eda16a400f6398618dc87406e053b44c3237148b4a88ee3af3bd997e7e", "warmup_time": -1}, "join_merge.Merge.time_merge_dataframe_empty_right": {"code": "class Merge:\n    def time_merge_dataframe_empty_right(self, sort):\n        merge(self.left, self.right.iloc[:0], sort=sort)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Merge:\n    def setup(self, sort):\n        N = 10000\n        indices = Index([f\"i-{i}\" for i in range(N)], dtype=object).values\n        indices2 = Index([f\"i-{i}\" for i in range(N)], dtype=object).values\n        key = np.tile(indices[:8000], 10)\n        key2 = np.tile(indices2[:8000], 10)\n        self.left = DataFrame(\n            {\"key\": key, \"key2\": key2, \"value\": np.random.randn(80000)}\n        )\n        self.right = DataFrame(\n            {\n                \"key\": indices[2000:],\n                \"key2\": indices2[2000:],\n                \"value2\": np.random.randn(8000),\n            }\n        )\n    \n        self.df = DataFrame(\n            {\n                \"key1\": np.tile(np.arange(500).repeat(10), 2),\n                \"key2\": np.tile(np.arange(250).repeat(10), 4),\n                \"value\": np.random.randn(10000),\n            }\n        )\n        self.df2 = DataFrame({\"key1\": np.arange(500), \"value2\": np.random.randn(500)})\n        self.df3 = self.df[:5000]", "min_run_count": 2, "name": "join_merge.Merge.time_merge_dataframe_empty_right", "number": 0, "param_names": ["sort"], "params": [["True", "False"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "1c458073428462f9afadf4c68a397a523995779eb31f4ba9dfa01d7b1c86853d", "warmup_time": -1}, "join_merge.Merge.time_merge_dataframe_integer_2key": {"code": "class Merge:\n    def time_merge_dataframe_integer_2key(self, sort):\n        merge(self.df, self.df3, sort=sort)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Merge:\n    def setup(self, sort):\n        N = 10000\n        indices = Index([f\"i-{i}\" for i in range(N)], dtype=object).values\n        indices2 = Index([f\"i-{i}\" for i in range(N)], dtype=object).values\n        key = np.tile(indices[:8000], 10)\n        key2 = np.tile(indices2[:8000], 10)\n        self.left = DataFrame(\n            {\"key\": key, \"key2\": key2, \"value\": np.random.randn(80000)}\n        )\n        self.right = DataFrame(\n            {\n                \"key\": indices[2000:],\n                \"key2\": indices2[2000:],\n                \"value2\": np.random.randn(8000),\n            }\n        )\n    \n        self.df = DataFrame(\n            {\n                \"key1\": np.tile(np.arange(500).repeat(10), 2),\n                \"key2\": np.tile(np.arange(250).repeat(10), 4),\n                \"value\": np.random.randn(10000),\n            }\n        )\n        self.df2 = DataFrame({\"key1\": np.arange(500), \"value2\": np.random.randn(500)})\n        self.df3 = self.df[:5000]", "min_run_count": 2, "name": "join_merge.Merge.time_merge_dataframe_integer_2key", "number": 0, "param_names": ["sort"], "params": [["True", "False"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "82965bb5c88367b7ca51c2841a96d09f5e13ef409582a2df03886b979a391141", "warmup_time": -1}, "join_merge.Merge.time_merge_dataframe_integer_key": {"code": "class Merge:\n    def time_merge_dataframe_integer_key(self, sort):\n        merge(self.df, self.df2, on=\"key1\", sort=sort)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Merge:\n    def setup(self, sort):\n        N = 10000\n        indices = Index([f\"i-{i}\" for i in range(N)], dtype=object).values\n        indices2 = Index([f\"i-{i}\" for i in range(N)], dtype=object).values\n        key = np.tile(indices[:8000], 10)\n        key2 = np.tile(indices2[:8000], 10)\n        self.left = DataFrame(\n            {\"key\": key, \"key2\": key2, \"value\": np.random.randn(80000)}\n        )\n        self.right = DataFrame(\n            {\n                \"key\": indices[2000:],\n                \"key2\": indices2[2000:],\n                \"value2\": np.random.randn(8000),\n            }\n        )\n    \n        self.df = DataFrame(\n            {\n                \"key1\": np.tile(np.arange(500).repeat(10), 2),\n                \"key2\": np.tile(np.arange(250).repeat(10), 4),\n                \"value\": np.random.randn(10000),\n            }\n        )\n        self.df2 = DataFrame({\"key1\": np.arange(500), \"value2\": np.random.randn(500)})\n        self.df3 = self.df[:5000]", "min_run_count": 2, "name": "join_merge.Merge.time_merge_dataframe_integer_key", "number": 0, "param_names": ["sort"], "params": [["True", "False"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "2de11a2e31283d7107f028ba38e3768119a8b6727421ad035d81d7523bc31df5", "warmup_time": -1}, "join_merge.Merge.time_merge_dataframes_cross": {"code": "class Merge:\n    def time_merge_dataframes_cross(self, sort):\n        merge(self.left.loc[:2000], self.right.loc[:2000], how=\"cross\", sort=sort)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Merge:\n    def setup(self, sort):\n        N = 10000\n        indices = Index([f\"i-{i}\" for i in range(N)], dtype=object).values\n        indices2 = Index([f\"i-{i}\" for i in range(N)], dtype=object).values\n        key = np.tile(indices[:8000], 10)\n        key2 = np.tile(indices2[:8000], 10)\n        self.left = DataFrame(\n            {\"key\": key, \"key2\": key2, \"value\": np.random.randn(80000)}\n        )\n        self.right = DataFrame(\n            {\n                \"key\": indices[2000:],\n                \"key2\": indices2[2000:],\n                \"value2\": np.random.randn(8000),\n            }\n        )\n    \n        self.df = DataFrame(\n            {\n                \"key1\": np.tile(np.arange(500).repeat(10), 2),\n                \"key2\": np.tile(np.arange(250).repeat(10), 4),\n                \"value\": np.random.randn(10000),\n            }\n        )\n        self.df2 = DataFrame({\"key1\": np.arange(500), \"value2\": np.random.randn(500)})\n        self.df3 = self.df[:5000]", "min_run_count": 2, "name": "join_merge.Merge.time_merge_dataframes_cross", "number": 0, "param_names": ["sort"], "params": [["True", "False"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "16ca5aa7ee0537da110abb59b4c2c6890937b10500617006e027f576afa9bf99", "warmup_time": -1}, "join_merge.MergeAsof.time_by_int": {"code": "class MergeAsof:\n    def time_by_int(self, direction, tolerance):\n        merge_asof(\n            self.df1c,\n            self.df2c,\n            on=\"time\",\n            by=\"key2\",\n            direction=direction,\n            tolerance=tolerance,\n        )\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass MergeAsof:\n    def setup(self, direction, tolerance):\n        one_count = 200000\n        two_count = 1000000\n    \n        df1 = DataFrame(\n            {\n                \"time\": np.random.randint(0, one_count / 20, one_count),\n                \"key\": np.random.choice(list(string.ascii_uppercase), one_count),\n                \"key2\": np.random.randint(0, 25, one_count),\n                \"value1\": np.random.randn(one_count),\n            }\n        )\n        df2 = DataFrame(\n            {\n                \"time\": np.random.randint(0, two_count / 20, two_count),\n                \"key\": np.random.choice(list(string.ascii_uppercase), two_count),\n                \"key2\": np.random.randint(0, 25, two_count),\n                \"value2\": np.random.randn(two_count),\n            }\n        )\n    \n        df1 = df1.sort_values(\"time\")\n        df2 = df2.sort_values(\"time\")\n    \n        df1[\"time32\"] = np.int32(df1.time)\n        df2[\"time32\"] = np.int32(df2.time)\n    \n        df1[\"timeu64\"] = np.uint64(df1.time)\n        df2[\"timeu64\"] = np.uint64(df2.time)\n    \n        self.df1a = df1[[\"time\", \"value1\"]]\n        self.df2a = df2[[\"time\", \"value2\"]]\n        self.df1b = df1[[\"time\", \"key\", \"value1\"]]\n        self.df2b = df2[[\"time\", \"key\", \"value2\"]]\n        self.df1c = df1[[\"time\", \"key2\", \"value1\"]]\n        self.df2c = df2[[\"time\", \"key2\", \"value2\"]]\n        self.df1d = df1[[\"time32\", \"value1\"]]\n        self.df2d = df2[[\"time32\", \"value2\"]]\n        self.df1e = df1[[\"time\", \"key\", \"key2\", \"value1\"]]\n        self.df2e = df2[[\"time\", \"key\", \"key2\", \"value2\"]]\n        self.df1f = df1[[\"timeu64\", \"value1\"]]\n        self.df2f = df2[[\"timeu64\", \"value2\"]]", "min_run_count": 2, "name": "join_merge.MergeAsof.time_by_int", "number": 0, "param_names": ["direction", "tolerance"], "params": [["'backward'", "'forward'", "'nearest'"], ["None", "5"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "9388814b37a8f7c3e8196e0e5e974f1114e5d09931e00ac3f102f86743babca9", "warmup_time": -1}, "join_merge.MergeAsof.time_by_object": {"code": "class MergeAsof:\n    def time_by_object(self, direction, tolerance):\n        merge_asof(\n            self.df1b,\n            self.df2b,\n            on=\"time\",\n            by=\"key\",\n            direction=direction,\n            tolerance=tolerance,\n        )\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass MergeAsof:\n    def setup(self, direction, tolerance):\n        one_count = 200000\n        two_count = 1000000\n    \n        df1 = DataFrame(\n            {\n                \"time\": np.random.randint(0, one_count / 20, one_count),\n                \"key\": np.random.choice(list(string.ascii_uppercase), one_count),\n                \"key2\": np.random.randint(0, 25, one_count),\n                \"value1\": np.random.randn(one_count),\n            }\n        )\n        df2 = DataFrame(\n            {\n                \"time\": np.random.randint(0, two_count / 20, two_count),\n                \"key\": np.random.choice(list(string.ascii_uppercase), two_count),\n                \"key2\": np.random.randint(0, 25, two_count),\n                \"value2\": np.random.randn(two_count),\n            }\n        )\n    \n        df1 = df1.sort_values(\"time\")\n        df2 = df2.sort_values(\"time\")\n    \n        df1[\"time32\"] = np.int32(df1.time)\n        df2[\"time32\"] = np.int32(df2.time)\n    \n        df1[\"timeu64\"] = np.uint64(df1.time)\n        df2[\"timeu64\"] = np.uint64(df2.time)\n    \n        self.df1a = df1[[\"time\", \"value1\"]]\n        self.df2a = df2[[\"time\", \"value2\"]]\n        self.df1b = df1[[\"time\", \"key\", \"value1\"]]\n        self.df2b = df2[[\"time\", \"key\", \"value2\"]]\n        self.df1c = df1[[\"time\", \"key2\", \"value1\"]]\n        self.df2c = df2[[\"time\", \"key2\", \"value2\"]]\n        self.df1d = df1[[\"time32\", \"value1\"]]\n        self.df2d = df2[[\"time32\", \"value2\"]]\n        self.df1e = df1[[\"time\", \"key\", \"key2\", \"value1\"]]\n        self.df2e = df2[[\"time\", \"key\", \"key2\", \"value2\"]]\n        self.df1f = df1[[\"timeu64\", \"value1\"]]\n        self.df2f = df2[[\"timeu64\", \"value2\"]]", "min_run_count": 2, "name": "join_merge.MergeAsof.time_by_object", "number": 0, "param_names": ["direction", "tolerance"], "params": [["'backward'", "'forward'", "'nearest'"], ["None", "5"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "164ee691bc50a6d10e4f62c99daae4dce68786d7b02f5bd35af7bf33191d0405", "warmup_time": -1}, "join_merge.MergeAsof.time_multiby": {"code": "class MergeAsof:\n    def time_multiby(self, direction, tolerance):\n        merge_asof(\n            self.df1e,\n            self.df2e,\n            on=\"time\",\n            by=[\"key\", \"key2\"],\n            direction=direction,\n            tolerance=tolerance,\n        )\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass MergeAsof:\n    def setup(self, direction, tolerance):\n        one_count = 200000\n        two_count = 1000000\n    \n        df1 = DataFrame(\n            {\n                \"time\": np.random.randint(0, one_count / 20, one_count),\n                \"key\": np.random.choice(list(string.ascii_uppercase), one_count),\n                \"key2\": np.random.randint(0, 25, one_count),\n                \"value1\": np.random.randn(one_count),\n            }\n        )\n        df2 = DataFrame(\n            {\n                \"time\": np.random.randint(0, two_count / 20, two_count),\n                \"key\": np.random.choice(list(string.ascii_uppercase), two_count),\n                \"key2\": np.random.randint(0, 25, two_count),\n                \"value2\": np.random.randn(two_count),\n            }\n        )\n    \n        df1 = df1.sort_values(\"time\")\n        df2 = df2.sort_values(\"time\")\n    \n        df1[\"time32\"] = np.int32(df1.time)\n        df2[\"time32\"] = np.int32(df2.time)\n    \n        df1[\"timeu64\"] = np.uint64(df1.time)\n        df2[\"timeu64\"] = np.uint64(df2.time)\n    \n        self.df1a = df1[[\"time\", \"value1\"]]\n        self.df2a = df2[[\"time\", \"value2\"]]\n        self.df1b = df1[[\"time\", \"key\", \"value1\"]]\n        self.df2b = df2[[\"time\", \"key\", \"value2\"]]\n        self.df1c = df1[[\"time\", \"key2\", \"value1\"]]\n        self.df2c = df2[[\"time\", \"key2\", \"value2\"]]\n        self.df1d = df1[[\"time32\", \"value1\"]]\n        self.df2d = df2[[\"time32\", \"value2\"]]\n        self.df1e = df1[[\"time\", \"key\", \"key2\", \"value1\"]]\n        self.df2e = df2[[\"time\", \"key\", \"key2\", \"value2\"]]\n        self.df1f = df1[[\"timeu64\", \"value1\"]]\n        self.df2f = df2[[\"timeu64\", \"value2\"]]", "min_run_count": 2, "name": "join_merge.MergeAsof.time_multiby", "number": 0, "param_names": ["direction", "tolerance"], "params": [["'backward'", "'forward'", "'nearest'"], ["None", "5"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "464ed78df4c5a78bcd7350edc12851af5dd87d18c63ed889b0ee80e806eed6a1", "warmup_time": -1}, "join_merge.MergeAsof.time_on_int": {"code": "class MergeAsof:\n    def time_on_int(self, direction, tolerance):\n        merge_asof(\n            self.df1a, self.df2a, on=\"time\", direction=direction, tolerance=tolerance\n        )\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass MergeAsof:\n    def setup(self, direction, tolerance):\n        one_count = 200000\n        two_count = 1000000\n    \n        df1 = DataFrame(\n            {\n                \"time\": np.random.randint(0, one_count / 20, one_count),\n                \"key\": np.random.choice(list(string.ascii_uppercase), one_count),\n                \"key2\": np.random.randint(0, 25, one_count),\n                \"value1\": np.random.randn(one_count),\n            }\n        )\n        df2 = DataFrame(\n            {\n                \"time\": np.random.randint(0, two_count / 20, two_count),\n                \"key\": np.random.choice(list(string.ascii_uppercase), two_count),\n                \"key2\": np.random.randint(0, 25, two_count),\n                \"value2\": np.random.randn(two_count),\n            }\n        )\n    \n        df1 = df1.sort_values(\"time\")\n        df2 = df2.sort_values(\"time\")\n    \n        df1[\"time32\"] = np.int32(df1.time)\n        df2[\"time32\"] = np.int32(df2.time)\n    \n        df1[\"timeu64\"] = np.uint64(df1.time)\n        df2[\"timeu64\"] = np.uint64(df2.time)\n    \n        self.df1a = df1[[\"time\", \"value1\"]]\n        self.df2a = df2[[\"time\", \"value2\"]]\n        self.df1b = df1[[\"time\", \"key\", \"value1\"]]\n        self.df2b = df2[[\"time\", \"key\", \"value2\"]]\n        self.df1c = df1[[\"time\", \"key2\", \"value1\"]]\n        self.df2c = df2[[\"time\", \"key2\", \"value2\"]]\n        self.df1d = df1[[\"time32\", \"value1\"]]\n        self.df2d = df2[[\"time32\", \"value2\"]]\n        self.df1e = df1[[\"time\", \"key\", \"key2\", \"value1\"]]\n        self.df2e = df2[[\"time\", \"key\", \"key2\", \"value2\"]]\n        self.df1f = df1[[\"timeu64\", \"value1\"]]\n        self.df2f = df2[[\"timeu64\", \"value2\"]]", "min_run_count": 2, "name": "join_merge.MergeAsof.time_on_int", "number": 0, "param_names": ["direction", "tolerance"], "params": [["'backward'", "'forward'", "'nearest'"], ["None", "5"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "a0ba76e01b99515f8c84950f1a4683fb1e2b601110a25798072287f3d1574ca1", "warmup_time": -1}, "join_merge.MergeAsof.time_on_int32": {"code": "class MergeAsof:\n    def time_on_int32(self, direction, tolerance):\n        merge_asof(\n            self.df1d, self.df2d, on=\"time32\", direction=direction, tolerance=tolerance\n        )\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass MergeAsof:\n    def setup(self, direction, tolerance):\n        one_count = 200000\n        two_count = 1000000\n    \n        df1 = DataFrame(\n            {\n                \"time\": np.random.randint(0, one_count / 20, one_count),\n                \"key\": np.random.choice(list(string.ascii_uppercase), one_count),\n                \"key2\": np.random.randint(0, 25, one_count),\n                \"value1\": np.random.randn(one_count),\n            }\n        )\n        df2 = DataFrame(\n            {\n                \"time\": np.random.randint(0, two_count / 20, two_count),\n                \"key\": np.random.choice(list(string.ascii_uppercase), two_count),\n                \"key2\": np.random.randint(0, 25, two_count),\n                \"value2\": np.random.randn(two_count),\n            }\n        )\n    \n        df1 = df1.sort_values(\"time\")\n        df2 = df2.sort_values(\"time\")\n    \n        df1[\"time32\"] = np.int32(df1.time)\n        df2[\"time32\"] = np.int32(df2.time)\n    \n        df1[\"timeu64\"] = np.uint64(df1.time)\n        df2[\"timeu64\"] = np.uint64(df2.time)\n    \n        self.df1a = df1[[\"time\", \"value1\"]]\n        self.df2a = df2[[\"time\", \"value2\"]]\n        self.df1b = df1[[\"time\", \"key\", \"value1\"]]\n        self.df2b = df2[[\"time\", \"key\", \"value2\"]]\n        self.df1c = df1[[\"time\", \"key2\", \"value1\"]]\n        self.df2c = df2[[\"time\", \"key2\", \"value2\"]]\n        self.df1d = df1[[\"time32\", \"value1\"]]\n        self.df2d = df2[[\"time32\", \"value2\"]]\n        self.df1e = df1[[\"time\", \"key\", \"key2\", \"value1\"]]\n        self.df2e = df2[[\"time\", \"key\", \"key2\", \"value2\"]]\n        self.df1f = df1[[\"timeu64\", \"value1\"]]\n        self.df2f = df2[[\"timeu64\", \"value2\"]]", "min_run_count": 2, "name": "join_merge.MergeAsof.time_on_int32", "number": 0, "param_names": ["direction", "tolerance"], "params": [["'backward'", "'forward'", "'nearest'"], ["None", "5"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "5c26b3578593ec04d313f1cbf97df60936516fb7691a67ad03f78d68554fa57f", "warmup_time": -1}, "join_merge.MergeAsof.time_on_uint64": {"code": "class MergeAsof:\n    def time_on_uint64(self, direction, tolerance):\n        merge_asof(\n            self.df1f, self.df2f, on=\"timeu64\", direction=direction, tolerance=tolerance\n        )\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass MergeAsof:\n    def setup(self, direction, tolerance):\n        one_count = 200000\n        two_count = 1000000\n    \n        df1 = DataFrame(\n            {\n                \"time\": np.random.randint(0, one_count / 20, one_count),\n                \"key\": np.random.choice(list(string.ascii_uppercase), one_count),\n                \"key2\": np.random.randint(0, 25, one_count),\n                \"value1\": np.random.randn(one_count),\n            }\n        )\n        df2 = DataFrame(\n            {\n                \"time\": np.random.randint(0, two_count / 20, two_count),\n                \"key\": np.random.choice(list(string.ascii_uppercase), two_count),\n                \"key2\": np.random.randint(0, 25, two_count),\n                \"value2\": np.random.randn(two_count),\n            }\n        )\n    \n        df1 = df1.sort_values(\"time\")\n        df2 = df2.sort_values(\"time\")\n    \n        df1[\"time32\"] = np.int32(df1.time)\n        df2[\"time32\"] = np.int32(df2.time)\n    \n        df1[\"timeu64\"] = np.uint64(df1.time)\n        df2[\"timeu64\"] = np.uint64(df2.time)\n    \n        self.df1a = df1[[\"time\", \"value1\"]]\n        self.df2a = df2[[\"time\", \"value2\"]]\n        self.df1b = df1[[\"time\", \"key\", \"value1\"]]\n        self.df2b = df2[[\"time\", \"key\", \"value2\"]]\n        self.df1c = df1[[\"time\", \"key2\", \"value1\"]]\n        self.df2c = df2[[\"time\", \"key2\", \"value2\"]]\n        self.df1d = df1[[\"time32\", \"value1\"]]\n        self.df2d = df2[[\"time32\", \"value2\"]]\n        self.df1e = df1[[\"time\", \"key\", \"key2\", \"value1\"]]\n        self.df2e = df2[[\"time\", \"key\", \"key2\", \"value2\"]]\n        self.df1f = df1[[\"timeu64\", \"value1\"]]\n        self.df2f = df2[[\"timeu64\", \"value2\"]]", "min_run_count": 2, "name": "join_merge.MergeAsof.time_on_uint64", "number": 0, "param_names": ["direction", "tolerance"], "params": [["'backward'", "'forward'", "'nearest'"], ["None", "5"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "272c9034f60d2e7af35cd9d80009bb4f6d2ed987924efec03f83106e40c406be", "warmup_time": -1}, "join_merge.MergeCategoricals.time_merge_cat": {"code": "class MergeCategoricals:\n    def time_merge_cat(self):\n        merge(self.left_cat, self.right_cat, on=\"X\")\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass MergeCategoricals:\n    def setup(self):\n        self.left_object = DataFrame(\n            {\n                \"X\": np.random.choice(range(10), size=(10000,)),\n                \"Y\": np.random.choice([\"one\", \"two\", \"three\"], size=(10000,)),\n            }\n        )\n    \n        self.right_object = DataFrame(\n            {\n                \"X\": np.random.choice(range(10), size=(10000,)),\n                \"Z\": np.random.choice([\"jjj\", \"kkk\", \"sss\"], size=(10000,)),\n            }\n        )\n    \n        self.left_cat = self.left_object.assign(\n            Y=self.left_object[\"Y\"].astype(\"category\")\n        )\n        self.right_cat = self.right_object.assign(\n            Z=self.right_object[\"Z\"].astype(\"category\")\n        )\n    \n        self.left_cat_col = self.left_object.astype({\"X\": \"category\"})\n        self.right_cat_col = self.right_object.astype({\"X\": \"category\"})\n    \n        self.left_cat_idx = self.left_cat_col.set_index(\"X\")\n        self.right_cat_idx = self.right_cat_col.set_index(\"X\")", "min_run_count": 2, "name": "join_merge.MergeCategoricals.time_merge_cat", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "00a33d8aa98005ee74e2a9419efbcba37da5a72412cf5677491a0d7e883e16ac", "warmup_time": -1}, "join_merge.MergeCategoricals.time_merge_object": {"code": "class MergeCategoricals:\n    def time_merge_object(self):\n        merge(self.left_object, self.right_object, on=\"X\")\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass MergeCategoricals:\n    def setup(self):\n        self.left_object = DataFrame(\n            {\n                \"X\": np.random.choice(range(10), size=(10000,)),\n                \"Y\": np.random.choice([\"one\", \"two\", \"three\"], size=(10000,)),\n            }\n        )\n    \n        self.right_object = DataFrame(\n            {\n                \"X\": np.random.choice(range(10), size=(10000,)),\n                \"Z\": np.random.choice([\"jjj\", \"kkk\", \"sss\"], size=(10000,)),\n            }\n        )\n    \n        self.left_cat = self.left_object.assign(\n            Y=self.left_object[\"Y\"].astype(\"category\")\n        )\n        self.right_cat = self.right_object.assign(\n            Z=self.right_object[\"Z\"].astype(\"category\")\n        )\n    \n        self.left_cat_col = self.left_object.astype({\"X\": \"category\"})\n        self.right_cat_col = self.right_object.astype({\"X\": \"category\"})\n    \n        self.left_cat_idx = self.left_cat_col.set_index(\"X\")\n        self.right_cat_idx = self.right_cat_col.set_index(\"X\")", "min_run_count": 2, "name": "join_merge.MergeCategoricals.time_merge_object", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "77cf8c07c705b35dc8457937294233b8bb0eefee79f670c7293bc9c2381afe22", "warmup_time": -1}, "join_merge.MergeCategoricals.time_merge_on_cat_col": {"code": "class MergeCategoricals:\n    def time_merge_on_cat_col(self):\n        merge(self.left_cat_col, self.right_cat_col, on=\"X\")\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass MergeCategoricals:\n    def setup(self):\n        self.left_object = DataFrame(\n            {\n                \"X\": np.random.choice(range(10), size=(10000,)),\n                \"Y\": np.random.choice([\"one\", \"two\", \"three\"], size=(10000,)),\n            }\n        )\n    \n        self.right_object = DataFrame(\n            {\n                \"X\": np.random.choice(range(10), size=(10000,)),\n                \"Z\": np.random.choice([\"jjj\", \"kkk\", \"sss\"], size=(10000,)),\n            }\n        )\n    \n        self.left_cat = self.left_object.assign(\n            Y=self.left_object[\"Y\"].astype(\"category\")\n        )\n        self.right_cat = self.right_object.assign(\n            Z=self.right_object[\"Z\"].astype(\"category\")\n        )\n    \n        self.left_cat_col = self.left_object.astype({\"X\": \"category\"})\n        self.right_cat_col = self.right_object.astype({\"X\": \"category\"})\n    \n        self.left_cat_idx = self.left_cat_col.set_index(\"X\")\n        self.right_cat_idx = self.right_cat_col.set_index(\"X\")", "min_run_count": 2, "name": "join_merge.MergeCategoricals.time_merge_on_cat_col", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "332c136f45e9500d990f645254420649a7483fe922cc1518686320b47d002d4d", "warmup_time": -1}, "join_merge.MergeCategoricals.time_merge_on_cat_idx": {"code": "class MergeCategoricals:\n    def time_merge_on_cat_idx(self):\n        merge(self.left_cat_idx, self.right_cat_idx, on=\"X\")\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass MergeCategoricals:\n    def setup(self):\n        self.left_object = DataFrame(\n            {\n                \"X\": np.random.choice(range(10), size=(10000,)),\n                \"Y\": np.random.choice([\"one\", \"two\", \"three\"], size=(10000,)),\n            }\n        )\n    \n        self.right_object = DataFrame(\n            {\n                \"X\": np.random.choice(range(10), size=(10000,)),\n                \"Z\": np.random.choice([\"jjj\", \"kkk\", \"sss\"], size=(10000,)),\n            }\n        )\n    \n        self.left_cat = self.left_object.assign(\n            Y=self.left_object[\"Y\"].astype(\"category\")\n        )\n        self.right_cat = self.right_object.assign(\n            Z=self.right_object[\"Z\"].astype(\"category\")\n        )\n    \n        self.left_cat_col = self.left_object.astype({\"X\": \"category\"})\n        self.right_cat_col = self.right_object.astype({\"X\": \"category\"})\n    \n        self.left_cat_idx = self.left_cat_col.set_index(\"X\")\n        self.right_cat_idx = self.right_cat_col.set_index(\"X\")", "min_run_count": 2, "name": "join_merge.MergeCategoricals.time_merge_on_cat_idx", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "fa95749bee211b87d0765b6dd09a6130d3f28acb1b0d329273458f1ffba8efd8", "warmup_time": -1}, "join_merge.MergeDatetime.time_merge": {"code": "class MergeDatetime:\n    def time_merge(self, units, tz, monotonic):\n        merge(self.left, self.right)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass MergeDatetime:\n    def setup(self, units, tz, monotonic):\n        unit_left, unit_right = units\n        N = 10_000\n        keys = Series(date_range(\"2012-01-01\", freq=\"min\", periods=N, tz=tz))\n        self.left = DataFrame(\n            {\n                \"key\": keys.sample(N * 10, replace=True).dt.as_unit(unit_left),\n                \"value1\": np.random.randn(N * 10),\n            }\n        )\n        self.right = DataFrame(\n            {\n                \"key\": keys[:8000].dt.as_unit(unit_right),\n                \"value2\": np.random.randn(8000),\n            }\n        )\n        if monotonic:\n            self.left = self.left.sort_values(\"key\")\n            self.right = self.right.sort_values(\"key\")", "min_run_count": 2, "name": "join_merge.MergeDatetime.time_merge", "number": 0, "param_names": ["units", "tz", "monotonic"], "params": [["('ns', 'ns')", "('ms', 'ms')", "('ns', 'ms')"], ["None", "'Europe/Brussels'"], ["True", "False"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "7fefbf78c16bc3a08818771113e2d29c712563606490a20e5d16660d9870a115", "warmup_time": -1}, "join_merge.MergeEA.time_merge": {"code": "class MergeEA:\n    def time_merge(self, dtype, monotonic):\n        merge(self.left, self.right)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass MergeEA:\n    def setup(self, dtype, monotonic):\n        N = 10_000\n        indices = np.arange(1, N)\n        key = np.tile(indices[:8000], 10)\n        self.left = DataFrame(\n            {\"key\": Series(key, dtype=dtype), \"value\": np.random.randn(80000)}\n        )\n        self.right = DataFrame(\n            {\n                \"key\": Series(indices[2000:], dtype=dtype),\n                \"value2\": np.random.randn(7999),\n            }\n        )\n        if monotonic:\n            self.left = self.left.sort_values(\"key\")\n            self.right = self.right.sort_values(\"key\")", "min_run_count": 2, "name": "join_merge.MergeEA.time_merge", "number": 0, "param_names": ["dtype", "monotonic"], "params": [["'Int64'", "'Int32'", "'Int16'", "'UInt64'", "'UInt32'", "'UInt16'", "'Float64'", "'Float32'"], ["True", "False"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "f0e5552415c5bc8cd8e34955cf48492cb0932495123062d6282b85ea95868817", "warmup_time": -1}, "join_merge.MergeMultiIndex.time_merge_sorted_multiindex": {"code": "class MergeMultiIndex:\n    def time_merge_sorted_multiindex(self, dtypes, how):\n        # copy to avoid MultiIndex._values caching\n        df1 = self.df1.copy()\n        df2 = self.df2.copy()\n        merge(df1, df2, how=how, left_index=True, right_index=True)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass MergeMultiIndex:\n    def setup(self, dtypes, how):\n        n = 100_000\n        offset = 50_000\n        mi1 = MultiIndex.from_arrays(\n            [\n                array(np.arange(n), dtype=dtypes[0]),\n                array(np.arange(n), dtype=dtypes[1]),\n            ]\n        )\n        mi2 = MultiIndex.from_arrays(\n            [\n                array(np.arange(offset, n + offset), dtype=dtypes[0]),\n                array(np.arange(offset, n + offset), dtype=dtypes[1]),\n            ]\n        )\n        self.df1 = DataFrame({\"col1\": 1}, index=mi1)\n        self.df2 = DataFrame({\"col2\": 2}, index=mi2)", "min_run_count": 2, "name": "join_merge.MergeMultiIndex.time_merge_sorted_multiindex", "number": 0, "param_names": ["dtypes", "how"], "params": [["('int64', 'int64')", "('datetime64[ns]', 'int64')", "('Int64', 'Int64')"], ["'left'", "'right'", "'inner'", "'outer'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "87d6032a44f31143b8c18c1f04684f8a2aa12fbf908500d9bb17310283004aa3", "warmup_time": -1}, "join_merge.MergeOrdered.time_merge_ordered": {"code": "class MergeOrdered:\n    def time_merge_ordered(self):\n        merge_ordered(self.left, self.right, on=\"key\", left_by=\"group\")\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass MergeOrdered:\n    def setup(self):\n        groups = Index([f\"i-{i}\" for i in range(10)], dtype=object).values\n        self.left = DataFrame(\n            {\n                \"group\": groups.repeat(5000),\n                \"key\": np.tile(np.arange(0, 10000, 2), 10),\n                \"lvalue\": np.random.randn(50000),\n            }\n        )\n        self.right = DataFrame(\n            {\"key\": np.arange(10000), \"rvalue\": np.random.randn(10000)}\n        )", "min_run_count": 2, "name": "join_merge.MergeOrdered.time_merge_ordered", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "d15295cd5ee465cbd2aaa4c0bfe30d6feba058e0379020f3360c6857fd4a6781", "warmup_time": -1}, "libs.CacheReadonly.time_cache_readonly": {"code": "class CacheReadonly:\n    def time_cache_readonly(self):\n        self.obj.prop\n\n    def setup(self):\n        class Foo:\n            @cache_readonly\n            def prop(self):\n                return 5\n    \n        self.obj = Foo()", "min_run_count": 2, "name": "libs.CacheReadonly.time_cache_readonly", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "0c1cb69a185e93f75c8a4df1942cf6b4e0cf583d0eb2f7e80d1df4e75305b788", "warmup_time": -1}, "libs.FastZip.time_lib_fast_zip": {"code": "class FastZip:\n    def time_lib_fast_zip(self):\n        lib.fast_zip(self.col_array_list)\n\n    def setup(self):\n        N = 10000\n        K = 10\n        key1 = Index([f\"i-{i}\" for i in range(N)], dtype=object).values.repeat(K)\n        key2 = Index([f\"i-{i}\" for i in range(N)], dtype=object).values.repeat(K)\n        col_array = np.vstack([key1, key2, np.random.randn(N * K)])\n        col_array2 = col_array.copy()\n        col_array2[:, :10000] = np.nan\n        self.col_array_list = list(col_array)", "min_run_count": 2, "name": "libs.FastZip.time_lib_fast_zip", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "91a51ca613db8362ac81df82eb2a907dd705058cd702a87ce9542e1b208d187e", "warmup_time": -1}, "libs.InferDtype.time_infer_dtype": {"code": "class InferDtype:\n    def time_infer_dtype(self, dtype):\n        infer_dtype(self.data_dict[dtype], skipna=False)", "min_run_count": 2, "name": "libs.InferDtype.time_infer_dtype", "number": 0, "param_names": ["dtype"], "params": [["'np-object'", "'py-object'", "'np-null'", "'py-null'", "'np-int'", "'np-floating'", "'empty'", "'bytes'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "125f86966c05a7552f7d61e8833a505c865982149242f645b314a569f9830a3e", "warmup_time": -1}, "libs.InferDtype.time_infer_dtype_skipna": {"code": "class InferDtype:\n    def time_infer_dtype_skipna(self, dtype):\n        infer_dtype(self.data_dict[dtype], skipna=True)", "min_run_count": 2, "name": "libs.InferDtype.time_infer_dtype_skipna", "number": 0, "param_names": ["dtype"], "params": [["'np-object'", "'py-object'", "'np-null'", "'py-null'", "'np-int'", "'np-floating'", "'empty'", "'bytes'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "92424cbc247a56269a3db019273c9b16434c61cd8f83fd7210ea2168ac4e31e0", "warmup_time": -1}, "libs.ScalarListLike.time_is_list_like": {"code": "class ScalarListLike:\n    def time_is_list_like(self, param):\n        is_list_like(param)", "min_run_count": 2, "name": "libs.ScalarListLike.time_is_list_like", "number": 0, "param_names": ["param1"], "params": [["0", "1.0", "(1+2j)", "True", "'foo'", "b'bar'", "None", "numpy.datetime64('1970-01-01T00:00:00.000000123')", "numpy.timedelta64(123,'ns')", "NaT", "<NA>", "array('123', dtype='<U3')", "array([1, 2, 3])", "{0: 1}", "{1, 2, 3}", "[1, 2, 3]", "(1, 2, 3)"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "f12c7f398bcc1c4a71e6dbe7b8aec6631a2565dd2a614a6f834dee7e64388bf8", "warmup_time": -1}, "libs.ScalarListLike.time_is_scalar": {"code": "class ScalarListLike:\n    def time_is_scalar(self, param):\n        is_scalar(param)", "min_run_count": 2, "name": "libs.ScalarListLike.time_is_scalar", "number": 0, "param_names": ["param1"], "params": [["0", "1.0", "(1+2j)", "True", "'foo'", "b'bar'", "None", "numpy.datetime64('1970-01-01T00:00:00.000000123')", "numpy.timedelta64(123,'ns')", "NaT", "<NA>", "array('123', dtype='<U3')", "array([1, 2, 3])", "{0: 1}", "{1, 2, 3}", "[1, 2, 3]", "(1, 2, 3)"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "ec357011e1e42690c47ad59e42ea37c1b167ef442f92e787301c3ef26d40a34d", "warmup_time": -1}, "multiindex_object.Append.time_append": {"code": "class Append:\n    def time_append(self, dtype):\n        self.left.append(self.right)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Append:\n    def setup(self, dtype):\n        N1 = 1000\n        N2 = 500\n        left_level1 = range(N1)\n        right_level1 = range(N1, N1 + N1)\n    \n        if dtype == \"datetime64[ns]\":\n            level2 = date_range(start=\"2000-01-01\", periods=N2)\n        elif dtype == \"int64\":\n            level2 = range(N2)\n        elif dtype == \"string\":\n            level2 = Index([f\"i-{i}\" for i in range(N2)], dtype=object)\n        else:\n            raise NotImplementedError\n    \n        self.left = MultiIndex.from_product([left_level1, level2])\n        self.right = MultiIndex.from_product([right_level1, level2])", "min_run_count": 2, "name": "multiindex_object.Append.time_append", "number": 0, "param_names": ["dtype"], "params": [["'datetime64[ns]'", "'int64'", "'string'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "76fd9f729ee3cd6d46110db9ab4c9d1c758cc7e3341892fdeda30d892e6c82ae", "warmup_time": -1}, "multiindex_object.CategoricalLevel.time_categorical_level": {"code": "class CategoricalLevel:\n    def time_categorical_level(self):\n        self.df.set_index([\"a\", \"b\"])\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass CategoricalLevel:\n    def setup(self):\n        self.df = DataFrame(\n            {\n                \"a\": np.arange(1_000_000, dtype=np.int32),\n                \"b\": np.arange(1_000_000, dtype=np.int64),\n                \"c\": np.arange(1_000_000, dtype=float),\n            }\n        ).astype({\"a\": \"category\", \"b\": \"category\"})", "min_run_count": 2, "name": "multiindex_object.CategoricalLevel.time_categorical_level", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "95746db84674b4c2c4a999d967e65da698fe749fb6a989c5cfa92e4a34dfe20f", "warmup_time": -1}, "multiindex_object.Difference.time_difference": {"code": "class Difference:\n    def time_difference(self, dtype):\n        self.left.difference(self.right)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Difference:\n    def setup(self, dtype):\n        N = 10**4 * 2\n        level1 = range(1000)\n    \n        level2 = date_range(start=\"1/1/2000\", periods=N // 1000)\n        dates_left = MultiIndex.from_product([level1, level2])\n    \n        level2 = range(N // 1000)\n        int_left = MultiIndex.from_product([level1, level2])\n    \n        level2 = Series(range(N // 1000), dtype=\"Int64\")\n        level2[0] = NA\n        ea_int_left = MultiIndex.from_product([level1, level2])\n    \n        level2 = Index([f\"i-{i}\" for i in range(N // 1000)], dtype=object).values\n        str_left = MultiIndex.from_product([level1, level2])\n    \n        data = {\n            \"datetime\": dates_left,\n            \"int\": int_left,\n            \"ea_int\": ea_int_left,\n            \"string\": str_left,\n        }\n    \n        data = {k: {\"left\": mi, \"right\": mi[:5]} for k, mi in data.items()}\n        self.left = data[dtype][\"left\"]\n        self.right = data[dtype][\"right\"]", "min_run_count": 2, "name": "multiindex_object.Difference.time_difference", "number": 0, "param_names": ["dtype"], "params": [["'datetime'", "'int'", "'string'", "'ea_int'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "0168a00ca95fba1c258cd54bdc3faf908f061cbf0a054c35404c75be0273497f", "warmup_time": -1}, "multiindex_object.Duplicated.time_duplicated": {"code": "class Duplicated:\n    def time_duplicated(self):\n        self.mi.duplicated()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Duplicated:\n    def setup(self):\n        n, k = 200, 5000\n        levels = [\n            np.arange(n),\n            Index([f\"i-{i}\" for i in range(n)], dtype=object).values,\n            1000 + np.arange(n),\n        ]\n        codes = [np.random.choice(n, (k * n)) for lev in levels]\n        self.mi = MultiIndex(levels=levels, codes=codes)", "min_run_count": 2, "name": "multiindex_object.Duplicated.time_duplicated", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "a38c9fead000e3b6fd3c54f7de782d3ba37dd31161e8fdd82c58194ae7324c22", "warmup_time": -1}, "multiindex_object.Duplicates.time_remove_unused_levels": {"code": "class Duplicates:\n    def time_remove_unused_levels(self):\n        self.mi_unused_levels.remove_unused_levels()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Duplicates:\n    def setup(self):\n        size = 65536\n        arrays = [np.random.randint(0, 8192, size), np.random.randint(0, 1024, size)]\n        mask = np.random.rand(size) < 0.1\n        self.mi_unused_levels = MultiIndex.from_arrays(arrays)\n        self.mi_unused_levels = self.mi_unused_levels[mask]", "min_run_count": 2, "name": "multiindex_object.Duplicates.time_remove_unused_levels", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "858a4d9728167fda18b01dd248d011becaf52569cc3789ebc23781748020a547", "warmup_time": -1}, "multiindex_object.Equals.time_equals_non_object_index": {"code": "class Equals:\n    def time_equals_non_object_index(self):\n        self.mi_large_slow.equals(self.idx_non_object)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Equals:\n    def setup(self):\n        idx_large_fast = RangeIndex(100000)\n        idx_small_slow = date_range(start=\"1/1/2012\", periods=1)\n        self.mi_large_slow = MultiIndex.from_product([idx_large_fast, idx_small_slow])\n    \n        self.idx_non_object = RangeIndex(1)", "min_run_count": 2, "name": "multiindex_object.Equals.time_equals_non_object_index", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "670ae29fa38e3f25c93a8fe7085dd856137ada08f63f625b17da442a35a357b8", "warmup_time": -1}, "multiindex_object.GetLoc.time_large_get_loc": {"code": "class GetLoc:\n    def time_large_get_loc(self):\n        self.mi_large.get_loc((999, 19, \"Z\"))\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass GetLoc:\n    def setup(self):\n        self.mi_large = MultiIndex.from_product(\n            [np.arange(1000), np.arange(20), list(string.ascii_letters)],\n            names=[\"one\", \"two\", \"three\"],\n        )\n        self.mi_med = MultiIndex.from_product(\n            [np.arange(1000), np.arange(10), list(\"A\")], names=[\"one\", \"two\", \"three\"]\n        )\n        self.mi_small = MultiIndex.from_product(\n            [np.arange(100), list(\"A\"), list(\"A\")], names=[\"one\", \"two\", \"three\"]\n        )", "min_run_count": 2, "name": "multiindex_object.GetLoc.time_large_get_loc", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "dd084286aabcc048d0407dfacebe59f29ed1f976d92d013a0a10f35ba2e96bdb", "warmup_time": -1}, "multiindex_object.GetLoc.time_large_get_loc_warm": {"code": "class GetLoc:\n    def time_large_get_loc_warm(self):\n        for _ in range(1000):\n            self.mi_large.get_loc((999, 19, \"Z\"))\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass GetLoc:\n    def setup(self):\n        self.mi_large = MultiIndex.from_product(\n            [np.arange(1000), np.arange(20), list(string.ascii_letters)],\n            names=[\"one\", \"two\", \"three\"],\n        )\n        self.mi_med = MultiIndex.from_product(\n            [np.arange(1000), np.arange(10), list(\"A\")], names=[\"one\", \"two\", \"three\"]\n        )\n        self.mi_small = MultiIndex.from_product(\n            [np.arange(100), list(\"A\"), list(\"A\")], names=[\"one\", \"two\", \"three\"]\n        )", "min_run_count": 2, "name": "multiindex_object.GetLoc.time_large_get_loc_warm", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "137653619e4d1b432e07d94aa7a9cf46441e320de449aa65f5129efc13888912", "warmup_time": -1}, "multiindex_object.GetLoc.time_med_get_loc": {"code": "class GetLoc:\n    def time_med_get_loc(self):\n        self.mi_med.get_loc((999, 9, \"A\"))\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass GetLoc:\n    def setup(self):\n        self.mi_large = MultiIndex.from_product(\n            [np.arange(1000), np.arange(20), list(string.ascii_letters)],\n            names=[\"one\", \"two\", \"three\"],\n        )\n        self.mi_med = MultiIndex.from_product(\n            [np.arange(1000), np.arange(10), list(\"A\")], names=[\"one\", \"two\", \"three\"]\n        )\n        self.mi_small = MultiIndex.from_product(\n            [np.arange(100), list(\"A\"), list(\"A\")], names=[\"one\", \"two\", \"three\"]\n        )", "min_run_count": 2, "name": "multiindex_object.GetLoc.time_med_get_loc", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "b783d9cb5dbdc6787a0879e0f8c0862c4014d5ea0611abb97c342d46f77826e1", "warmup_time": -1}, "multiindex_object.GetLoc.time_med_get_loc_warm": {"code": "class GetLoc:\n    def time_med_get_loc_warm(self):\n        for _ in range(1000):\n            self.mi_med.get_loc((999, 9, \"A\"))\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass GetLoc:\n    def setup(self):\n        self.mi_large = MultiIndex.from_product(\n            [np.arange(1000), np.arange(20), list(string.ascii_letters)],\n            names=[\"one\", \"two\", \"three\"],\n        )\n        self.mi_med = MultiIndex.from_product(\n            [np.arange(1000), np.arange(10), list(\"A\")], names=[\"one\", \"two\", \"three\"]\n        )\n        self.mi_small = MultiIndex.from_product(\n            [np.arange(100), list(\"A\"), list(\"A\")], names=[\"one\", \"two\", \"three\"]\n        )", "min_run_count": 2, "name": "multiindex_object.GetLoc.time_med_get_loc_warm", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "50ea4f6a67d9f88227e60e668996edef05b7564987506a1145e7b2c23a2ccb41", "warmup_time": -1}, "multiindex_object.GetLoc.time_small_get_loc_warm": {"code": "class GetLoc:\n    def time_small_get_loc_warm(self):\n        for _ in range(1000):\n            self.mi_small.get_loc((99, \"A\", \"A\"))\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass GetLoc:\n    def setup(self):\n        self.mi_large = MultiIndex.from_product(\n            [np.arange(1000), np.arange(20), list(string.ascii_letters)],\n            names=[\"one\", \"two\", \"three\"],\n        )\n        self.mi_med = MultiIndex.from_product(\n            [np.arange(1000), np.arange(10), list(\"A\")], names=[\"one\", \"two\", \"three\"]\n        )\n        self.mi_small = MultiIndex.from_product(\n            [np.arange(100), list(\"A\"), list(\"A\")], names=[\"one\", \"two\", \"three\"]\n        )", "min_run_count": 2, "name": "multiindex_object.GetLoc.time_small_get_loc_warm", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "fe1c2475d50cac160a619e2371fc123f6053a4346c2f4d01018f499d4cfec4e7", "warmup_time": -1}, "multiindex_object.GetLoc.time_string_get_loc": {"code": "class GetLoc:\n    def time_string_get_loc(self):\n        self.mi_small.get_loc((99, \"A\", \"A\"))\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass GetLoc:\n    def setup(self):\n        self.mi_large = MultiIndex.from_product(\n            [np.arange(1000), np.arange(20), list(string.ascii_letters)],\n            names=[\"one\", \"two\", \"three\"],\n        )\n        self.mi_med = MultiIndex.from_product(\n            [np.arange(1000), np.arange(10), list(\"A\")], names=[\"one\", \"two\", \"three\"]\n        )\n        self.mi_small = MultiIndex.from_product(\n            [np.arange(100), list(\"A\"), list(\"A\")], names=[\"one\", \"two\", \"three\"]\n        )", "min_run_count": 2, "name": "multiindex_object.GetLoc.time_string_get_loc", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "e96912b143865fa80131f906e8f63d1f3c40b3d142b8571de3b1b9615adf1801", "warmup_time": -1}, "multiindex_object.GetLocs.time_large_get_locs": {"code": "class GetLocs:\n    def time_large_get_locs(self):\n        self.mi_large.get_locs([999, 19, \"Z\"])\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass GetLocs:\n    def setup(self):\n        self.mi_large = MultiIndex.from_product(\n            [np.arange(1000), np.arange(20), list(string.ascii_letters)],\n            names=[\"one\", \"two\", \"three\"],\n        )\n        self.mi_med = MultiIndex.from_product(\n            [np.arange(1000), np.arange(10), list(\"A\")], names=[\"one\", \"two\", \"three\"]\n        )\n        self.mi_small = MultiIndex.from_product(\n            [np.arange(100), list(\"A\"), list(\"A\")], names=[\"one\", \"two\", \"three\"]\n        )", "min_run_count": 2, "name": "multiindex_object.GetLocs.time_large_get_locs", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "f6945fa307f8737f7231a2a44181eb523a78c225bc91dbcb18e3b75194dfc5bc", "warmup_time": -1}, "multiindex_object.GetLocs.time_med_get_locs": {"code": "class GetLocs:\n    def time_med_get_locs(self):\n        self.mi_med.get_locs([999, 9, \"A\"])\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass GetLocs:\n    def setup(self):\n        self.mi_large = MultiIndex.from_product(\n            [np.arange(1000), np.arange(20), list(string.ascii_letters)],\n            names=[\"one\", \"two\", \"three\"],\n        )\n        self.mi_med = MultiIndex.from_product(\n            [np.arange(1000), np.arange(10), list(\"A\")], names=[\"one\", \"two\", \"three\"]\n        )\n        self.mi_small = MultiIndex.from_product(\n            [np.arange(100), list(\"A\"), list(\"A\")], names=[\"one\", \"two\", \"three\"]\n        )", "min_run_count": 2, "name": "multiindex_object.GetLocs.time_med_get_locs", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "cf1640cb0f946d097ff83e7740951339843061148884ca31b8394c7abfa2c016", "warmup_time": -1}, "multiindex_object.GetLocs.time_small_get_locs": {"code": "class GetLocs:\n    def time_small_get_locs(self):\n        self.mi_small.get_locs([99, \"A\", \"A\"])\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass GetLocs:\n    def setup(self):\n        self.mi_large = MultiIndex.from_product(\n            [np.arange(1000), np.arange(20), list(string.ascii_letters)],\n            names=[\"one\", \"two\", \"three\"],\n        )\n        self.mi_med = MultiIndex.from_product(\n            [np.arange(1000), np.arange(10), list(\"A\")], names=[\"one\", \"two\", \"three\"]\n        )\n        self.mi_small = MultiIndex.from_product(\n            [np.arange(100), list(\"A\"), list(\"A\")], names=[\"one\", \"two\", \"three\"]\n        )", "min_run_count": 2, "name": "multiindex_object.GetLocs.time_small_get_locs", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "e20e0ac51b10b4dd999beefc7d99e3da94d32206cbb5cad3f13e2f9f110c765e", "warmup_time": -1}, "multiindex_object.Integer.time_get_indexer": {"code": "class Integer:\n    def time_get_indexer(self):\n        self.mi_int.get_indexer(self.obj_index)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Integer:\n    def setup(self):\n        self.mi_int = MultiIndex.from_product(\n            [np.arange(1000), np.arange(1000)], names=[\"one\", \"two\"]\n        )\n        self.obj_index = np.array(\n            [\n                (0, 10),\n                (0, 11),\n                (0, 12),\n                (0, 13),\n                (0, 14),\n                (0, 15),\n                (0, 16),\n                (0, 17),\n                (0, 18),\n                (0, 19),\n            ],\n            dtype=object,\n        )\n        self.other_mi_many_mismatches = MultiIndex.from_tuples(\n            [\n                (-7, 41),\n                (-2, 3),\n                (-0.7, 5),\n                (0, 0),\n                (0, 1.5),\n                (0, 340),\n                (0, 1001),\n                (1, -4),\n                (1, 20),\n                (1, 1040),\n                (432, -5),\n                (432, 17),\n                (439, 165.5),\n                (998, -4),\n                (998, 24065),\n                (999, 865.2),\n                (999, 1000),\n                (1045, -843),\n            ]\n        )", "min_run_count": 2, "name": "multiindex_object.Integer.time_get_indexer", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "fbdc58718b979f87ea6a8c82f9bc10f0b1ebc5fb70ea385528f54cff5edb41e7", "warmup_time": -1}, "multiindex_object.Integer.time_get_indexer_and_backfill": {"code": "class Integer:\n    def time_get_indexer_and_backfill(self):\n        self.mi_int.get_indexer(self.other_mi_many_mismatches, method=\"backfill\")\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Integer:\n    def setup(self):\n        self.mi_int = MultiIndex.from_product(\n            [np.arange(1000), np.arange(1000)], names=[\"one\", \"two\"]\n        )\n        self.obj_index = np.array(\n            [\n                (0, 10),\n                (0, 11),\n                (0, 12),\n                (0, 13),\n                (0, 14),\n                (0, 15),\n                (0, 16),\n                (0, 17),\n                (0, 18),\n                (0, 19),\n            ],\n            dtype=object,\n        )\n        self.other_mi_many_mismatches = MultiIndex.from_tuples(\n            [\n                (-7, 41),\n                (-2, 3),\n                (-0.7, 5),\n                (0, 0),\n                (0, 1.5),\n                (0, 340),\n                (0, 1001),\n                (1, -4),\n                (1, 20),\n                (1, 1040),\n                (432, -5),\n                (432, 17),\n                (439, 165.5),\n                (998, -4),\n                (998, 24065),\n                (999, 865.2),\n                (999, 1000),\n                (1045, -843),\n            ]\n        )", "min_run_count": 2, "name": "multiindex_object.Integer.time_get_indexer_and_backfill", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "f3a337ce0bc68b9b181e2f10744c48edfc0aea4481ed3ae1d3daf65dc1c9d53b", "warmup_time": -1}, "multiindex_object.Integer.time_get_indexer_and_pad": {"code": "class Integer:\n    def time_get_indexer_and_pad(self):\n        self.mi_int.get_indexer(self.other_mi_many_mismatches, method=\"pad\")\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Integer:\n    def setup(self):\n        self.mi_int = MultiIndex.from_product(\n            [np.arange(1000), np.arange(1000)], names=[\"one\", \"two\"]\n        )\n        self.obj_index = np.array(\n            [\n                (0, 10),\n                (0, 11),\n                (0, 12),\n                (0, 13),\n                (0, 14),\n                (0, 15),\n                (0, 16),\n                (0, 17),\n                (0, 18),\n                (0, 19),\n            ],\n            dtype=object,\n        )\n        self.other_mi_many_mismatches = MultiIndex.from_tuples(\n            [\n                (-7, 41),\n                (-2, 3),\n                (-0.7, 5),\n                (0, 0),\n                (0, 1.5),\n                (0, 340),\n                (0, 1001),\n                (1, -4),\n                (1, 20),\n                (1, 1040),\n                (432, -5),\n                (432, 17),\n                (439, 165.5),\n                (998, -4),\n                (998, 24065),\n                (999, 865.2),\n                (999, 1000),\n                (1045, -843),\n            ]\n        )", "min_run_count": 2, "name": "multiindex_object.Integer.time_get_indexer_and_pad", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "ee2af65e57a49d84022609e04c926f032e6e248514ffaccf6af4a25038d13f78", "warmup_time": -1}, "multiindex_object.Integer.time_is_monotonic": {"code": "class Integer:\n    def time_is_monotonic(self):\n        self.mi_int.is_monotonic_increasing\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Integer:\n    def setup(self):\n        self.mi_int = MultiIndex.from_product(\n            [np.arange(1000), np.arange(1000)], names=[\"one\", \"two\"]\n        )\n        self.obj_index = np.array(\n            [\n                (0, 10),\n                (0, 11),\n                (0, 12),\n                (0, 13),\n                (0, 14),\n                (0, 15),\n                (0, 16),\n                (0, 17),\n                (0, 18),\n                (0, 19),\n            ],\n            dtype=object,\n        )\n        self.other_mi_many_mismatches = MultiIndex.from_tuples(\n            [\n                (-7, 41),\n                (-2, 3),\n                (-0.7, 5),\n                (0, 0),\n                (0, 1.5),\n                (0, 340),\n                (0, 1001),\n                (1, -4),\n                (1, 20),\n                (1, 1040),\n                (432, -5),\n                (432, 17),\n                (439, 165.5),\n                (998, -4),\n                (998, 24065),\n                (999, 865.2),\n                (999, 1000),\n                (1045, -843),\n            ]\n        )", "min_run_count": 2, "name": "multiindex_object.Integer.time_is_monotonic", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "fe8e8d89536abf16fb7a6ef01595817776ab712a6865435f65f407568be53b2b", "warmup_time": -1}, "multiindex_object.Isin.time_isin_large": {"code": "class Isin:\n    def time_isin_large(self, dtype):\n        self.midx.isin(self.values_large)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Isin:\n    def setup(self, dtype):\n        N = 10**5\n        level1 = range(1000)\n    \n        level2 = date_range(start=\"1/1/2000\", periods=N // 1000)\n        dates_midx = MultiIndex.from_product([level1, level2])\n    \n        level2 = range(N // 1000)\n        int_midx = MultiIndex.from_product([level1, level2])\n    \n        level2 = Index([f\"i-{i}\" for i in range(N // 1000)], dtype=object).values\n        str_midx = MultiIndex.from_product([level1, level2])\n    \n        data = {\n            \"datetime\": dates_midx,\n            \"int\": int_midx,\n            \"string\": str_midx,\n        }\n    \n        self.midx = data[dtype]\n        self.values_small = self.midx[:100]\n        self.values_large = self.midx[100:]", "min_run_count": 2, "name": "multiindex_object.Isin.time_isin_large", "number": 0, "param_names": ["dtype"], "params": [["'string'", "'int'", "'datetime'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "7d85e0708b91ce1073f3eb5be362351b5419529c28ad4c98794a4fea4adf8773", "warmup_time": -1}, "multiindex_object.Isin.time_isin_small": {"code": "class Isin:\n    def time_isin_small(self, dtype):\n        self.midx.isin(self.values_small)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Isin:\n    def setup(self, dtype):\n        N = 10**5\n        level1 = range(1000)\n    \n        level2 = date_range(start=\"1/1/2000\", periods=N // 1000)\n        dates_midx = MultiIndex.from_product([level1, level2])\n    \n        level2 = range(N // 1000)\n        int_midx = MultiIndex.from_product([level1, level2])\n    \n        level2 = Index([f\"i-{i}\" for i in range(N // 1000)], dtype=object).values\n        str_midx = MultiIndex.from_product([level1, level2])\n    \n        data = {\n            \"datetime\": dates_midx,\n            \"int\": int_midx,\n            \"string\": str_midx,\n        }\n    \n        self.midx = data[dtype]\n        self.values_small = self.midx[:100]\n        self.values_large = self.midx[100:]", "min_run_count": 2, "name": "multiindex_object.Isin.time_isin_small", "number": 0, "param_names": ["dtype"], "params": [["'string'", "'int'", "'datetime'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "6c13190c2ec3169da4f76b0363e486cf173c635d7bb1edba8daec0a6a089f193", "warmup_time": -1}, "multiindex_object.Putmask.time_putmask": {"code": "class Putmask:\n    def time_putmask(self):\n        self.midx.putmask(self.mask, self.midx_values)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Putmask:\n    def setup(self):\n        N = 10**5\n        level1 = range(1_000)\n    \n        level2 = date_range(start=\"1/1/2000\", periods=N // 1000)\n        self.midx = MultiIndex.from_product([level1, level2])\n    \n        level1 = range(1_000, 2_000)\n        self.midx_values = MultiIndex.from_product([level1, level2])\n    \n        level2 = date_range(start=\"1/1/2010\", periods=N // 1000)\n        self.midx_values_different = MultiIndex.from_product([level1, level2])\n        self.mask = np.array([True, False] * (N // 2))", "min_run_count": 2, "name": "multiindex_object.Putmask.time_putmask", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "50b446c4932ddf04ca8086ddae7020ac3b1392556c9a5ec0bceee4a3471b774c", "warmup_time": -1}, "multiindex_object.Putmask.time_putmask_all_different": {"code": "class Putmask:\n    def time_putmask_all_different(self):\n        self.midx.putmask(self.mask, self.midx_values_different)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Putmask:\n    def setup(self):\n        N = 10**5\n        level1 = range(1_000)\n    \n        level2 = date_range(start=\"1/1/2000\", periods=N // 1000)\n        self.midx = MultiIndex.from_product([level1, level2])\n    \n        level1 = range(1_000, 2_000)\n        self.midx_values = MultiIndex.from_product([level1, level2])\n    \n        level2 = date_range(start=\"1/1/2010\", periods=N // 1000)\n        self.midx_values_different = MultiIndex.from_product([level1, level2])\n        self.mask = np.array([True, False] * (N // 2))", "min_run_count": 2, "name": "multiindex_object.Putmask.time_putmask_all_different", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "df38cba739c0876f17aa511e01ea4c5d6ae937fab90a3c6ba526fe149c270ac5", "warmup_time": -1}, "multiindex_object.SetOperations.time_operation": {"code": "class SetOperations:\n    def time_operation(self, index_structure, dtype, method, sort):\n        getattr(self.left, method)(self.right, sort=sort)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass SetOperations:\n    def setup(self, index_structure, dtype, method, sort):\n        N = 10**5\n        level1 = range(1000)\n    \n        level2 = date_range(start=\"1/1/2000\", periods=N // 1000)\n        dates_left = MultiIndex.from_product([level1, level2])\n    \n        level2 = range(N // 1000)\n        int_left = MultiIndex.from_product([level1, level2])\n    \n        level2 = Index([f\"i-{i}\" for i in range(N // 1000)], dtype=object).values\n        str_left = MultiIndex.from_product([level1, level2])\n    \n        level2 = range(N // 1000)\n        ea_int_left = MultiIndex.from_product([level1, Series(level2, dtype=\"Int64\")])\n    \n        data = {\n            \"datetime\": dates_left,\n            \"int\": int_left,\n            \"string\": str_left,\n            \"ea_int\": ea_int_left,\n        }\n    \n        if index_structure == \"non_monotonic\":\n            data = {k: mi[::-1] for k, mi in data.items()}\n    \n        data = {k: {\"left\": mi, \"right\": mi[:-1]} for k, mi in data.items()}\n        self.left = data[dtype][\"left\"]\n        self.right = data[dtype][\"right\"]", "min_run_count": 2, "name": "multiindex_object.SetOperations.time_operation", "number": 0, "param_names": ["index_structure", "dtype", "method", "sort"], "params": [["'monotonic'", "'non_monotonic'"], ["'datetime'", "'int'", "'string'", "'ea_int'"], ["'intersection'", "'union'", "'symmetric_difference'"], ["False", "None"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "dc16c7e3877db2721ec17de5cc8eb031f00bbf400e50f5f1e1565c4c64ba78aa", "warmup_time": -1}, "multiindex_object.SortValues.time_sort_values": {"code": "class SortValues:\n    def time_sort_values(self, dtype):\n        self.mi.sort_values()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass SortValues:\n    def setup(self, dtype):\n        a = array(np.tile(np.arange(100), 1000), dtype=dtype)\n        b = array(np.tile(np.arange(1000), 100), dtype=dtype)\n        self.mi = MultiIndex.from_arrays([a, b])", "min_run_count": 2, "name": "multiindex_object.SortValues.time_sort_values", "number": 0, "param_names": ["dtype"], "params": [["'int64'", "'Int64'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "eb98215f2130dc70e3c3979ccb2442480cccf2a7f1fe46dabae490de9fa669ce", "warmup_time": -1}, "multiindex_object.Sortlevel.time_sortlevel_int64": {"code": "class Sortlevel:\n    def time_sortlevel_int64(self):\n        self.mi_int.sortlevel()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Sortlevel:\n    def setup(self):\n        n = 1182720\n        low, high = -4096, 4096\n        arrs = [\n            np.repeat(np.random.randint(low, high, (n // k)), k)\n            for k in [11, 7, 5, 3, 1]\n        ]\n        self.mi_int = MultiIndex.from_arrays(arrs)[np.random.permutation(n)]\n    \n        a = np.repeat(np.arange(100), 1000)\n        b = np.tile(np.arange(1000), 100)\n        self.mi = MultiIndex.from_arrays([a, b])\n        self.mi = self.mi.take(np.random.permutation(np.arange(100000)))", "min_run_count": 2, "name": "multiindex_object.Sortlevel.time_sortlevel_int64", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "a8b2951c7f045b903e0cd3abcea3295e405768580e65c267316e5d7993c375e4", "warmup_time": -1}, "multiindex_object.Sortlevel.time_sortlevel_one": {"code": "class Sortlevel:\n    def time_sortlevel_one(self):\n        self.mi.sortlevel(1)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Sortlevel:\n    def setup(self):\n        n = 1182720\n        low, high = -4096, 4096\n        arrs = [\n            np.repeat(np.random.randint(low, high, (n // k)), k)\n            for k in [11, 7, 5, 3, 1]\n        ]\n        self.mi_int = MultiIndex.from_arrays(arrs)[np.random.permutation(n)]\n    \n        a = np.repeat(np.arange(100), 1000)\n        b = np.tile(np.arange(1000), 100)\n        self.mi = MultiIndex.from_arrays([a, b])\n        self.mi = self.mi.take(np.random.permutation(np.arange(100000)))", "min_run_count": 2, "name": "multiindex_object.Sortlevel.time_sortlevel_one", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "17b98983847e3899dd3aecd51f007b8eee9219cafba180bcd18d23a273f074e4", "warmup_time": -1}, "multiindex_object.Sortlevel.time_sortlevel_zero": {"code": "class Sortlevel:\n    def time_sortlevel_zero(self):\n        self.mi.sortlevel(0)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Sortlevel:\n    def setup(self):\n        n = 1182720\n        low, high = -4096, 4096\n        arrs = [\n            np.repeat(np.random.randint(low, high, (n // k)), k)\n            for k in [11, 7, 5, 3, 1]\n        ]\n        self.mi_int = MultiIndex.from_arrays(arrs)[np.random.permutation(n)]\n    \n        a = np.repeat(np.arange(100), 1000)\n        b = np.tile(np.arange(1000), 100)\n        self.mi = MultiIndex.from_arrays([a, b])\n        self.mi = self.mi.take(np.random.permutation(np.arange(100000)))", "min_run_count": 2, "name": "multiindex_object.Sortlevel.time_sortlevel_zero", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "1f7d209d70d9ce641fdba817c8598ab8212457073e4f1218e5ecec974b8af00b", "warmup_time": -1}, "multiindex_object.Unique.time_unique": {"code": "class Unique:\n    def time_unique(self, dtype_val):\n        self.midx.unique()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Unique:\n    def setup(self, dtype_val):\n        level = Series(\n            [1, 2, dtype_val[1], dtype_val[1]] + list(range(1_000_000)),\n            dtype=dtype_val[0],\n        )\n        self.midx = MultiIndex.from_arrays([level, level])\n    \n        level_dups = Series(\n            [1, 2, dtype_val[1], dtype_val[1]] + list(range(500_000)) * 2,\n            dtype=dtype_val[0],\n        )\n    \n        self.midx_dups = MultiIndex.from_arrays([level_dups, level_dups])", "min_run_count": 2, "name": "multiindex_object.Unique.time_unique", "number": 0, "param_names": ["dtype_val"], "params": [["('Int64', <NA>)", "('int64', 0)"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "92002a61c3c2deb0be986b18be58b6f290334692a0ddda344728454264d8c69f", "warmup_time": -1}, "multiindex_object.Unique.time_unique_dups": {"code": "class Unique:\n    def time_unique_dups(self, dtype_val):\n        self.midx_dups.unique()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Unique:\n    def setup(self, dtype_val):\n        level = Series(\n            [1, 2, dtype_val[1], dtype_val[1]] + list(range(1_000_000)),\n            dtype=dtype_val[0],\n        )\n        self.midx = MultiIndex.from_arrays([level, level])\n    \n        level_dups = Series(\n            [1, 2, dtype_val[1], dtype_val[1]] + list(range(500_000)) * 2,\n            dtype=dtype_val[0],\n        )\n    \n        self.midx_dups = MultiIndex.from_arrays([level_dups, level_dups])", "min_run_count": 2, "name": "multiindex_object.Unique.time_unique_dups", "number": 0, "param_names": ["dtype_val"], "params": [["('Int64', <NA>)", "('int64', 0)"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "e7f6ae2612b4e61ab7e9b6ec0fa03d09c37653dcccd19cf141ea041ff0d0eec7", "warmup_time": -1}, "multiindex_object.Values.time_datetime_level_values_copy": {"code": "class Values:\n    def time_datetime_level_values_copy(self, mi):\n        mi.copy().values\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Values:\n    def setup_cache(self):\n        level1 = range(1000)\n        level2 = date_range(start=\"1/1/2012\", periods=100)\n        mi = MultiIndex.from_product([level1, level2])\n        return mi", "min_run_count": 2, "name": "multiindex_object.Values.time_datetime_level_values_copy", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "setup_cache_key": "multiindex_object:197", "timeout": 60.0, "type": "time", "unit": "seconds", "version": "63e7a47c0b022503f19576c75633ea3ca8a93ecce618be6e102892f9bd42dc33", "warmup_time": -1}, "multiindex_object.Values.time_datetime_level_values_sliced": {"code": "class Values:\n    def time_datetime_level_values_sliced(self, mi):\n        mi[:10].values\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Values:\n    def setup_cache(self):\n        level1 = range(1000)\n        level2 = date_range(start=\"1/1/2012\", periods=100)\n        mi = MultiIndex.from_product([level1, level2])\n        return mi", "min_run_count": 2, "name": "multiindex_object.Values.time_datetime_level_values_sliced", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "setup_cache_key": "multiindex_object:197", "timeout": 60.0, "type": "time", "unit": "seconds", "version": "6cfa5ee6916e13b58f6d108ca083f0ce269ffc3682b201c7fb24a2c4f82119bf", "warmup_time": -1}, "package.TimeImport.time_import": {"code": "class TimeImport:\n    def time_import(self):\n        # on py37+ we the \"-X importtime\" usage gives us a more precise\n        #  measurement of the import time we actually care about,\n        #  without the subprocess or interpreter overhead\n        cmd = [sys.executable, \"-X\", \"importtime\", \"-c\", \"import pandas as pd\"]\n        p = subprocess.run(cmd, stderr=subprocess.PIPE, check=True)\n    \n        line = p.stderr.splitlines()[-1]\n        field = line.split(b\"|\")[-2].strip()\n        total = int(field)  # microseconds\n        return total", "min_run_count": 2, "name": "package.TimeImport.time_import", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "83a56070bd7dda7f68a557d63e6b32341f956e6303d5820f6f5f3cfd62ac924b", "warmup_time": -1}, "period.Algorithms.time_drop_duplicates": {"code": "class Algorithms:\n    def time_drop_duplicates(self, typ):\n        self.vector.drop_duplicates()\n\n    def setup(self, typ):\n        data = [\n            Period(\"2011-01\", freq=\"M\"),\n            Period(\"2011-02\", freq=\"M\"),\n            Period(\"2011-03\", freq=\"M\"),\n            Period(\"2011-04\", freq=\"M\"),\n        ]\n    \n        if typ == \"index\":\n            self.vector = PeriodIndex(data * 1000, freq=\"M\")\n        elif typ == \"series\":\n            self.vector = Series(data * 1000)", "min_run_count": 2, "name": "period.Algorithms.time_drop_duplicates", "number": 0, "param_names": ["typ"], "params": [["'index'", "'series'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "5ed71a0e29ea9fe94acdf37fe778becc6a166703e59fe06b43693190e73c358c", "warmup_time": -1}, "period.Algorithms.time_value_counts": {"code": "class Algorithms:\n    def time_value_counts(self, typ):\n        self.vector.value_counts()\n\n    def setup(self, typ):\n        data = [\n            Period(\"2011-01\", freq=\"M\"),\n            Period(\"2011-02\", freq=\"M\"),\n            Period(\"2011-03\", freq=\"M\"),\n            Period(\"2011-04\", freq=\"M\"),\n        ]\n    \n        if typ == \"index\":\n            self.vector = PeriodIndex(data * 1000, freq=\"M\")\n        elif typ == \"series\":\n            self.vector = Series(data * 1000)", "min_run_count": 2, "name": "period.Algorithms.time_value_counts", "number": 0, "param_names": ["typ"], "params": [["'index'", "'series'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "7aaad3304a09d800100a2dc5f7da82c36953722c7da6aca2ca4c2e446a3badc8", "warmup_time": -1}, "period.DataFramePeriodColumn.time_set_index": {"code": "class DataFramePeriodColumn:\n    def time_set_index(self):\n        # GH#21582 limited by comparisons of Period objects\n        self.df[\"col2\"] = self.rng\n        self.df.set_index(\"col2\", append=True)\n\n    def setup(self):\n        self.rng = period_range(start=\"1/1/1990\", freq=\"s\", periods=20000)\n        self.df = DataFrame(index=range(len(self.rng)))", "min_run_count": 2, "name": "period.DataFramePeriodColumn.time_set_index", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "575f1539efb942f285e06bed12d6e468229977eb8dfe5637e627fc97f98d5c0a", "warmup_time": -1}, "period.DataFramePeriodColumn.time_setitem_period_column": {"code": "class DataFramePeriodColumn:\n    def time_setitem_period_column(self):\n        self.df[\"col\"] = self.rng\n\n    def setup(self):\n        self.rng = period_range(start=\"1/1/1990\", freq=\"s\", periods=20000)\n        self.df = DataFrame(index=range(len(self.rng)))", "min_run_count": 2, "name": "period.DataFramePeriodColumn.time_setitem_period_column", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "da793a842fd7c5e41b19f604fed3ece4f2373f1946c06c9733baad3cc9ae9168", "warmup_time": -1}, "period.Indexing.time_align": {"code": "class Indexing:\n    def time_align(self):\n        DataFrame({\"a\": self.series, \"b\": self.series[:500]})\n\n    def setup(self):\n        self.index = period_range(start=\"1985\", periods=1000, freq=\"D\")\n        self.series = Series(range(1000), index=self.index)\n        self.period = self.index[500]", "min_run_count": 2, "name": "period.Indexing.time_align", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "7ba91f5b4184a97b1e578ce06acd5823a15ef927984c534ef97a97209494f3e9", "warmup_time": -1}, "period.Indexing.time_get_loc": {"code": "class Indexing:\n    def time_get_loc(self):\n        self.index.get_loc(self.period)\n\n    def setup(self):\n        self.index = period_range(start=\"1985\", periods=1000, freq=\"D\")\n        self.series = Series(range(1000), index=self.index)\n        self.period = self.index[500]", "min_run_count": 2, "name": "period.Indexing.time_get_loc", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "16c0233f1354d0efad7e0568b42faab3ceda761dbe321e610db062449c038b2b", "warmup_time": -1}, "period.Indexing.time_intersection": {"code": "class Indexing:\n    def time_intersection(self):\n        self.index[:750].intersection(self.index[250:])\n\n    def setup(self):\n        self.index = period_range(start=\"1985\", periods=1000, freq=\"D\")\n        self.series = Series(range(1000), index=self.index)\n        self.period = self.index[500]", "min_run_count": 2, "name": "period.Indexing.time_intersection", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "e473ad8ce23861754e1a2322452188035f32546b5106e9c354504575f161c9dc", "warmup_time": -1}, "period.Indexing.time_series_loc": {"code": "class Indexing:\n    def time_series_loc(self):\n        self.series.loc[self.period]\n\n    def setup(self):\n        self.index = period_range(start=\"1985\", periods=1000, freq=\"D\")\n        self.series = Series(range(1000), index=self.index)\n        self.period = self.index[500]", "min_run_count": 2, "name": "period.Indexing.time_series_loc", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "051bdec8fea0886aa445b372b56bf9dc434ca870d0168882015b967bb1545aa4", "warmup_time": -1}, "period.Indexing.time_shallow_copy": {"code": "class Indexing:\n    def time_shallow_copy(self):\n        self.index._view()\n\n    def setup(self):\n        self.index = period_range(start=\"1985\", periods=1000, freq=\"D\")\n        self.series = Series(range(1000), index=self.index)\n        self.period = self.index[500]", "min_run_count": 2, "name": "period.Indexing.time_shallow_copy", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "ec340ef909e8666710788924d6a879a98eceecf319ce9ddaa3afaef7f7c6a891", "warmup_time": -1}, "period.Indexing.time_unique": {"code": "class Indexing:\n    def time_unique(self):\n        self.index.unique()\n\n    def setup(self):\n        self.index = period_range(start=\"1985\", periods=1000, freq=\"D\")\n        self.series = Series(range(1000), index=self.index)\n        self.period = self.index[500]", "min_run_count": 2, "name": "period.Indexing.time_unique", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "c4ce9c886be5dcc91f24921a741cee9552a169c54f69f0ec4893b19145ca6cda", "warmup_time": -1}, "period.PeriodIndexConstructor.time_from_date_range": {"code": "class PeriodIndexConstructor:\n    def time_from_date_range(self, freq, is_offset):\n        PeriodIndex(self.rng, freq=freq)\n\n    def setup(self, freq, is_offset):\n        self.rng = date_range(\"1985\", periods=1000)\n        self.rng2 = date_range(\"1985\", periods=1000).to_pydatetime()\n        self.ints = list(range(2000, 3000))\n        self.daily_ints = (\n            date_range(\"1/1/2000\", periods=1000, freq=freq).strftime(\"%Y%m%d\").map(int)\n        )\n        if is_offset:\n            self.freq = to_offset(freq)\n        else:\n            self.freq = freq", "min_run_count": 2, "name": "period.PeriodIndexConstructor.time_from_date_range", "number": 0, "param_names": ["freq", "is_offset"], "params": [["'D'"], ["True", "False"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "90341c890b6fd853e93fe5ad5a5d9935048545a0c2bf70da9324aca627215961", "warmup_time": -1}, "period.PeriodIndexConstructor.time_from_ints": {"code": "class PeriodIndexConstructor:\n    def time_from_ints(self, freq, is_offset):\n        PeriodIndex(self.ints, freq=freq)\n\n    def setup(self, freq, is_offset):\n        self.rng = date_range(\"1985\", periods=1000)\n        self.rng2 = date_range(\"1985\", periods=1000).to_pydatetime()\n        self.ints = list(range(2000, 3000))\n        self.daily_ints = (\n            date_range(\"1/1/2000\", periods=1000, freq=freq).strftime(\"%Y%m%d\").map(int)\n        )\n        if is_offset:\n            self.freq = to_offset(freq)\n        else:\n            self.freq = freq", "min_run_count": 2, "name": "period.PeriodIndexConstructor.time_from_ints", "number": 0, "param_names": ["freq", "is_offset"], "params": [["'D'"], ["True", "False"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "40e20dbe294496152b0cab99ad8277ec6836602167d363e0c665de9915971d7d", "warmup_time": -1}, "period.PeriodIndexConstructor.time_from_ints_daily": {"code": "class PeriodIndexConstructor:\n    def time_from_ints_daily(self, freq, is_offset):\n        PeriodIndex(self.daily_ints, freq=freq)\n\n    def setup(self, freq, is_offset):\n        self.rng = date_range(\"1985\", periods=1000)\n        self.rng2 = date_range(\"1985\", periods=1000).to_pydatetime()\n        self.ints = list(range(2000, 3000))\n        self.daily_ints = (\n            date_range(\"1/1/2000\", periods=1000, freq=freq).strftime(\"%Y%m%d\").map(int)\n        )\n        if is_offset:\n            self.freq = to_offset(freq)\n        else:\n            self.freq = freq", "min_run_count": 2, "name": "period.PeriodIndexConstructor.time_from_ints_daily", "number": 0, "param_names": ["freq", "is_offset"], "params": [["'D'"], ["True", "False"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "7ec1c957be1d06e33b08c4eb1a645648cba0172013a8b73a1e8c8d8f8e5725a8", "warmup_time": -1}, "period.PeriodIndexConstructor.time_from_pydatetime": {"code": "class PeriodIndexConstructor:\n    def time_from_pydatetime(self, freq, is_offset):\n        PeriodIndex(self.rng2, freq=freq)\n\n    def setup(self, freq, is_offset):\n        self.rng = date_range(\"1985\", periods=1000)\n        self.rng2 = date_range(\"1985\", periods=1000).to_pydatetime()\n        self.ints = list(range(2000, 3000))\n        self.daily_ints = (\n            date_range(\"1/1/2000\", periods=1000, freq=freq).strftime(\"%Y%m%d\").map(int)\n        )\n        if is_offset:\n            self.freq = to_offset(freq)\n        else:\n            self.freq = freq", "min_run_count": 2, "name": "period.PeriodIndexConstructor.time_from_pydatetime", "number": 0, "param_names": ["freq", "is_offset"], "params": [["'D'"], ["True", "False"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "2e9a86e7434b9d0777e5ccc8fc9165eaf99b3ae701c88bb9a2f2bfbb3a8742c1", "warmup_time": -1}, "plotting.BackendLoading.time_get_plot_backend": {"code": "class BackendLoading:\n    def time_get_plot_backend(self):\n        # finds the first my_ep_backend\n        _get_plot_backend(\"my_ep_backend\")\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass BackendLoading:\n    def setup(self):\n        mod = importlib.util.module_from_spec(\n            importlib.machinery.ModuleSpec(\"pandas_dummy_backend\", None)\n        )\n        mod.plot = lambda *args, **kwargs: 1\n    \n        with contextlib.ExitStack() as stack:\n            stack.enter_context(\n                mock.patch.dict(sys.modules, {\"pandas_dummy_backend\": mod})\n            )\n            tmp_path = pathlib.Path(stack.enter_context(tempfile.TemporaryDirectory()))\n    \n            sys.path.insert(0, os.fsdecode(tmp_path))\n            stack.callback(sys.path.remove, os.fsdecode(tmp_path))\n    \n            dist_info = tmp_path / \"my_backend-0.0.0.dist-info\"\n            dist_info.mkdir()\n            (dist_info / \"entry_points.txt\").write_bytes(\n                b\"[pandas_plotting_backends]\\n\"\n                b\"my_ep_backend = pandas_dummy_backend\\n\"\n                b\"my_ep_backend0 = pandas_dummy_backend\\n\"\n                b\"my_ep_backend1 = pandas_dummy_backend\\n\"\n                b\"my_ep_backend2 = pandas_dummy_backend\\n\"\n                b\"my_ep_backend3 = pandas_dummy_backend\\n\"\n                b\"my_ep_backend4 = pandas_dummy_backend\\n\"\n                b\"my_ep_backend5 = pandas_dummy_backend\\n\"\n                b\"my_ep_backend6 = pandas_dummy_backend\\n\"\n                b\"my_ep_backend7 = pandas_dummy_backend\\n\"\n                b\"my_ep_backend8 = pandas_dummy_backend\\n\"\n                b\"my_ep_backend9 = pandas_dummy_backend\\n\"\n            )\n            self.stack = stack.pop_all()", "min_run_count": 2, "name": "plotting.BackendLoading.time_get_plot_backend", "number": 1, "param_names": [], "params": [], "repeat": 1, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "275ed8f1d87eb6e40f19e678ae4e0130a88ef153363ae407c9576044f4455591", "warmup_time": 0}, "plotting.BackendLoading.time_get_plot_backend_fallback": {"code": "class BackendLoading:\n    def time_get_plot_backend_fallback(self):\n        # iterates through all the my_ep_backend[0-9] before falling back\n        # to importlib.import_module\n        _get_plot_backend(\"pandas_dummy_backend\")\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass BackendLoading:\n    def setup(self):\n        mod = importlib.util.module_from_spec(\n            importlib.machinery.ModuleSpec(\"pandas_dummy_backend\", None)\n        )\n        mod.plot = lambda *args, **kwargs: 1\n    \n        with contextlib.ExitStack() as stack:\n            stack.enter_context(\n                mock.patch.dict(sys.modules, {\"pandas_dummy_backend\": mod})\n            )\n            tmp_path = pathlib.Path(stack.enter_context(tempfile.TemporaryDirectory()))\n    \n            sys.path.insert(0, os.fsdecode(tmp_path))\n            stack.callback(sys.path.remove, os.fsdecode(tmp_path))\n    \n            dist_info = tmp_path / \"my_backend-0.0.0.dist-info\"\n            dist_info.mkdir()\n            (dist_info / \"entry_points.txt\").write_bytes(\n                b\"[pandas_plotting_backends]\\n\"\n                b\"my_ep_backend = pandas_dummy_backend\\n\"\n                b\"my_ep_backend0 = pandas_dummy_backend\\n\"\n                b\"my_ep_backend1 = pandas_dummy_backend\\n\"\n                b\"my_ep_backend2 = pandas_dummy_backend\\n\"\n                b\"my_ep_backend3 = pandas_dummy_backend\\n\"\n                b\"my_ep_backend4 = pandas_dummy_backend\\n\"\n                b\"my_ep_backend5 = pandas_dummy_backend\\n\"\n                b\"my_ep_backend6 = pandas_dummy_backend\\n\"\n                b\"my_ep_backend7 = pandas_dummy_backend\\n\"\n                b\"my_ep_backend8 = pandas_dummy_backend\\n\"\n                b\"my_ep_backend9 = pandas_dummy_backend\\n\"\n            )\n            self.stack = stack.pop_all()", "min_run_count": 2, "name": "plotting.BackendLoading.time_get_plot_backend_fallback", "number": 1, "param_names": [], "params": [], "repeat": 1, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "5910845eb9f1e056392eea6799696858a13e4b42bcc4462d896f69e4c4e69fdc", "warmup_time": 0}, "plotting.FramePlotting.time_frame_plot": {"code": "class FramePlotting:\n    def time_frame_plot(self, kind):\n        self.df.plot(x=\"x\", y=\"y\", kind=kind)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass FramePlotting:\n    def setup(self, kind):\n        if kind in [\"bar\", \"barh\", \"pie\"]:\n            n = 100\n        elif kind in [\"kde\", \"scatter\", \"hexbin\"]:\n            n = 10000\n        else:\n            n = 1000000\n    \n        self.x = Series(np.random.randn(n))\n        self.y = Series(np.random.randn(n))\n        if kind in [\"area\", \"pie\"]:\n            self.x = self.x.abs()\n            self.y = self.y.abs()\n        self.df = DataFrame({\"x\": self.x, \"y\": self.y})", "min_run_count": 2, "name": "plotting.FramePlotting.time_frame_plot", "number": 0, "param_names": ["kind"], "params": [["'line'", "'bar'", "'area'", "'barh'", "'hist'", "'kde'", "'pie'", "'scatter'", "'hexbin'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "d6c19f0e6ee8994eb981863b029fa07bc3dc6e28ca77fd1947a32124682e279a", "warmup_time": -1}, "plotting.Misc.time_plot_andrews_curves": {"code": "class Misc:\n    def time_plot_andrews_curves(self):\n        andrews_curves(self.df, \"Name\")\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Misc:\n    def setup(self):\n        N = 500\n        M = 10\n        self.df = DataFrame(np.random.randn(N, M))\n        self.df[\"Name\"] = [\"A\"] * N", "min_run_count": 2, "name": "plotting.Misc.time_plot_andrews_curves", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "c5cdb631131db0763b96053825ebc29d36564b7efc93174553deebff526d0e51", "warmup_time": -1}, "plotting.SeriesPlotting.time_series_plot": {"code": "class SeriesPlotting:\n    def time_series_plot(self, kind):\n        self.s.plot(kind=kind)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass SeriesPlotting:\n    def setup(self, kind):\n        if kind in [\"bar\", \"barh\", \"pie\"]:\n            n = 100\n        elif kind in [\"kde\"]:\n            n = 10000\n        else:\n            n = 1000000\n    \n        self.s = Series(np.random.randn(n))\n        if kind in [\"area\", \"pie\"]:\n            self.s = self.s.abs()", "min_run_count": 2, "name": "plotting.SeriesPlotting.time_series_plot", "number": 0, "param_names": ["kind"], "params": [["'line'", "'bar'", "'area'", "'barh'", "'hist'", "'kde'", "'pie'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "160ab68dd1bbcfdc4cb7ac7c745857d954d7b49e2140f072e93341253436ffb2", "warmup_time": -1}, "plotting.TimeseriesPlotting.time_plot_irregular": {"code": "class TimeseriesPlotting:\n    def time_plot_irregular(self):\n        self.df2.plot()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass TimeseriesPlotting:\n    def setup(self):\n        N = 2000\n        M = 5\n        idx = date_range(\"1/1/1975\", periods=N)\n        self.df = DataFrame(np.random.randn(N, M), index=idx)\n    \n        idx_irregular = DatetimeIndex(\n            np.concatenate((idx.values[0:10], idx.values[12:]))\n        )\n        self.df2 = DataFrame(\n            np.random.randn(len(idx_irregular), M), index=idx_irregular\n        )", "min_run_count": 2, "name": "plotting.TimeseriesPlotting.time_plot_irregular", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "eebbebf937fc740e9be07af175a3643c600ac60a98e1f1606d1ed7150b2966b0", "warmup_time": -1}, "plotting.TimeseriesPlotting.time_plot_regular": {"code": "class TimeseriesPlotting:\n    def time_plot_regular(self):\n        self.df.plot()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass TimeseriesPlotting:\n    def setup(self):\n        N = 2000\n        M = 5\n        idx = date_range(\"1/1/1975\", periods=N)\n        self.df = DataFrame(np.random.randn(N, M), index=idx)\n    \n        idx_irregular = DatetimeIndex(\n            np.concatenate((idx.values[0:10], idx.values[12:]))\n        )\n        self.df2 = DataFrame(\n            np.random.randn(len(idx_irregular), M), index=idx_irregular\n        )", "min_run_count": 2, "name": "plotting.TimeseriesPlotting.time_plot_regular", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "c3871908c149bdf0cd9d3c7cdce5ed7bd993762db8bacec201061775ac030be2", "warmup_time": -1}, "plotting.TimeseriesPlotting.time_plot_regular_compat": {"code": "class TimeseriesPlotting:\n    def time_plot_regular_compat(self):\n        self.df.plot(x_compat=True)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass TimeseriesPlotting:\n    def setup(self):\n        N = 2000\n        M = 5\n        idx = date_range(\"1/1/1975\", periods=N)\n        self.df = DataFrame(np.random.randn(N, M), index=idx)\n    \n        idx_irregular = DatetimeIndex(\n            np.concatenate((idx.values[0:10], idx.values[12:]))\n        )\n        self.df2 = DataFrame(\n            np.random.randn(len(idx_irregular), M), index=idx_irregular\n        )", "min_run_count": 2, "name": "plotting.TimeseriesPlotting.time_plot_regular_compat", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "6b83eb693399183277a784aee0704171f06e4913b66ddd6bddde0dcc2fb427ff", "warmup_time": -1}, "plotting.TimeseriesPlotting.time_plot_table": {"code": "class TimeseriesPlotting:\n    def time_plot_table(self):\n        self.df.plot(table=True)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass TimeseriesPlotting:\n    def setup(self):\n        N = 2000\n        M = 5\n        idx = date_range(\"1/1/1975\", periods=N)\n        self.df = DataFrame(np.random.randn(N, M), index=idx)\n    \n        idx_irregular = DatetimeIndex(\n            np.concatenate((idx.values[0:10], idx.values[12:]))\n        )\n        self.df2 = DataFrame(\n            np.random.randn(len(idx_irregular), M), index=idx_irregular\n        )", "min_run_count": 2, "name": "plotting.TimeseriesPlotting.time_plot_table", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "2c526eb7965a6c381c8aa22565224994f1cbd2c378f4a0aa87af283821f76da3", "warmup_time": -1}, "reindex.Align.time_align_series_irregular_string": {"code": "class Align:\n    def time_align_series_irregular_string(self):\n        self.x + self.y\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Align:\n    def setup(self):\n        n = 50000\n        indices = Index([f\"i-{i}\" for i in range(n)], dtype=object)\n        subsample_size = 40000\n        self.x = Series(np.random.randn(n), indices)\n        self.y = Series(\n            np.random.randn(subsample_size),\n            index=np.random.choice(indices, subsample_size, replace=False),\n        )", "min_run_count": 2, "name": "reindex.Align.time_align_series_irregular_string", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "99535222ff12826c671cd482a3e3dce8a1feb88c9e23e1a204057e24eff7019a", "warmup_time": -1}, "reindex.DropDuplicates.time_frame_drop_dups": {"code": "class DropDuplicates:\n    def time_frame_drop_dups(self, inplace):\n        self.df.drop_duplicates([\"key1\", \"key2\"], inplace=inplace)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass DropDuplicates:\n    def setup(self, inplace):\n        N = 10000\n        K = 10\n        key1 = Index([f\"i-{i}\" for i in range(N)], dtype=object).values.repeat(K)\n        key2 = Index([f\"i-{i}\" for i in range(N)], dtype=object).values.repeat(K)\n        self.df = DataFrame(\n            {\"key1\": key1, \"key2\": key2, \"value\": np.random.randn(N * K)}\n        )\n        self.df_nan = self.df.copy()\n        self.df_nan.iloc[:10000, :] = np.nan\n    \n        self.s = Series(np.random.randint(0, 1000, size=10000))\n        self.s_str = Series(\n            np.tile(Index([f\"i-{i}\" for i in range(1000)], dtype=object).values, 10)\n        )\n    \n        N = 1000000\n        K = 10000\n        key1 = np.random.randint(0, K, size=N)\n        self.df_int = DataFrame({\"key1\": key1})\n        self.df_bool = DataFrame(np.random.randint(0, 2, size=(K, 10), dtype=bool))", "min_run_count": 2, "name": "reindex.DropDuplicates.time_frame_drop_dups", "number": 0, "param_names": ["inplace"], "params": [["True", "False"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "9e3407f683cc7f16fac045b6c3c7aa89bb7ab9c2f86d11a22aa26844cdfc8bd8", "warmup_time": -1}, "reindex.DropDuplicates.time_frame_drop_dups_bool": {"code": "class DropDuplicates:\n    def time_frame_drop_dups_bool(self, inplace):\n        self.df_bool.drop_duplicates(inplace=inplace)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass DropDuplicates:\n    def setup(self, inplace):\n        N = 10000\n        K = 10\n        key1 = Index([f\"i-{i}\" for i in range(N)], dtype=object).values.repeat(K)\n        key2 = Index([f\"i-{i}\" for i in range(N)], dtype=object).values.repeat(K)\n        self.df = DataFrame(\n            {\"key1\": key1, \"key2\": key2, \"value\": np.random.randn(N * K)}\n        )\n        self.df_nan = self.df.copy()\n        self.df_nan.iloc[:10000, :] = np.nan\n    \n        self.s = Series(np.random.randint(0, 1000, size=10000))\n        self.s_str = Series(\n            np.tile(Index([f\"i-{i}\" for i in range(1000)], dtype=object).values, 10)\n        )\n    \n        N = 1000000\n        K = 10000\n        key1 = np.random.randint(0, K, size=N)\n        self.df_int = DataFrame({\"key1\": key1})\n        self.df_bool = DataFrame(np.random.randint(0, 2, size=(K, 10), dtype=bool))", "min_run_count": 2, "name": "reindex.DropDuplicates.time_frame_drop_dups_bool", "number": 0, "param_names": ["inplace"], "params": [["True", "False"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "ff1fe38fe30683f1f77e7f0d500e80fdc6a7c481f9529f0faceacb438bf8acf3", "warmup_time": -1}, "reindex.DropDuplicates.time_frame_drop_dups_int": {"code": "class DropDuplicates:\n    def time_frame_drop_dups_int(self, inplace):\n        self.df_int.drop_duplicates(inplace=inplace)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass DropDuplicates:\n    def setup(self, inplace):\n        N = 10000\n        K = 10\n        key1 = Index([f\"i-{i}\" for i in range(N)], dtype=object).values.repeat(K)\n        key2 = Index([f\"i-{i}\" for i in range(N)], dtype=object).values.repeat(K)\n        self.df = DataFrame(\n            {\"key1\": key1, \"key2\": key2, \"value\": np.random.randn(N * K)}\n        )\n        self.df_nan = self.df.copy()\n        self.df_nan.iloc[:10000, :] = np.nan\n    \n        self.s = Series(np.random.randint(0, 1000, size=10000))\n        self.s_str = Series(\n            np.tile(Index([f\"i-{i}\" for i in range(1000)], dtype=object).values, 10)\n        )\n    \n        N = 1000000\n        K = 10000\n        key1 = np.random.randint(0, K, size=N)\n        self.df_int = DataFrame({\"key1\": key1})\n        self.df_bool = DataFrame(np.random.randint(0, 2, size=(K, 10), dtype=bool))", "min_run_count": 2, "name": "reindex.DropDuplicates.time_frame_drop_dups_int", "number": 0, "param_names": ["inplace"], "params": [["True", "False"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "219d98c5c189760cab8a4753d551329b822cec481ba3587429a5918348833430", "warmup_time": -1}, "reindex.DropDuplicates.time_frame_drop_dups_na": {"code": "class DropDuplicates:\n    def time_frame_drop_dups_na(self, inplace):\n        self.df_nan.drop_duplicates([\"key1\", \"key2\"], inplace=inplace)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass DropDuplicates:\n    def setup(self, inplace):\n        N = 10000\n        K = 10\n        key1 = Index([f\"i-{i}\" for i in range(N)], dtype=object).values.repeat(K)\n        key2 = Index([f\"i-{i}\" for i in range(N)], dtype=object).values.repeat(K)\n        self.df = DataFrame(\n            {\"key1\": key1, \"key2\": key2, \"value\": np.random.randn(N * K)}\n        )\n        self.df_nan = self.df.copy()\n        self.df_nan.iloc[:10000, :] = np.nan\n    \n        self.s = Series(np.random.randint(0, 1000, size=10000))\n        self.s_str = Series(\n            np.tile(Index([f\"i-{i}\" for i in range(1000)], dtype=object).values, 10)\n        )\n    \n        N = 1000000\n        K = 10000\n        key1 = np.random.randint(0, K, size=N)\n        self.df_int = DataFrame({\"key1\": key1})\n        self.df_bool = DataFrame(np.random.randint(0, 2, size=(K, 10), dtype=bool))", "min_run_count": 2, "name": "reindex.DropDuplicates.time_frame_drop_dups_na", "number": 0, "param_names": ["inplace"], "params": [["True", "False"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "6645f4d4309d703c15aee91e0cccb7387dddfe3a50a13a8ee231b2e8598539f0", "warmup_time": -1}, "reindex.DropDuplicates.time_series_drop_dups_int": {"code": "class DropDuplicates:\n    def time_series_drop_dups_int(self, inplace):\n        self.s.drop_duplicates(inplace=inplace)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass DropDuplicates:\n    def setup(self, inplace):\n        N = 10000\n        K = 10\n        key1 = Index([f\"i-{i}\" for i in range(N)], dtype=object).values.repeat(K)\n        key2 = Index([f\"i-{i}\" for i in range(N)], dtype=object).values.repeat(K)\n        self.df = DataFrame(\n            {\"key1\": key1, \"key2\": key2, \"value\": np.random.randn(N * K)}\n        )\n        self.df_nan = self.df.copy()\n        self.df_nan.iloc[:10000, :] = np.nan\n    \n        self.s = Series(np.random.randint(0, 1000, size=10000))\n        self.s_str = Series(\n            np.tile(Index([f\"i-{i}\" for i in range(1000)], dtype=object).values, 10)\n        )\n    \n        N = 1000000\n        K = 10000\n        key1 = np.random.randint(0, K, size=N)\n        self.df_int = DataFrame({\"key1\": key1})\n        self.df_bool = DataFrame(np.random.randint(0, 2, size=(K, 10), dtype=bool))", "min_run_count": 2, "name": "reindex.DropDuplicates.time_series_drop_dups_int", "number": 0, "param_names": ["inplace"], "params": [["True", "False"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "0d5f8b5b9a0532b4bf319dbe2d7ccb87052976d4333850a3eaf137b4d9b23e5d", "warmup_time": -1}, "reindex.DropDuplicates.time_series_drop_dups_string": {"code": "class DropDuplicates:\n    def time_series_drop_dups_string(self, inplace):\n        self.s_str.drop_duplicates(inplace=inplace)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass DropDuplicates:\n    def setup(self, inplace):\n        N = 10000\n        K = 10\n        key1 = Index([f\"i-{i}\" for i in range(N)], dtype=object).values.repeat(K)\n        key2 = Index([f\"i-{i}\" for i in range(N)], dtype=object).values.repeat(K)\n        self.df = DataFrame(\n            {\"key1\": key1, \"key2\": key2, \"value\": np.random.randn(N * K)}\n        )\n        self.df_nan = self.df.copy()\n        self.df_nan.iloc[:10000, :] = np.nan\n    \n        self.s = Series(np.random.randint(0, 1000, size=10000))\n        self.s_str = Series(\n            np.tile(Index([f\"i-{i}\" for i in range(1000)], dtype=object).values, 10)\n        )\n    \n        N = 1000000\n        K = 10000\n        key1 = np.random.randint(0, K, size=N)\n        self.df_int = DataFrame({\"key1\": key1})\n        self.df_bool = DataFrame(np.random.randint(0, 2, size=(K, 10), dtype=bool))", "min_run_count": 2, "name": "reindex.DropDuplicates.time_series_drop_dups_string", "number": 0, "param_names": ["inplace"], "params": [["True", "False"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "0c0a1fb01f308c8f6dfbb4593af90cb7d596b775640ebe908d4556cc6e00938c", "warmup_time": -1}, "reindex.LevelAlign.time_align_level": {"code": "class LevelAlign:\n    def time_align_level(self):\n        self.df.align(self.df_level, level=1, copy=False)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass LevelAlign:\n    def setup(self):\n        self.index = MultiIndex(\n            levels=[np.arange(10), np.arange(100), np.arange(100)],\n            codes=[\n                np.arange(10).repeat(10000),\n                np.tile(np.arange(100).repeat(100), 10),\n                np.tile(np.tile(np.arange(100), 100), 10),\n            ],\n        )\n        self.df = DataFrame(np.random.randn(len(self.index), 4), index=self.index)\n        self.df_level = DataFrame(np.random.randn(100, 4), index=self.index.levels[1])", "min_run_count": 2, "name": "reindex.LevelAlign.time_align_level", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "cced19c77cf2154fcd7f760f955314b571a4c552f1c3dda834b08449c39cf96a", "warmup_time": -1}, "reindex.LevelAlign.time_reindex_level": {"code": "class LevelAlign:\n    def time_reindex_level(self):\n        self.df_level.reindex(self.index, level=1)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass LevelAlign:\n    def setup(self):\n        self.index = MultiIndex(\n            levels=[np.arange(10), np.arange(100), np.arange(100)],\n            codes=[\n                np.arange(10).repeat(10000),\n                np.tile(np.arange(100).repeat(100), 10),\n                np.tile(np.tile(np.arange(100), 100), 10),\n            ],\n        )\n        self.df = DataFrame(np.random.randn(len(self.index), 4), index=self.index)\n        self.df_level = DataFrame(np.random.randn(100, 4), index=self.index.levels[1])", "min_run_count": 2, "name": "reindex.LevelAlign.time_reindex_level", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "9c4e829ee0f877d248f2dca88a52830e615dd62d42be7dc5b046cd79771b41d2", "warmup_time": -1}, "reindex.Reindex.time_reindex_columns": {"code": "class Reindex:\n    def time_reindex_columns(self):\n        self.df2.reindex(columns=self.df.columns[1:5])\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Reindex:\n    def setup(self):\n        rng = date_range(start=\"1/1/1970\", periods=10000, freq=\"1min\")\n        self.df = DataFrame(np.random.rand(10000, 10), index=rng, columns=range(10))\n        self.df[\"foo\"] = \"bar\"\n        self.rng_subset = Index(rng[::2])\n        self.df2 = DataFrame(\n            index=range(10000), data=np.random.rand(10000, 30), columns=range(30)\n        )\n        N = 5000\n        K = 200\n        level1 = Index([f\"i-{i}\" for i in range(N)], dtype=object).values.repeat(K)\n        level2 = np.tile(Index([f\"i-{i}\" for i in range(K)], dtype=object).values, N)\n        index = MultiIndex.from_arrays([level1, level2])\n        self.s = Series(np.random.randn(N * K), index=index)\n        self.s_subset = self.s[::2]\n        self.s_subset_no_cache = self.s[::2].copy()\n    \n        mi = MultiIndex.from_product([rng, range(100)])\n        self.s2 = Series(np.random.randn(len(mi)), index=mi)\n        self.s2_subset = self.s2[::2].copy()", "min_run_count": 2, "name": "reindex.Reindex.time_reindex_columns", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "00a301c16f6c5bce541f67b2a6f047a8d90ab2341ce70509821a6cfb1c0d38df", "warmup_time": -1}, "reindex.Reindex.time_reindex_dates": {"code": "class Reindex:\n    def time_reindex_dates(self):\n        self.df.reindex(self.rng_subset)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Reindex:\n    def setup(self):\n        rng = date_range(start=\"1/1/1970\", periods=10000, freq=\"1min\")\n        self.df = DataFrame(np.random.rand(10000, 10), index=rng, columns=range(10))\n        self.df[\"foo\"] = \"bar\"\n        self.rng_subset = Index(rng[::2])\n        self.df2 = DataFrame(\n            index=range(10000), data=np.random.rand(10000, 30), columns=range(30)\n        )\n        N = 5000\n        K = 200\n        level1 = Index([f\"i-{i}\" for i in range(N)], dtype=object).values.repeat(K)\n        level2 = np.tile(Index([f\"i-{i}\" for i in range(K)], dtype=object).values, N)\n        index = MultiIndex.from_arrays([level1, level2])\n        self.s = Series(np.random.randn(N * K), index=index)\n        self.s_subset = self.s[::2]\n        self.s_subset_no_cache = self.s[::2].copy()\n    \n        mi = MultiIndex.from_product([rng, range(100)])\n        self.s2 = Series(np.random.randn(len(mi)), index=mi)\n        self.s2_subset = self.s2[::2].copy()", "min_run_count": 2, "name": "reindex.Reindex.time_reindex_dates", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "d8bf7e54481378634e8e80cc8c0c55d1700f313f036d19ab3de1dca31e190f66", "warmup_time": -1}, "reindex.Reindex.time_reindex_multiindex_no_cache": {"code": "class Reindex:\n    def time_reindex_multiindex_no_cache(self):\n        # Copy to avoid MultiIndex._values getting cached\n        self.s.reindex(self.s_subset_no_cache.index.copy())\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Reindex:\n    def setup(self):\n        rng = date_range(start=\"1/1/1970\", periods=10000, freq=\"1min\")\n        self.df = DataFrame(np.random.rand(10000, 10), index=rng, columns=range(10))\n        self.df[\"foo\"] = \"bar\"\n        self.rng_subset = Index(rng[::2])\n        self.df2 = DataFrame(\n            index=range(10000), data=np.random.rand(10000, 30), columns=range(30)\n        )\n        N = 5000\n        K = 200\n        level1 = Index([f\"i-{i}\" for i in range(N)], dtype=object).values.repeat(K)\n        level2 = np.tile(Index([f\"i-{i}\" for i in range(K)], dtype=object).values, N)\n        index = MultiIndex.from_arrays([level1, level2])\n        self.s = Series(np.random.randn(N * K), index=index)\n        self.s_subset = self.s[::2]\n        self.s_subset_no_cache = self.s[::2].copy()\n    \n        mi = MultiIndex.from_product([rng, range(100)])\n        self.s2 = Series(np.random.randn(len(mi)), index=mi)\n        self.s2_subset = self.s2[::2].copy()", "min_run_count": 2, "name": "reindex.Reindex.time_reindex_multiindex_no_cache", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "a87224c6ab473aaa760c5bef29410e56f6234562f30eaa05cd52c79d7ee74f25", "warmup_time": -1}, "reindex.Reindex.time_reindex_multiindex_no_cache_dates": {"code": "class Reindex:\n    def time_reindex_multiindex_no_cache_dates(self):\n        # Copy to avoid MultiIndex._values getting cached\n        self.s2_subset.reindex(self.s2.index.copy())\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Reindex:\n    def setup(self):\n        rng = date_range(start=\"1/1/1970\", periods=10000, freq=\"1min\")\n        self.df = DataFrame(np.random.rand(10000, 10), index=rng, columns=range(10))\n        self.df[\"foo\"] = \"bar\"\n        self.rng_subset = Index(rng[::2])\n        self.df2 = DataFrame(\n            index=range(10000), data=np.random.rand(10000, 30), columns=range(30)\n        )\n        N = 5000\n        K = 200\n        level1 = Index([f\"i-{i}\" for i in range(N)], dtype=object).values.repeat(K)\n        level2 = np.tile(Index([f\"i-{i}\" for i in range(K)], dtype=object).values, N)\n        index = MultiIndex.from_arrays([level1, level2])\n        self.s = Series(np.random.randn(N * K), index=index)\n        self.s_subset = self.s[::2]\n        self.s_subset_no_cache = self.s[::2].copy()\n    \n        mi = MultiIndex.from_product([rng, range(100)])\n        self.s2 = Series(np.random.randn(len(mi)), index=mi)\n        self.s2_subset = self.s2[::2].copy()", "min_run_count": 2, "name": "reindex.Reindex.time_reindex_multiindex_no_cache_dates", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "34d18834462d53c009ef308fc30cfadd3c904d729da717f68d96a14ef887073a", "warmup_time": -1}, "reindex.Reindex.time_reindex_multiindex_with_cache": {"code": "class Reindex:\n    def time_reindex_multiindex_with_cache(self):\n        # MultiIndex._values gets cached\n        self.s.reindex(self.s_subset.index)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Reindex:\n    def setup(self):\n        rng = date_range(start=\"1/1/1970\", periods=10000, freq=\"1min\")\n        self.df = DataFrame(np.random.rand(10000, 10), index=rng, columns=range(10))\n        self.df[\"foo\"] = \"bar\"\n        self.rng_subset = Index(rng[::2])\n        self.df2 = DataFrame(\n            index=range(10000), data=np.random.rand(10000, 30), columns=range(30)\n        )\n        N = 5000\n        K = 200\n        level1 = Index([f\"i-{i}\" for i in range(N)], dtype=object).values.repeat(K)\n        level2 = np.tile(Index([f\"i-{i}\" for i in range(K)], dtype=object).values, N)\n        index = MultiIndex.from_arrays([level1, level2])\n        self.s = Series(np.random.randn(N * K), index=index)\n        self.s_subset = self.s[::2]\n        self.s_subset_no_cache = self.s[::2].copy()\n    \n        mi = MultiIndex.from_product([rng, range(100)])\n        self.s2 = Series(np.random.randn(len(mi)), index=mi)\n        self.s2_subset = self.s2[::2].copy()", "min_run_count": 2, "name": "reindex.Reindex.time_reindex_multiindex_with_cache", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "fcee94dfdbc0f691c1052335d9fe83cbb8a3adf26ff91b6a60701a0f2b512526", "warmup_time": -1}, "reindex.ReindexMethod.time_reindex_method": {"code": "class ReindexMethod:\n    def time_reindex_method(self, method, constructor):\n        self.ts.reindex(self.idx, method=method)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ReindexMethod:\n    def setup(self, method, constructor):\n        N = 100000\n        self.idx = constructor(\"1/1/2000\", periods=N, freq=\"1min\")\n        self.ts = Series(np.random.randn(N), index=self.idx)[::2]", "min_run_count": 2, "name": "reindex.ReindexMethod.time_reindex_method", "number": 0, "param_names": ["method", "constructor"], "params": [["'pad'", "'backfill'"], ["<function date_range>", "<function period_range>"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "52e66df756313fc255334a8a0cb3c1dbaf796d0b655126ff3c140d0a2207a3bc", "warmup_time": -1}, "replace.Convert.time_replace": {"code": "class Convert:\n    def time_replace(self, constructor, replace_data):\n        self.data.replace(self.to_replace)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Convert:\n    def setup(self, constructor, replace_data):\n        N = 10**3\n        data = {\n            \"Series\": pd.Series(np.random.randint(N, size=N)),\n            \"DataFrame\": pd.DataFrame(\n                {\"A\": np.random.randint(N, size=N), \"B\": np.random.randint(N, size=N)}\n            ),\n        }\n        self.to_replace = {i: getattr(pd, replace_data) for i in range(N)}\n        self.data = data[constructor]", "min_run_count": 2, "name": "replace.Convert.time_replace", "number": 0, "param_names": ["constructor", "replace_data"], "params": [["'DataFrame'", "'Series'"], ["'Timestamp'", "'Timedelta'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "a744fa5ba9e82cf960d86890e5316fd597568f0134b134ef39e6a068d4a6fcaa", "warmup_time": -1}, "replace.FillNa.time_fillna": {"code": "class FillNa:\n    def time_fillna(self, inplace):\n        self.ts.fillna(0.0, inplace=inplace)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass FillNa:\n    def setup(self, inplace):\n        N = 10**6\n        rng = pd.date_range(\"1/1/2000\", periods=N, freq=\"min\")\n        data = np.random.randn(N)\n        data[::2] = np.nan\n        self.ts = pd.Series(data, index=rng)", "min_run_count": 2, "name": "replace.FillNa.time_fillna", "number": 0, "param_names": ["inplace"], "params": [["True", "False"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "0b76c4847fb4ab0037ada56a69ae0191854beb20a29f7c1fdb937679f1a20cfa", "warmup_time": -1}, "replace.FillNa.time_replace": {"code": "class FillNa:\n    def time_replace(self, inplace):\n        self.ts.replace(np.nan, 0.0, inplace=inplace)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass FillNa:\n    def setup(self, inplace):\n        N = 10**6\n        rng = pd.date_range(\"1/1/2000\", periods=N, freq=\"min\")\n        data = np.random.randn(N)\n        data[::2] = np.nan\n        self.ts = pd.Series(data, index=rng)", "min_run_count": 2, "name": "replace.FillNa.time_replace", "number": 0, "param_names": ["inplace"], "params": [["True", "False"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "ce112dec862dc388710999d0a5afaf6410c6e73eb37747f783c8f0f031390817", "warmup_time": -1}, "replace.ReplaceDict.time_replace_series": {"code": "class ReplaceDict:\n    def time_replace_series(self, inplace):\n        self.s.replace(self.to_rep, inplace=inplace)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ReplaceDict:\n    def setup(self, inplace):\n        N = 10**5\n        start_value = 10**5\n        self.to_rep = dict(enumerate(np.arange(N) + start_value))\n        self.s = pd.Series(np.random.randint(N, size=10**3))", "min_run_count": 2, "name": "replace.ReplaceDict.time_replace_series", "number": 0, "param_names": ["inplace"], "params": [["True", "False"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "8597d90cda40f0b788096a546f8abbf5caa952c6eea9f9e47eb8d4ce2d3c1aa2", "warmup_time": -1}, "replace.ReplaceList.time_replace_list": {"code": "class ReplaceList:\n    def time_replace_list(self, inplace):\n        self.df.replace([np.inf, -np.inf], np.nan, inplace=inplace)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ReplaceList:\n    def setup(self, inplace):\n        self.df = pd.DataFrame({\"A\": 0, \"B\": 0}, index=range(10**7))", "min_run_count": 2, "name": "replace.ReplaceList.time_replace_list", "number": 0, "param_names": ["inplace"], "params": [["True", "False"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "959eed35fcb7e64cf2b5aec83263f040060cf5f6bbbff9dcbc719a20863b5eac", "warmup_time": -1}, "replace.ReplaceList.time_replace_list_one_match": {"code": "class ReplaceList:\n    def time_replace_list_one_match(self, inplace):\n        # the 1 can be held in self._df.blocks[0], while the inf and -inf can't\n        self.df.replace([np.inf, -np.inf, 1], np.nan, inplace=inplace)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ReplaceList:\n    def setup(self, inplace):\n        self.df = pd.DataFrame({\"A\": 0, \"B\": 0}, index=range(10**7))", "min_run_count": 2, "name": "replace.ReplaceList.time_replace_list_one_match", "number": 0, "param_names": ["inplace"], "params": [["True", "False"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "6d505bdc8d7c3ba7390852b2bee3c44fcb2c810e807722f5dbc7bbf9e5969c02", "warmup_time": -1}, "reshape.Crosstab.time_crosstab": {"code": "class Crosstab:\n    def time_crosstab(self):\n        pd.crosstab(self.vec1, self.vec2)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Crosstab:\n    def setup(self):\n        N = 100000\n        fac1 = np.array([\"A\", \"B\", \"C\"], dtype=\"O\")\n        fac2 = np.array([\"one\", \"two\"], dtype=\"O\")\n        self.ind1 = np.random.randint(0, 3, size=N)\n        self.ind2 = np.random.randint(0, 2, size=N)\n        self.vec1 = fac1.take(self.ind1)\n        self.vec2 = fac2.take(self.ind2)", "min_run_count": 2, "name": "reshape.Crosstab.time_crosstab", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "9111a9ad9a258688c45ba6a0c05b7b226f360b676432ed650b695e5397fde93e", "warmup_time": -1}, "reshape.Crosstab.time_crosstab_normalize": {"code": "class Crosstab:\n    def time_crosstab_normalize(self):\n        pd.crosstab(self.vec1, self.vec2, normalize=True)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Crosstab:\n    def setup(self):\n        N = 100000\n        fac1 = np.array([\"A\", \"B\", \"C\"], dtype=\"O\")\n        fac2 = np.array([\"one\", \"two\"], dtype=\"O\")\n        self.ind1 = np.random.randint(0, 3, size=N)\n        self.ind2 = np.random.randint(0, 2, size=N)\n        self.vec1 = fac1.take(self.ind1)\n        self.vec2 = fac2.take(self.ind2)", "min_run_count": 2, "name": "reshape.Crosstab.time_crosstab_normalize", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "5aca65001068430d0914d98785bddb8561273e9c8aa15b387c7dd93043ebf568", "warmup_time": -1}, "reshape.Crosstab.time_crosstab_normalize_margins": {"code": "class Crosstab:\n    def time_crosstab_normalize_margins(self):\n        pd.crosstab(self.vec1, self.vec2, normalize=True, margins=True)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Crosstab:\n    def setup(self):\n        N = 100000\n        fac1 = np.array([\"A\", \"B\", \"C\"], dtype=\"O\")\n        fac2 = np.array([\"one\", \"two\"], dtype=\"O\")\n        self.ind1 = np.random.randint(0, 3, size=N)\n        self.ind2 = np.random.randint(0, 2, size=N)\n        self.vec1 = fac1.take(self.ind1)\n        self.vec2 = fac2.take(self.ind2)", "min_run_count": 2, "name": "reshape.Crosstab.time_crosstab_normalize_margins", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "4c136fc000722c789e91a8ae69e2c658c5bedd669b2178c0fc2a1f4f2b42727b", "warmup_time": -1}, "reshape.Crosstab.time_crosstab_values": {"code": "class Crosstab:\n    def time_crosstab_values(self):\n        pd.crosstab(self.vec1, self.vec2, values=self.ind1, aggfunc=\"sum\")\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Crosstab:\n    def setup(self):\n        N = 100000\n        fac1 = np.array([\"A\", \"B\", \"C\"], dtype=\"O\")\n        fac2 = np.array([\"one\", \"two\"], dtype=\"O\")\n        self.ind1 = np.random.randint(0, 3, size=N)\n        self.ind2 = np.random.randint(0, 2, size=N)\n        self.vec1 = fac1.take(self.ind1)\n        self.vec2 = fac2.take(self.ind2)", "min_run_count": 2, "name": "reshape.Crosstab.time_crosstab_values", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "3b4ec27deb69daa12d4b65e15cc4b7b2edcc88df3a066962121c333f57a3423e", "warmup_time": -1}, "reshape.Cut.peakmem_cut_interval": {"code": "class Cut:\n    def peakmem_cut_interval(self, bins):\n        # GH 27668\n        pd.cut(self.int_series, self.interval_bins)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Cut:\n    def setup(self, bins):\n        N = 10**5\n        self.int_series = pd.Series(np.arange(N).repeat(5))\n        self.float_series = pd.Series(np.random.randn(N).repeat(5))\n        self.timedelta_series = pd.Series(\n            np.random.randint(N, size=N), dtype=\"timedelta64[ns]\"\n        )\n        self.datetime_series = pd.Series(\n            np.random.randint(N, size=N), dtype=\"datetime64[ns]\"\n        )\n        self.interval_bins = pd.IntervalIndex.from_breaks(np.linspace(0, N, bins))", "name": "reshape.Cut.peakmem_cut_interval", "param_names": ["bins"], "params": [["4", "10", "1000"]], "timeout": 60.0, "type": "peakmemory", "unit": "bytes", "version": "4a50cdb22148145d78b66b3246a5d917de2b2b2c2a79baab6c336150c6028996"}, "reshape.Cut.time_cut_datetime": {"code": "class Cut:\n    def time_cut_datetime(self, bins):\n        pd.cut(self.datetime_series, bins)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Cut:\n    def setup(self, bins):\n        N = 10**5\n        self.int_series = pd.Series(np.arange(N).repeat(5))\n        self.float_series = pd.Series(np.random.randn(N).repeat(5))\n        self.timedelta_series = pd.Series(\n            np.random.randint(N, size=N), dtype=\"timedelta64[ns]\"\n        )\n        self.datetime_series = pd.Series(\n            np.random.randint(N, size=N), dtype=\"datetime64[ns]\"\n        )\n        self.interval_bins = pd.IntervalIndex.from_breaks(np.linspace(0, N, bins))", "min_run_count": 2, "name": "reshape.Cut.time_cut_datetime", "number": 0, "param_names": ["bins"], "params": [["4", "10", "1000"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "58412e44ffc063ce05ec9eabf6599316b54c12e85398a5cd91280e5f2eaec7de", "warmup_time": -1}, "reshape.Cut.time_cut_float": {"code": "class Cut:\n    def time_cut_float(self, bins):\n        pd.cut(self.float_series, bins)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Cut:\n    def setup(self, bins):\n        N = 10**5\n        self.int_series = pd.Series(np.arange(N).repeat(5))\n        self.float_series = pd.Series(np.random.randn(N).repeat(5))\n        self.timedelta_series = pd.Series(\n            np.random.randint(N, size=N), dtype=\"timedelta64[ns]\"\n        )\n        self.datetime_series = pd.Series(\n            np.random.randint(N, size=N), dtype=\"datetime64[ns]\"\n        )\n        self.interval_bins = pd.IntervalIndex.from_breaks(np.linspace(0, N, bins))", "min_run_count": 2, "name": "reshape.Cut.time_cut_float", "number": 0, "param_names": ["bins"], "params": [["4", "10", "1000"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "85096ca698be2f3208680d4f35d7aeded90a2e9795781508cbc5dfdf35e7e36b", "warmup_time": -1}, "reshape.Cut.time_cut_int": {"code": "class Cut:\n    def time_cut_int(self, bins):\n        pd.cut(self.int_series, bins)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Cut:\n    def setup(self, bins):\n        N = 10**5\n        self.int_series = pd.Series(np.arange(N).repeat(5))\n        self.float_series = pd.Series(np.random.randn(N).repeat(5))\n        self.timedelta_series = pd.Series(\n            np.random.randint(N, size=N), dtype=\"timedelta64[ns]\"\n        )\n        self.datetime_series = pd.Series(\n            np.random.randint(N, size=N), dtype=\"datetime64[ns]\"\n        )\n        self.interval_bins = pd.IntervalIndex.from_breaks(np.linspace(0, N, bins))", "min_run_count": 2, "name": "reshape.Cut.time_cut_int", "number": 0, "param_names": ["bins"], "params": [["4", "10", "1000"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "e8b43cd5e06cec8978579ef14b528be88fb90d1577ba5cc34c0c00559616d982", "warmup_time": -1}, "reshape.Cut.time_cut_interval": {"code": "class Cut:\n    def time_cut_interval(self, bins):\n        # GH 27668\n        pd.cut(self.int_series, self.interval_bins)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Cut:\n    def setup(self, bins):\n        N = 10**5\n        self.int_series = pd.Series(np.arange(N).repeat(5))\n        self.float_series = pd.Series(np.random.randn(N).repeat(5))\n        self.timedelta_series = pd.Series(\n            np.random.randint(N, size=N), dtype=\"timedelta64[ns]\"\n        )\n        self.datetime_series = pd.Series(\n            np.random.randint(N, size=N), dtype=\"datetime64[ns]\"\n        )\n        self.interval_bins = pd.IntervalIndex.from_breaks(np.linspace(0, N, bins))", "min_run_count": 2, "name": "reshape.Cut.time_cut_interval", "number": 0, "param_names": ["bins"], "params": [["4", "10", "1000"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "379c2ec4450e760810c91f3626fdd11aad35e5d872d5b8912a9db3362f42e133", "warmup_time": -1}, "reshape.Cut.time_cut_timedelta": {"code": "class Cut:\n    def time_cut_timedelta(self, bins):\n        pd.cut(self.timedelta_series, bins)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Cut:\n    def setup(self, bins):\n        N = 10**5\n        self.int_series = pd.Series(np.arange(N).repeat(5))\n        self.float_series = pd.Series(np.random.randn(N).repeat(5))\n        self.timedelta_series = pd.Series(\n            np.random.randint(N, size=N), dtype=\"timedelta64[ns]\"\n        )\n        self.datetime_series = pd.Series(\n            np.random.randint(N, size=N), dtype=\"datetime64[ns]\"\n        )\n        self.interval_bins = pd.IntervalIndex.from_breaks(np.linspace(0, N, bins))", "min_run_count": 2, "name": "reshape.Cut.time_cut_timedelta", "number": 0, "param_names": ["bins"], "params": [["4", "10", "1000"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "758ab752e664d48441ccb021304bc8e71171846cee22a64b2e72be3351f00447", "warmup_time": -1}, "reshape.Cut.time_qcut_datetime": {"code": "class Cut:\n    def time_qcut_datetime(self, bins):\n        pd.qcut(self.datetime_series, bins)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Cut:\n    def setup(self, bins):\n        N = 10**5\n        self.int_series = pd.Series(np.arange(N).repeat(5))\n        self.float_series = pd.Series(np.random.randn(N).repeat(5))\n        self.timedelta_series = pd.Series(\n            np.random.randint(N, size=N), dtype=\"timedelta64[ns]\"\n        )\n        self.datetime_series = pd.Series(\n            np.random.randint(N, size=N), dtype=\"datetime64[ns]\"\n        )\n        self.interval_bins = pd.IntervalIndex.from_breaks(np.linspace(0, N, bins))", "min_run_count": 2, "name": "reshape.Cut.time_qcut_datetime", "number": 0, "param_names": ["bins"], "params": [["4", "10", "1000"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "d04a2db349c29907a75caab0e3a9c580e577e50262df736e1650eb96f77d134d", "warmup_time": -1}, "reshape.Cut.time_qcut_float": {"code": "class Cut:\n    def time_qcut_float(self, bins):\n        pd.qcut(self.float_series, bins)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Cut:\n    def setup(self, bins):\n        N = 10**5\n        self.int_series = pd.Series(np.arange(N).repeat(5))\n        self.float_series = pd.Series(np.random.randn(N).repeat(5))\n        self.timedelta_series = pd.Series(\n            np.random.randint(N, size=N), dtype=\"timedelta64[ns]\"\n        )\n        self.datetime_series = pd.Series(\n            np.random.randint(N, size=N), dtype=\"datetime64[ns]\"\n        )\n        self.interval_bins = pd.IntervalIndex.from_breaks(np.linspace(0, N, bins))", "min_run_count": 2, "name": "reshape.Cut.time_qcut_float", "number": 0, "param_names": ["bins"], "params": [["4", "10", "1000"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "0482097ddcc850236edbae620fd920d073c84d385fe332eaefbfb40041f64df2", "warmup_time": -1}, "reshape.Cut.time_qcut_int": {"code": "class Cut:\n    def time_qcut_int(self, bins):\n        pd.qcut(self.int_series, bins)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Cut:\n    def setup(self, bins):\n        N = 10**5\n        self.int_series = pd.Series(np.arange(N).repeat(5))\n        self.float_series = pd.Series(np.random.randn(N).repeat(5))\n        self.timedelta_series = pd.Series(\n            np.random.randint(N, size=N), dtype=\"timedelta64[ns]\"\n        )\n        self.datetime_series = pd.Series(\n            np.random.randint(N, size=N), dtype=\"datetime64[ns]\"\n        )\n        self.interval_bins = pd.IntervalIndex.from_breaks(np.linspace(0, N, bins))", "min_run_count": 2, "name": "reshape.Cut.time_qcut_int", "number": 0, "param_names": ["bins"], "params": [["4", "10", "1000"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "83d5a7e00e70a8e2dae57a0f38abad70d2db20c1bc5fe39c202f1d94ba5f6360", "warmup_time": -1}, "reshape.Cut.time_qcut_timedelta": {"code": "class Cut:\n    def time_qcut_timedelta(self, bins):\n        pd.qcut(self.timedelta_series, bins)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Cut:\n    def setup(self, bins):\n        N = 10**5\n        self.int_series = pd.Series(np.arange(N).repeat(5))\n        self.float_series = pd.Series(np.random.randn(N).repeat(5))\n        self.timedelta_series = pd.Series(\n            np.random.randint(N, size=N), dtype=\"timedelta64[ns]\"\n        )\n        self.datetime_series = pd.Series(\n            np.random.randint(N, size=N), dtype=\"datetime64[ns]\"\n        )\n        self.interval_bins = pd.IntervalIndex.from_breaks(np.linspace(0, N, bins))", "min_run_count": 2, "name": "reshape.Cut.time_qcut_timedelta", "number": 0, "param_names": ["bins"], "params": [["4", "10", "1000"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "ce5e325613d980c2c58926140ecd066ba1caa5ff13d1f13c4b028bf98cb83b0f", "warmup_time": -1}, "reshape.Explode.time_explode": {"code": "class Explode:\n    def time_explode(self, n_rows, max_list_length):\n        self.series.explode()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Explode:\n    def setup(self, n_rows, max_list_length):\n        data = [np.arange(np.random.randint(max_list_length)) for _ in range(n_rows)]\n        self.series = pd.Series(data)", "min_run_count": 2, "name": "reshape.Explode.time_explode", "number": 0, "param_names": ["n_rows", "max_list_length"], "params": [["100", "1000", "10000"], ["3", "5", "10"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "1e8e8da03418f2a12d85f80f073278296ec8c8f9e43fc8bcc690b704c5f258de", "warmup_time": -1}, "reshape.GetDummies.time_get_dummies_1d": {"code": "class GetDummies:\n    def time_get_dummies_1d(self):\n        pd.get_dummies(self.s, sparse=False)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass GetDummies:\n    def setup(self):\n        categories = list(string.ascii_letters[:12])\n        s = pd.Series(\n            np.random.choice(categories, size=1000000),\n            dtype=CategoricalDtype(categories),\n        )\n        self.s = s", "min_run_count": 2, "name": "reshape.GetDummies.time_get_dummies_1d", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "f6981c8b44fbd13f60eff496356529e393625318426d340155a55ed3d7ffb4ee", "warmup_time": -1}, "reshape.GetDummies.time_get_dummies_1d_sparse": {"code": "class GetDummies:\n    def time_get_dummies_1d_sparse(self):\n        pd.get_dummies(self.s, sparse=True)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass GetDummies:\n    def setup(self):\n        categories = list(string.ascii_letters[:12])\n        s = pd.Series(\n            np.random.choice(categories, size=1000000),\n            dtype=CategoricalDtype(categories),\n        )\n        self.s = s", "min_run_count": 2, "name": "reshape.GetDummies.time_get_dummies_1d_sparse", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "f4b85a94bf96350e6ae89b0267fcb36cf05e306063a0915e425fc9e5a1a4467e", "warmup_time": -1}, "reshape.Melt.time_melt_dataframe": {"code": "class Melt:\n    def time_melt_dataframe(self, dtype):\n        melt(self.df, id_vars=[\"id1\", \"id2\"])\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Melt:\n    def setup(self, dtype):\n        self.df = DataFrame(\n            np.random.randn(100_000, 3), columns=[\"A\", \"B\", \"C\"], dtype=dtype\n        )\n        self.df[\"id1\"] = pd.Series(np.random.randint(0, 10, 10000))\n        self.df[\"id2\"] = pd.Series(np.random.randint(100, 1000, 10000))", "min_run_count": 2, "name": "reshape.Melt.time_melt_dataframe", "number": 0, "param_names": ["dtype"], "params": [["'float64'", "'Float64'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "22a1727a0e67859dc0ec65b547a3d44f8c9725863c959eba27153fb0d8f66d4c", "warmup_time": -1}, "reshape.Pivot.time_reshape_pivot_time_series": {"code": "class Pivot:\n    def time_reshape_pivot_time_series(self):\n        self.df.pivot(index=\"date\", columns=\"variable\", values=\"value\")\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Pivot:\n    def setup(self):\n        N = 10000\n        index = date_range(\"1/1/2000\", periods=N, freq=\"h\")\n        data = {\n            \"value\": np.random.randn(N * 50),\n            \"variable\": np.arange(50).repeat(N),\n            \"date\": np.tile(index.values, 50),\n        }\n        self.df = DataFrame(data)", "min_run_count": 2, "name": "reshape.Pivot.time_reshape_pivot_time_series", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "7466faab8bdadd61fa94c30f9a91cca68cb993c7d0bcf34c64f2b9a31994d7b8", "warmup_time": -1}, "reshape.PivotTable.time_pivot_table": {"code": "class PivotTable:\n    def time_pivot_table(self):\n        self.df.pivot_table(index=\"key1\", columns=[\"key2\", \"key3\"])\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass PivotTable:\n    def setup(self):\n        N = 100000\n        fac1 = np.array([\"A\", \"B\", \"C\"], dtype=\"O\")\n        fac2 = np.array([\"one\", \"two\"], dtype=\"O\")\n        ind1 = np.random.randint(0, 3, size=N)\n        ind2 = np.random.randint(0, 2, size=N)\n        self.df = DataFrame(\n            {\n                \"key1\": fac1.take(ind1),\n                \"key2\": fac2.take(ind2),\n                \"key3\": fac2.take(ind2),\n                \"value1\": np.random.randn(N),\n                \"value2\": np.random.randn(N),\n                \"value3\": np.random.randn(N),\n            }\n        )\n        self.df2 = DataFrame(\n            {\"col1\": list(\"abcde\"), \"col2\": list(\"fghij\"), \"col3\": [1, 2, 3, 4, 5]}\n        )\n        self.df2.col1 = self.df2.col1.astype(\"category\")\n        self.df2.col2 = self.df2.col2.astype(\"category\")", "min_run_count": 2, "name": "reshape.PivotTable.time_pivot_table", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "03f1827427df23f7923b9d2b4ff8790a8896570fbbccf7ccd79cda77f3b29fb6", "warmup_time": -1}, "reshape.PivotTable.time_pivot_table_agg": {"code": "class PivotTable:\n    def time_pivot_table_agg(self):\n        self.df.pivot_table(\n            index=\"key1\", columns=[\"key2\", \"key3\"], aggfunc=[\"sum\", \"mean\"]\n        )\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass PivotTable:\n    def setup(self):\n        N = 100000\n        fac1 = np.array([\"A\", \"B\", \"C\"], dtype=\"O\")\n        fac2 = np.array([\"one\", \"two\"], dtype=\"O\")\n        ind1 = np.random.randint(0, 3, size=N)\n        ind2 = np.random.randint(0, 2, size=N)\n        self.df = DataFrame(\n            {\n                \"key1\": fac1.take(ind1),\n                \"key2\": fac2.take(ind2),\n                \"key3\": fac2.take(ind2),\n                \"value1\": np.random.randn(N),\n                \"value2\": np.random.randn(N),\n                \"value3\": np.random.randn(N),\n            }\n        )\n        self.df2 = DataFrame(\n            {\"col1\": list(\"abcde\"), \"col2\": list(\"fghij\"), \"col3\": [1, 2, 3, 4, 5]}\n        )\n        self.df2.col1 = self.df2.col1.astype(\"category\")\n        self.df2.col2 = self.df2.col2.astype(\"category\")", "min_run_count": 2, "name": "reshape.PivotTable.time_pivot_table_agg", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "e31596884db26ad8a96fbca432b50937254b59d0e4139cefbc2d930b6835d13b", "warmup_time": -1}, "reshape.PivotTable.time_pivot_table_categorical": {"code": "class PivotTable:\n    def time_pivot_table_categorical(self):\n        self.df2.pivot_table(\n            index=\"col1\", values=\"col3\", columns=\"col2\", aggfunc=\"sum\", fill_value=0\n        )\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass PivotTable:\n    def setup(self):\n        N = 100000\n        fac1 = np.array([\"A\", \"B\", \"C\"], dtype=\"O\")\n        fac2 = np.array([\"one\", \"two\"], dtype=\"O\")\n        ind1 = np.random.randint(0, 3, size=N)\n        ind2 = np.random.randint(0, 2, size=N)\n        self.df = DataFrame(\n            {\n                \"key1\": fac1.take(ind1),\n                \"key2\": fac2.take(ind2),\n                \"key3\": fac2.take(ind2),\n                \"value1\": np.random.randn(N),\n                \"value2\": np.random.randn(N),\n                \"value3\": np.random.randn(N),\n            }\n        )\n        self.df2 = DataFrame(\n            {\"col1\": list(\"abcde\"), \"col2\": list(\"fghij\"), \"col3\": [1, 2, 3, 4, 5]}\n        )\n        self.df2.col1 = self.df2.col1.astype(\"category\")\n        self.df2.col2 = self.df2.col2.astype(\"category\")", "min_run_count": 2, "name": "reshape.PivotTable.time_pivot_table_categorical", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "d8d0ae28f6fb18e72ed98a04ed6ec36ca77902bf4ebba37acf33e7df0fd6ca21", "warmup_time": -1}, "reshape.PivotTable.time_pivot_table_categorical_observed": {"code": "class PivotTable:\n    def time_pivot_table_categorical_observed(self):\n        self.df2.pivot_table(\n            index=\"col1\",\n            values=\"col3\",\n            columns=\"col2\",\n            aggfunc=\"sum\",\n            fill_value=0,\n            observed=True,\n        )\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass PivotTable:\n    def setup(self):\n        N = 100000\n        fac1 = np.array([\"A\", \"B\", \"C\"], dtype=\"O\")\n        fac2 = np.array([\"one\", \"two\"], dtype=\"O\")\n        ind1 = np.random.randint(0, 3, size=N)\n        ind2 = np.random.randint(0, 2, size=N)\n        self.df = DataFrame(\n            {\n                \"key1\": fac1.take(ind1),\n                \"key2\": fac2.take(ind2),\n                \"key3\": fac2.take(ind2),\n                \"value1\": np.random.randn(N),\n                \"value2\": np.random.randn(N),\n                \"value3\": np.random.randn(N),\n            }\n        )\n        self.df2 = DataFrame(\n            {\"col1\": list(\"abcde\"), \"col2\": list(\"fghij\"), \"col3\": [1, 2, 3, 4, 5]}\n        )\n        self.df2.col1 = self.df2.col1.astype(\"category\")\n        self.df2.col2 = self.df2.col2.astype(\"category\")", "min_run_count": 2, "name": "reshape.PivotTable.time_pivot_table_categorical_observed", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "06e19f29bad0004311d0422c04884a94e54d725e383443b1c5476d40e62a64df", "warmup_time": -1}, "reshape.PivotTable.time_pivot_table_margins": {"code": "class PivotTable:\n    def time_pivot_table_margins(self):\n        self.df.pivot_table(index=\"key1\", columns=[\"key2\", \"key3\"], margins=True)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass PivotTable:\n    def setup(self):\n        N = 100000\n        fac1 = np.array([\"A\", \"B\", \"C\"], dtype=\"O\")\n        fac2 = np.array([\"one\", \"two\"], dtype=\"O\")\n        ind1 = np.random.randint(0, 3, size=N)\n        ind2 = np.random.randint(0, 2, size=N)\n        self.df = DataFrame(\n            {\n                \"key1\": fac1.take(ind1),\n                \"key2\": fac2.take(ind2),\n                \"key3\": fac2.take(ind2),\n                \"value1\": np.random.randn(N),\n                \"value2\": np.random.randn(N),\n                \"value3\": np.random.randn(N),\n            }\n        )\n        self.df2 = DataFrame(\n            {\"col1\": list(\"abcde\"), \"col2\": list(\"fghij\"), \"col3\": [1, 2, 3, 4, 5]}\n        )\n        self.df2.col1 = self.df2.col1.astype(\"category\")\n        self.df2.col2 = self.df2.col2.astype(\"category\")", "min_run_count": 2, "name": "reshape.PivotTable.time_pivot_table_margins", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "0afefd1f2578cc7e47b9f9ef6791eac3f77b8ec807c5725b2ef687d228c99241", "warmup_time": -1}, "reshape.PivotTable.time_pivot_table_margins_only_column": {"code": "class PivotTable:\n    def time_pivot_table_margins_only_column(self):\n        self.df.pivot_table(columns=[\"key1\", \"key2\", \"key3\"], margins=True)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass PivotTable:\n    def setup(self):\n        N = 100000\n        fac1 = np.array([\"A\", \"B\", \"C\"], dtype=\"O\")\n        fac2 = np.array([\"one\", \"two\"], dtype=\"O\")\n        ind1 = np.random.randint(0, 3, size=N)\n        ind2 = np.random.randint(0, 2, size=N)\n        self.df = DataFrame(\n            {\n                \"key1\": fac1.take(ind1),\n                \"key2\": fac2.take(ind2),\n                \"key3\": fac2.take(ind2),\n                \"value1\": np.random.randn(N),\n                \"value2\": np.random.randn(N),\n                \"value3\": np.random.randn(N),\n            }\n        )\n        self.df2 = DataFrame(\n            {\"col1\": list(\"abcde\"), \"col2\": list(\"fghij\"), \"col3\": [1, 2, 3, 4, 5]}\n        )\n        self.df2.col1 = self.df2.col1.astype(\"category\")\n        self.df2.col2 = self.df2.col2.astype(\"category\")", "min_run_count": 2, "name": "reshape.PivotTable.time_pivot_table_margins_only_column", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "21e105d206932a8572d6c9e47758f4bc5a6ee77cb384c346e1d145fd2bb9bbfe", "warmup_time": -1}, "reshape.ReshapeExtensionDtype.time_stack": {"code": "class ReshapeExtensionDtype:\n    def time_stack(self, dtype):\n        self.df.stack()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ReshapeExtensionDtype:\n    def setup(self, dtype):\n        lev = pd.Index(list(\"ABCDEFGHIJ\"))\n        ri = pd.Index(range(1000))\n        mi = MultiIndex.from_product([lev, ri], names=[\"foo\", \"bar\"])\n    \n        index = date_range(\"2016-01-01\", periods=10000, freq=\"s\", tz=\"US/Pacific\")\n        if dtype == \"Period[s]\":\n            index = index.tz_localize(None).to_period(\"s\")\n    \n        ser = pd.Series(index, index=mi)\n        df = ser.unstack(\"bar\")\n        # roundtrips -> df.stack().equals(ser)\n    \n        self.ser = ser\n        self.df = df", "min_run_count": 2, "name": "reshape.ReshapeExtensionDtype.time_stack", "number": 0, "param_names": ["dtype"], "params": [["'datetime64[ns, US/Pacific]'", "'Period[s]'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "71f50c1837c91a2ab25587dc3675ead2ce4cc6662b0442f0b8aabc7677405330", "warmup_time": -1}, "reshape.ReshapeExtensionDtype.time_transpose": {"code": "class ReshapeExtensionDtype:\n    def time_transpose(self, dtype):\n        self.df.T\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ReshapeExtensionDtype:\n    def setup(self, dtype):\n        lev = pd.Index(list(\"ABCDEFGHIJ\"))\n        ri = pd.Index(range(1000))\n        mi = MultiIndex.from_product([lev, ri], names=[\"foo\", \"bar\"])\n    \n        index = date_range(\"2016-01-01\", periods=10000, freq=\"s\", tz=\"US/Pacific\")\n        if dtype == \"Period[s]\":\n            index = index.tz_localize(None).to_period(\"s\")\n    \n        ser = pd.Series(index, index=mi)\n        df = ser.unstack(\"bar\")\n        # roundtrips -> df.stack().equals(ser)\n    \n        self.ser = ser\n        self.df = df", "min_run_count": 2, "name": "reshape.ReshapeExtensionDtype.time_transpose", "number": 0, "param_names": ["dtype"], "params": [["'datetime64[ns, US/Pacific]'", "'Period[s]'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "de98fb88e477fc5bd7f6b256e4a9b735100ef3450027db1f429fee20265ecde3", "warmup_time": -1}, "reshape.ReshapeExtensionDtype.time_unstack_fast": {"code": "class ReshapeExtensionDtype:\n    def time_unstack_fast(self, dtype):\n        # last level -> doesn't have to make copies\n        self.ser.unstack(\"bar\")\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ReshapeExtensionDtype:\n    def setup(self, dtype):\n        lev = pd.Index(list(\"ABCDEFGHIJ\"))\n        ri = pd.Index(range(1000))\n        mi = MultiIndex.from_product([lev, ri], names=[\"foo\", \"bar\"])\n    \n        index = date_range(\"2016-01-01\", periods=10000, freq=\"s\", tz=\"US/Pacific\")\n        if dtype == \"Period[s]\":\n            index = index.tz_localize(None).to_period(\"s\")\n    \n        ser = pd.Series(index, index=mi)\n        df = ser.unstack(\"bar\")\n        # roundtrips -> df.stack().equals(ser)\n    \n        self.ser = ser\n        self.df = df", "min_run_count": 2, "name": "reshape.ReshapeExtensionDtype.time_unstack_fast", "number": 0, "param_names": ["dtype"], "params": [["'datetime64[ns, US/Pacific]'", "'Period[s]'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "bfb452390fbd0c8f64654a5fa654ae3cba890d1d7668880d51f418f1c2ea0059", "warmup_time": -1}, "reshape.ReshapeExtensionDtype.time_unstack_slow": {"code": "class ReshapeExtensionDtype:\n    def time_unstack_slow(self, dtype):\n        # first level -> must make copies\n        self.ser.unstack(\"foo\")\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ReshapeExtensionDtype:\n    def setup(self, dtype):\n        lev = pd.Index(list(\"ABCDEFGHIJ\"))\n        ri = pd.Index(range(1000))\n        mi = MultiIndex.from_product([lev, ri], names=[\"foo\", \"bar\"])\n    \n        index = date_range(\"2016-01-01\", periods=10000, freq=\"s\", tz=\"US/Pacific\")\n        if dtype == \"Period[s]\":\n            index = index.tz_localize(None).to_period(\"s\")\n    \n        ser = pd.Series(index, index=mi)\n        df = ser.unstack(\"bar\")\n        # roundtrips -> df.stack().equals(ser)\n    \n        self.ser = ser\n        self.df = df", "min_run_count": 2, "name": "reshape.ReshapeExtensionDtype.time_unstack_slow", "number": 0, "param_names": ["dtype"], "params": [["'datetime64[ns, US/Pacific]'", "'Period[s]'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "19cf929eb6cc86687d322f9c25207cd480041be2aafd11fe37cf4815e5be49c8", "warmup_time": -1}, "reshape.ReshapeMaskedArrayDtype.time_stack": {"code": "class ReshapeExtensionDtype:\n    def time_stack(self, dtype):\n        self.df.stack()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ReshapeMaskedArrayDtype:\n    def setup(self, dtype):\n        lev = pd.Index(list(\"ABCDEFGHIJ\"))\n        ri = pd.Index(range(1000))\n        mi = MultiIndex.from_product([lev, ri], names=[\"foo\", \"bar\"])\n    \n        values = np.random.randn(10_000).astype(int)\n    \n        ser = pd.Series(values, dtype=dtype, index=mi)\n        df = ser.unstack(\"bar\")\n        # roundtrips -> df.stack().equals(ser)\n    \n        self.ser = ser\n        self.df = df", "min_run_count": 2, "name": "reshape.ReshapeMaskedArrayDtype.time_stack", "number": 0, "param_names": ["dtype"], "params": [["'Int64'", "'Float64'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "1eeaeec84de4310b0b92095ad52b62f6c1ec17563f5cc993db36df1fc9f1bc86", "warmup_time": -1}, "reshape.ReshapeMaskedArrayDtype.time_transpose": {"code": "class ReshapeExtensionDtype:\n    def time_transpose(self, dtype):\n        self.df.T\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ReshapeMaskedArrayDtype:\n    def setup(self, dtype):\n        lev = pd.Index(list(\"ABCDEFGHIJ\"))\n        ri = pd.Index(range(1000))\n        mi = MultiIndex.from_product([lev, ri], names=[\"foo\", \"bar\"])\n    \n        values = np.random.randn(10_000).astype(int)\n    \n        ser = pd.Series(values, dtype=dtype, index=mi)\n        df = ser.unstack(\"bar\")\n        # roundtrips -> df.stack().equals(ser)\n    \n        self.ser = ser\n        self.df = df", "min_run_count": 2, "name": "reshape.ReshapeMaskedArrayDtype.time_transpose", "number": 0, "param_names": ["dtype"], "params": [["'Int64'", "'Float64'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "bb124b2b5f9cfebdc4507a7ef8c75f1112caf5fa34c040451cb2ef3ad5f0040e", "warmup_time": -1}, "reshape.ReshapeMaskedArrayDtype.time_unstack_fast": {"code": "class ReshapeExtensionDtype:\n    def time_unstack_fast(self, dtype):\n        # last level -> doesn't have to make copies\n        self.ser.unstack(\"bar\")\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ReshapeMaskedArrayDtype:\n    def setup(self, dtype):\n        lev = pd.Index(list(\"ABCDEFGHIJ\"))\n        ri = pd.Index(range(1000))\n        mi = MultiIndex.from_product([lev, ri], names=[\"foo\", \"bar\"])\n    \n        values = np.random.randn(10_000).astype(int)\n    \n        ser = pd.Series(values, dtype=dtype, index=mi)\n        df = ser.unstack(\"bar\")\n        # roundtrips -> df.stack().equals(ser)\n    \n        self.ser = ser\n        self.df = df", "min_run_count": 2, "name": "reshape.ReshapeMaskedArrayDtype.time_unstack_fast", "number": 0, "param_names": ["dtype"], "params": [["'Int64'", "'Float64'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "a267ffdd7317e4df0f6a83ebde82619df89c2a8e4737cf4d9563453b9b18ddc0", "warmup_time": -1}, "reshape.ReshapeMaskedArrayDtype.time_unstack_slow": {"code": "class ReshapeExtensionDtype:\n    def time_unstack_slow(self, dtype):\n        # first level -> must make copies\n        self.ser.unstack(\"foo\")\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ReshapeMaskedArrayDtype:\n    def setup(self, dtype):\n        lev = pd.Index(list(\"ABCDEFGHIJ\"))\n        ri = pd.Index(range(1000))\n        mi = MultiIndex.from_product([lev, ri], names=[\"foo\", \"bar\"])\n    \n        values = np.random.randn(10_000).astype(int)\n    \n        ser = pd.Series(values, dtype=dtype, index=mi)\n        df = ser.unstack(\"bar\")\n        # roundtrips -> df.stack().equals(ser)\n    \n        self.ser = ser\n        self.df = df", "min_run_count": 2, "name": "reshape.ReshapeMaskedArrayDtype.time_unstack_slow", "number": 0, "param_names": ["dtype"], "params": [["'Int64'", "'Float64'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "e11dd322f7d3a2fa04944bb0e94c949b1f27eb0b27cef49390542c77bc015bc9", "warmup_time": -1}, "reshape.SimpleReshape.time_stack": {"code": "class SimpleReshape:\n    def time_stack(self):\n        self.udf.stack()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass SimpleReshape:\n    def setup(self):\n        arrays = [np.arange(100).repeat(100), np.roll(np.tile(np.arange(100), 100), 25)]\n        index = MultiIndex.from_arrays(arrays)\n        self.df = DataFrame(np.random.randn(10000, 4), index=index)\n        self.udf = self.df.unstack(1)", "min_run_count": 2, "name": "reshape.SimpleReshape.time_stack", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "a6d770036abb815e9c3a58b1e211a9731ce733599757aa8153db703496818011", "warmup_time": -1}, "reshape.SimpleReshape.time_unstack": {"code": "class SimpleReshape:\n    def time_unstack(self):\n        self.df.unstack(1)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass SimpleReshape:\n    def setup(self):\n        arrays = [np.arange(100).repeat(100), np.roll(np.tile(np.arange(100), 100), 25)]\n        index = MultiIndex.from_arrays(arrays)\n        self.df = DataFrame(np.random.randn(10000, 4), index=index)\n        self.udf = self.df.unstack(1)", "min_run_count": 2, "name": "reshape.SimpleReshape.time_unstack", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "ee883fcccbd0ef7d6c8bb60b550c2de5d2bc5b98458113c63b9f23a2f652e873", "warmup_time": -1}, "reshape.SparseIndex.time_unstack": {"code": "class SparseIndex:\n    def time_unstack(self):\n        self.df.unstack()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass SparseIndex:\n    def setup(self):\n        NUM_ROWS = 1000\n        self.df = DataFrame(\n            {\n                \"A\": np.random.randint(50, size=NUM_ROWS),\n                \"B\": np.random.randint(50, size=NUM_ROWS),\n                \"C\": np.random.randint(-10, 10, size=NUM_ROWS),\n                \"D\": np.random.randint(-10, 10, size=NUM_ROWS),\n                \"E\": np.random.randint(10, size=NUM_ROWS),\n                \"F\": np.random.randn(NUM_ROWS),\n            }\n        )\n        self.df = self.df.set_index([\"A\", \"B\", \"C\", \"D\", \"E\"])", "min_run_count": 2, "name": "reshape.SparseIndex.time_unstack", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "41381253268a24b9d6ee1f0c20e6602a24860a05d0e483f11a992776103b51be", "warmup_time": -1}, "reshape.Unstack.time_full_product": {"code": "class Unstack:\n    def time_full_product(self, dtype):\n        self.df.unstack()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Unstack:\n    def setup(self, dtype):\n        m = 100\n        n = 1000\n    \n        levels = np.arange(m)\n        index = MultiIndex.from_product([levels] * 2)\n        columns = np.arange(n)\n        if dtype == \"int\":\n            values = np.arange(m * m * n).reshape(m * m, n)\n            self.df = DataFrame(values, index, columns)\n        else:\n            # the category branch is ~20x slower than int. So we\n            # cut down the size a bit. Now it's only ~3x slower.\n            n = 50\n            columns = columns[:n]\n            indices = np.random.randint(0, 52, size=(m * m, n))\n            values = np.take(list(string.ascii_letters), indices)\n            values = [pd.Categorical(v) for v in values.T]\n    \n            self.df = DataFrame(dict(enumerate(values)), index, columns)\n    \n        self.df2 = self.df.iloc[:-1]", "min_run_count": 2, "name": "reshape.Unstack.time_full_product", "number": 0, "param_names": ["param1"], "params": [["'int'", "'category'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "b28492d9054e9dc56a19db0f8cd8638ff873d22ea2faeb49de210add68896584", "warmup_time": -1}, "reshape.Unstack.time_without_last_row": {"code": "class Unstack:\n    def time_without_last_row(self, dtype):\n        self.df2.unstack()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Unstack:\n    def setup(self, dtype):\n        m = 100\n        n = 1000\n    \n        levels = np.arange(m)\n        index = MultiIndex.from_product([levels] * 2)\n        columns = np.arange(n)\n        if dtype == \"int\":\n            values = np.arange(m * m * n).reshape(m * m, n)\n            self.df = DataFrame(values, index, columns)\n        else:\n            # the category branch is ~20x slower than int. So we\n            # cut down the size a bit. Now it's only ~3x slower.\n            n = 50\n            columns = columns[:n]\n            indices = np.random.randint(0, 52, size=(m * m, n))\n            values = np.take(list(string.ascii_letters), indices)\n            values = [pd.Categorical(v) for v in values.T]\n    \n            self.df = DataFrame(dict(enumerate(values)), index, columns)\n    \n        self.df2 = self.df.iloc[:-1]", "min_run_count": 2, "name": "reshape.Unstack.time_without_last_row", "number": 0, "param_names": ["param1"], "params": [["'int'", "'category'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "0c546381b8ec02b2e96bf78f998f4f2a191ac77f0045346909d25e8b88f3e1e1", "warmup_time": -1}, "reshape.WideToLong.time_wide_to_long_big": {"code": "class WideToLong:\n    def time_wide_to_long_big(self):\n        wide_to_long(self.df, self.letters, i=\"id\", j=\"year\")\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass WideToLong:\n    def setup(self):\n        nyrs = 20\n        nidvars = 20\n        N = 5000\n        self.letters = list(\"ABCD\")\n        yrvars = [\n            letter + str(num)\n            for letter, num in product(self.letters, range(1, nyrs + 1))\n        ]\n        columns = [str(i) for i in range(nidvars)] + yrvars\n        self.df = DataFrame(np.random.randn(N, nidvars + len(yrvars)), columns=columns)\n        self.df[\"id\"] = self.df.index", "min_run_count": 2, "name": "reshape.WideToLong.time_wide_to_long_big", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "38b6ee0820735de02ad64b598a14cbe298769f714808e915411fde11e73f8598", "warmup_time": -1}, "rolling.Apply.time_rolling": {"code": "class Apply:\n    def time_rolling(self, constructor, window, dtype, function, raw):\n        self.roll.apply(function, raw=raw)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Apply:\n    def setup(self, constructor, window, dtype, function, raw):\n        N = 10**3\n        arr = (100 * np.random.random(N)).astype(dtype)\n        self.roll = getattr(pd, constructor)(arr).rolling(window)", "min_run_count": 2, "name": "rolling.Apply.time_rolling", "number": 0, "param_names": ["constructor", "window", "dtype", "function", "raw"], "params": [["'DataFrame'", "'Series'"], ["3", "300"], ["'int'", "'float'"], ["<built-in function sum>", "<function sum>", "<function Apply.<lambda>>"], ["True", "False"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "871accb43f689bd0f04df4d9d50bb65a4d3403027f3ff0b5e49789cf4cf80a70", "warmup_time": -1}, "rolling.EWMMethods.time_ewm": {"code": "class EWMMethods:\n    def time_ewm(self, constructor, kwargs_method, dtype):\n        getattr(self.ewm, self.method)()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass EWMMethods:\n    def setup(self, constructor, kwargs_method, dtype):\n        N = 10**5\n        kwargs, method = kwargs_method\n        arr = (100 * np.random.random(N)).astype(dtype)\n        self.method = method\n        self.ewm = getattr(pd, constructor)(arr).ewm(**kwargs)", "min_run_count": 2, "name": "rolling.EWMMethods.time_ewm", "number": 0, "param_names": ["constructor", "kwargs_method", "dtype"], "params": [["'DataFrame'", "'Series'"], ["({'halflife': 10}, 'mean')", "({'halflife': 10}, 'std')", "({'halflife': 1000}, 'mean')", "({'halflife': 1000}, 'std')", "({'halflife': '1 Day', 'times': DatetimeIndex(['1900-01-01 00:00:00', '1900-01-01 00:00:23',\n               '1900-01-01 00:00:46', '1900-01-01 00:01:09',\n               '1900-01-01 00:01:32', '1900-01-01 00:01:55',\n               '1900-01-01 00:02:18', '1900-01-01 00:02:41',\n               '1900-01-01 00:03:04', '1900-01-01 00:03:27',\n               ...\n               '1900-01-27 14:49:30', '1900-01-27 14:49:53',\n               '1900-01-27 14:50:16', '1900-01-27 14:50:39',\n               '1900-01-27 14:51:02', '1900-01-27 14:51:25',\n               '1900-01-27 14:51:48', '1900-01-27 14:52:11',\n               '1900-01-27 14:52:34', '1900-01-27 14:52:57'],\n              dtype='datetime64[ns]', length=100000, freq='23s')}, 'mean')"], ["'int'", "'float'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "44cf214a28e488cb440a036e0178da2f3f3ea426055c4f0952f4fdedbd55eff8", "warmup_time": -1}, "rolling.ForwardWindowMethods.peakmem_rolling": {"code": "class ForwardWindowMethods:\n    def peakmem_rolling(self, constructor, window_size, dtype, method):\n        getattr(self.roll, method)()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ForwardWindowMethods:\n    def setup(self, constructor, window_size, dtype, method):\n        N = 10**5\n        arr = np.random.random(N).astype(dtype)\n        indexer = pd.api.indexers.FixedForwardWindowIndexer(window_size=window_size)\n        self.roll = getattr(pd, constructor)(arr).rolling(window=indexer)", "name": "rolling.ForwardWindowMethods.peakmem_rolling", "param_names": ["constructor", "window_size", "dtype", "method"], "params": [["'DataFrame'", "'Series'"], ["10", "1000"], ["'int'", "'float'"], ["'median'", "'mean'", "'max'", "'min'", "'kurt'", "'sum'"]], "timeout": 60.0, "type": "peakmemory", "unit": "bytes", "version": "9ac3a0bf8c769f331e8cd492fdbc30f03ab699681211d932253349936b2ec964"}, "rolling.ForwardWindowMethods.time_rolling": {"code": "class ForwardWindowMethods:\n    def time_rolling(self, constructor, window_size, dtype, method):\n        getattr(self.roll, method)()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ForwardWindowMethods:\n    def setup(self, constructor, window_size, dtype, method):\n        N = 10**5\n        arr = np.random.random(N).astype(dtype)\n        indexer = pd.api.indexers.FixedForwardWindowIndexer(window_size=window_size)\n        self.roll = getattr(pd, constructor)(arr).rolling(window=indexer)", "min_run_count": 2, "name": "rolling.ForwardWindowMethods.time_rolling", "number": 0, "param_names": ["constructor", "window_size", "dtype", "method"], "params": [["'DataFrame'", "'Series'"], ["10", "1000"], ["'int'", "'float'"], ["'median'", "'mean'", "'max'", "'min'", "'kurt'", "'sum'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "6dfc98201296ab54c1be4d985a80b8f835a8c4b225f3719c6869e418405eac45", "warmup_time": -1}, "rolling.Groupby.time_method": {"code": "class Groupby:\n    def time_method(self, method, window_kwargs):\n        getattr(self.groupby_window, method)()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Groupby:\n    def setup(self, method, window_kwargs):\n        N = 1000\n        window, kwargs = window_kwargs\n        df = pd.DataFrame(\n            {\n                \"A\": [str(i) for i in range(N)] * 10,\n                \"B\": list(range(N)) * 10,\n            }\n        )\n        if isinstance(kwargs.get(\"window\", None), str):\n            df.index = pd.date_range(start=\"1900-01-01\", freq=\"1min\", periods=N * 10)\n        self.groupby_window = getattr(df.groupby(\"A\"), window)(**kwargs)", "min_run_count": 2, "name": "rolling.Groupby.time_method", "number": 0, "param_names": ["param1", "param2"], "params": [["'sum' (0)", "'median'", "'mean'", "'max'", "'min'", "'kurt'", "'sum' (1)"], ["('rolling', {'window': 2})", "('rolling', {'window': '30s'})", "('expanding', {})"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "1f0550f768119c2d4aa887f71e8c464ca76822e8f39b17def026e6701ff98501", "warmup_time": -1}, "rolling.GroupbyEWM.time_groupby_method": {"code": "class GroupbyEWM:\n    def time_groupby_method(self, method):\n        getattr(self.gb_ewm, method)()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass GroupbyEWM:\n    def setup(self, method):\n        df = pd.DataFrame({\"A\": range(50), \"B\": range(50)})\n        self.gb_ewm = df.groupby(\"A\").ewm(com=1.0)", "min_run_count": 2, "name": "rolling.GroupbyEWM.time_groupby_method", "number": 0, "param_names": ["method"], "params": [["'var'", "'std'", "'cov'", "'corr'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "ad6a51326eb042f1ee88615e2048d6bc92adf02dfecb26d43ba24834f3c61150", "warmup_time": -1}, "rolling.GroupbyEWMEngine.time_groupby_mean": {"code": "class GroupbyEWMEngine:\n    def time_groupby_mean(self, engine):\n        self.gb_ewm.mean(engine=engine)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass GroupbyEWMEngine:\n    def setup(self, engine):\n        df = pd.DataFrame({\"A\": range(50), \"B\": range(50)})\n        self.gb_ewm = df.groupby(\"A\").ewm(com=1.0)", "min_run_count": 2, "name": "rolling.GroupbyEWMEngine.time_groupby_mean", "number": 0, "param_names": ["engine"], "params": [["'cython'", "'numba'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "d69e116193dcb411ee111f0a146b8d596d2d73236f686eb16ef4e9221bd2bd52", "warmup_time": -1}, "rolling.GroupbyLargeGroups.time_rolling_multiindex_creation": {"code": "class GroupbyLargeGroups:\n    def time_rolling_multiindex_creation(self):\n        self.df.groupby(\"A\").rolling(3).mean()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass GroupbyLargeGroups:\n    def setup(self):\n        N = 100000\n        self.df = pd.DataFrame({\"A\": [1, 2] * (N // 2), \"B\": np.random.randn(N)})", "min_run_count": 2, "name": "rolling.GroupbyLargeGroups.time_rolling_multiindex_creation", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "31a34a6b020d62e4c7b595aeb804a131f135c1fd1497365577c3bbf2fe7c511c", "warmup_time": -1}, "rolling.Methods.peakmem_method": {"code": "class Methods:\n    def peakmem_method(self, constructor, window_kwargs, dtype, method):\n        getattr(self.window, method)()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Methods:\n    def setup(self, constructor, window_kwargs, dtype, method):\n        N = 10**5\n        window, kwargs = window_kwargs\n        arr = (100 * np.random.random(N)).astype(dtype)\n        obj = getattr(pd, constructor)(arr)\n        self.window = getattr(obj, window)(**kwargs)", "name": "rolling.Methods.peakmem_method", "param_names": ["constructor", "window_kwargs", "dtype", "method"], "params": [["'DataFrame'", "'Series'"], ["('rolling', {'window': 10})", "('rolling', {'window': 1000})", "('expanding', {})"], ["'int'", "'float'"], ["'median'", "'mean'", "'max'", "'min'", "'std'", "'count'", "'skew'", "'kurt'", "'sum'", "'sem'"]], "timeout": 60.0, "type": "peakmemory", "unit": "bytes", "version": "0c01a9273a20049fc5dfd09ead608a5e199977644711bc856c0dbaf525d6d0d5"}, "rolling.Methods.time_method": {"code": "class Methods:\n    def time_method(self, constructor, window_kwargs, dtype, method):\n        getattr(self.window, method)()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Methods:\n    def setup(self, constructor, window_kwargs, dtype, method):\n        N = 10**5\n        window, kwargs = window_kwargs\n        arr = (100 * np.random.random(N)).astype(dtype)\n        obj = getattr(pd, constructor)(arr)\n        self.window = getattr(obj, window)(**kwargs)", "min_run_count": 2, "name": "rolling.Methods.time_method", "number": 0, "param_names": ["constructor", "window_kwargs", "dtype", "method"], "params": [["'DataFrame'", "'Series'"], ["('rolling', {'window': 10})", "('rolling', {'window': 1000})", "('expanding', {})"], ["'int'", "'float'"], ["'median'", "'mean'", "'max'", "'min'", "'std'", "'count'", "'skew'", "'kurt'", "'sum'", "'sem'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "5402683efd6d1e8b4bab7594be55921fa6334cec6319e73a3f3660d99df1a7a5", "warmup_time": -1}, "rolling.Pairwise.time_groupby": {"code": "class Pairwise:\n    def time_groupby(self, kwargs_window, method, pairwise):\n        getattr(self.window_group, method)(self.df, pairwise=pairwise)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Pairwise:\n    def setup(self, kwargs_window, method, pairwise):\n        N = 10**4\n        n_groups = 20\n        kwargs, window = kwargs_window\n        groups = [i for _ in range(N // n_groups) for i in range(n_groups)]\n        arr = np.random.random(N)\n        self.df = pd.DataFrame(arr)\n        self.window = getattr(self.df, window)(**kwargs)\n        self.window_group = getattr(\n            pd.DataFrame({\"A\": groups, \"B\": arr}).groupby(\"A\"), window\n        )(**kwargs)", "min_run_count": 2, "name": "rolling.Pairwise.time_groupby", "number": 0, "param_names": ["window_kwargs", "method", "pairwise"], "params": [["({'window': 10}, 'rolling')", "({'window': 1000}, 'rolling')", "({}, 'expanding')"], ["'corr'", "'cov'"], ["True", "False"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "f1e4be4e4d441bdc8b2cebdbc678ae970eb20874fa682bb1ca41352d98a0a23e", "warmup_time": -1}, "rolling.Pairwise.time_pairwise": {"code": "class Pairwise:\n    def time_pairwise(self, kwargs_window, method, pairwise):\n        getattr(self.window, method)(self.df, pairwise=pairwise)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Pairwise:\n    def setup(self, kwargs_window, method, pairwise):\n        N = 10**4\n        n_groups = 20\n        kwargs, window = kwargs_window\n        groups = [i for _ in range(N // n_groups) for i in range(n_groups)]\n        arr = np.random.random(N)\n        self.df = pd.DataFrame(arr)\n        self.window = getattr(self.df, window)(**kwargs)\n        self.window_group = getattr(\n            pd.DataFrame({\"A\": groups, \"B\": arr}).groupby(\"A\"), window\n        )(**kwargs)", "min_run_count": 2, "name": "rolling.Pairwise.time_pairwise", "number": 0, "param_names": ["window_kwargs", "method", "pairwise"], "params": [["({'window': 10}, 'rolling')", "({'window': 1000}, 'rolling')", "({}, 'expanding')"], ["'corr'", "'cov'"], ["True", "False"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "315ccdf22c0f4d21fa6ee729bdd8f21c51913704006fbcdfc1f4e2500d816ef3", "warmup_time": -1}, "rolling.PeakMemFixedWindowMinMax.peakmem_fixed": {"code": "class PeakMemFixedWindowMinMax:\n    def peakmem_fixed(self, operation):\n        for x in range(5):\n            getattr(self.roll, operation)()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass PeakMemFixedWindowMinMax:\n    def setup(self, operation):\n        N = 10**6\n        arr = np.random.random(N)\n        self.roll = pd.Series(arr).rolling(2)", "name": "rolling.PeakMemFixedWindowMinMax.peakmem_fixed", "param_names": ["param1"], "params": [["'min'", "'max'"]], "timeout": 60.0, "type": "peakmemory", "unit": "bytes", "version": "b9767f691709345094cdfdc4984bb728c9e78389a22aa1bae02462af8dd67ec2"}, "rolling.Quantile.time_quantile": {"code": "class Quantile:\n    def time_quantile(self, constructor, window, dtype, percentile, interpolation):\n        self.roll.quantile(percentile, interpolation=interpolation)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Quantile:\n    def setup(self, constructor, window, dtype, percentile, interpolation):\n        N = 10**5\n        arr = np.random.random(N).astype(dtype)\n        self.roll = getattr(pd, constructor)(arr).rolling(window)", "min_run_count": 2, "name": "rolling.Quantile.time_quantile", "number": 0, "param_names": ["constructor", "window", "dtype", "percentile", "param5"], "params": [["'DataFrame'", "'Series'"], ["10", "1000"], ["'int'", "'float'"], ["0", "0.5", "1"], ["'linear'", "'nearest'", "'lower'", "'higher'", "'midpoint'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "f94389cbc4b3cca82ab4db4970a4acd0daa3c0fbf9cc3f230a6b7d69e841bc4f", "warmup_time": -1}, "rolling.Rank.time_rank": {"code": "class Rank:\n    def time_rank(self, constructor, window, dtype, percentile, ascending, method):\n        self.roll.rank(pct=percentile, ascending=ascending, method=method)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Rank:\n    def setup(self, constructor, window, dtype, percentile, ascending, method):\n        N = 10**5\n        arr = np.random.random(N).astype(dtype)\n        self.roll = getattr(pd, constructor)(arr).rolling(window)", "min_run_count": 2, "name": "rolling.Rank.time_rank", "number": 0, "param_names": ["constructor", "window", "dtype", "percentile", "ascending", "method"], "params": [["'DataFrame'", "'Series'"], ["10", "1000"], ["'int'", "'float'"], ["True", "False"], ["True", "False"], ["'min'", "'max'", "'average'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "f02fd2586b260b9f5ab15f641e1279b2d47c07b805c6059cdf5f0e5f424a5b6c", "warmup_time": -1}, "rolling.TableMethod.time_apply": {"code": "class TableMethod:\n    def time_apply(self, method):\n        self.df.rolling(2, method=method).apply(\n            table_method_func, raw=True, engine=\"numba\"\n        )\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass TableMethod:\n    def setup(self, method):\n        self.df = pd.DataFrame(np.random.randn(10, 1000))", "min_run_count": 2, "name": "rolling.TableMethod.time_apply", "number": 0, "param_names": ["method"], "params": [["'single'", "'table'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "30880eb453b9d41a953d95fc25ba24088b0a48b94ab49ea12406e4abc0b976ac", "warmup_time": -1}, "rolling.TableMethod.time_ewm_mean": {"code": "class TableMethod:\n    def time_ewm_mean(self, method):\n        self.df.ewm(1, method=method).mean(engine=\"numba\")\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass TableMethod:\n    def setup(self, method):\n        self.df = pd.DataFrame(np.random.randn(10, 1000))", "min_run_count": 2, "name": "rolling.TableMethod.time_ewm_mean", "number": 0, "param_names": ["method"], "params": [["'single'", "'table'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "446dcdc251bda1381a3cf943305e8a6a22ea15ca4513ec2dc7454a8692ab99ad", "warmup_time": -1}, "rolling.VariableWindowMethods.peakmem_method": {"code": "class Methods:\n    def peakmem_method(self, constructor, window_kwargs, dtype, method):\n        getattr(self.window, method)()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass VariableWindowMethods:\n    def setup(self, constructor, window, dtype, method):\n        N = 10**5\n        arr = (100 * np.random.random(N)).astype(dtype)\n        index = pd.date_range(\"2017-01-01\", periods=N, freq=\"5s\")\n        self.window = getattr(pd, constructor)(arr, index=index).rolling(window)", "name": "rolling.VariableWindowMethods.peakmem_method", "param_names": ["constructor", "window", "dtype", "method"], "params": [["'DataFrame'", "'Series'"], ["'50s'", "'1h'", "'1d'"], ["'int'", "'float'"], ["'median'", "'mean'", "'max'", "'min'", "'std'", "'count'", "'skew'", "'kurt'", "'sum'", "'sem'"]], "timeout": 60.0, "type": "peakmemory", "unit": "bytes", "version": "7b52c11d6e1b242c90ddaa78b88fb15e12a3676d5faf98af9807087e0243c3e8"}, "rolling.VariableWindowMethods.time_method": {"code": "class Methods:\n    def time_method(self, constructor, window_kwargs, dtype, method):\n        getattr(self.window, method)()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass VariableWindowMethods:\n    def setup(self, constructor, window, dtype, method):\n        N = 10**5\n        arr = (100 * np.random.random(N)).astype(dtype)\n        index = pd.date_range(\"2017-01-01\", periods=N, freq=\"5s\")\n        self.window = getattr(pd, constructor)(arr, index=index).rolling(window)", "min_run_count": 2, "name": "rolling.VariableWindowMethods.time_method", "number": 0, "param_names": ["constructor", "window", "dtype", "method"], "params": [["'DataFrame'", "'Series'"], ["'50s'", "'1h'", "'1d'"], ["'int'", "'float'"], ["'median'", "'mean'", "'max'", "'min'", "'std'", "'count'", "'skew'", "'kurt'", "'sum'", "'sem'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "f5b8129df64b00950a4dbfbcf89e760f149ee8ffb5df1d544c0b87cceb86c41b", "warmup_time": -1}, "series_methods.All.time_all": {"code": "class All:\n    def time_all(self, N, case, dtype):\n        self.s.all()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass All:\n    def setup(self, N, case, dtype):\n        val = case != \"fast\"\n        self.s = Series([val] * N, dtype=dtype)", "min_run_count": 2, "name": "series_methods.All.time_all", "number": 0, "param_names": ["N", "case", "dtype"], "params": [["1000", "1000000"], ["'fast'", "'slow'"], ["'bool'", "'boolean'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "45f86547ce03394cb299551fd376fc8a763de3a613d475e1b9b2e71852b8c4f9", "warmup_time": -1}, "series_methods.Any.time_any": {"code": "class Any:\n    def time_any(self, N, case, dtype):\n        self.s.any()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Any:\n    def setup(self, N, case, dtype):\n        val = case == \"fast\"\n        self.s = Series([val] * N, dtype=dtype)", "min_run_count": 2, "name": "series_methods.Any.time_any", "number": 0, "param_names": ["N", "case", "dtype"], "params": [["1000", "1000000"], ["'fast'", "'slow'"], ["'bool'", "'boolean'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "2e53bbc75704910ed273c169cc5a41b3037436503911ac1dd4fa9a62a7261c44", "warmup_time": -1}, "series_methods.Clip.time_clip": {"code": "class Clip:\n    def time_clip(self, n):\n        self.s.clip(0, 1)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Clip:\n    def setup(self, n):\n        self.s = Series(np.random.randn(n))", "min_run_count": 2, "name": "series_methods.Clip.time_clip", "number": 0, "param_names": ["n"], "params": [["50", "1000", "100000"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "8179a96510fbe69a1326ac0c3cdb1466db7b5719d20b59a243564362d9b56a4a", "warmup_time": -1}, "series_methods.ClipDt.time_clip": {"code": "class ClipDt:\n    def time_clip(self):\n        self.s.clip(upper=self.clipper_dt)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ClipDt:\n    def setup(self):\n        dr = date_range(\"20220101\", periods=100_000, freq=\"s\", tz=\"UTC\")\n        self.clipper_dt = dr[0:1_000].repeat(100)\n        self.s = Series(dr)", "min_run_count": 2, "name": "series_methods.ClipDt.time_clip", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "5e24ee89ae59664da88494ca3070b3c7d1a6c1fe48429471f94661dbff272408", "warmup_time": -1}, "series_methods.Dir.time_dir_strings": {"code": "class Dir:\n    def time_dir_strings(self):\n        dir(self.s)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Dir:\n    def setup(self):\n        self.s = Series(index=Index([f\"i-{i}\" for i in range(10000)], dtype=object))", "min_run_count": 2, "name": "series_methods.Dir.time_dir_strings", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "7d61c7dcd41b858046d7576d5e7a6ab11653a5972d6c06e62c3537f02301c81e", "warmup_time": -1}, "series_methods.Dropna.time_dropna": {"code": "class Dropna:\n    def time_dropna(self, dtype):\n        self.s.dropna()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Dropna:\n    def setup(self, dtype):\n        N = 10**6\n        data = {\n            \"int\": np.random.randint(1, 10, N),\n            \"datetime\": date_range(\"2000-01-01\", freq=\"s\", periods=N),\n        }\n        self.s = Series(data[dtype])\n        if dtype == \"datetime\":\n            self.s[np.random.randint(1, N, 100)] = NaT", "min_run_count": 2, "name": "series_methods.Dropna.time_dropna", "number": 0, "param_names": ["dtype"], "params": [["'int'", "'datetime'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "d04113f96c3ce4c734ec801a839150033050d2312e0df5c6763e3e5093c05792", "warmup_time": -1}, "series_methods.Fillna.time_bfill": {"code": "class Fillna:\n    def time_bfill(self, dtype):\n        self.ser.bfill()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Fillna:\n    def setup(self, dtype):\n        N = 10**6\n        if dtype == \"datetime64[ns]\":\n            data = date_range(\"2000-01-01\", freq=\"s\", periods=N)\n            na_value = NaT\n        elif dtype in (\"float64\", \"Float64\"):\n            data = np.random.randn(N)\n            na_value = np.nan\n        elif dtype in (\"Int64\", \"int64[pyarrow]\"):\n            data = np.arange(N)\n            na_value = NA\n        elif dtype in (\"string\", \"string[pyarrow]\"):\n            data = np.array([str(i) * 5 for i in range(N)], dtype=object)\n            na_value = NA\n        else:\n            raise NotImplementedError\n        fill_value = data[0]\n        ser = Series(data, dtype=dtype)\n        ser[::2] = na_value\n        self.ser = ser\n        self.fill_value = fill_value", "min_run_count": 2, "name": "series_methods.Fillna.time_bfill", "number": 0, "param_names": ["dtype"], "params": [["'datetime64[ns]'", "'float32'", "'float64'", "'Float64'", "'Int64'", "'int64[pyarrow]'", "'string'", "'string[pyarrow]'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "956fc00ef50dc099cc2bf7e02378c6f7503e72c339b42237bafe8c85c2981f61", "warmup_time": -1}, "series_methods.Fillna.time_ffill": {"code": "class Fillna:\n    def time_ffill(self, dtype):\n        self.ser.ffill()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Fillna:\n    def setup(self, dtype):\n        N = 10**6\n        if dtype == \"datetime64[ns]\":\n            data = date_range(\"2000-01-01\", freq=\"s\", periods=N)\n            na_value = NaT\n        elif dtype in (\"float64\", \"Float64\"):\n            data = np.random.randn(N)\n            na_value = np.nan\n        elif dtype in (\"Int64\", \"int64[pyarrow]\"):\n            data = np.arange(N)\n            na_value = NA\n        elif dtype in (\"string\", \"string[pyarrow]\"):\n            data = np.array([str(i) * 5 for i in range(N)], dtype=object)\n            na_value = NA\n        else:\n            raise NotImplementedError\n        fill_value = data[0]\n        ser = Series(data, dtype=dtype)\n        ser[::2] = na_value\n        self.ser = ser\n        self.fill_value = fill_value", "min_run_count": 2, "name": "series_methods.Fillna.time_ffill", "number": 0, "param_names": ["dtype"], "params": [["'datetime64[ns]'", "'float32'", "'float64'", "'Float64'", "'Int64'", "'int64[pyarrow]'", "'string'", "'string[pyarrow]'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "e625516727ac9a43cf480c4279e94bf2cd7ed62ea4a68ac86fe8c6e10fc4ef81", "warmup_time": -1}, "series_methods.Fillna.time_fillna": {"code": "class Fillna:\n    def time_fillna(self, dtype):\n        self.ser.fillna(value=self.fill_value)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Fillna:\n    def setup(self, dtype):\n        N = 10**6\n        if dtype == \"datetime64[ns]\":\n            data = date_range(\"2000-01-01\", freq=\"s\", periods=N)\n            na_value = NaT\n        elif dtype in (\"float64\", \"Float64\"):\n            data = np.random.randn(N)\n            na_value = np.nan\n        elif dtype in (\"Int64\", \"int64[pyarrow]\"):\n            data = np.arange(N)\n            na_value = NA\n        elif dtype in (\"string\", \"string[pyarrow]\"):\n            data = np.array([str(i) * 5 for i in range(N)], dtype=object)\n            na_value = NA\n        else:\n            raise NotImplementedError\n        fill_value = data[0]\n        ser = Series(data, dtype=dtype)\n        ser[::2] = na_value\n        self.ser = ser\n        self.fill_value = fill_value", "min_run_count": 2, "name": "series_methods.Fillna.time_fillna", "number": 0, "param_names": ["dtype"], "params": [["'datetime64[ns]'", "'float32'", "'float64'", "'Float64'", "'Int64'", "'int64[pyarrow]'", "'string'", "'string[pyarrow]'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "02aebbbe16436923ebd160a95e13d6289dd497f1890f5fca503fa6150f330da5", "warmup_time": -1}, "series_methods.Iter.time_iter": {"code": "class Iter:\n    def time_iter(self, dtype):\n        for v in self.s:\n            pass\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Iter:\n    def setup(self, dtype):\n        N = 10**5\n        if dtype in [\"bool\", \"boolean\"]:\n            data = np.repeat([True, False], N // 2)\n        elif dtype in [\"int64\", \"Int64\"]:\n            data = np.arange(N)\n        elif dtype in [\"float64\", \"Float64\"]:\n            data = np.random.randn(N)\n        elif dtype == \"datetime64[ns]\":\n            data = date_range(\"2000-01-01\", freq=\"s\", periods=N)\n        else:\n            raise NotImplementedError\n    \n        self.s = Series(data, dtype=dtype)", "min_run_count": 2, "name": "series_methods.Iter.time_iter", "number": 0, "param_names": ["dtype"], "params": [["'bool'", "'boolean'", "'int64'", "'Int64'", "'float64'", "'Float64'", "'datetime64[ns]'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "8d4391387859c36e6cb82fe13b7d67993a73ba3541e8bc6e6e2c3d8c28a11a42", "warmup_time": -1}, "series_methods.Map.time_map": {"code": "class Map:\n    def time_map(self, mapper, *args, **kwargs):\n        self.s.map(self.map_data)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Map:\n    def setup(self, mapper, dtype):\n        map_size = 1000\n        map_data = Series(map_size - np.arange(map_size), dtype=dtype)\n    \n        # construct mapper\n        if mapper == \"Series\":\n            self.map_data = map_data\n        elif mapper == \"dict\":\n            self.map_data = map_data.to_dict()\n        elif mapper == \"lambda\":\n            map_dict = map_data.to_dict()\n            self.map_data = lambda x: map_dict[x]\n        else:\n            raise NotImplementedError\n    \n        self.s = Series(np.random.randint(0, map_size, 10000), dtype=dtype)", "min_run_count": 2, "name": "series_methods.Map.time_map", "number": 0, "param_names": ["m", "a"], "params": [["'dict'", "'Series'", "'lambda'"], ["'object'", "'category'", "'int'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "fc78503b1588b9f3f6ca02d55c628c9cf0ea126fdb6ebdcec3080a88d01028bd", "warmup_time": -1}, "series_methods.Mode.time_mode": {"code": "class Mode:\n    def time_mode(self, N, dtype):\n        self.s.mode()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Mode:\n    def setup(self, N, dtype):\n        self.s = Series(np.random.randint(0, N, size=10 * N)).astype(dtype)", "min_run_count": 2, "name": "series_methods.Mode.time_mode", "number": 0, "param_names": ["N", "dtype"], "params": [["1000", "10000", "100000"], ["'int'", "'uint'", "'float'", "'object'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "293b41b446df29f5e77e19b14540c5af87a0168e4710d64dbb12037435ef4202", "warmup_time": -1}, "series_methods.ModeObjectDropNAFalse.time_mode": {"code": "class ModeObjectDropNAFalse:\n    def time_mode(self, N):\n        self.s.mode(dropna=False)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ModeObjectDropNAFalse:\n    def setup(self, N):\n        self.s = Series(np.random.randint(0, N, size=10 * N)).astype(\"object\")", "min_run_count": 2, "name": "series_methods.ModeObjectDropNAFalse.time_mode", "number": 0, "param_names": ["N"], "params": [["1000", "10000", "100000"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "e2488dac5c2fdbcfe29cc7e9e32e32b33227ebda39debbcf7e35dbc59aea3f4a", "warmup_time": -1}, "series_methods.NSort.time_nlargest": {"code": "class NSort:\n    def time_nlargest(self, keep):\n        self.s.nlargest(3, keep=keep)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass NSort:\n    def setup(self, keep):\n        self.s = Series(np.random.randint(1, 10, 100000))", "min_run_count": 2, "name": "series_methods.NSort.time_nlargest", "number": 0, "param_names": ["keep"], "params": [["'first'", "'last'", "'all'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "b2d7318a10dc119adee969b91b3e8224c14af04542e29aea061c0c549cfbe264", "warmup_time": -1}, "series_methods.NSort.time_nsmallest": {"code": "class NSort:\n    def time_nsmallest(self, keep):\n        self.s.nsmallest(3, keep=keep)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass NSort:\n    def setup(self, keep):\n        self.s = Series(np.random.randint(1, 10, 100000))", "min_run_count": 2, "name": "series_methods.NSort.time_nsmallest", "number": 0, "param_names": ["keep"], "params": [["'first'", "'last'", "'all'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "8b1f411ecb151ecb227a739c4be77e69ccde5647917c3adb93dca8fbcae978e1", "warmup_time": -1}, "series_methods.NanOps.time_func": {"code": "class NanOps:\n    def time_func(self, func, N, dtype):\n        self.func()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass NanOps:\n    def setup(self, func, N, dtype):\n        if func == \"argmax\" and dtype in {\"Int64\", \"boolean\"}:\n            # Skip argmax for nullable int since this doesn't work yet (GH-24382)\n            raise NotImplementedError\n        self.s = Series(np.ones(N), dtype=dtype)\n        self.func = getattr(self.s, func)", "min_run_count": 2, "name": "series_methods.NanOps.time_func", "number": 0, "param_names": ["func", "N", "dtype"], "params": [["'var'", "'mean'", "'median'", "'max'", "'min'", "'sum'", "'std'", "'sem'", "'argmax'", "'skew'", "'kurt'", "'prod'"], ["1000", "1000000"], ["'int8'", "'int32'", "'int64'", "'float64'", "'Int64'", "'boolean'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "4e7a30930490c8c97bb09a4b0301621652f43531dbe206b758cd0b8a25cde577", "warmup_time": -1}, "series_methods.Rank.time_rank": {"code": "class Rank:\n    def time_rank(self, dtype):\n        self.s.rank()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Rank:\n    def setup(self, dtype):\n        self.s = Series(np.random.randint(0, 1000, size=100000), dtype=dtype)", "min_run_count": 2, "name": "series_methods.Rank.time_rank", "number": 0, "param_names": ["dtype"], "params": [["'int'", "'uint'", "'float'", "'object'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "cf912b236884d1fded0314151a2a53dce2cf23529a155f2103666ee9d002bff7", "warmup_time": -1}, "series_methods.Replace.peakmem_replace_dict": {"code": "class Replace:\n    def peakmem_replace_dict(self, num_to_replace):\n        self.ser.replace(self.replace_dict)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Replace:\n    def setup(self, num_to_replace):\n        N = 1_000_000\n        self.arr = np.random.randn(N)\n        self.arr1 = self.arr.copy()\n        np.random.shuffle(self.arr1)\n        self.ser = Series(self.arr)\n    \n        self.to_replace_list = np.random.choice(self.arr, num_to_replace)\n        self.values_list = np.random.choice(self.arr1, num_to_replace)\n    \n        self.replace_dict = dict(zip(self.to_replace_list, self.values_list))", "name": "series_methods.Replace.peakmem_replace_dict", "param_names": ["num_to_replace"], "params": [["100", "1000"]], "timeout": 60.0, "type": "peakmemory", "unit": "bytes", "version": "82dfd71ffd244c5b1205af03154e4e4547227fe2551d07660db4b7656efdac03"}, "series_methods.Replace.peakmem_replace_list": {"code": "class Replace:\n    def peakmem_replace_list(self, num_to_replace):\n        self.ser.replace(self.to_replace_list, self.values_list)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Replace:\n    def setup(self, num_to_replace):\n        N = 1_000_000\n        self.arr = np.random.randn(N)\n        self.arr1 = self.arr.copy()\n        np.random.shuffle(self.arr1)\n        self.ser = Series(self.arr)\n    \n        self.to_replace_list = np.random.choice(self.arr, num_to_replace)\n        self.values_list = np.random.choice(self.arr1, num_to_replace)\n    \n        self.replace_dict = dict(zip(self.to_replace_list, self.values_list))", "name": "series_methods.Replace.peakmem_replace_list", "param_names": ["num_to_replace"], "params": [["100", "1000"]], "timeout": 60.0, "type": "peakmemory", "unit": "bytes", "version": "11d050f21303f90f57bfaf0eef0535a9459a8ef82e29053f7e1a7090ef4b226c"}, "series_methods.Replace.time_replace_dict": {"code": "class Replace:\n    def time_replace_dict(self, num_to_replace):\n        self.ser.replace(self.replace_dict)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Replace:\n    def setup(self, num_to_replace):\n        N = 1_000_000\n        self.arr = np.random.randn(N)\n        self.arr1 = self.arr.copy()\n        np.random.shuffle(self.arr1)\n        self.ser = Series(self.arr)\n    \n        self.to_replace_list = np.random.choice(self.arr, num_to_replace)\n        self.values_list = np.random.choice(self.arr1, num_to_replace)\n    \n        self.replace_dict = dict(zip(self.to_replace_list, self.values_list))", "min_run_count": 2, "name": "series_methods.Replace.time_replace_dict", "number": 0, "param_names": ["num_to_replace"], "params": [["100", "1000"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "61cb7f463d734dcaf1edbd292af75ede0994c5b2aed3311d7807aac689771d2d", "warmup_time": -1}, "series_methods.Replace.time_replace_list": {"code": "class Replace:\n    def time_replace_list(self, num_to_replace):\n        self.ser.replace(self.to_replace_list, self.values_list)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Replace:\n    def setup(self, num_to_replace):\n        N = 1_000_000\n        self.arr = np.random.randn(N)\n        self.arr1 = self.arr.copy()\n        np.random.shuffle(self.arr1)\n        self.ser = Series(self.arr)\n    \n        self.to_replace_list = np.random.choice(self.arr, num_to_replace)\n        self.values_list = np.random.choice(self.arr1, num_to_replace)\n    \n        self.replace_dict = dict(zip(self.to_replace_list, self.values_list))", "min_run_count": 2, "name": "series_methods.Replace.time_replace_list", "number": 0, "param_names": ["num_to_replace"], "params": [["100", "1000"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "bb772d4b5c8a9a6917a2f3b97f69478c55a246981d6e2350802c926011741b0a", "warmup_time": -1}, "series_methods.SearchSorted.time_searchsorted": {"code": "class SearchSorted:\n    def time_searchsorted(self, dtype):\n        key = \"2\" if dtype == \"str\" else 2\n        self.s.searchsorted(key)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass SearchSorted:\n    def setup(self, dtype):\n        N = 10**5\n        data = np.array([1] * N + [2] * N + [3] * N).astype(dtype)\n        self.s = Series(data)", "min_run_count": 2, "name": "series_methods.SearchSorted.time_searchsorted", "number": 0, "param_names": ["dtype"], "params": [["'int8'", "'int16'", "'int32'", "'int64'", "'uint8'", "'uint16'", "'uint32'", "'uint64'", "'float16'", "'float32'", "'float64'", "'str'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "323b35cab3b64f29d4f839af05bd6b12ad82170fc35bfee718e2e9d52b7fd61e", "warmup_time": -1}, "series_methods.SeriesConstructor.time_constructor_dict": {"code": "class SeriesConstructor:\n    def time_constructor_dict(self):\n        Series(data=self.data, index=self.idx)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass SeriesConstructor:\n    def setup(self):\n        self.idx = date_range(\n            start=datetime(2015, 10, 26), end=datetime(2016, 1, 1), freq=\"50s\"\n        )\n        self.data = dict(zip(self.idx, range(len(self.idx))))\n        self.array = np.array([1, 2, 3])\n        self.idx2 = Index([\"a\", \"b\", \"c\"])", "min_run_count": 2, "name": "series_methods.SeriesConstructor.time_constructor_dict", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "e71f5d93471f71f757d994db2550ae233bb7f18e13e21aca22dafa53f833fb4e", "warmup_time": -1}, "series_methods.SeriesConstructor.time_constructor_no_data": {"code": "class SeriesConstructor:\n    def time_constructor_no_data(self):\n        Series(data=None, index=self.idx)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass SeriesConstructor:\n    def setup(self):\n        self.idx = date_range(\n            start=datetime(2015, 10, 26), end=datetime(2016, 1, 1), freq=\"50s\"\n        )\n        self.data = dict(zip(self.idx, range(len(self.idx))))\n        self.array = np.array([1, 2, 3])\n        self.idx2 = Index([\"a\", \"b\", \"c\"])", "min_run_count": 2, "name": "series_methods.SeriesConstructor.time_constructor_no_data", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "c55e26955fd47febad07ecd223347b24a08ae3454ba16023ad6bb73ec4aaf43a", "warmup_time": -1}, "series_methods.SeriesGetattr.time_series_datetimeindex_repr": {"code": "class SeriesGetattr:\n    def time_series_datetimeindex_repr(self):\n        getattr(self.s, \"a\", None)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass SeriesGetattr:\n    def setup(self):\n        self.s = Series(1, index=date_range(\"2012-01-01\", freq=\"s\", periods=10**6))", "min_run_count": 2, "name": "series_methods.SeriesGetattr.time_series_datetimeindex_repr", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "a1c5e293ae62939d93cd88e2ea4047f3f42f8c318db822e2539805b7e16b72a7", "warmup_time": -1}, "series_methods.ToFrame.time_to_frame": {"code": "class ToFrame:\n    def time_to_frame(self, dtype, name):\n        self.ser.to_frame(name)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToFrame:\n    def setup(self, dtype, name):\n        arr = np.arange(10**5)\n        ser = Series(arr, dtype=dtype)\n        self.ser = ser", "min_run_count": 2, "name": "series_methods.ToFrame.time_to_frame", "number": 0, "param_names": ["dtype", "name"], "params": [["'int64'", "'datetime64[ns]'", "'category'", "'Int64'"], ["None", "'foo'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "9837bd38099b9a8813a9b22a59b46e9e9afd7614361947eb24b302192b97eb20", "warmup_time": -1}, "series_methods.ToNumpy.time_to_numpy": {"code": "class ToNumpy:\n    def time_to_numpy(self):\n        self.ser.to_numpy()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToNumpy:\n    def setup(self):\n        N = 1_000_000\n        self.ser = Series(\n            np.random.randn(\n                N,\n            )\n        )", "min_run_count": 2, "name": "series_methods.ToNumpy.time_to_numpy", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "0ffdc5fb3536043b1cc8a7e1f7f402cf3fe4a601504d03eef9003017585b1037", "warmup_time": -1}, "series_methods.ToNumpy.time_to_numpy_copy": {"code": "class ToNumpy:\n    def time_to_numpy_copy(self):\n        self.ser.to_numpy(copy=True)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToNumpy:\n    def setup(self):\n        N = 1_000_000\n        self.ser = Series(\n            np.random.randn(\n                N,\n            )\n        )", "min_run_count": 2, "name": "series_methods.ToNumpy.time_to_numpy_copy", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "d702db82db43d7f93cd41a3786618d602a7938313ff783cfc0a836026c2997dd", "warmup_time": -1}, "series_methods.ToNumpy.time_to_numpy_double_copy": {"code": "class ToNumpy:\n    def time_to_numpy_double_copy(self):\n        self.ser.to_numpy(dtype=\"float64\", copy=True)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToNumpy:\n    def setup(self):\n        N = 1_000_000\n        self.ser = Series(\n            np.random.randn(\n                N,\n            )\n        )", "min_run_count": 2, "name": "series_methods.ToNumpy.time_to_numpy_double_copy", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "5ef7c18c63ba7e87e2f511e1b4eb1466a36198dbd621bc47d2c7ac5cde81682d", "warmup_time": -1}, "series_methods.ToNumpy.time_to_numpy_float_with_nan": {"code": "class ToNumpy:\n    def time_to_numpy_float_with_nan(self):\n        self.ser.to_numpy(dtype=\"float64\", na_value=np.nan)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToNumpy:\n    def setup(self):\n        N = 1_000_000\n        self.ser = Series(\n            np.random.randn(\n                N,\n            )\n        )", "min_run_count": 2, "name": "series_methods.ToNumpy.time_to_numpy_float_with_nan", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "d62d4317f22ebf4486d4d6a4902963ccadd2a4c3a1ef2dd8cf1e8e4413545f18", "warmup_time": -1}, "series_methods.ValueCounts.time_value_counts": {"code": "class ValueCounts:\n    def time_value_counts(self, N, dtype):\n        self.s.value_counts()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ValueCounts:\n    def setup(self, N, dtype):\n        self.s = Series(np.random.randint(0, N, size=10 * N)).astype(dtype)", "min_run_count": 2, "name": "series_methods.ValueCounts.time_value_counts", "number": 0, "param_names": ["N", "dtype"], "params": [["1000", "10000", "100000"], ["'int'", "'uint'", "'float'", "'object'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "1f5bd690b4a0f777032140a9e0c26ed03c57e4402268b2e8a64b3e1a88d4ee63", "warmup_time": -1}, "series_methods.ValueCountsEA.time_value_counts": {"code": "class ValueCountsEA:\n    def time_value_counts(self, N, dropna):\n        self.s.value_counts(dropna=dropna)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ValueCountsEA:\n    def setup(self, N, dropna):\n        self.s = Series(np.random.randint(0, N, size=10 * N), dtype=\"Int64\")\n        self.s.loc[1] = NA", "min_run_count": 2, "name": "series_methods.ValueCountsEA.time_value_counts", "number": 0, "param_names": ["N", "dropna"], "params": [["1000", "10000", "100000"], ["True", "False"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "b1c2f96329a2881dd15f3586facaa30e4405bf239449cae6534cde266ed71cd4", "warmup_time": -1}, "series_methods.ValueCountsObjectDropNAFalse.time_value_counts": {"code": "class ValueCountsObjectDropNAFalse:\n    def time_value_counts(self, N):\n        self.s.value_counts(dropna=False)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ValueCountsObjectDropNAFalse:\n    def setup(self, N):\n        self.s = Series(np.random.randint(0, N, size=10 * N)).astype(\"object\")", "min_run_count": 2, "name": "series_methods.ValueCountsObjectDropNAFalse.time_value_counts", "number": 0, "param_names": ["N"], "params": [["1000", "10000", "100000"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "a95ddcf5298c1d0d3e53729949f04ee80696bd4b75829dc18ba02781f93d57eb", "warmup_time": -1}, "sparse.Arithmetic.time_add": {"code": "class Arithmetic:\n    def time_add(self, dense_proportion, fill_value):\n        self.array1 + self.array2\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Arithmetic:\n    def setup(self, dense_proportion, fill_value):\n        N = 10**6\n        arr1 = make_array(N, dense_proportion, fill_value, np.int64)\n        self.array1 = SparseArray(arr1, fill_value=fill_value)\n        arr2 = make_array(N, dense_proportion, fill_value, np.int64)\n        self.array2 = SparseArray(arr2, fill_value=fill_value)", "min_run_count": 2, "name": "sparse.Arithmetic.time_add", "number": 0, "param_names": ["dense_proportion", "fill_value"], "params": [["0.1", "0.01"], ["0", "nan"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "de0c48747f8d85c11b89324f25d19e454599ce8ea41d8a20d4ad622ee0df72f2", "warmup_time": -1}, "sparse.Arithmetic.time_divide": {"code": "class Arithmetic:\n    def time_divide(self, dense_proportion, fill_value):\n        self.array1 / self.array2\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Arithmetic:\n    def setup(self, dense_proportion, fill_value):\n        N = 10**6\n        arr1 = make_array(N, dense_proportion, fill_value, np.int64)\n        self.array1 = SparseArray(arr1, fill_value=fill_value)\n        arr2 = make_array(N, dense_proportion, fill_value, np.int64)\n        self.array2 = SparseArray(arr2, fill_value=fill_value)", "min_run_count": 2, "name": "sparse.Arithmetic.time_divide", "number": 0, "param_names": ["dense_proportion", "fill_value"], "params": [["0.1", "0.01"], ["0", "nan"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "3144ab0a952cbf5c353d0326f3901df201f82d17b53a4384714904cb31a1d650", "warmup_time": -1}, "sparse.Arithmetic.time_intersect": {"code": "class Arithmetic:\n    def time_intersect(self, dense_proportion, fill_value):\n        self.array1.sp_index.intersect(self.array2.sp_index)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Arithmetic:\n    def setup(self, dense_proportion, fill_value):\n        N = 10**6\n        arr1 = make_array(N, dense_proportion, fill_value, np.int64)\n        self.array1 = SparseArray(arr1, fill_value=fill_value)\n        arr2 = make_array(N, dense_proportion, fill_value, np.int64)\n        self.array2 = SparseArray(arr2, fill_value=fill_value)", "min_run_count": 2, "name": "sparse.Arithmetic.time_intersect", "number": 0, "param_names": ["dense_proportion", "fill_value"], "params": [["0.1", "0.01"], ["0", "nan"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "7ac983ea31ec4919e8b0a02237314df70f5fc22fccdc3f2873c848da78bf7bf1", "warmup_time": -1}, "sparse.Arithmetic.time_make_union": {"code": "class Arithmetic:\n    def time_make_union(self, dense_proportion, fill_value):\n        self.array1.sp_index.make_union(self.array2.sp_index)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Arithmetic:\n    def setup(self, dense_proportion, fill_value):\n        N = 10**6\n        arr1 = make_array(N, dense_proportion, fill_value, np.int64)\n        self.array1 = SparseArray(arr1, fill_value=fill_value)\n        arr2 = make_array(N, dense_proportion, fill_value, np.int64)\n        self.array2 = SparseArray(arr2, fill_value=fill_value)", "min_run_count": 2, "name": "sparse.Arithmetic.time_make_union", "number": 0, "param_names": ["dense_proportion", "fill_value"], "params": [["0.1", "0.01"], ["0", "nan"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "024b326e3d80e2aa19a052c3e01a3a543974a28c12de2b047b91eb1b4a166106", "warmup_time": -1}, "sparse.ArithmeticBlock.time_addition": {"code": "class ArithmeticBlock:\n    def time_addition(self, fill_value):\n        self.arr1 + self.arr2\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ArithmeticBlock:\n    def setup(self, fill_value):\n        N = 10**6\n        self.arr1 = self.make_block_array(\n            length=N, num_blocks=1000, block_size=10, fill_value=fill_value\n        )\n        self.arr2 = self.make_block_array(\n            length=N, num_blocks=1000, block_size=10, fill_value=fill_value\n        )", "min_run_count": 2, "name": "sparse.ArithmeticBlock.time_addition", "number": 0, "param_names": ["fill_value"], "params": [["nan", "0"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "23ca7b349bf4efc6f2264729829fecf63394a0b3c46d61c3f2259d925bb9fc8f", "warmup_time": -1}, "sparse.ArithmeticBlock.time_division": {"code": "class ArithmeticBlock:\n    def time_division(self, fill_value):\n        self.arr1 / self.arr2\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ArithmeticBlock:\n    def setup(self, fill_value):\n        N = 10**6\n        self.arr1 = self.make_block_array(\n            length=N, num_blocks=1000, block_size=10, fill_value=fill_value\n        )\n        self.arr2 = self.make_block_array(\n            length=N, num_blocks=1000, block_size=10, fill_value=fill_value\n        )", "min_run_count": 2, "name": "sparse.ArithmeticBlock.time_division", "number": 0, "param_names": ["fill_value"], "params": [["nan", "0"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "642210e7c27c272426725acf65d9abba4f9ef4960d2f195e11b7a83598035d72", "warmup_time": -1}, "sparse.ArithmeticBlock.time_intersect": {"code": "class ArithmeticBlock:\n    def time_intersect(self, fill_value):\n        self.arr2.sp_index.intersect(self.arr2.sp_index)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ArithmeticBlock:\n    def setup(self, fill_value):\n        N = 10**6\n        self.arr1 = self.make_block_array(\n            length=N, num_blocks=1000, block_size=10, fill_value=fill_value\n        )\n        self.arr2 = self.make_block_array(\n            length=N, num_blocks=1000, block_size=10, fill_value=fill_value\n        )", "min_run_count": 2, "name": "sparse.ArithmeticBlock.time_intersect", "number": 0, "param_names": ["fill_value"], "params": [["nan", "0"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "163f2bc776313f35b5c130a63fa439494f45003c8ed9ad3fbf8d319b3d47d43f", "warmup_time": -1}, "sparse.ArithmeticBlock.time_make_union": {"code": "class ArithmeticBlock:\n    def time_make_union(self, fill_value):\n        self.arr1.sp_index.make_union(self.arr2.sp_index)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ArithmeticBlock:\n    def setup(self, fill_value):\n        N = 10**6\n        self.arr1 = self.make_block_array(\n            length=N, num_blocks=1000, block_size=10, fill_value=fill_value\n        )\n        self.arr2 = self.make_block_array(\n            length=N, num_blocks=1000, block_size=10, fill_value=fill_value\n        )", "min_run_count": 2, "name": "sparse.ArithmeticBlock.time_make_union", "number": 0, "param_names": ["fill_value"], "params": [["nan", "0"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "7d3b3e09ca0bfcd7880498366bd319799da49101f951ebee8cac1a364a829ace", "warmup_time": -1}, "sparse.FromCoo.time_sparse_series_from_coo": {"code": "class FromCoo:\n    def time_sparse_series_from_coo(self):\n        Series.sparse.from_coo(self.matrix)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass FromCoo:\n    def setup(self):\n        self.matrix = scipy.sparse.coo_matrix(\n            ([3.0, 1.0, 2.0], ([1, 0, 0], [0, 2, 3])), shape=(100, 100)\n        )", "min_run_count": 2, "name": "sparse.FromCoo.time_sparse_series_from_coo", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "195924096fa77c5284cc4c2886c3e4e1ec58441bb83c1afe52ee2d94f9987a1a", "warmup_time": -1}, "sparse.GetItem.time_integer_indexing": {"code": "class GetItem:\n    def time_integer_indexing(self):\n        self.sp_arr[78]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass GetItem:\n    def setup(self):\n        N = 1_000_000\n        d = 1e-5\n        arr = make_array(N, d, np.nan, np.float64)\n        self.sp_arr = SparseArray(arr)", "min_run_count": 2, "name": "sparse.GetItem.time_integer_indexing", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "33a91e68a6e5a68dc11115130afb1282d75e72c695768deefdefa5cd05f90191", "warmup_time": -1}, "sparse.GetItem.time_slice": {"code": "class GetItem:\n    def time_slice(self):\n        self.sp_arr[1:]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass GetItem:\n    def setup(self):\n        N = 1_000_000\n        d = 1e-5\n        arr = make_array(N, d, np.nan, np.float64)\n        self.sp_arr = SparseArray(arr)", "min_run_count": 2, "name": "sparse.GetItem.time_slice", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "b5ccb973e1258c02d5f387766bf0fea6895662936594235434c58e2ab78122e6", "warmup_time": -1}, "sparse.GetItemMask.time_mask": {"code": "class GetItemMask:\n    def time_mask(self, fill_value):\n        self.sp_arr[self.sp_b_arr]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass GetItemMask:\n    def setup(self, fill_value):\n        N = 1_000_000\n        d = 1e-5\n        arr = make_array(N, d, np.nan, np.float64)\n        self.sp_arr = SparseArray(arr)\n        b_arr = np.full(shape=N, fill_value=fill_value, dtype=np.bool_)\n        fv_inds = np.unique(\n            np.random.randint(low=0, high=N - 1, size=int(N * d), dtype=np.int32)\n        )\n        b_arr[fv_inds] = True if pd.isna(fill_value) else not fill_value\n        self.sp_b_arr = SparseArray(b_arr, dtype=np.bool_, fill_value=fill_value)", "min_run_count": 2, "name": "sparse.GetItemMask.time_mask", "number": 0, "param_names": ["fill_value"], "params": [["True", "False", "nan"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "faec0e7113d63984cae0b03f7857c1d88a455a72fd5f1dd15f082e047f8139c2", "warmup_time": -1}, "sparse.MinMax.time_min_max": {"code": "class MinMax:\n    def time_min_max(self, func, fill_value):\n        getattr(self.sp_arr, func)()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass MinMax:\n    def setup(self, func, fill_value):\n        N = 1_000_000\n        arr = make_array(N, 1e-5, fill_value, np.float64)\n        self.sp_arr = SparseArray(arr, fill_value=fill_value)", "min_run_count": 2, "name": "sparse.MinMax.time_min_max", "number": 0, "param_names": ["func", "fill_value"], "params": [["'min'", "'max'"], ["0.0", "nan"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "5666067aa9bdd3647031cbff0f601ab81231b8c4dc791adc44067a9f361d169a", "warmup_time": -1}, "sparse.SparseArrayConstructor.time_sparse_array": {"code": "class SparseArrayConstructor:\n    def time_sparse_array(self, dense_proportion, fill_value, dtype):\n        SparseArray(self.array, fill_value=fill_value, dtype=dtype)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass SparseArrayConstructor:\n    def setup(self, dense_proportion, fill_value, dtype):\n        N = 10**6\n        self.array = make_array(N, dense_proportion, fill_value, dtype)", "min_run_count": 2, "name": "sparse.SparseArrayConstructor.time_sparse_array", "number": 0, "param_names": ["dense_proportion", "fill_value", "dtype"], "params": [["0.1", "0.01"], ["0", "nan"], ["<class 'numpy.int64'>", "<class 'numpy.float64'>", "<class 'object'>"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "e55fb75aef7adab66fc35b1f00e5d38f4c21a7465625d0a1cce5873ce8096110", "warmup_time": -1}, "sparse.SparseDataFrameConstructor.time_from_scipy": {"code": "class SparseDataFrameConstructor:\n    def time_from_scipy(self):\n        pd.DataFrame.sparse.from_spmatrix(self.sparse)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass SparseDataFrameConstructor:\n    def setup(self):\n        N = 1000\n        self.sparse = scipy.sparse.rand(N, N, 0.005)", "min_run_count": 2, "name": "sparse.SparseDataFrameConstructor.time_from_scipy", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "177d56dfb0c583f7adb94c9adb8e996066558bf79bf5c7600620c4d85eac136f", "warmup_time": -1}, "sparse.SparseSeriesToFrame.time_series_to_frame": {"code": "class SparseSeriesToFrame:\n    def time_series_to_frame(self):\n        pd.DataFrame(self.series)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass SparseSeriesToFrame:\n    def setup(self):\n        K = 50\n        N = 50001\n        rng = date_range(\"1/1/2000\", periods=N, freq=\"min\")\n        self.series = {}\n        for i in range(1, K):\n            data = np.random.randn(N)[:-i]\n            idx = rng[:-i]\n            data[100:] = np.nan\n            self.series[i] = Series(SparseArray(data), index=idx)", "min_run_count": 2, "name": "sparse.SparseSeriesToFrame.time_series_to_frame", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "f2c3253236bf887dec28449ec4523175e3527457017bb55c9b937e6cd0911d3f", "warmup_time": -1}, "sparse.Take.time_take": {"code": "class Take:\n    def time_take(self, indices, allow_fill):\n        self.sp_arr.take(indices, allow_fill=allow_fill)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Take:\n    def setup(self, indices, allow_fill):\n        N = 1_000_000\n        fill_value = 0.0\n        arr = make_array(N, 1e-5, fill_value, np.float64)\n        self.sp_arr = SparseArray(arr, fill_value=fill_value)", "min_run_count": 2, "name": "sparse.Take.time_take", "number": 0, "param_names": ["indices", "allow_fill"], "params": [["array([0])", "array([    0,     1,     2, ..., 99997, 99998, 99999])", "array([-1, -1, -1, ..., -1, -1, -1])"], ["True", "False"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "de40b85a6b156eead56c80f2a8a02564cec85e5cda7f49c947f0385fc4552dbb", "warmup_time": -1}, "sparse.ToCoo.time_sparse_series_to_coo": {"code": "class ToCoo:\n    def time_sparse_series_to_coo(self, sort_labels):\n        self.ss_mult_lvl.sparse.to_coo(\n            row_levels=[0, 1], column_levels=[2, 3], sort_labels=sort_labels\n        )\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToCoo:\n    def setup(self, sort_labels):\n        s = Series([np.nan] * 10000)\n        s[0] = 3.0\n        s[100] = -1.0\n        s[999] = 12.1\n    \n        s_mult_lvl = s.set_axis(MultiIndex.from_product([range(10)] * 4))\n        self.ss_mult_lvl = s_mult_lvl.astype(\"Sparse\")\n    \n        s_two_lvl = s.set_axis(MultiIndex.from_product([range(100)] * 2))\n        self.ss_two_lvl = s_two_lvl.astype(\"Sparse\")", "min_run_count": 2, "name": "sparse.ToCoo.time_sparse_series_to_coo", "number": 0, "param_names": ["sort_labels"], "params": [["True", "False"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "30ca6ac73768cb7fe0d759bfd836f6ccc90dbdfcd666842cfe90d333c4063300", "warmup_time": -1}, "sparse.ToCoo.time_sparse_series_to_coo_single_level": {"code": "class ToCoo:\n    def time_sparse_series_to_coo_single_level(self, sort_labels):\n        self.ss_two_lvl.sparse.to_coo(sort_labels=sort_labels)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToCoo:\n    def setup(self, sort_labels):\n        s = Series([np.nan] * 10000)\n        s[0] = 3.0\n        s[100] = -1.0\n        s[999] = 12.1\n    \n        s_mult_lvl = s.set_axis(MultiIndex.from_product([range(10)] * 4))\n        self.ss_mult_lvl = s_mult_lvl.astype(\"Sparse\")\n    \n        s_two_lvl = s.set_axis(MultiIndex.from_product([range(100)] * 2))\n        self.ss_two_lvl = s_two_lvl.astype(\"Sparse\")", "min_run_count": 2, "name": "sparse.ToCoo.time_sparse_series_to_coo_single_level", "number": 0, "param_names": ["sort_labels"], "params": [["True", "False"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "9f146457117b9ef50ec361711446aad79f7c706f074b3b9d901b5536c47680c0", "warmup_time": -1}, "sparse.ToCooFrame.time_to_coo": {"code": "class ToCooFrame:\n    def time_to_coo(self):\n        self.df.sparse.to_coo()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToCooFrame:\n    def setup(self):\n        N = 10000\n        k = 10\n        arr = np.zeros((N, k), dtype=float)\n        arr[0, 0] = 3.0\n        arr[12, 7] = -1.0\n        arr[0, 9] = 11.2\n        self.df = pd.DataFrame(arr, dtype=pd.SparseDtype(\"float\", fill_value=0.0))", "min_run_count": 2, "name": "sparse.ToCooFrame.time_to_coo", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "aa52b43e43b97a10066b7eb8a13b85c06203c3660e6293bf051b23418b51d48a", "warmup_time": -1}, "stat_ops.Correlation.peakmem_corr_wide": {"code": "class Correlation:\n    def peakmem_corr_wide(self, method):\n        self.df_wide.corr(method=method)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Correlation:\n    def setup(self, method):\n        self.df = pd.DataFrame(np.random.randn(500, 15))\n        self.df2 = pd.DataFrame(np.random.randn(500, 15))\n        self.df_wide = pd.DataFrame(np.random.randn(500, 100))\n        self.df_wide_nans = self.df_wide.where(np.random.random((500, 100)) < 0.9)\n        self.s = pd.Series(np.random.randn(500))\n        self.s2 = pd.Series(np.random.randn(500))", "name": "stat_ops.Correlation.peakmem_corr_wide", "param_names": ["method"], "params": [["'spearman'", "'kendall'", "'pearson'"]], "timeout": 60.0, "type": "peakmemory", "unit": "bytes", "version": "3ee8f436749f1f2d1f0a071b811c2fa8f22e5b7bfa05919d0449957533179b9a"}, "stat_ops.Correlation.time_corr": {"code": "class Correlation:\n    def time_corr(self, method):\n        self.df.corr(method=method)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Correlation:\n    def setup(self, method):\n        self.df = pd.DataFrame(np.random.randn(500, 15))\n        self.df2 = pd.DataFrame(np.random.randn(500, 15))\n        self.df_wide = pd.DataFrame(np.random.randn(500, 100))\n        self.df_wide_nans = self.df_wide.where(np.random.random((500, 100)) < 0.9)\n        self.s = pd.Series(np.random.randn(500))\n        self.s2 = pd.Series(np.random.randn(500))", "min_run_count": 2, "name": "stat_ops.Correlation.time_corr", "number": 0, "param_names": ["method"], "params": [["'spearman'", "'kendall'", "'pearson'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "985b3d9669fc0dfe69164a9a3e932c4cab6585326d0af33ff34da7dcfcc72ecd", "warmup_time": -1}, "stat_ops.Correlation.time_corr_series": {"code": "class Correlation:\n    def time_corr_series(self, method):\n        self.s.corr(self.s2, method=method)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Correlation:\n    def setup(self, method):\n        self.df = pd.DataFrame(np.random.randn(500, 15))\n        self.df2 = pd.DataFrame(np.random.randn(500, 15))\n        self.df_wide = pd.DataFrame(np.random.randn(500, 100))\n        self.df_wide_nans = self.df_wide.where(np.random.random((500, 100)) < 0.9)\n        self.s = pd.Series(np.random.randn(500))\n        self.s2 = pd.Series(np.random.randn(500))", "min_run_count": 2, "name": "stat_ops.Correlation.time_corr_series", "number": 0, "param_names": ["method"], "params": [["'spearman'", "'kendall'", "'pearson'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "15f8a4d1a6ad3002de031f6c6188e46257f89004dd83e0efb0133cda90ddfa33", "warmup_time": -1}, "stat_ops.Correlation.time_corr_wide": {"code": "class Correlation:\n    def time_corr_wide(self, method):\n        self.df_wide.corr(method=method)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Correlation:\n    def setup(self, method):\n        self.df = pd.DataFrame(np.random.randn(500, 15))\n        self.df2 = pd.DataFrame(np.random.randn(500, 15))\n        self.df_wide = pd.DataFrame(np.random.randn(500, 100))\n        self.df_wide_nans = self.df_wide.where(np.random.random((500, 100)) < 0.9)\n        self.s = pd.Series(np.random.randn(500))\n        self.s2 = pd.Series(np.random.randn(500))", "min_run_count": 2, "name": "stat_ops.Correlation.time_corr_wide", "number": 0, "param_names": ["method"], "params": [["'spearman'", "'kendall'", "'pearson'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "54637cc9be24613ba7ed8eb9724167b189a287c89fc91fcc80840fa02444d657", "warmup_time": -1}, "stat_ops.Correlation.time_corr_wide_nans": {"code": "class Correlation:\n    def time_corr_wide_nans(self, method):\n        self.df_wide_nans.corr(method=method)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Correlation:\n    def setup(self, method):\n        self.df = pd.DataFrame(np.random.randn(500, 15))\n        self.df2 = pd.DataFrame(np.random.randn(500, 15))\n        self.df_wide = pd.DataFrame(np.random.randn(500, 100))\n        self.df_wide_nans = self.df_wide.where(np.random.random((500, 100)) < 0.9)\n        self.s = pd.Series(np.random.randn(500))\n        self.s2 = pd.Series(np.random.randn(500))", "min_run_count": 2, "name": "stat_ops.Correlation.time_corr_wide_nans", "number": 0, "param_names": ["method"], "params": [["'spearman'", "'kendall'", "'pearson'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "07c00330d5c6a030d9e77e6aaec677ed606490cdf7f574cf00748a8a8d00c6b9", "warmup_time": -1}, "stat_ops.Correlation.time_corrwith_cols": {"code": "class Correlation:\n    def time_corrwith_cols(self, method):\n        self.df.corrwith(self.df2, method=method)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Correlation:\n    def setup(self, method):\n        self.df = pd.DataFrame(np.random.randn(500, 15))\n        self.df2 = pd.DataFrame(np.random.randn(500, 15))\n        self.df_wide = pd.DataFrame(np.random.randn(500, 100))\n        self.df_wide_nans = self.df_wide.where(np.random.random((500, 100)) < 0.9)\n        self.s = pd.Series(np.random.randn(500))\n        self.s2 = pd.Series(np.random.randn(500))", "min_run_count": 2, "name": "stat_ops.Correlation.time_corrwith_cols", "number": 0, "param_names": ["method"], "params": [["'spearman'", "'kendall'", "'pearson'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "5d0002de6d691b52406c99ef171a6bef8d6f9569a32c8223c1544b748f1cee3f", "warmup_time": -1}, "stat_ops.Correlation.time_corrwith_rows": {"code": "class Correlation:\n    def time_corrwith_rows(self, method):\n        self.df.corrwith(self.df2, axis=1, method=method)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Correlation:\n    def setup(self, method):\n        self.df = pd.DataFrame(np.random.randn(500, 15))\n        self.df2 = pd.DataFrame(np.random.randn(500, 15))\n        self.df_wide = pd.DataFrame(np.random.randn(500, 100))\n        self.df_wide_nans = self.df_wide.where(np.random.random((500, 100)) < 0.9)\n        self.s = pd.Series(np.random.randn(500))\n        self.s2 = pd.Series(np.random.randn(500))", "min_run_count": 2, "name": "stat_ops.Correlation.time_corrwith_rows", "number": 0, "param_names": ["method"], "params": [["'spearman'", "'kendall'", "'pearson'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "537c1ca1a5384e46898eef91e2a713efab1b5f27bece96d73baa8c1084a319eb", "warmup_time": -1}, "stat_ops.Covariance.time_cov_series": {"code": "class Covariance:\n    def time_cov_series(self):\n        self.s.cov(self.s2)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Covariance:\n    def setup(self):\n        self.s = pd.Series(np.random.randn(100000))\n        self.s2 = pd.Series(np.random.randn(100000))", "min_run_count": 2, "name": "stat_ops.Covariance.time_cov_series", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "5127b263e3a6473e609cbc77952bf516e224e61656efd15280caf5a2bd93ac5f", "warmup_time": -1}, "stat_ops.FrameMixedDtypesOps.time_op": {"code": "class FrameMixedDtypesOps:\n    def time_op(self, op, axis):\n        self.df_func(axis=axis)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass FrameMixedDtypesOps:\n    def setup(self, op, axis):\n        if op in (\"sum\", \"skew\", \"kurt\", \"prod\", \"sem\", \"var\") or (\n            (op, axis)\n            in (\n                (\"mean\", 1),\n                (\"mean\", None),\n                (\"median\", 1),\n                (\"median\", None),\n                (\"std\", 1),\n            )\n        ):\n            # Skipping cases where datetime aggregations are not implemented\n            raise NotImplementedError\n    \n        N = 1_000_000\n        df = pd.DataFrame(\n            {\n                \"f\": np.random.normal(0.0, 1.0, N),\n                \"i\": np.random.randint(0, N, N),\n                \"ts\": pd.date_range(start=\"1/1/2000\", periods=N, freq=\"h\"),\n            }\n        )\n    \n        self.df_func = getattr(df, op)", "min_run_count": 2, "name": "stat_ops.FrameMixedDtypesOps.time_op", "number": 0, "param_names": ["op", "axis"], "params": [["'mean'", "'sum'", "'median'", "'std'", "'skew'", "'kurt'", "'prod'", "'sem'", "'var'"], ["0", "1", "None"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "cb12738b3378731fbbebed5824f44760aa9be875317346ff0aa84948432c0aeb", "warmup_time": -1}, "stat_ops.FrameMultiIndexOps.time_op": {"code": "class FrameMultiIndexOps:\n    def time_op(self, op):\n        self.df_func()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass FrameMultiIndexOps:\n    def setup(self, op):\n        levels = [np.arange(10), np.arange(100), np.arange(100)]\n        codes = [\n            np.arange(10).repeat(10000),\n            np.tile(np.arange(100).repeat(100), 10),\n            np.tile(np.tile(np.arange(100), 100), 10),\n        ]\n        index = pd.MultiIndex(levels=levels, codes=codes)\n        df = pd.DataFrame(np.random.randn(len(index), 4), index=index)\n        self.df_func = getattr(df, op)", "min_run_count": 2, "name": "stat_ops.FrameMultiIndexOps.time_op", "number": 0, "param_names": ["op"], "params": [["'mean'", "'sum'", "'median'", "'std'", "'skew'", "'kurt'", "'prod'", "'sem'", "'var'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "13a0374ca338a8b54f1bd16d1ffe134ba780a1d942f5be7ac191ba76b2be4f8f", "warmup_time": -1}, "stat_ops.FrameOps.time_op": {"code": "class FrameOps:\n    def time_op(self, op, dtype, axis):\n        self.df_func(axis=axis)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass FrameOps:\n    def setup(self, op, dtype, axis):\n        values = np.random.randn(100000, 4)\n        if dtype == \"Int64\":\n            values = values.astype(int)\n        df = pd.DataFrame(values).astype(dtype)\n        self.df_func = getattr(df, op)", "min_run_count": 2, "name": "stat_ops.FrameOps.time_op", "number": 0, "param_names": ["op", "dtype", "axis"], "params": [["'mean'", "'sum'", "'median'", "'std'", "'skew'", "'kurt'", "'prod'", "'sem'", "'var'"], ["'float'", "'int'", "'Int64'"], ["0", "1", "None"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "b07391c064482d2f0ffb065b28ce25a0cc9d57d9d0281a2d85490c669a986f7e", "warmup_time": -1}, "stat_ops.Rank.time_average_old": {"code": "class Rank:\n    def time_average_old(self, constructor, pct):\n        self.data.rank(pct=pct) / len(self.data)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Rank:\n    def setup(self, constructor, pct):\n        values = np.random.randn(10**5)\n        self.data = getattr(pd, constructor)(values)", "min_run_count": 2, "name": "stat_ops.Rank.time_average_old", "number": 0, "param_names": ["constructor", "pct"], "params": [["'DataFrame'", "'Series'"], ["True", "False"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "82f64cd32e871ed31fd99deb14e611ab16a04df9a99cf92bf1e12863d0d82bda", "warmup_time": -1}, "stat_ops.Rank.time_rank": {"code": "class Rank:\n    def time_rank(self, constructor, pct):\n        self.data.rank(pct=pct)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Rank:\n    def setup(self, constructor, pct):\n        values = np.random.randn(10**5)\n        self.data = getattr(pd, constructor)(values)", "min_run_count": 2, "name": "stat_ops.Rank.time_rank", "number": 0, "param_names": ["constructor", "pct"], "params": [["'DataFrame'", "'Series'"], ["True", "False"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "f8b083c6f46cf347224b1f03549284db11f310cb7e3936a705627eddfeb01142", "warmup_time": -1}, "stat_ops.SeriesMultiIndexOps.time_op": {"code": "class SeriesMultiIndexOps:\n    def time_op(self, op):\n        self.s_func()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass SeriesMultiIndexOps:\n    def setup(self, op):\n        levels = [np.arange(10), np.arange(100), np.arange(100)]\n        codes = [\n            np.arange(10).repeat(10000),\n            np.tile(np.arange(100).repeat(100), 10),\n            np.tile(np.tile(np.arange(100), 100), 10),\n        ]\n        index = pd.MultiIndex(levels=levels, codes=codes)\n        s = pd.Series(np.random.randn(len(index)), index=index)\n        self.s_func = getattr(s, op)", "min_run_count": 2, "name": "stat_ops.SeriesMultiIndexOps.time_op", "number": 0, "param_names": ["op"], "params": [["'mean'", "'sum'", "'median'", "'std'", "'skew'", "'kurt'", "'prod'", "'sem'", "'var'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "fafe7c22ddf1ddd0aa6871d8d9537041f3e037adacdc1794d69166a0bfc9dbaa", "warmup_time": -1}, "stat_ops.SeriesOps.time_op": {"code": "class SeriesOps:\n    def time_op(self, op, dtype):\n        self.s_func()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass SeriesOps:\n    def setup(self, op, dtype):\n        s = pd.Series(np.random.randn(100000)).astype(dtype)\n        self.s_func = getattr(s, op)", "min_run_count": 2, "name": "stat_ops.SeriesOps.time_op", "number": 0, "param_names": ["op", "dtype"], "params": [["'mean'", "'sum'", "'median'", "'std'", "'skew'", "'kurt'", "'prod'", "'sem'", "'var'"], ["'float'", "'int'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "32cfffab59594606bcaccdcd64c3521e5ffec20c0dcf9b1c864e4d0a6dc41bd4", "warmup_time": -1}, "strftime.BusinessHourStrftime.time_frame_offset_repr": {"code": "class BusinessHourStrftime:\n    def time_frame_offset_repr(self, nobs):\n        self.data[\"off\"].apply(repr)\n\n    def setup(self, nobs):\n        self.data = pd.DataFrame(\n            {\n                \"off\": [offsets.BusinessHour()] * nobs,\n            }\n        )", "min_run_count": 2, "name": "strftime.BusinessHourStrftime.time_frame_offset_repr", "number": 0, "param_names": ["nobs"], "params": [["1000", "10000"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 1500, "type": "time", "unit": "seconds", "version": "a46e69099d417d6960551a9c61f7218c1c698b1a064f46cb71253c6e94b54baf", "warmup_time": -1}, "strftime.BusinessHourStrftime.time_frame_offset_str": {"code": "class BusinessHourStrftime:\n    def time_frame_offset_str(self, nobs):\n        self.data[\"off\"].apply(str)\n\n    def setup(self, nobs):\n        self.data = pd.DataFrame(\n            {\n                \"off\": [offsets.BusinessHour()] * nobs,\n            }\n        )", "min_run_count": 2, "name": "strftime.BusinessHourStrftime.time_frame_offset_str", "number": 0, "param_names": ["nobs"], "params": [["1000", "10000"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 1500, "type": "time", "unit": "seconds", "version": "c6bd6a7c9015f044c74ec8ada5991b59b8e6811009465b189b2998771710e66c", "warmup_time": -1}, "strftime.DatetimeStrftime.time_frame_date_formatting_custom": {"code": "class DatetimeStrftime:\n    def time_frame_date_formatting_custom(self, nobs):\n        self.data[\"d\"].dt.strftime(date_format=\"%Y---%m---%d\")\n\n    def setup(self, nobs):\n        d = \"2018-11-29\"\n        dt = \"2018-11-26 11:18:27.0\"\n        self.data = pd.DataFrame(\n            {\n                \"dt\": [np.datetime64(dt)] * nobs,\n                \"d\": [np.datetime64(d)] * nobs,\n                \"r\": [np.random.uniform()] * nobs,\n            }\n        )", "min_run_count": 2, "name": "strftime.DatetimeStrftime.time_frame_date_formatting_custom", "number": 0, "param_names": ["nobs"], "params": [["1000", "10000"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 1500, "type": "time", "unit": "seconds", "version": "d8c2ef0e234003004a808414432827b34b1314aec0c69a9322be2df115c12c28", "warmup_time": -1}, "strftime.DatetimeStrftime.time_frame_date_formatting_default": {"code": "class DatetimeStrftime:\n    def time_frame_date_formatting_default(self, nobs):\n        self.data[\"d\"].dt.strftime(date_format=None)\n\n    def setup(self, nobs):\n        d = \"2018-11-29\"\n        dt = \"2018-11-26 11:18:27.0\"\n        self.data = pd.DataFrame(\n            {\n                \"dt\": [np.datetime64(dt)] * nobs,\n                \"d\": [np.datetime64(d)] * nobs,\n                \"r\": [np.random.uniform()] * nobs,\n            }\n        )", "min_run_count": 2, "name": "strftime.DatetimeStrftime.time_frame_date_formatting_default", "number": 0, "param_names": ["nobs"], "params": [["1000", "10000"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 1500, "type": "time", "unit": "seconds", "version": "4d7dbcd663f6d27bf3c01012b2b750c048d3b893fbae2f63b59de0ff09ba544f", "warmup_time": -1}, "strftime.DatetimeStrftime.time_frame_date_formatting_default_explicit": {"code": "class DatetimeStrftime:\n    def time_frame_date_formatting_default_explicit(self, nobs):\n        self.data[\"d\"].dt.strftime(date_format=\"%Y-%m-%d\")\n\n    def setup(self, nobs):\n        d = \"2018-11-29\"\n        dt = \"2018-11-26 11:18:27.0\"\n        self.data = pd.DataFrame(\n            {\n                \"dt\": [np.datetime64(dt)] * nobs,\n                \"d\": [np.datetime64(d)] * nobs,\n                \"r\": [np.random.uniform()] * nobs,\n            }\n        )", "min_run_count": 2, "name": "strftime.DatetimeStrftime.time_frame_date_formatting_default_explicit", "number": 0, "param_names": ["nobs"], "params": [["1000", "10000"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 1500, "type": "time", "unit": "seconds", "version": "413c43d2510bbf20e866c514a93a3d2f808f687f6cbf2c2d7fcb586332b29878", "warmup_time": -1}, "strftime.DatetimeStrftime.time_frame_date_to_str": {"code": "class DatetimeStrftime:\n    def time_frame_date_to_str(self, nobs):\n        self.data[\"d\"].astype(str)\n\n    def setup(self, nobs):\n        d = \"2018-11-29\"\n        dt = \"2018-11-26 11:18:27.0\"\n        self.data = pd.DataFrame(\n            {\n                \"dt\": [np.datetime64(dt)] * nobs,\n                \"d\": [np.datetime64(d)] * nobs,\n                \"r\": [np.random.uniform()] * nobs,\n            }\n        )", "min_run_count": 2, "name": "strftime.DatetimeStrftime.time_frame_date_to_str", "number": 0, "param_names": ["nobs"], "params": [["1000", "10000"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 1500, "type": "time", "unit": "seconds", "version": "054e08eca2d4a8767e953c76bde4ff267409bb5703360cece151bbe66a333160", "warmup_time": -1}, "strftime.DatetimeStrftime.time_frame_datetime_formatting_custom": {"code": "class DatetimeStrftime:\n    def time_frame_datetime_formatting_custom(self, nobs):\n        self.data[\"dt\"].dt.strftime(date_format=\"%Y-%m-%d --- %H:%M:%S\")\n\n    def setup(self, nobs):\n        d = \"2018-11-29\"\n        dt = \"2018-11-26 11:18:27.0\"\n        self.data = pd.DataFrame(\n            {\n                \"dt\": [np.datetime64(dt)] * nobs,\n                \"d\": [np.datetime64(d)] * nobs,\n                \"r\": [np.random.uniform()] * nobs,\n            }\n        )", "min_run_count": 2, "name": "strftime.DatetimeStrftime.time_frame_datetime_formatting_custom", "number": 0, "param_names": ["nobs"], "params": [["1000", "10000"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 1500, "type": "time", "unit": "seconds", "version": "45f78787f94eb5bc3a07ef4de1615aeb63966f4bc0323e6efd09f5e1a4466fc2", "warmup_time": -1}, "strftime.DatetimeStrftime.time_frame_datetime_formatting_default": {"code": "class DatetimeStrftime:\n    def time_frame_datetime_formatting_default(self, nobs):\n        self.data[\"dt\"].dt.strftime(date_format=None)\n\n    def setup(self, nobs):\n        d = \"2018-11-29\"\n        dt = \"2018-11-26 11:18:27.0\"\n        self.data = pd.DataFrame(\n            {\n                \"dt\": [np.datetime64(dt)] * nobs,\n                \"d\": [np.datetime64(d)] * nobs,\n                \"r\": [np.random.uniform()] * nobs,\n            }\n        )", "min_run_count": 2, "name": "strftime.DatetimeStrftime.time_frame_datetime_formatting_default", "number": 0, "param_names": ["nobs"], "params": [["1000", "10000"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 1500, "type": "time", "unit": "seconds", "version": "fa3e5c135498e5597fee3a7b0be426c176f10b8619cbee4f27ac55f095e64407", "warmup_time": -1}, "strftime.DatetimeStrftime.time_frame_datetime_formatting_default_explicit": {"code": "class DatetimeStrftime:\n    def time_frame_datetime_formatting_default_explicit(self, nobs):\n        self.data[\"dt\"].dt.strftime(date_format=\"%Y-%m-%d %H:%M:%S\")\n\n    def setup(self, nobs):\n        d = \"2018-11-29\"\n        dt = \"2018-11-26 11:18:27.0\"\n        self.data = pd.DataFrame(\n            {\n                \"dt\": [np.datetime64(dt)] * nobs,\n                \"d\": [np.datetime64(d)] * nobs,\n                \"r\": [np.random.uniform()] * nobs,\n            }\n        )", "min_run_count": 2, "name": "strftime.DatetimeStrftime.time_frame_datetime_formatting_default_explicit", "number": 0, "param_names": ["nobs"], "params": [["1000", "10000"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 1500, "type": "time", "unit": "seconds", "version": "ec080e75b9842b184e4d1ffec10e5499756d68b597c0665dd44b755de1e5d72c", "warmup_time": -1}, "strftime.DatetimeStrftime.time_frame_datetime_formatting_default_explicit_date_only": {"code": "class DatetimeStrftime:\n    def time_frame_datetime_formatting_default_explicit_date_only(self, nobs):\n        self.data[\"dt\"].dt.strftime(date_format=\"%Y-%m-%d\")\n\n    def setup(self, nobs):\n        d = \"2018-11-29\"\n        dt = \"2018-11-26 11:18:27.0\"\n        self.data = pd.DataFrame(\n            {\n                \"dt\": [np.datetime64(dt)] * nobs,\n                \"d\": [np.datetime64(d)] * nobs,\n                \"r\": [np.random.uniform()] * nobs,\n            }\n        )", "min_run_count": 2, "name": "strftime.DatetimeStrftime.time_frame_datetime_formatting_default_explicit_date_only", "number": 0, "param_names": ["nobs"], "params": [["1000", "10000"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 1500, "type": "time", "unit": "seconds", "version": "2d5a4bbcd37dd7efc7834d4fe604fa054058f030eaac3f245f2eed5c2a384df6", "warmup_time": -1}, "strftime.DatetimeStrftime.time_frame_datetime_formatting_default_with_float": {"code": "class DatetimeStrftime:\n    def time_frame_datetime_formatting_default_with_float(self, nobs):\n        self.data[\"dt\"].dt.strftime(date_format=\"%Y-%m-%d %H:%M:%S.%f\")\n\n    def setup(self, nobs):\n        d = \"2018-11-29\"\n        dt = \"2018-11-26 11:18:27.0\"\n        self.data = pd.DataFrame(\n            {\n                \"dt\": [np.datetime64(dt)] * nobs,\n                \"d\": [np.datetime64(d)] * nobs,\n                \"r\": [np.random.uniform()] * nobs,\n            }\n        )", "min_run_count": 2, "name": "strftime.DatetimeStrftime.time_frame_datetime_formatting_default_with_float", "number": 0, "param_names": ["nobs"], "params": [["1000", "10000"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 1500, "type": "time", "unit": "seconds", "version": "c3d5e3fc1b3d0590232afef2ae418ff61154bc7d430b0475e7e70cdf7dcc4723", "warmup_time": -1}, "strftime.DatetimeStrftime.time_frame_datetime_to_str": {"code": "class DatetimeStrftime:\n    def time_frame_datetime_to_str(self, nobs):\n        self.data[\"dt\"].astype(str)\n\n    def setup(self, nobs):\n        d = \"2018-11-29\"\n        dt = \"2018-11-26 11:18:27.0\"\n        self.data = pd.DataFrame(\n            {\n                \"dt\": [np.datetime64(dt)] * nobs,\n                \"d\": [np.datetime64(d)] * nobs,\n                \"r\": [np.random.uniform()] * nobs,\n            }\n        )", "min_run_count": 2, "name": "strftime.DatetimeStrftime.time_frame_datetime_to_str", "number": 0, "param_names": ["nobs"], "params": [["1000", "10000"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 1500, "type": "time", "unit": "seconds", "version": "5a4c4ba96a951bbfd2b09497a9dfe6a72abfa1eac880c8f2d90e19c7bed5b98b", "warmup_time": -1}, "strftime.PeriodStrftime.time_frame_period_formatting_custom": {"code": "class PeriodStrftime:\n    def time_frame_period_formatting_custom(self, nobs, freq):\n        self.data[\"p\"].dt.strftime(date_format=\"%Y-%m-%d --- %H:%M:%S\")\n\n    def setup(self, nobs, freq):\n        self.data = pd.DataFrame(\n            {\n                \"p\": pd.period_range(start=\"2000-01-01\", periods=nobs, freq=freq),\n                \"r\": [np.random.uniform()] * nobs,\n            }\n        )\n        self.data[\"i\"] = self.data[\"p\"]\n        self.data.set_index(\"i\", inplace=True)\n        if freq == \"D\":\n            self.default_fmt = \"%Y-%m-%d\"\n        elif freq == \"h\":\n            self.default_fmt = \"%Y-%m-%d %H:00\"", "min_run_count": 2, "name": "strftime.PeriodStrftime.time_frame_period_formatting_custom", "number": 0, "param_names": ["nobs", "freq"], "params": [["1000", "10000"], ["'D'", "'h'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 1500, "type": "time", "unit": "seconds", "version": "16999601594a1d9cd57cfa7155f55be9da4b04ddd986430761e938fe4138d5ff", "warmup_time": -1}, "strftime.PeriodStrftime.time_frame_period_formatting_default": {"code": "class PeriodStrftime:\n    def time_frame_period_formatting_default(self, nobs, freq):\n        self.data[\"p\"].dt.strftime(date_format=None)\n\n    def setup(self, nobs, freq):\n        self.data = pd.DataFrame(\n            {\n                \"p\": pd.period_range(start=\"2000-01-01\", periods=nobs, freq=freq),\n                \"r\": [np.random.uniform()] * nobs,\n            }\n        )\n        self.data[\"i\"] = self.data[\"p\"]\n        self.data.set_index(\"i\", inplace=True)\n        if freq == \"D\":\n            self.default_fmt = \"%Y-%m-%d\"\n        elif freq == \"h\":\n            self.default_fmt = \"%Y-%m-%d %H:00\"", "min_run_count": 2, "name": "strftime.PeriodStrftime.time_frame_period_formatting_default", "number": 0, "param_names": ["nobs", "freq"], "params": [["1000", "10000"], ["'D'", "'h'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 1500, "type": "time", "unit": "seconds", "version": "9043ba2fbb552e444f04b49a0bad1382d6e7d4e1f55d150b30bd5117704ca1a9", "warmup_time": -1}, "strftime.PeriodStrftime.time_frame_period_formatting_default_explicit": {"code": "class PeriodStrftime:\n    def time_frame_period_formatting_default_explicit(self, nobs, freq):\n        self.data[\"p\"].dt.strftime(date_format=self.default_fmt)\n\n    def setup(self, nobs, freq):\n        self.data = pd.DataFrame(\n            {\n                \"p\": pd.period_range(start=\"2000-01-01\", periods=nobs, freq=freq),\n                \"r\": [np.random.uniform()] * nobs,\n            }\n        )\n        self.data[\"i\"] = self.data[\"p\"]\n        self.data.set_index(\"i\", inplace=True)\n        if freq == \"D\":\n            self.default_fmt = \"%Y-%m-%d\"\n        elif freq == \"h\":\n            self.default_fmt = \"%Y-%m-%d %H:00\"", "min_run_count": 2, "name": "strftime.PeriodStrftime.time_frame_period_formatting_default_explicit", "number": 0, "param_names": ["nobs", "freq"], "params": [["1000", "10000"], ["'D'", "'h'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 1500, "type": "time", "unit": "seconds", "version": "b18eda1cc34ea4b3062f32befb43ba338a0f37eb1ffae5221f65db35f7c86c2e", "warmup_time": -1}, "strftime.PeriodStrftime.time_frame_period_formatting_index_default": {"code": "class PeriodStrftime:\n    def time_frame_period_formatting_index_default(self, nobs, freq):\n        self.data.index.format()\n\n    def setup(self, nobs, freq):\n        self.data = pd.DataFrame(\n            {\n                \"p\": pd.period_range(start=\"2000-01-01\", periods=nobs, freq=freq),\n                \"r\": [np.random.uniform()] * nobs,\n            }\n        )\n        self.data[\"i\"] = self.data[\"p\"]\n        self.data.set_index(\"i\", inplace=True)\n        if freq == \"D\":\n            self.default_fmt = \"%Y-%m-%d\"\n        elif freq == \"h\":\n            self.default_fmt = \"%Y-%m-%d %H:00\"", "min_run_count": 2, "name": "strftime.PeriodStrftime.time_frame_period_formatting_index_default", "number": 0, "param_names": ["nobs", "freq"], "params": [["1000", "10000"], ["'D'", "'h'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 1500, "type": "time", "unit": "seconds", "version": "bbe10c363fee9234191bc025a24f9a5e8c4c89512ca7bf4a58a2f37a1f83a642", "warmup_time": -1}, "strftime.PeriodStrftime.time_frame_period_formatting_index_default_explicit": {"code": "class PeriodStrftime:\n    def time_frame_period_formatting_index_default_explicit(self, nobs, freq):\n        self.data.index.format(self.default_fmt)\n\n    def setup(self, nobs, freq):\n        self.data = pd.DataFrame(\n            {\n                \"p\": pd.period_range(start=\"2000-01-01\", periods=nobs, freq=freq),\n                \"r\": [np.random.uniform()] * nobs,\n            }\n        )\n        self.data[\"i\"] = self.data[\"p\"]\n        self.data.set_index(\"i\", inplace=True)\n        if freq == \"D\":\n            self.default_fmt = \"%Y-%m-%d\"\n        elif freq == \"h\":\n            self.default_fmt = \"%Y-%m-%d %H:00\"", "min_run_count": 2, "name": "strftime.PeriodStrftime.time_frame_period_formatting_index_default_explicit", "number": 0, "param_names": ["nobs", "freq"], "params": [["1000", "10000"], ["'D'", "'h'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 1500, "type": "time", "unit": "seconds", "version": "8cc0d0bcef193d45424bc5241b91e809ac56a64f236359f42048dd8957ed2d0d", "warmup_time": -1}, "strftime.PeriodStrftime.time_frame_period_formatting_iso8601_strftime_Z": {"code": "class PeriodStrftime:\n    def time_frame_period_formatting_iso8601_strftime_Z(self, nobs, freq):\n        self.data[\"p\"].dt.strftime(date_format=\"%Y-%m-%dT%H:%M:%SZ\")\n\n    def setup(self, nobs, freq):\n        self.data = pd.DataFrame(\n            {\n                \"p\": pd.period_range(start=\"2000-01-01\", periods=nobs, freq=freq),\n                \"r\": [np.random.uniform()] * nobs,\n            }\n        )\n        self.data[\"i\"] = self.data[\"p\"]\n        self.data.set_index(\"i\", inplace=True)\n        if freq == \"D\":\n            self.default_fmt = \"%Y-%m-%d\"\n        elif freq == \"h\":\n            self.default_fmt = \"%Y-%m-%d %H:00\"", "min_run_count": 2, "name": "strftime.PeriodStrftime.time_frame_period_formatting_iso8601_strftime_Z", "number": 0, "param_names": ["nobs", "freq"], "params": [["1000", "10000"], ["'D'", "'h'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 1500, "type": "time", "unit": "seconds", "version": "f5de27264273a2cee140307660efbe5e2f798fdf298074c308d5029ca9c58d76", "warmup_time": -1}, "strftime.PeriodStrftime.time_frame_period_formatting_iso8601_strftime_offset": {"code": "class PeriodStrftime:\n    def time_frame_period_formatting_iso8601_strftime_offset(self, nobs, freq):\n        \"\"\"Not optimized yet as %z is not supported by `convert_strftime_format`\"\"\"\n        self.data[\"p\"].dt.strftime(date_format=\"%Y-%m-%dT%H:%M:%S%z\")\n\n    def setup(self, nobs, freq):\n        self.data = pd.DataFrame(\n            {\n                \"p\": pd.period_range(start=\"2000-01-01\", periods=nobs, freq=freq),\n                \"r\": [np.random.uniform()] * nobs,\n            }\n        )\n        self.data[\"i\"] = self.data[\"p\"]\n        self.data.set_index(\"i\", inplace=True)\n        if freq == \"D\":\n            self.default_fmt = \"%Y-%m-%d\"\n        elif freq == \"h\":\n            self.default_fmt = \"%Y-%m-%d %H:00\"", "min_run_count": 2, "name": "strftime.PeriodStrftime.time_frame_period_formatting_iso8601_strftime_offset", "number": 0, "param_names": ["nobs", "freq"], "params": [["1000", "10000"], ["'D'", "'h'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 1500, "type": "time", "unit": "seconds", "version": "5ba896f46eb860aff2aef5027c2302bd7b1b7eb8ec9d264467a11db4f4ffafe4", "warmup_time": -1}, "strftime.PeriodStrftime.time_frame_period_to_str": {"code": "class PeriodStrftime:\n    def time_frame_period_to_str(self, nobs, freq):\n        self.data[\"p\"].astype(str)\n\n    def setup(self, nobs, freq):\n        self.data = pd.DataFrame(\n            {\n                \"p\": pd.period_range(start=\"2000-01-01\", periods=nobs, freq=freq),\n                \"r\": [np.random.uniform()] * nobs,\n            }\n        )\n        self.data[\"i\"] = self.data[\"p\"]\n        self.data.set_index(\"i\", inplace=True)\n        if freq == \"D\":\n            self.default_fmt = \"%Y-%m-%d\"\n        elif freq == \"h\":\n            self.default_fmt = \"%Y-%m-%d %H:00\"", "min_run_count": 2, "name": "strftime.PeriodStrftime.time_frame_period_to_str", "number": 0, "param_names": ["nobs", "freq"], "params": [["1000", "10000"], ["'D'", "'h'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 1500, "type": "time", "unit": "seconds", "version": "1cdd45d58644445828a73b51075c943c00e4d5d0665144898cc6f8b8ffc16e19", "warmup_time": -1}, "strings.Cat.time_cat": {"code": "class Cat:\n    def time_cat(self, other_cols, sep, na_rep, na_frac):\n        # before the concatenation (one caller + other_cols columns), the total\n        # expected fraction of rows containing any NaN is:\n        # reduce(lambda t, _: t + (1 - t) * na_frac, range(other_cols + 1), 0)\n        # for other_cols=3 and na_frac=0.15, this works out to ~48%\n        self.s.str.cat(others=self.others, sep=sep, na_rep=na_rep)\n\n    def setup(self, other_cols, sep, na_rep, na_frac):\n        N = 10**5\n        mask_gen = lambda: np.random.choice([True, False], N, p=[1 - na_frac, na_frac])\n        self.s = Series(Index([f\"i-{i}\" for i in range(N)], dtype=object)).where(\n            mask_gen()\n        )\n        if other_cols == 0:\n            # str.cat self-concatenates only for others=None\n            self.others = None\n        else:\n            self.others = DataFrame(\n                {\n                    i: Index([f\"i-{i}\" for i in range(N)], dtype=object).where(\n                        mask_gen()\n                    )\n                    for i in range(other_cols)\n                }\n            )", "min_run_count": 2, "name": "strings.Cat.time_cat", "number": 0, "param_names": ["other_cols", "sep", "na_rep", "na_frac"], "params": [["0", "3"], ["None", "','"], ["None", "'-'"], ["0.0", "0.001", "0.15"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "b52f18e7cc25692faed0025e10bc3626a9ae604f84505b3a27457ae00fed759a", "warmup_time": -1}, "strings.Construction.peakmem_construction": {"code": "class Construction:\n    def peakmem_construction(self, pd_type, dtype):\n        self.pd_mapping[pd_type](self.arr, dtype=dtype)\n\n    def setup(self, pd_type, dtype):\n        series_arr = np.array(\n            [str(i) * 10 for i in range(100_000)], dtype=self.dtype_mapping[dtype]\n        )\n        if pd_type == \"series\":\n            self.arr = series_arr\n        elif pd_type == \"frame\":\n            self.arr = series_arr.reshape((50_000, 2)).copy()\n        elif pd_type == \"categorical_series\":\n            # GH37371. Testing construction of string series/frames from ExtensionArrays\n            self.arr = Categorical(series_arr)", "name": "strings.Construction.peakmem_construction", "param_names": ["pd_type", "dtype"], "params": [["'series'", "'frame'", "'categorical_series'"], ["'str'", "'string[python]'", "'string[pyarrow]'"]], "timeout": 60.0, "type": "peakmemory", "unit": "bytes", "version": "388fe5a8cc42f895e1448afe8c9ef9f4345e9cdb97befbfa8ec7e38f4ff97a1d"}, "strings.Construction.time_construction": {"code": "class Construction:\n    def time_construction(self, pd_type, dtype):\n        self.pd_mapping[pd_type](self.arr, dtype=dtype)\n\n    def setup(self, pd_type, dtype):\n        series_arr = np.array(\n            [str(i) * 10 for i in range(100_000)], dtype=self.dtype_mapping[dtype]\n        )\n        if pd_type == \"series\":\n            self.arr = series_arr\n        elif pd_type == \"frame\":\n            self.arr = series_arr.reshape((50_000, 2)).copy()\n        elif pd_type == \"categorical_series\":\n            # GH37371. Testing construction of string series/frames from ExtensionArrays\n            self.arr = Categorical(series_arr)", "min_run_count": 2, "name": "strings.Construction.time_construction", "number": 0, "param_names": ["pd_type", "dtype"], "params": [["'series'", "'frame'", "'categorical_series'"], ["'str'", "'string[python]'", "'string[pyarrow]'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "c957bf7cd41d3cf91aba30f7a6a9da9ebfdb15a91e538ec7f97aca263e832104", "warmup_time": -1}, "strings.Contains.time_contains": {"code": "class Contains:\n    def time_contains(self, dtype, regex):\n        self.s.str.contains(\"A\", regex=regex)\n\n    def setup(self, dtype, regex):\n        super().setup(dtype)", "min_run_count": 2, "name": "strings.Contains.time_contains", "number": 0, "param_names": ["dtype", "regex"], "params": [["'str'", "'string[python]'", "'string[pyarrow]'"], ["True", "False"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "059d755b738e508f2767456a3bcb5561731b1d7d8ac1ad2e92fddc4828e30270", "warmup_time": -1}, "strings.Dummies.time_get_dummies": {"code": "class Dummies:\n    def time_get_dummies(self, dtype):\n        self.s.str.get_dummies(\"|\")\n\n    def setup(self, dtype):\n        super().setup(dtype)\n        N = len(self.s) // 5\n        self.s = self.s[:N].str.join(\"|\")", "min_run_count": 2, "name": "strings.Dummies.time_get_dummies", "number": 0, "param_names": ["dtype"], "params": [["'str'", "'string[python]'", "'string[pyarrow]'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "3636a8f3b31beca3d40035add6c3a6c089964df164eebcdad0b37494708ed25d", "warmup_time": -1}, "strings.Encode.time_encode_decode": {"code": "class Encode:\n    def time_encode_decode(self):\n        self.ser.str.encode(\"utf-8\").str.decode(\"utf-8\")\n\n    def setup(self):\n        self.ser = Series(Index([f\"i-{i}\" for i in range(10_000)], dtype=object))", "min_run_count": 2, "name": "strings.Encode.time_encode_decode", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "98f6dd64fcea519c34e03c7f29d78170688c0d7b9dd676aac55e4f511c3f8f4c", "warmup_time": -1}, "strings.Extract.time_extract_single_group": {"code": "class Extract:\n    def time_extract_single_group(self, dtype, expand):\n        with warnings.catch_warnings(record=True):\n            self.s.str.extract(\"(\\\\w*)A\", expand=expand)\n\n    def setup(self, dtype, expand):\n        super().setup(dtype)", "min_run_count": 2, "name": "strings.Extract.time_extract_single_group", "number": 0, "param_names": ["dtype", "expand"], "params": [["'str'", "'string[python]'", "'string[pyarrow]'"], ["True", "False"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "4a4c5c7bdd1645c137d0f4bcafc4eb9b92be955e5bb27fd6fe7994d2466c32e7", "warmup_time": -1}, "strings.Iter.time_iter": {"code": "class Iter:\n    def time_iter(self, dtype):\n        for i in self.s:\n            pass\n\nclass Dtypes:\n    def setup(self, dtype):\n        try:\n            self.s = Series(\n                Index([f\"i-{i}\" for i in range(10000)], dtype=object), dtype=dtype\n            )\n        except ImportError:\n            raise NotImplementedError", "min_run_count": 2, "name": "strings.Iter.time_iter", "number": 0, "param_names": ["dtype"], "params": [["'str'", "'string[python]'", "'string[pyarrow]'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "69f77566ebc11677dd60bdf5be32d714bf3ee503dabe2034fba51b3d678bfe6e", "warmup_time": -1}, "strings.Methods.time_center": {"code": "class Methods:\n    def time_center(self, dtype):\n        self.s.str.center(100)\n\nclass Dtypes:\n    def setup(self, dtype):\n        try:\n            self.s = Series(\n                Index([f\"i-{i}\" for i in range(10000)], dtype=object), dtype=dtype\n            )\n        except ImportError:\n            raise NotImplementedError", "min_run_count": 2, "name": "strings.Methods.time_center", "number": 0, "param_names": ["dtype"], "params": [["'str'", "'string[python]'", "'string[pyarrow]'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "02575d2208876717a10b46af7b1c133363cadf1381253d805e6fe86c763631c7", "warmup_time": -1}, "strings.Methods.time_count": {"code": "class Methods:\n    def time_count(self, dtype):\n        self.s.str.count(\"A\")\n\nclass Dtypes:\n    def setup(self, dtype):\n        try:\n            self.s = Series(\n                Index([f\"i-{i}\" for i in range(10000)], dtype=object), dtype=dtype\n            )\n        except ImportError:\n            raise NotImplementedError", "min_run_count": 2, "name": "strings.Methods.time_count", "number": 0, "param_names": ["dtype"], "params": [["'str'", "'string[python]'", "'string[pyarrow]'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "7f7d091509a3b1894630c7db6393714b63d0fd0d866a4d900f590778798debfb", "warmup_time": -1}, "strings.Methods.time_endswith": {"code": "class Methods:\n    def time_endswith(self, dtype):\n        self.s.str.endswith(\"A\")\n\nclass Dtypes:\n    def setup(self, dtype):\n        try:\n            self.s = Series(\n                Index([f\"i-{i}\" for i in range(10000)], dtype=object), dtype=dtype\n            )\n        except ImportError:\n            raise NotImplementedError", "min_run_count": 2, "name": "strings.Methods.time_endswith", "number": 0, "param_names": ["dtype"], "params": [["'str'", "'string[python]'", "'string[pyarrow]'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "fbd7a2b6cb71d0f3b3ada803587f71261c4a69040f73bc32cc0b7cc5f5fb26ac", "warmup_time": -1}, "strings.Methods.time_extract": {"code": "class Methods:\n    def time_extract(self, dtype):\n        with warnings.catch_warnings(record=True):\n            self.s.str.extract(\"(\\\\w*)A(\\\\w*)\")\n\nclass Dtypes:\n    def setup(self, dtype):\n        try:\n            self.s = Series(\n                Index([f\"i-{i}\" for i in range(10000)], dtype=object), dtype=dtype\n            )\n        except ImportError:\n            raise NotImplementedError", "min_run_count": 2, "name": "strings.Methods.time_extract", "number": 0, "param_names": ["dtype"], "params": [["'str'", "'string[python]'", "'string[pyarrow]'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "23efc647fcf6549fb947ce417907ca27e44da45ebdb5650374cbf1b475bb4543", "warmup_time": -1}, "strings.Methods.time_find": {"code": "class Methods:\n    def time_find(self, dtype):\n        self.s.str.find(\"[A-Z]+\")\n\nclass Dtypes:\n    def setup(self, dtype):\n        try:\n            self.s = Series(\n                Index([f\"i-{i}\" for i in range(10000)], dtype=object), dtype=dtype\n            )\n        except ImportError:\n            raise NotImplementedError", "min_run_count": 2, "name": "strings.Methods.time_find", "number": 0, "param_names": ["dtype"], "params": [["'str'", "'string[python]'", "'string[pyarrow]'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "61f630237c109bfb31ec9c081d6812a576b6711e80a6a7c37dfef20510d5df02", "warmup_time": -1}, "strings.Methods.time_findall": {"code": "class Methods:\n    def time_findall(self, dtype):\n        self.s.str.findall(\"[A-Z]+\")\n\nclass Dtypes:\n    def setup(self, dtype):\n        try:\n            self.s = Series(\n                Index([f\"i-{i}\" for i in range(10000)], dtype=object), dtype=dtype\n            )\n        except ImportError:\n            raise NotImplementedError", "min_run_count": 2, "name": "strings.Methods.time_findall", "number": 0, "param_names": ["dtype"], "params": [["'str'", "'string[python]'", "'string[pyarrow]'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "878ff15c98135b1cd903023a0509540da514d6402db05050ade1868f8c1271ce", "warmup_time": -1}, "strings.Methods.time_fullmatch": {"code": "class Methods:\n    def time_fullmatch(self, dtype):\n        self.s.str.fullmatch(\"A\")\n\nclass Dtypes:\n    def setup(self, dtype):\n        try:\n            self.s = Series(\n                Index([f\"i-{i}\" for i in range(10000)], dtype=object), dtype=dtype\n            )\n        except ImportError:\n            raise NotImplementedError", "min_run_count": 2, "name": "strings.Methods.time_fullmatch", "number": 0, "param_names": ["dtype"], "params": [["'str'", "'string[python]'", "'string[pyarrow]'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "67dd6e038447c78df3bbbceb603cd27b032228f24695443f6523b5dfadbefe08", "warmup_time": -1}, "strings.Methods.time_get": {"code": "class Methods:\n    def time_get(self, dtype):\n        self.s.str.get(0)\n\nclass Dtypes:\n    def setup(self, dtype):\n        try:\n            self.s = Series(\n                Index([f\"i-{i}\" for i in range(10000)], dtype=object), dtype=dtype\n            )\n        except ImportError:\n            raise NotImplementedError", "min_run_count": 2, "name": "strings.Methods.time_get", "number": 0, "param_names": ["dtype"], "params": [["'str'", "'string[python]'", "'string[pyarrow]'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "e6bd7606c610e69319a3ac512eaab2122dd7a19414a3ef81a5252591963ed424", "warmup_time": -1}, "strings.Methods.time_isalnum": {"code": "class Methods:\n    def time_isalnum(self, dtype):\n        self.s.str.isalnum()\n\nclass Dtypes:\n    def setup(self, dtype):\n        try:\n            self.s = Series(\n                Index([f\"i-{i}\" for i in range(10000)], dtype=object), dtype=dtype\n            )\n        except ImportError:\n            raise NotImplementedError", "min_run_count": 2, "name": "strings.Methods.time_isalnum", "number": 0, "param_names": ["dtype"], "params": [["'str'", "'string[python]'", "'string[pyarrow]'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "7b84fcf1abc9aef463ee449b82ee8bc6e214cd4ceb2dc4f93b1bf06d143b0ccf", "warmup_time": -1}, "strings.Methods.time_isalpha": {"code": "class Methods:\n    def time_isalpha(self, dtype):\n        self.s.str.isalpha()\n\nclass Dtypes:\n    def setup(self, dtype):\n        try:\n            self.s = Series(\n                Index([f\"i-{i}\" for i in range(10000)], dtype=object), dtype=dtype\n            )\n        except ImportError:\n            raise NotImplementedError", "min_run_count": 2, "name": "strings.Methods.time_isalpha", "number": 0, "param_names": ["dtype"], "params": [["'str'", "'string[python]'", "'string[pyarrow]'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "c3059f582e91c8bf23efcb7887a739c1daaa1fd47e2aa200ce0fc57a787cc73e", "warmup_time": -1}, "strings.Methods.time_isdecimal": {"code": "class Methods:\n    def time_isdecimal(self, dtype):\n        self.s.str.isdecimal()\n\nclass Dtypes:\n    def setup(self, dtype):\n        try:\n            self.s = Series(\n                Index([f\"i-{i}\" for i in range(10000)], dtype=object), dtype=dtype\n            )\n        except ImportError:\n            raise NotImplementedError", "min_run_count": 2, "name": "strings.Methods.time_isdecimal", "number": 0, "param_names": ["dtype"], "params": [["'str'", "'string[python]'", "'string[pyarrow]'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "a133eff6a688040348b9aba20d4f3670d2a2abaef3cd4db084d9342aff7619ea", "warmup_time": -1}, "strings.Methods.time_isdigit": {"code": "class Methods:\n    def time_isdigit(self, dtype):\n        self.s.str.isdigit()\n\nclass Dtypes:\n    def setup(self, dtype):\n        try:\n            self.s = Series(\n                Index([f\"i-{i}\" for i in range(10000)], dtype=object), dtype=dtype\n            )\n        except ImportError:\n            raise NotImplementedError", "min_run_count": 2, "name": "strings.Methods.time_isdigit", "number": 0, "param_names": ["dtype"], "params": [["'str'", "'string[python]'", "'string[pyarrow]'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "be7b38fd7589177214ffd988d7c17aa746b2a50b45e68787939c7931e710454a", "warmup_time": -1}, "strings.Methods.time_islower": {"code": "class Methods:\n    def time_islower(self, dtype):\n        self.s.str.islower()\n\nclass Dtypes:\n    def setup(self, dtype):\n        try:\n            self.s = Series(\n                Index([f\"i-{i}\" for i in range(10000)], dtype=object), dtype=dtype\n            )\n        except ImportError:\n            raise NotImplementedError", "min_run_count": 2, "name": "strings.Methods.time_islower", "number": 0, "param_names": ["dtype"], "params": [["'str'", "'string[python]'", "'string[pyarrow]'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "ab894ea2bd6e9ae8f54c400ab2c2afecd14ca1b87692b231e06588722ff98735", "warmup_time": -1}, "strings.Methods.time_isnumeric": {"code": "class Methods:\n    def time_isnumeric(self, dtype):\n        self.s.str.isnumeric()\n\nclass Dtypes:\n    def setup(self, dtype):\n        try:\n            self.s = Series(\n                Index([f\"i-{i}\" for i in range(10000)], dtype=object), dtype=dtype\n            )\n        except ImportError:\n            raise NotImplementedError", "min_run_count": 2, "name": "strings.Methods.time_isnumeric", "number": 0, "param_names": ["dtype"], "params": [["'str'", "'string[python]'", "'string[pyarrow]'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "4b424316398ebde171b9979ff11df865922dc1cd4e52f3ef8ff346a9572dce1d", "warmup_time": -1}, "strings.Methods.time_isspace": {"code": "class Methods:\n    def time_isspace(self, dtype):\n        self.s.str.isspace()\n\nclass Dtypes:\n    def setup(self, dtype):\n        try:\n            self.s = Series(\n                Index([f\"i-{i}\" for i in range(10000)], dtype=object), dtype=dtype\n            )\n        except ImportError:\n            raise NotImplementedError", "min_run_count": 2, "name": "strings.Methods.time_isspace", "number": 0, "param_names": ["dtype"], "params": [["'str'", "'string[python]'", "'string[pyarrow]'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "91c55b8437685223b759f34c4d40517c92f10a57c7e3c025371bb7c7b654cceb", "warmup_time": -1}, "strings.Methods.time_istitle": {"code": "class Methods:\n    def time_istitle(self, dtype):\n        self.s.str.istitle()\n\nclass Dtypes:\n    def setup(self, dtype):\n        try:\n            self.s = Series(\n                Index([f\"i-{i}\" for i in range(10000)], dtype=object), dtype=dtype\n            )\n        except ImportError:\n            raise NotImplementedError", "min_run_count": 2, "name": "strings.Methods.time_istitle", "number": 0, "param_names": ["dtype"], "params": [["'str'", "'string[python]'", "'string[pyarrow]'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "d61e94f9110826d951512379c4dd92ffd72d920cb1411a06797125f198b5e605", "warmup_time": -1}, "strings.Methods.time_isupper": {"code": "class Methods:\n    def time_isupper(self, dtype):\n        self.s.str.isupper()\n\nclass Dtypes:\n    def setup(self, dtype):\n        try:\n            self.s = Series(\n                Index([f\"i-{i}\" for i in range(10000)], dtype=object), dtype=dtype\n            )\n        except ImportError:\n            raise NotImplementedError", "min_run_count": 2, "name": "strings.Methods.time_isupper", "number": 0, "param_names": ["dtype"], "params": [["'str'", "'string[python]'", "'string[pyarrow]'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "e6363383d6598975dd47272aa7f8e254241033f350260923bae071184c6250e7", "warmup_time": -1}, "strings.Methods.time_join": {"code": "class Methods:\n    def time_join(self, dtype):\n        self.s.str.join(\" \")\n\nclass Dtypes:\n    def setup(self, dtype):\n        try:\n            self.s = Series(\n                Index([f\"i-{i}\" for i in range(10000)], dtype=object), dtype=dtype\n            )\n        except ImportError:\n            raise NotImplementedError", "min_run_count": 2, "name": "strings.Methods.time_join", "number": 0, "param_names": ["dtype"], "params": [["'str'", "'string[python]'", "'string[pyarrow]'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "44a4671d9f6112889de2e559ba999c4f4e0ecff99e321d9070fe24aaa68b2589", "warmup_time": -1}, "strings.Methods.time_len": {"code": "class Methods:\n    def time_len(self, dtype):\n        self.s.str.len()\n\nclass Dtypes:\n    def setup(self, dtype):\n        try:\n            self.s = Series(\n                Index([f\"i-{i}\" for i in range(10000)], dtype=object), dtype=dtype\n            )\n        except ImportError:\n            raise NotImplementedError", "min_run_count": 2, "name": "strings.Methods.time_len", "number": 0, "param_names": ["dtype"], "params": [["'str'", "'string[python]'", "'string[pyarrow]'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "ea8d923aad55ca09f05b97d29ffd4931a45a17fc0ec5fb9382ee57a2fa94cedf", "warmup_time": -1}, "strings.Methods.time_lower": {"code": "class Methods:\n    def time_lower(self, dtype):\n        self.s.str.lower()\n\nclass Dtypes:\n    def setup(self, dtype):\n        try:\n            self.s = Series(\n                Index([f\"i-{i}\" for i in range(10000)], dtype=object), dtype=dtype\n            )\n        except ImportError:\n            raise NotImplementedError", "min_run_count": 2, "name": "strings.Methods.time_lower", "number": 0, "param_names": ["dtype"], "params": [["'str'", "'string[python]'", "'string[pyarrow]'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "8f48922b3cf3ea16687833db01e4292c5cd6aa3d9def39ff87f019eb9b0dc815", "warmup_time": -1}, "strings.Methods.time_lstrip": {"code": "class Methods:\n    def time_lstrip(self, dtype):\n        self.s.str.lstrip(\"A\")\n\nclass Dtypes:\n    def setup(self, dtype):\n        try:\n            self.s = Series(\n                Index([f\"i-{i}\" for i in range(10000)], dtype=object), dtype=dtype\n            )\n        except ImportError:\n            raise NotImplementedError", "min_run_count": 2, "name": "strings.Methods.time_lstrip", "number": 0, "param_names": ["dtype"], "params": [["'str'", "'string[python]'", "'string[pyarrow]'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "e3fe88f4068de9a8a08639ffa82b312a72966e55f0591c2d7b8b94fe6e62cd49", "warmup_time": -1}, "strings.Methods.time_match": {"code": "class Methods:\n    def time_match(self, dtype):\n        self.s.str.match(\"A\")\n\nclass Dtypes:\n    def setup(self, dtype):\n        try:\n            self.s = Series(\n                Index([f\"i-{i}\" for i in range(10000)], dtype=object), dtype=dtype\n            )\n        except ImportError:\n            raise NotImplementedError", "min_run_count": 2, "name": "strings.Methods.time_match", "number": 0, "param_names": ["dtype"], "params": [["'str'", "'string[python]'", "'string[pyarrow]'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "f0a4cfd1fc049fde4ab7000a979098280f98886685cd7160c76d1c491bfc604c", "warmup_time": -1}, "strings.Methods.time_normalize": {"code": "class Methods:\n    def time_normalize(self, dtype):\n        self.s.str.normalize(\"NFC\")\n\nclass Dtypes:\n    def setup(self, dtype):\n        try:\n            self.s = Series(\n                Index([f\"i-{i}\" for i in range(10000)], dtype=object), dtype=dtype\n            )\n        except ImportError:\n            raise NotImplementedError", "min_run_count": 2, "name": "strings.Methods.time_normalize", "number": 0, "param_names": ["dtype"], "params": [["'str'", "'string[python]'", "'string[pyarrow]'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "29dba75a422f9de4754775be36f67f81e07932bf7e05d4f1a5f9e6b8089e4a16", "warmup_time": -1}, "strings.Methods.time_pad": {"code": "class Methods:\n    def time_pad(self, dtype):\n        self.s.str.pad(100, side=\"both\")\n\nclass Dtypes:\n    def setup(self, dtype):\n        try:\n            self.s = Series(\n                Index([f\"i-{i}\" for i in range(10000)], dtype=object), dtype=dtype\n            )\n        except ImportError:\n            raise NotImplementedError", "min_run_count": 2, "name": "strings.Methods.time_pad", "number": 0, "param_names": ["dtype"], "params": [["'str'", "'string[python]'", "'string[pyarrow]'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "0ed517828bfc1d1f9530a835c999f7b74767010d7cacb2ddd83be9cab0000f1f", "warmup_time": -1}, "strings.Methods.time_partition": {"code": "class Methods:\n    def time_partition(self, dtype):\n        self.s.str.partition(\"A\")\n\nclass Dtypes:\n    def setup(self, dtype):\n        try:\n            self.s = Series(\n                Index([f\"i-{i}\" for i in range(10000)], dtype=object), dtype=dtype\n            )\n        except ImportError:\n            raise NotImplementedError", "min_run_count": 2, "name": "strings.Methods.time_partition", "number": 0, "param_names": ["dtype"], "params": [["'str'", "'string[python]'", "'string[pyarrow]'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "8b42e493214fb5a4f493a748525ebada3636decce472e69b418e85faf4b89558", "warmup_time": -1}, "strings.Methods.time_replace": {"code": "class Methods:\n    def time_replace(self, dtype):\n        self.s.str.replace(\"A\", \"\\x01\\x01\")\n\nclass Dtypes:\n    def setup(self, dtype):\n        try:\n            self.s = Series(\n                Index([f\"i-{i}\" for i in range(10000)], dtype=object), dtype=dtype\n            )\n        except ImportError:\n            raise NotImplementedError", "min_run_count": 2, "name": "strings.Methods.time_replace", "number": 0, "param_names": ["dtype"], "params": [["'str'", "'string[python]'", "'string[pyarrow]'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "6d9521be03de9cbda3ca02dc90ba4a4092596776e354567ba2995bee12d7d1ee", "warmup_time": -1}, "strings.Methods.time_rfind": {"code": "class Methods:\n    def time_rfind(self, dtype):\n        self.s.str.rfind(\"[A-Z]+\")\n\nclass Dtypes:\n    def setup(self, dtype):\n        try:\n            self.s = Series(\n                Index([f\"i-{i}\" for i in range(10000)], dtype=object), dtype=dtype\n            )\n        except ImportError:\n            raise NotImplementedError", "min_run_count": 2, "name": "strings.Methods.time_rfind", "number": 0, "param_names": ["dtype"], "params": [["'str'", "'string[python]'", "'string[pyarrow]'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "afd7bc4f21c75d4f193ea4e61c7962ced58c6f61f4677fd842d778293a3e26d7", "warmup_time": -1}, "strings.Methods.time_rpartition": {"code": "class Methods:\n    def time_rpartition(self, dtype):\n        self.s.str.rpartition(\"A\")\n\nclass Dtypes:\n    def setup(self, dtype):\n        try:\n            self.s = Series(\n                Index([f\"i-{i}\" for i in range(10000)], dtype=object), dtype=dtype\n            )\n        except ImportError:\n            raise NotImplementedError", "min_run_count": 2, "name": "strings.Methods.time_rpartition", "number": 0, "param_names": ["dtype"], "params": [["'str'", "'string[python]'", "'string[pyarrow]'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "c3f8a7d1956fb8faa413fe1175b96d456670abb0b17b249a0aee92c3e28cfa93", "warmup_time": -1}, "strings.Methods.time_rstrip": {"code": "class Methods:\n    def time_rstrip(self, dtype):\n        self.s.str.rstrip(\"A\")\n\nclass Dtypes:\n    def setup(self, dtype):\n        try:\n            self.s = Series(\n                Index([f\"i-{i}\" for i in range(10000)], dtype=object), dtype=dtype\n            )\n        except ImportError:\n            raise NotImplementedError", "min_run_count": 2, "name": "strings.Methods.time_rstrip", "number": 0, "param_names": ["dtype"], "params": [["'str'", "'string[python]'", "'string[pyarrow]'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "c038afd010967ecd36eeeef78d1b1b57370d78c8b68c2b27d540d69b9b8b7d37", "warmup_time": -1}, "strings.Methods.time_slice": {"code": "class Methods:\n    def time_slice(self, dtype):\n        self.s.str.slice(5, 15, 2)\n\nclass Dtypes:\n    def setup(self, dtype):\n        try:\n            self.s = Series(\n                Index([f\"i-{i}\" for i in range(10000)], dtype=object), dtype=dtype\n            )\n        except ImportError:\n            raise NotImplementedError", "min_run_count": 2, "name": "strings.Methods.time_slice", "number": 0, "param_names": ["dtype"], "params": [["'str'", "'string[python]'", "'string[pyarrow]'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "44f206d3f7075b4d422efe68ace7bc9f652f62028e9d505a189001f473363fc9", "warmup_time": -1}, "strings.Methods.time_startswith": {"code": "class Methods:\n    def time_startswith(self, dtype):\n        self.s.str.startswith(\"A\")\n\nclass Dtypes:\n    def setup(self, dtype):\n        try:\n            self.s = Series(\n                Index([f\"i-{i}\" for i in range(10000)], dtype=object), dtype=dtype\n            )\n        except ImportError:\n            raise NotImplementedError", "min_run_count": 2, "name": "strings.Methods.time_startswith", "number": 0, "param_names": ["dtype"], "params": [["'str'", "'string[python]'", "'string[pyarrow]'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "82e1e20fa825548b6c487a1fa2080d4be63dfac832146f35dcfa863cf8950394", "warmup_time": -1}, "strings.Methods.time_strip": {"code": "class Methods:\n    def time_strip(self, dtype):\n        self.s.str.strip(\"A\")\n\nclass Dtypes:\n    def setup(self, dtype):\n        try:\n            self.s = Series(\n                Index([f\"i-{i}\" for i in range(10000)], dtype=object), dtype=dtype\n            )\n        except ImportError:\n            raise NotImplementedError", "min_run_count": 2, "name": "strings.Methods.time_strip", "number": 0, "param_names": ["dtype"], "params": [["'str'", "'string[python]'", "'string[pyarrow]'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "f7662c7c2e02b24369d2b3a10debc1129bb7ce0710d269faeecccdd6cd1a5606", "warmup_time": -1}, "strings.Methods.time_title": {"code": "class Methods:\n    def time_title(self, dtype):\n        self.s.str.title()\n\nclass Dtypes:\n    def setup(self, dtype):\n        try:\n            self.s = Series(\n                Index([f\"i-{i}\" for i in range(10000)], dtype=object), dtype=dtype\n            )\n        except ImportError:\n            raise NotImplementedError", "min_run_count": 2, "name": "strings.Methods.time_title", "number": 0, "param_names": ["dtype"], "params": [["'str'", "'string[python]'", "'string[pyarrow]'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "3115e0ecefb832faff640ce4eaca40a457501d8c6952fc5a88302cc3cb150d4b", "warmup_time": -1}, "strings.Methods.time_translate": {"code": "class Methods:\n    def time_translate(self, dtype):\n        self.s.str.translate({\"A\": \"\\x01\\x01\"})\n\nclass Dtypes:\n    def setup(self, dtype):\n        try:\n            self.s = Series(\n                Index([f\"i-{i}\" for i in range(10000)], dtype=object), dtype=dtype\n            )\n        except ImportError:\n            raise NotImplementedError", "min_run_count": 2, "name": "strings.Methods.time_translate", "number": 0, "param_names": ["dtype"], "params": [["'str'", "'string[python]'", "'string[pyarrow]'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "59be23979bc496796c806d572f9d8613eb9798e0d916e0750d9cce1e1852ca80", "warmup_time": -1}, "strings.Methods.time_upper": {"code": "class Methods:\n    def time_upper(self, dtype):\n        self.s.str.upper()\n\nclass Dtypes:\n    def setup(self, dtype):\n        try:\n            self.s = Series(\n                Index([f\"i-{i}\" for i in range(10000)], dtype=object), dtype=dtype\n            )\n        except ImportError:\n            raise NotImplementedError", "min_run_count": 2, "name": "strings.Methods.time_upper", "number": 0, "param_names": ["dtype"], "params": [["'str'", "'string[python]'", "'string[pyarrow]'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "5cdf1e831d11033104be23c2ced3a557ac3ac02d18e1aec8fe722583ba79e1e4", "warmup_time": -1}, "strings.Methods.time_wrap": {"code": "class Methods:\n    def time_wrap(self, dtype):\n        self.s.str.wrap(10)\n\nclass Dtypes:\n    def setup(self, dtype):\n        try:\n            self.s = Series(\n                Index([f\"i-{i}\" for i in range(10000)], dtype=object), dtype=dtype\n            )\n        except ImportError:\n            raise NotImplementedError", "min_run_count": 2, "name": "strings.Methods.time_wrap", "number": 0, "param_names": ["dtype"], "params": [["'str'", "'string[python]'", "'string[pyarrow]'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "30e3970dc4e43400103591fdf927378eacd6fe915ba4a166be9a959f9eab9bae", "warmup_time": -1}, "strings.Methods.time_zfill": {"code": "class Methods:\n    def time_zfill(self, dtype):\n        self.s.str.zfill(10)\n\nclass Dtypes:\n    def setup(self, dtype):\n        try:\n            self.s = Series(\n                Index([f\"i-{i}\" for i in range(10000)], dtype=object), dtype=dtype\n            )\n        except ImportError:\n            raise NotImplementedError", "min_run_count": 2, "name": "strings.Methods.time_zfill", "number": 0, "param_names": ["dtype"], "params": [["'str'", "'string[python]'", "'string[pyarrow]'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "ad3580c210bab66f2ab1f2270e61ea15de12f65e1958203fdbe4ee1b3153a1ea", "warmup_time": -1}, "strings.Repeat.time_repeat": {"code": "class Repeat:\n    def time_repeat(self, repeats):\n        self.s.str.repeat(self.values)\n\n    def setup(self, repeats):\n        N = 10**5\n        self.s = Series(Index([f\"i-{i}\" for i in range(N)], dtype=object))\n        repeat = {\"int\": 1, \"array\": np.random.randint(1, 3, N)}\n        self.values = repeat[repeats]", "min_run_count": 2, "name": "strings.Repeat.time_repeat", "number": 0, "param_names": ["repeats"], "params": [["'int'", "'array'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "1020d0debc1446a71cfda9efe059407dc390e74d806d2783566fdba4e7d1de98", "warmup_time": -1}, "strings.Slice.time_vector_slice": {"code": "class Slice:\n    def time_vector_slice(self):\n        # GH 2602\n        self.s.str[:5]\n\n    def setup(self):\n        self.s = Series([\"abcdefg\", np.nan] * 500000)", "min_run_count": 2, "name": "strings.Slice.time_vector_slice", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "aaf1ec9c90cc2539c76cae9af1c26b6b5ffb1d0311ec7d6dafe7d228d106ef86", "warmup_time": -1}, "strings.Split.time_rsplit": {"code": "class Split:\n    def time_rsplit(self, dtype, expand):\n        self.s.str.rsplit(\"--\", expand=expand)\n\n    def setup(self, dtype, expand):\n        super().setup(dtype)\n        self.s = self.s.str.join(\"--\")", "min_run_count": 2, "name": "strings.Split.time_rsplit", "number": 0, "param_names": ["dtype", "expand"], "params": [["'str'", "'string[python]'", "'string[pyarrow]'"], ["True", "False"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "c748bf724293b4083adf3d91ce7a5255043bddcd7ecaba38777cac47767ad1f0", "warmup_time": -1}, "strings.Split.time_split": {"code": "class Split:\n    def time_split(self, dtype, expand):\n        self.s.str.split(\"--\", expand=expand)\n\n    def setup(self, dtype, expand):\n        super().setup(dtype)\n        self.s = self.s.str.join(\"--\")", "min_run_count": 2, "name": "strings.Split.time_split", "number": 0, "param_names": ["dtype", "expand"], "params": [["'str'", "'string[python]'", "'string[pyarrow]'"], ["True", "False"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "abecb3cbc4195a6fedc3bc41353ecd447d36060b1cd5e43944cda06edfa8a2e6", "warmup_time": -1}, "strings.StringArrayConstruction.peakmem_stringarray_construction": {"code": "class StringArrayConstruction:\n    def peakmem_stringarray_construction(self):\n        StringArray(self.series_arr)\n\n    def setup(self):\n        self.series_arr = np.array([str(i) * 10 for i in range(10**5)], dtype=object)\n        self.series_arr_nan = np.concatenate([self.series_arr, np.array([NA] * 1000)])", "name": "strings.StringArrayConstruction.peakmem_stringarray_construction", "param_names": [], "params": [], "timeout": 60.0, "type": "peakmemory", "unit": "bytes", "version": "1644a62bd4fef4c7214ab6a613fb523651eb795bdc0eca8bafc1bceb6af4bc8d"}, "strings.StringArrayConstruction.time_string_array_construction": {"code": "class StringArrayConstruction:\n    def time_string_array_construction(self):\n        StringArray(self.series_arr)\n\n    def setup(self):\n        self.series_arr = np.array([str(i) * 10 for i in range(10**5)], dtype=object)\n        self.series_arr_nan = np.concatenate([self.series_arr, np.array([NA] * 1000)])", "min_run_count": 2, "name": "strings.StringArrayConstruction.time_string_array_construction", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "4ded60d6eacf6b7203c61d538380497e0dd86ed15910c739819f0c18299357a4", "warmup_time": -1}, "strings.StringArrayConstruction.time_string_array_with_nan_construction": {"code": "class StringArrayConstruction:\n    def time_string_array_with_nan_construction(self):\n        StringArray(self.series_arr_nan)\n\n    def setup(self):\n        self.series_arr = np.array([str(i) * 10 for i in range(10**5)], dtype=object)\n        self.series_arr_nan = np.concatenate([self.series_arr, np.array([NA] * 1000)])", "min_run_count": 2, "name": "strings.StringArrayConstruction.time_string_array_with_nan_construction", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "c7ef4a3758ceb79e8124d016a878c5be0d6bf37399e516da63b10e21cb3fc1d5", "warmup_time": -1}, "timedelta.DatetimeAccessor.time_dt_accessor": {"code": "class DatetimeAccessor:\n    def time_dt_accessor(self, series):\n        series.dt\n\n    def setup_cache(self):\n        N = 100000\n        series = Series(timedelta_range(\"1 days\", periods=N, freq=\"h\"))\n        return series", "min_run_count": 2, "name": "timedelta.DatetimeAccessor.time_dt_accessor", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "setup_cache_key": "timedelta:14", "timeout": 60.0, "type": "time", "unit": "seconds", "version": "56ad9655f66a0485943ce9ca9547af9c97e48f5b12779c60896c3147c5422526", "warmup_time": -1}, "timedelta.DatetimeAccessor.time_timedelta_days": {"code": "class DatetimeAccessor:\n    def time_timedelta_days(self, series):\n        series.dt.days\n\n    def setup_cache(self):\n        N = 100000\n        series = Series(timedelta_range(\"1 days\", periods=N, freq=\"h\"))\n        return series", "min_run_count": 2, "name": "timedelta.DatetimeAccessor.time_timedelta_days", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "setup_cache_key": "timedelta:14", "timeout": 60.0, "type": "time", "unit": "seconds", "version": "06c603c515e826893772c4d64fe4de8ff76367d3c422060262604d4917fbec03", "warmup_time": -1}, "timedelta.DatetimeAccessor.time_timedelta_microseconds": {"code": "class DatetimeAccessor:\n    def time_timedelta_microseconds(self, series):\n        series.dt.microseconds\n\n    def setup_cache(self):\n        N = 100000\n        series = Series(timedelta_range(\"1 days\", periods=N, freq=\"h\"))\n        return series", "min_run_count": 2, "name": "timedelta.DatetimeAccessor.time_timedelta_microseconds", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "setup_cache_key": "timedelta:14", "timeout": 60.0, "type": "time", "unit": "seconds", "version": "6504e61d63ba227783a76d2cab32c1d791b1af813406a8c384fc386ca60b1898", "warmup_time": -1}, "timedelta.DatetimeAccessor.time_timedelta_nanoseconds": {"code": "class DatetimeAccessor:\n    def time_timedelta_nanoseconds(self, series):\n        series.dt.nanoseconds\n\n    def setup_cache(self):\n        N = 100000\n        series = Series(timedelta_range(\"1 days\", periods=N, freq=\"h\"))\n        return series", "min_run_count": 2, "name": "timedelta.DatetimeAccessor.time_timedelta_nanoseconds", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "setup_cache_key": "timedelta:14", "timeout": 60.0, "type": "time", "unit": "seconds", "version": "c1cc39aec7c93cb50ced4bf81ec26506de8bfddaaee6968142c0c018f91e296a", "warmup_time": -1}, "timedelta.DatetimeAccessor.time_timedelta_seconds": {"code": "class DatetimeAccessor:\n    def time_timedelta_seconds(self, series):\n        series.dt.seconds\n\n    def setup_cache(self):\n        N = 100000\n        series = Series(timedelta_range(\"1 days\", periods=N, freq=\"h\"))\n        return series", "min_run_count": 2, "name": "timedelta.DatetimeAccessor.time_timedelta_seconds", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "setup_cache_key": "timedelta:14", "timeout": 60.0, "type": "time", "unit": "seconds", "version": "0514e9978f000e47c609125255de6d9536aed804334d426a9222e1347183702d", "warmup_time": -1}, "timedelta.TimedeltaIndexing.time_align": {"code": "class TimedeltaIndexing:\n    def time_align(self):\n        DataFrame({\"a\": self.series, \"b\": self.series[:500]})\n\n    def setup(self):\n        self.index = timedelta_range(start=\"1985\", periods=1000, freq=\"D\")\n        self.index2 = timedelta_range(start=\"1986\", periods=1000, freq=\"D\")\n        self.series = Series(range(1000), index=self.index)\n        self.timedelta = self.index[500]", "min_run_count": 2, "name": "timedelta.TimedeltaIndexing.time_align", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "f5833d39497fb06bb05cac21fd9feeebace738d8e1cb626bea9fb0bbd86049ce", "warmup_time": -1}, "timedelta.TimedeltaIndexing.time_get_loc": {"code": "class TimedeltaIndexing:\n    def time_get_loc(self):\n        self.index.get_loc(self.timedelta)\n\n    def setup(self):\n        self.index = timedelta_range(start=\"1985\", periods=1000, freq=\"D\")\n        self.index2 = timedelta_range(start=\"1986\", periods=1000, freq=\"D\")\n        self.series = Series(range(1000), index=self.index)\n        self.timedelta = self.index[500]", "min_run_count": 2, "name": "timedelta.TimedeltaIndexing.time_get_loc", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "25e9df433acdb6dcf3c1df99f789a41f9c774fba04d175a24c5b8688dad9a7f3", "warmup_time": -1}, "timedelta.TimedeltaIndexing.time_intersection": {"code": "class TimedeltaIndexing:\n    def time_intersection(self):\n        self.index.intersection(self.index2)\n\n    def setup(self):\n        self.index = timedelta_range(start=\"1985\", periods=1000, freq=\"D\")\n        self.index2 = timedelta_range(start=\"1986\", periods=1000, freq=\"D\")\n        self.series = Series(range(1000), index=self.index)\n        self.timedelta = self.index[500]", "min_run_count": 2, "name": "timedelta.TimedeltaIndexing.time_intersection", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "c3f027dc76eb6a9ef0eff1bc06dd59ee562b54fbdb029d2a6a6c4865601424c1", "warmup_time": -1}, "timedelta.TimedeltaIndexing.time_series_loc": {"code": "class TimedeltaIndexing:\n    def time_series_loc(self):\n        self.series.loc[self.timedelta]\n\n    def setup(self):\n        self.index = timedelta_range(start=\"1985\", periods=1000, freq=\"D\")\n        self.index2 = timedelta_range(start=\"1986\", periods=1000, freq=\"D\")\n        self.series = Series(range(1000), index=self.index)\n        self.timedelta = self.index[500]", "min_run_count": 2, "name": "timedelta.TimedeltaIndexing.time_series_loc", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "5902b5b4b32fc27d85bee9808b6014b1f9664e7f28f444e498a7d04083c92e05", "warmup_time": -1}, "timedelta.TimedeltaIndexing.time_shallow_copy": {"code": "class TimedeltaIndexing:\n    def time_shallow_copy(self):\n        self.index._view()\n\n    def setup(self):\n        self.index = timedelta_range(start=\"1985\", periods=1000, freq=\"D\")\n        self.index2 = timedelta_range(start=\"1986\", periods=1000, freq=\"D\")\n        self.series = Series(range(1000), index=self.index)\n        self.timedelta = self.index[500]", "min_run_count": 2, "name": "timedelta.TimedeltaIndexing.time_shallow_copy", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "fae422a896cb1cff9173dd94eb799be107e0957d5845004660eed3d30e0540ba", "warmup_time": -1}, "timedelta.TimedeltaIndexing.time_union": {"code": "class TimedeltaIndexing:\n    def time_union(self):\n        self.index.union(self.index2)\n\n    def setup(self):\n        self.index = timedelta_range(start=\"1985\", periods=1000, freq=\"D\")\n        self.index2 = timedelta_range(start=\"1986\", periods=1000, freq=\"D\")\n        self.series = Series(range(1000), index=self.index)\n        self.timedelta = self.index[500]", "min_run_count": 2, "name": "timedelta.TimedeltaIndexing.time_union", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "266034126c423f3e411bf2195dc68cd983b6a181466b383df54ba9341232ad71", "warmup_time": -1}, "timedelta.TimedeltaIndexing.time_unique": {"code": "class TimedeltaIndexing:\n    def time_unique(self):\n        self.index.unique()\n\n    def setup(self):\n        self.index = timedelta_range(start=\"1985\", periods=1000, freq=\"D\")\n        self.index2 = timedelta_range(start=\"1986\", periods=1000, freq=\"D\")\n        self.series = Series(range(1000), index=self.index)\n        self.timedelta = self.index[500]", "min_run_count": 2, "name": "timedelta.TimedeltaIndexing.time_unique", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "17ea4667001a64a4f9df8c9594ca120a6491a18edd28102cd5712c88535ac416", "warmup_time": -1}, "timeseries.AsOf.time_asof": {"code": "class AsOf:\n    def time_asof(self, constructor):\n        self.ts.asof(self.dates)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass AsOf:\n    def setup(self, constructor):\n        N = 10000\n        M = 10\n        rng = date_range(start=\"1/1/1990\", periods=N, freq=\"53s\")\n        data = {\n            \"DataFrame\": DataFrame(np.random.randn(N, M)),\n            \"Series\": Series(np.random.randn(N)),\n        }\n        self.ts = data[constructor]\n        self.ts.index = rng\n        self.ts2 = self.ts.copy()\n        self.ts2.iloc[250:5000] = np.nan\n        self.ts3 = self.ts.copy()\n        self.ts3.iloc[-5000:] = np.nan\n        self.dates = date_range(start=\"1/1/1990\", periods=N * 10, freq=\"5s\")\n        self.date = self.dates[0]\n        self.date_last = self.dates[-1]\n        self.date_early = self.date - timedelta(10)", "min_run_count": 2, "name": "timeseries.AsOf.time_asof", "number": 0, "param_names": ["constructor"], "params": [["'DataFrame'", "'Series'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "37bd4ce5386fd0b7c34272d255acd943468380376dc1ee5dd9dea070fb806805", "warmup_time": -1}, "timeseries.AsOf.time_asof_nan": {"code": "class AsOf:\n    def time_asof_nan(self, constructor):\n        self.ts2.asof(self.dates)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass AsOf:\n    def setup(self, constructor):\n        N = 10000\n        M = 10\n        rng = date_range(start=\"1/1/1990\", periods=N, freq=\"53s\")\n        data = {\n            \"DataFrame\": DataFrame(np.random.randn(N, M)),\n            \"Series\": Series(np.random.randn(N)),\n        }\n        self.ts = data[constructor]\n        self.ts.index = rng\n        self.ts2 = self.ts.copy()\n        self.ts2.iloc[250:5000] = np.nan\n        self.ts3 = self.ts.copy()\n        self.ts3.iloc[-5000:] = np.nan\n        self.dates = date_range(start=\"1/1/1990\", periods=N * 10, freq=\"5s\")\n        self.date = self.dates[0]\n        self.date_last = self.dates[-1]\n        self.date_early = self.date - timedelta(10)", "min_run_count": 2, "name": "timeseries.AsOf.time_asof_nan", "number": 0, "param_names": ["constructor"], "params": [["'DataFrame'", "'Series'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "501dd990a898123eb091528ad6846c32abada27e5834f83a86729b32c4a0bcde", "warmup_time": -1}, "timeseries.AsOf.time_asof_nan_single": {"code": "class AsOf:\n    def time_asof_nan_single(self, constructor):\n        self.ts3.asof(self.date_last)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass AsOf:\n    def setup(self, constructor):\n        N = 10000\n        M = 10\n        rng = date_range(start=\"1/1/1990\", periods=N, freq=\"53s\")\n        data = {\n            \"DataFrame\": DataFrame(np.random.randn(N, M)),\n            \"Series\": Series(np.random.randn(N)),\n        }\n        self.ts = data[constructor]\n        self.ts.index = rng\n        self.ts2 = self.ts.copy()\n        self.ts2.iloc[250:5000] = np.nan\n        self.ts3 = self.ts.copy()\n        self.ts3.iloc[-5000:] = np.nan\n        self.dates = date_range(start=\"1/1/1990\", periods=N * 10, freq=\"5s\")\n        self.date = self.dates[0]\n        self.date_last = self.dates[-1]\n        self.date_early = self.date - timedelta(10)", "min_run_count": 2, "name": "timeseries.AsOf.time_asof_nan_single", "number": 0, "param_names": ["constructor"], "params": [["'DataFrame'", "'Series'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "5607d6a56f2adf8c34116da998623d2111a97c21c45c0d1287f625a3ecda0055", "warmup_time": -1}, "timeseries.AsOf.time_asof_single": {"code": "class AsOf:\n    def time_asof_single(self, constructor):\n        self.ts.asof(self.date)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass AsOf:\n    def setup(self, constructor):\n        N = 10000\n        M = 10\n        rng = date_range(start=\"1/1/1990\", periods=N, freq=\"53s\")\n        data = {\n            \"DataFrame\": DataFrame(np.random.randn(N, M)),\n            \"Series\": Series(np.random.randn(N)),\n        }\n        self.ts = data[constructor]\n        self.ts.index = rng\n        self.ts2 = self.ts.copy()\n        self.ts2.iloc[250:5000] = np.nan\n        self.ts3 = self.ts.copy()\n        self.ts3.iloc[-5000:] = np.nan\n        self.dates = date_range(start=\"1/1/1990\", periods=N * 10, freq=\"5s\")\n        self.date = self.dates[0]\n        self.date_last = self.dates[-1]\n        self.date_early = self.date - timedelta(10)", "min_run_count": 2, "name": "timeseries.AsOf.time_asof_single", "number": 0, "param_names": ["constructor"], "params": [["'DataFrame'", "'Series'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "afe0b338280acc8cfed3251b3ee2abf5e165c63fe746d8032f062675bf9021ac", "warmup_time": -1}, "timeseries.AsOf.time_asof_single_early": {"code": "class AsOf:\n    def time_asof_single_early(self, constructor):\n        self.ts.asof(self.date_early)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass AsOf:\n    def setup(self, constructor):\n        N = 10000\n        M = 10\n        rng = date_range(start=\"1/1/1990\", periods=N, freq=\"53s\")\n        data = {\n            \"DataFrame\": DataFrame(np.random.randn(N, M)),\n            \"Series\": Series(np.random.randn(N)),\n        }\n        self.ts = data[constructor]\n        self.ts.index = rng\n        self.ts2 = self.ts.copy()\n        self.ts2.iloc[250:5000] = np.nan\n        self.ts3 = self.ts.copy()\n        self.ts3.iloc[-5000:] = np.nan\n        self.dates = date_range(start=\"1/1/1990\", periods=N * 10, freq=\"5s\")\n        self.date = self.dates[0]\n        self.date_last = self.dates[-1]\n        self.date_early = self.date - timedelta(10)", "min_run_count": 2, "name": "timeseries.AsOf.time_asof_single_early", "number": 0, "param_names": ["constructor"], "params": [["'DataFrame'", "'Series'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "2ce4002d656f7b5513c14e1e36605c59ff9c7a0c53ce76a87dc70c83c7052b1c", "warmup_time": -1}, "timeseries.DatetimeAccessor.time_dt_accessor": {"code": "class DatetimeAccessor:\n    def time_dt_accessor(self, tz):\n        self.series.dt\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass DatetimeAccessor:\n    def setup(self, tz):\n        N = 100000\n        self.series = Series(date_range(start=\"1/1/2000\", periods=N, freq=\"min\", tz=tz))", "min_run_count": 2, "name": "timeseries.DatetimeAccessor.time_dt_accessor", "number": 0, "param_names": ["t"], "params": [["None", "'US/Eastern'", "'UTC'", "tzutc()"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "c4654d6ecec4d6eb77017231cdf50af038043ea4902f77696dfe07ccf474acbd", "warmup_time": -1}, "timeseries.DatetimeAccessor.time_dt_accessor_date": {"code": "class DatetimeAccessor:\n    def time_dt_accessor_date(self, tz):\n        self.series.dt.date\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass DatetimeAccessor:\n    def setup(self, tz):\n        N = 100000\n        self.series = Series(date_range(start=\"1/1/2000\", periods=N, freq=\"min\", tz=tz))", "min_run_count": 2, "name": "timeseries.DatetimeAccessor.time_dt_accessor_date", "number": 0, "param_names": ["t"], "params": [["None", "'US/Eastern'", "'UTC'", "tzutc()"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "094be7aa69f4d56549e49c066b297e49081304a97ea4b4099a49b4dc4bd7a42b", "warmup_time": -1}, "timeseries.DatetimeAccessor.time_dt_accessor_day_name": {"code": "class DatetimeAccessor:\n    def time_dt_accessor_day_name(self, tz):\n        self.series.dt.day_name()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass DatetimeAccessor:\n    def setup(self, tz):\n        N = 100000\n        self.series = Series(date_range(start=\"1/1/2000\", periods=N, freq=\"min\", tz=tz))", "min_run_count": 2, "name": "timeseries.DatetimeAccessor.time_dt_accessor_day_name", "number": 0, "param_names": ["t"], "params": [["None", "'US/Eastern'", "'UTC'", "tzutc()"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "df76b5c41131ea1ca919a20e8df2e83bba306d899e8870b93f5d9384ce80faa1", "warmup_time": -1}, "timeseries.DatetimeAccessor.time_dt_accessor_month_name": {"code": "class DatetimeAccessor:\n    def time_dt_accessor_month_name(self, tz):\n        self.series.dt.month_name()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass DatetimeAccessor:\n    def setup(self, tz):\n        N = 100000\n        self.series = Series(date_range(start=\"1/1/2000\", periods=N, freq=\"min\", tz=tz))", "min_run_count": 2, "name": "timeseries.DatetimeAccessor.time_dt_accessor_month_name", "number": 0, "param_names": ["t"], "params": [["None", "'US/Eastern'", "'UTC'", "tzutc()"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "9b5673999481df055b0f075354fdf3e35bd5b1607adbe41ebe9f93f1ade8fbc4", "warmup_time": -1}, "timeseries.DatetimeAccessor.time_dt_accessor_normalize": {"code": "class DatetimeAccessor:\n    def time_dt_accessor_normalize(self, tz):\n        self.series.dt.normalize()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass DatetimeAccessor:\n    def setup(self, tz):\n        N = 100000\n        self.series = Series(date_range(start=\"1/1/2000\", periods=N, freq=\"min\", tz=tz))", "min_run_count": 2, "name": "timeseries.DatetimeAccessor.time_dt_accessor_normalize", "number": 0, "param_names": ["t"], "params": [["None", "'US/Eastern'", "'UTC'", "tzutc()"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "f72f5ac1e6051cfb422cd5c2e7d24d223f12e59d0e999c03edad788b7a625078", "warmup_time": -1}, "timeseries.DatetimeAccessor.time_dt_accessor_time": {"code": "class DatetimeAccessor:\n    def time_dt_accessor_time(self, tz):\n        self.series.dt.time\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass DatetimeAccessor:\n    def setup(self, tz):\n        N = 100000\n        self.series = Series(date_range(start=\"1/1/2000\", periods=N, freq=\"min\", tz=tz))", "min_run_count": 2, "name": "timeseries.DatetimeAccessor.time_dt_accessor_time", "number": 0, "param_names": ["t"], "params": [["None", "'US/Eastern'", "'UTC'", "tzutc()"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "7f9eb32f2fbf8aee4af73e69833ddc753487025f72b66b7880110bb5a972edc1", "warmup_time": -1}, "timeseries.DatetimeAccessor.time_dt_accessor_year": {"code": "class DatetimeAccessor:\n    def time_dt_accessor_year(self, tz):\n        self.series.dt.year\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass DatetimeAccessor:\n    def setup(self, tz):\n        N = 100000\n        self.series = Series(date_range(start=\"1/1/2000\", periods=N, freq=\"min\", tz=tz))", "min_run_count": 2, "name": "timeseries.DatetimeAccessor.time_dt_accessor_year", "number": 0, "param_names": ["t"], "params": [["None", "'US/Eastern'", "'UTC'", "tzutc()"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "cc33ec3abfe516cac3685bdca04c77540a7b773f1f8ac33dbbea439353070373", "warmup_time": -1}, "timeseries.DatetimeIndex.time_add_timedelta": {"code": "class DatetimeIndex:\n    def time_add_timedelta(self, index_type):\n        self.index + timedelta(minutes=2)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass DatetimeIndex:\n    def setup(self, index_type):\n        N = 100000\n        dtidxes = {\n            \"dst\": date_range(\n                start=\"10/29/2000 1:00:00\", end=\"10/29/2000 1:59:59\", freq=\"s\"\n            ),\n            \"repeated\": date_range(start=\"2000\", periods=N / 10, freq=\"s\").repeat(10),\n            \"tz_aware\": date_range(start=\"2000\", periods=N, freq=\"s\", tz=\"US/Eastern\"),\n            \"tz_local\": date_range(\n                start=\"2000\", periods=N, freq=\"s\", tz=dateutil.tz.tzlocal()\n            ),\n            \"tz_naive\": date_range(start=\"2000\", periods=N, freq=\"s\"),\n        }\n        self.index = dtidxes[index_type]", "min_run_count": 2, "name": "timeseries.DatetimeIndex.time_add_timedelta", "number": 0, "param_names": ["index_type"], "params": [["'dst'", "'repeated'", "'tz_aware'", "'tz_local'", "'tz_naive'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "e5692bb426e02b8f7225293c6fb331beec6966fb1e0f2d821ea9a4bbe1731ef6", "warmup_time": -1}, "timeseries.DatetimeIndex.time_get": {"code": "class DatetimeIndex:\n    def time_get(self, index_type):\n        self.index[0]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass DatetimeIndex:\n    def setup(self, index_type):\n        N = 100000\n        dtidxes = {\n            \"dst\": date_range(\n                start=\"10/29/2000 1:00:00\", end=\"10/29/2000 1:59:59\", freq=\"s\"\n            ),\n            \"repeated\": date_range(start=\"2000\", periods=N / 10, freq=\"s\").repeat(10),\n            \"tz_aware\": date_range(start=\"2000\", periods=N, freq=\"s\", tz=\"US/Eastern\"),\n            \"tz_local\": date_range(\n                start=\"2000\", periods=N, freq=\"s\", tz=dateutil.tz.tzlocal()\n            ),\n            \"tz_naive\": date_range(start=\"2000\", periods=N, freq=\"s\"),\n        }\n        self.index = dtidxes[index_type]", "min_run_count": 2, "name": "timeseries.DatetimeIndex.time_get", "number": 0, "param_names": ["index_type"], "params": [["'dst'", "'repeated'", "'tz_aware'", "'tz_local'", "'tz_naive'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "c23b9b6d9ac66c20f7f4329018bc00d6460788d6c4e40f14766f5693346d4775", "warmup_time": -1}, "timeseries.DatetimeIndex.time_is_dates_only": {"code": "class DatetimeIndex:\n    def time_is_dates_only(self, index_type):\n        self.index._is_dates_only\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass DatetimeIndex:\n    def setup(self, index_type):\n        N = 100000\n        dtidxes = {\n            \"dst\": date_range(\n                start=\"10/29/2000 1:00:00\", end=\"10/29/2000 1:59:59\", freq=\"s\"\n            ),\n            \"repeated\": date_range(start=\"2000\", periods=N / 10, freq=\"s\").repeat(10),\n            \"tz_aware\": date_range(start=\"2000\", periods=N, freq=\"s\", tz=\"US/Eastern\"),\n            \"tz_local\": date_range(\n                start=\"2000\", periods=N, freq=\"s\", tz=dateutil.tz.tzlocal()\n            ),\n            \"tz_naive\": date_range(start=\"2000\", periods=N, freq=\"s\"),\n        }\n        self.index = dtidxes[index_type]", "min_run_count": 2, "name": "timeseries.DatetimeIndex.time_is_dates_only", "number": 0, "param_names": ["index_type"], "params": [["'dst'", "'repeated'", "'tz_aware'", "'tz_local'", "'tz_naive'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "c56fe60c5b00ce500e2bd3b47251a958c309561d16bdc9d48b48acaa071aa834", "warmup_time": -1}, "timeseries.DatetimeIndex.time_normalize": {"code": "class DatetimeIndex:\n    def time_normalize(self, index_type):\n        self.index.normalize()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass DatetimeIndex:\n    def setup(self, index_type):\n        N = 100000\n        dtidxes = {\n            \"dst\": date_range(\n                start=\"10/29/2000 1:00:00\", end=\"10/29/2000 1:59:59\", freq=\"s\"\n            ),\n            \"repeated\": date_range(start=\"2000\", periods=N / 10, freq=\"s\").repeat(10),\n            \"tz_aware\": date_range(start=\"2000\", periods=N, freq=\"s\", tz=\"US/Eastern\"),\n            \"tz_local\": date_range(\n                start=\"2000\", periods=N, freq=\"s\", tz=dateutil.tz.tzlocal()\n            ),\n            \"tz_naive\": date_range(start=\"2000\", periods=N, freq=\"s\"),\n        }\n        self.index = dtidxes[index_type]", "min_run_count": 2, "name": "timeseries.DatetimeIndex.time_normalize", "number": 0, "param_names": ["index_type"], "params": [["'dst'", "'repeated'", "'tz_aware'", "'tz_local'", "'tz_naive'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "bd3fab7ff72ce5154da23a14d534dc87453aadffc9336df13921c627d636efbd", "warmup_time": -1}, "timeseries.DatetimeIndex.time_timeseries_is_month_start": {"code": "class DatetimeIndex:\n    def time_timeseries_is_month_start(self, index_type):\n        self.index.is_month_start\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass DatetimeIndex:\n    def setup(self, index_type):\n        N = 100000\n        dtidxes = {\n            \"dst\": date_range(\n                start=\"10/29/2000 1:00:00\", end=\"10/29/2000 1:59:59\", freq=\"s\"\n            ),\n            \"repeated\": date_range(start=\"2000\", periods=N / 10, freq=\"s\").repeat(10),\n            \"tz_aware\": date_range(start=\"2000\", periods=N, freq=\"s\", tz=\"US/Eastern\"),\n            \"tz_local\": date_range(\n                start=\"2000\", periods=N, freq=\"s\", tz=dateutil.tz.tzlocal()\n            ),\n            \"tz_naive\": date_range(start=\"2000\", periods=N, freq=\"s\"),\n        }\n        self.index = dtidxes[index_type]", "min_run_count": 2, "name": "timeseries.DatetimeIndex.time_timeseries_is_month_start", "number": 0, "param_names": ["index_type"], "params": [["'dst'", "'repeated'", "'tz_aware'", "'tz_local'", "'tz_naive'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "04538a018d4fbc67b946e359a0972dfd1e3e9332370256f2cc0a49625fb6641b", "warmup_time": -1}, "timeseries.DatetimeIndex.time_to_date": {"code": "class DatetimeIndex:\n    def time_to_date(self, index_type):\n        self.index.date\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass DatetimeIndex:\n    def setup(self, index_type):\n        N = 100000\n        dtidxes = {\n            \"dst\": date_range(\n                start=\"10/29/2000 1:00:00\", end=\"10/29/2000 1:59:59\", freq=\"s\"\n            ),\n            \"repeated\": date_range(start=\"2000\", periods=N / 10, freq=\"s\").repeat(10),\n            \"tz_aware\": date_range(start=\"2000\", periods=N, freq=\"s\", tz=\"US/Eastern\"),\n            \"tz_local\": date_range(\n                start=\"2000\", periods=N, freq=\"s\", tz=dateutil.tz.tzlocal()\n            ),\n            \"tz_naive\": date_range(start=\"2000\", periods=N, freq=\"s\"),\n        }\n        self.index = dtidxes[index_type]", "min_run_count": 2, "name": "timeseries.DatetimeIndex.time_to_date", "number": 0, "param_names": ["index_type"], "params": [["'dst'", "'repeated'", "'tz_aware'", "'tz_local'", "'tz_naive'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "7cca1d94795aacc571156ae0c3d26b501e230d2f713b179b76d821653ee5f493", "warmup_time": -1}, "timeseries.DatetimeIndex.time_to_pydatetime": {"code": "class DatetimeIndex:\n    def time_to_pydatetime(self, index_type):\n        self.index.to_pydatetime()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass DatetimeIndex:\n    def setup(self, index_type):\n        N = 100000\n        dtidxes = {\n            \"dst\": date_range(\n                start=\"10/29/2000 1:00:00\", end=\"10/29/2000 1:59:59\", freq=\"s\"\n            ),\n            \"repeated\": date_range(start=\"2000\", periods=N / 10, freq=\"s\").repeat(10),\n            \"tz_aware\": date_range(start=\"2000\", periods=N, freq=\"s\", tz=\"US/Eastern\"),\n            \"tz_local\": date_range(\n                start=\"2000\", periods=N, freq=\"s\", tz=dateutil.tz.tzlocal()\n            ),\n            \"tz_naive\": date_range(start=\"2000\", periods=N, freq=\"s\"),\n        }\n        self.index = dtidxes[index_type]", "min_run_count": 2, "name": "timeseries.DatetimeIndex.time_to_pydatetime", "number": 0, "param_names": ["index_type"], "params": [["'dst'", "'repeated'", "'tz_aware'", "'tz_local'", "'tz_naive'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "25f86a8e691206b1750a4c195cf9e99e4af49ef72f5d9a07a2b04287ea59c63d", "warmup_time": -1}, "timeseries.DatetimeIndex.time_to_time": {"code": "class DatetimeIndex:\n    def time_to_time(self, index_type):\n        self.index.time\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass DatetimeIndex:\n    def setup(self, index_type):\n        N = 100000\n        dtidxes = {\n            \"dst\": date_range(\n                start=\"10/29/2000 1:00:00\", end=\"10/29/2000 1:59:59\", freq=\"s\"\n            ),\n            \"repeated\": date_range(start=\"2000\", periods=N / 10, freq=\"s\").repeat(10),\n            \"tz_aware\": date_range(start=\"2000\", periods=N, freq=\"s\", tz=\"US/Eastern\"),\n            \"tz_local\": date_range(\n                start=\"2000\", periods=N, freq=\"s\", tz=dateutil.tz.tzlocal()\n            ),\n            \"tz_naive\": date_range(start=\"2000\", periods=N, freq=\"s\"),\n        }\n        self.index = dtidxes[index_type]", "min_run_count": 2, "name": "timeseries.DatetimeIndex.time_to_time", "number": 0, "param_names": ["index_type"], "params": [["'dst'", "'repeated'", "'tz_aware'", "'tz_local'", "'tz_naive'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "c77993d64cbff2bdeafb8ca4dfb4bdec09a2617ceafc56a56b8e7b3d7dcf61bf", "warmup_time": -1}, "timeseries.DatetimeIndex.time_unique": {"code": "class DatetimeIndex:\n    def time_unique(self, index_type):\n        self.index.unique()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass DatetimeIndex:\n    def setup(self, index_type):\n        N = 100000\n        dtidxes = {\n            \"dst\": date_range(\n                start=\"10/29/2000 1:00:00\", end=\"10/29/2000 1:59:59\", freq=\"s\"\n            ),\n            \"repeated\": date_range(start=\"2000\", periods=N / 10, freq=\"s\").repeat(10),\n            \"tz_aware\": date_range(start=\"2000\", periods=N, freq=\"s\", tz=\"US/Eastern\"),\n            \"tz_local\": date_range(\n                start=\"2000\", periods=N, freq=\"s\", tz=dateutil.tz.tzlocal()\n            ),\n            \"tz_naive\": date_range(start=\"2000\", periods=N, freq=\"s\"),\n        }\n        self.index = dtidxes[index_type]", "min_run_count": 2, "name": "timeseries.DatetimeIndex.time_unique", "number": 0, "param_names": ["index_type"], "params": [["'dst'", "'repeated'", "'tz_aware'", "'tz_local'", "'tz_naive'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "68362ad5b9b82f0e257361845561c05470456d74a5f4587034a740262e7d4a3e", "warmup_time": -1}, "timeseries.InferFreq.time_infer_freq": {"code": "class InferFreq:\n    def time_infer_freq(self, freq):\n        infer_freq(self.idx)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass InferFreq:\n    def setup(self, freq):\n        if freq is None:\n            self.idx = date_range(start=\"1/1/1700\", freq=\"D\", periods=10000)\n            self.idx._data._freq = None\n        else:\n            self.idx = date_range(start=\"1/1/1700\", freq=freq, periods=10000)", "min_run_count": 2, "name": "timeseries.InferFreq.time_infer_freq", "number": 0, "param_names": ["freq"], "params": [["None", "'D'", "'B'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "52f02044de50a1a68041e7526ab41b12d85500472c7652ce485fa54cfe87ecc0", "warmup_time": -1}, "timeseries.Iteration.time_iter": {"code": "class Iteration:\n    def time_iter(self, time_index):\n        for _ in self.idx:\n            pass\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Iteration:\n    def setup(self, time_index):\n        N = 10**6\n        if time_index is timedelta_range:\n            self.idx = time_index(start=0, freq=\"min\", periods=N)\n        else:\n            self.idx = time_index(start=\"20140101\", freq=\"min\", periods=N)\n        self.exit = 10000", "min_run_count": 2, "name": "timeseries.Iteration.time_iter", "number": 0, "param_names": ["time_index"], "params": [["<function date_range>", "<function period_range>", "<function timedelta_range>"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "7462a5f79cb42d4bd08d938457631a39d3b1fe203fef2eaca6dd612ccf0956a7", "warmup_time": -1}, "timeseries.Iteration.time_iter_preexit": {"code": "class Iteration:\n    def time_iter_preexit(self, time_index):\n        for i, _ in enumerate(self.idx):\n            if i > self.exit:\n                break\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Iteration:\n    def setup(self, time_index):\n        N = 10**6\n        if time_index is timedelta_range:\n            self.idx = time_index(start=0, freq=\"min\", periods=N)\n        else:\n            self.idx = time_index(start=\"20140101\", freq=\"min\", periods=N)\n        self.exit = 10000", "min_run_count": 2, "name": "timeseries.Iteration.time_iter_preexit", "number": 0, "param_names": ["time_index"], "params": [["<function date_range>", "<function period_range>", "<function timedelta_range>"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "8c6848d29bdf8fb903dbbb06fcb0a6ef5405d6f4d2d02679fb20236f69ff6070", "warmup_time": -1}, "timeseries.Lookup.time_lookup_and_cleanup": {"code": "class Lookup:\n    def time_lookup_and_cleanup(self):\n        self.ts[self.lookup_val]\n        self.ts.index._cleanup()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Lookup:\n    def setup(self):\n        N = 1500000\n        rng = date_range(start=\"1/1/2000\", periods=N, freq=\"s\")\n        self.ts = Series(1, index=rng)\n        self.lookup_val = rng[N // 2]", "min_run_count": 2, "name": "timeseries.Lookup.time_lookup_and_cleanup", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "622243e3fbc3f77c3a07df1366425577e34f93696a149766f75e2f67ebbdfbfe", "warmup_time": -1}, "timeseries.ResampleDataFrame.time_method": {"code": "class ResampleDataFrame:\n    def time_method(self, method):\n        self.resample()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ResampleDataFrame:\n    def setup(self, method):\n        rng = date_range(start=\"20130101\", periods=100000, freq=\"50ms\")\n        df = DataFrame(np.random.randn(100000, 2), index=rng)\n        self.resample = getattr(df.resample(\"1s\"), method)", "min_run_count": 2, "name": "timeseries.ResampleDataFrame.time_method", "number": 0, "param_names": ["method"], "params": [["'max'", "'mean'", "'min'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "a4fb6ef3ce886b50c0e792fa873de3cd9aee12fb92d9f2952dd99045ea9ca6d4", "warmup_time": -1}, "timeseries.ResampleDatetetime64.time_resample": {"code": "class ResampleDatetetime64:\n    def time_resample(self):\n        self.dt_ts.resample(\"1S\").last()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ResampleDatetetime64:\n    def setup(self):\n        rng3 = date_range(\n            start=\"2000-01-01 00:00:00\", end=\"2000-01-01 10:00:00\", freq=\"555000us\"\n        )\n        self.dt_ts = Series(5, rng3, dtype=\"datetime64[ns]\")", "min_run_count": 2, "name": "timeseries.ResampleDatetetime64.time_resample", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "6a3fd308277c5b95b5efe2bf748adf2aa3aded1362509af843635dea6f66a2a1", "warmup_time": -1}, "timeseries.ResampleSeries.time_resample": {"code": "class ResampleSeries:\n    def time_resample(self, index, freq, method):\n        self.resample()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ResampleSeries:\n    def setup(self, index, freq, method):\n        indexes = {\n            \"period\": period_range(start=\"1/1/2000\", end=\"1/1/2001\", freq=\"min\"),\n            \"datetime\": date_range(start=\"1/1/2000\", end=\"1/1/2001\", freq=\"min\"),\n        }\n        idx = indexes[index]\n        ts = Series(np.random.randn(len(idx)), index=idx)\n        self.resample = getattr(ts.resample(freq), method)", "min_run_count": 2, "name": "timeseries.ResampleSeries.time_resample", "number": 0, "param_names": ["index", "freq", "method"], "params": [["'period'", "'datetime'"], ["'5min'", "'1D'"], ["'mean'", "'ohlc'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "55b0e708ae03f83acfe58adc721a2552d94d0f4c55f29b01731e881a672a4338", "warmup_time": -1}, "timeseries.ResetIndex.time_reset_datetimeindex": {"code": "class ResetIndex:\n    def time_reset_datetimeindex(self, tz):\n        self.df.reset_index()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ResetIndex:\n    def setup(self, tz):\n        idx = date_range(start=\"1/1/2000\", periods=1000, freq=\"h\", tz=tz)\n        self.df = DataFrame(np.random.randn(1000, 2), index=idx)", "min_run_count": 2, "name": "timeseries.ResetIndex.time_reset_datetimeindex", "number": 0, "param_names": ["t"], "params": [["None", "'US/Eastern'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "69f268ece46afbbdef1c2696b72b004a1ea89cb77eef5125c1ef70576c922b24", "warmup_time": -1}, "timeseries.SortIndex.time_get_slice": {"code": "class SortIndex:\n    def time_get_slice(self, monotonic):\n        self.s[:10000]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass SortIndex:\n    def setup(self, monotonic):\n        N = 10**5\n        idx = date_range(start=\"1/1/2000\", periods=N, freq=\"s\")\n        self.s = Series(np.random.randn(N), index=idx)\n        if not monotonic:\n            self.s = self.s.sample(frac=1)", "min_run_count": 2, "name": "timeseries.SortIndex.time_get_slice", "number": 0, "param_names": ["monotonic"], "params": [["True", "False"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "0a9e9e75d9711805af9e2bd23525b886c146db147bda183e7c62c68212a7d2af", "warmup_time": -1}, "timeseries.SortIndex.time_sort_index": {"code": "class SortIndex:\n    def time_sort_index(self, monotonic):\n        self.s.sort_index()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass SortIndex:\n    def setup(self, monotonic):\n        N = 10**5\n        idx = date_range(start=\"1/1/2000\", periods=N, freq=\"s\")\n        self.s = Series(np.random.randn(N), index=idx)\n        if not monotonic:\n            self.s = self.s.sample(frac=1)", "min_run_count": 2, "name": "timeseries.SortIndex.time_sort_index", "number": 0, "param_names": ["monotonic"], "params": [["True", "False"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "4e3d97e97d12382b09d20e93cc00244951e5d85c15eb06dd5e57dc55c553db37", "warmup_time": -1}, "timeseries.TimeDatetimeConverter.time_convert": {"code": "class TimeDatetimeConverter:\n    def time_convert(self):\n        DatetimeConverter.convert(self.rng, None, None)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass TimeDatetimeConverter:\n    def setup(self):\n        N = 100000\n        self.rng = date_range(start=\"1/1/2000\", periods=N, freq=\"min\")", "min_run_count": 2, "name": "timeseries.TimeDatetimeConverter.time_convert", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "79f58665e747b6d28bf6b6a355cb6518597a5b4f0bb838b47ca93e0e6e7d19b7", "warmup_time": -1}, "timeseries.TzLocalize.time_infer_dst": {"code": "class TzLocalize:\n    def time_infer_dst(self, tz):\n        self.index.tz_localize(tz, ambiguous=\"infer\")\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass TzLocalize:\n    def setup(self, tz):\n        dst_rng = date_range(\n            start=\"10/29/2000 1:00:00\", end=\"10/29/2000 1:59:59\", freq=\"s\"\n        )\n        self.index = date_range(start=\"10/29/2000\", end=\"10/29/2000 00:59:59\", freq=\"s\")\n        self.index = self.index.append(dst_rng)\n        self.index = self.index.append(dst_rng)\n        self.index = self.index.append(\n            date_range(start=\"10/29/2000 2:00:00\", end=\"10/29/2000 3:00:00\", freq=\"s\")\n        )", "min_run_count": 2, "name": "timeseries.TzLocalize.time_infer_dst", "number": 0, "param_names": ["t"], "params": [["None", "'US/Eastern'", "'UTC'", "tzutc()"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "ed09ad3f4f73b8252ef5fb6874b8019d0077dae5d4ef1828a52519d880aef55b", "warmup_time": -1}, "tslibs.fields.TimeGetDateField.time_get_date_field": {"code": "class TimeGetDateField:\n    def time_get_date_field(self, size, field):\n        get_date_field(self.i8data, field)\n\n    def setup(self, size, field):\n        arr = np.random.randint(0, 10, size=size, dtype=\"i8\")\n        self.i8data = arr", "min_run_count": 2, "name": "tslibs.fields.TimeGetDateField.time_get_date_field", "number": 0, "param_names": ["size", "field"], "params": [["0", "1", "100", "10000", "1000000"], ["'Y'", "'M'", "'D'", "'h'", "'m'", "'s'", "'us'", "'ns'", "'doy'", "'dow'", "'woy'", "'q'", "'dim'", "'is_leap_year'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "032d05ffd3cddf25687d384f76ac9d5aeacf2e7476a8aeb4baf025aa07fc3887", "warmup_time": -1}, "tslibs.fields.TimeGetStartEndField.time_get_start_end_field": {"code": "class TimeGetStartEndField:\n    def time_get_start_end_field(self, size, side, period, freqstr, month_kw):\n        get_start_end_field(self.i8data, self.attrname, freqstr, month_kw=month_kw)\n\n    def setup(self, size, side, period, freqstr, month_kw):\n        arr = np.random.randint(0, 10, size=size, dtype=\"i8\")\n        self.i8data = arr\n    \n        self.attrname = f\"is_{period}_{side}\"", "min_run_count": 2, "name": "tslibs.fields.TimeGetStartEndField.time_get_start_end_field", "number": 0, "param_names": ["size", "side", "period", "freqstr", "month_kw"], "params": [["0", "1", "100", "10000", "1000000"], ["'start'", "'end'"], ["'month'", "'quarter'", "'year'"], ["'B'", "None", "'QS'"], ["12", "3", "5"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "3457501ae50d04017ceec6b67dce5e99aa99af7ededd796eddbd0c87b01b8d9a", "warmup_time": -1}, "tslibs.fields.TimeGetTimedeltaField.time_get_timedelta_field": {"code": "class TimeGetTimedeltaField:\n    def time_get_timedelta_field(self, size, field):\n        get_timedelta_field(self.i8data, field)\n\n    def setup(self, size, field):\n        arr = np.random.randint(0, 10, size=size, dtype=\"i8\")\n        self.i8data = arr", "min_run_count": 2, "name": "tslibs.fields.TimeGetTimedeltaField.time_get_timedelta_field", "number": 0, "param_names": ["size", "field"], "params": [["0", "1", "100", "10000", "1000000"], ["'seconds'", "'microseconds'", "'nanoseconds'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "83971f7c0e7b0651fbe80cda16bb176f840b200191f86e1207d2de1d30d4a4de", "warmup_time": -1}, "tslibs.normalize.Normalize.time_is_date_array_normalized": {"code": "class Normalize:\n    def time_is_date_array_normalized(self, size, tz):\n        # TODO: cases with different levels of short-circuiting\n        # 10 i.e. NPY_FR_ns\n        is_date_array_normalized(self.i8data, tz, 10)\n\n    def setup(self, size, tz):\n        # use an array that will have is_date_array_normalized give True,\n        #  so we do not short-circuit early.\n        dti = pd.date_range(\"2016-01-01\", periods=10, tz=tz).repeat(size // 10)\n        self.i8data = dti.asi8\n    \n        if size == 10**6 and tz is tzlocal_obj:\n            # tzlocal is cumbersomely slow, so skip to keep runtime in check\n            raise NotImplementedError", "min_run_count": 2, "name": "tslibs.normalize.Normalize.time_is_date_array_normalized", "number": 0, "param_names": ["size", "tz"], "params": [["0", "1", "100", "10000", "1000000"], ["None", "datetime.timezone.utc", "datetime.timezone(datetime.timedelta(seconds=3600))", "<DstTzInfo 'US/Pacific' LMT-1 day, 16:07:00 STD>", "tzfile('/usr/share/zoneinfo/Asia/Tokyo')", "tzlocal()"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "8a0062a64c2f0559eaee437a8eeefbae5c75e27db5faf86541286085b875a6d2", "warmup_time": -1}, "tslibs.normalize.Normalize.time_normalize_i8_timestamps": {"code": "class Normalize:\n    def time_normalize_i8_timestamps(self, size, tz):\n        # 10 i.e. NPY_FR_ns\n        normalize_i8_timestamps(self.i8data, tz, 10)\n\n    def setup(self, size, tz):\n        # use an array that will have is_date_array_normalized give True,\n        #  so we do not short-circuit early.\n        dti = pd.date_range(\"2016-01-01\", periods=10, tz=tz).repeat(size // 10)\n        self.i8data = dti.asi8\n    \n        if size == 10**6 and tz is tzlocal_obj:\n            # tzlocal is cumbersomely slow, so skip to keep runtime in check\n            raise NotImplementedError", "min_run_count": 2, "name": "tslibs.normalize.Normalize.time_normalize_i8_timestamps", "number": 0, "param_names": ["size", "tz"], "params": [["0", "1", "100", "10000", "1000000"], ["None", "datetime.timezone.utc", "datetime.timezone(datetime.timedelta(seconds=3600))", "<DstTzInfo 'US/Pacific' LMT-1 day, 16:07:00 STD>", "tzfile('/usr/share/zoneinfo/Asia/Tokyo')", "tzlocal()"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "90e93c0bf30f84159194f95da549370de993eadd2b9924b3bc6dc1d0ac05889e", "warmup_time": -1}, "tslibs.offsets.OffestDatetimeArithmetic.time_add": {"code": "class OffestDatetimeArithmetic:\n    def time_add(self, offset):\n        self.date + offset\n\n    def setup(self, offset):\n        self.date = datetime(2011, 1, 1)\n        self.dt64 = np.datetime64(\"2011-01-01 09:00Z\")", "min_run_count": 2, "name": "tslibs.offsets.OffestDatetimeArithmetic.time_add", "number": 0, "param_names": ["offset"], "params": [["<Day>", "<BYearEnd: month=12>", "<BYearBegin: month=1>", "<BusinessQuarterEnd: startingMonth=3>", "<BusinessQuarterBegin: startingMonth=3>", "<BusinessMonthEnd>", "<BusinessMonthBegin>", "<CustomBusinessDay> (0)", "<CustomBusinessDay> (1)", "<CustomBusinessMonthBegin>", "<CustomBusinessMonthEnd> (0)", "<CustomBusinessMonthEnd> (1)", "<YearEnd: month=12>", "<YearBegin: month=1>", "<QuarterEnd: startingMonth=3>", "<QuarterBegin: startingMonth=3>", "<MonthEnd>", "<MonthBegin>", "<DateOffset: days=2, months=2>", "<BusinessDay>", "<SemiMonthEnd: day_of_month=15>", "<SemiMonthBegin: day_of_month=15>"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "bfb2ef7f8d94ebf443a43ab768a426b24846a01bcb9e60873cfca5ac9d84acbb", "warmup_time": -1}, "tslibs.offsets.OffestDatetimeArithmetic.time_add_10": {"code": "class OffestDatetimeArithmetic:\n    def time_add_10(self, offset):\n        self.date + (10 * offset)\n\n    def setup(self, offset):\n        self.date = datetime(2011, 1, 1)\n        self.dt64 = np.datetime64(\"2011-01-01 09:00Z\")", "min_run_count": 2, "name": "tslibs.offsets.OffestDatetimeArithmetic.time_add_10", "number": 0, "param_names": ["offset"], "params": [["<Day>", "<BYearEnd: month=12>", "<BYearBegin: month=1>", "<BusinessQuarterEnd: startingMonth=3>", "<BusinessQuarterBegin: startingMonth=3>", "<BusinessMonthEnd>", "<BusinessMonthBegin>", "<CustomBusinessDay> (0)", "<CustomBusinessDay> (1)", "<CustomBusinessMonthBegin>", "<CustomBusinessMonthEnd> (0)", "<CustomBusinessMonthEnd> (1)", "<YearEnd: month=12>", "<YearBegin: month=1>", "<QuarterEnd: startingMonth=3>", "<QuarterBegin: startingMonth=3>", "<MonthEnd>", "<MonthBegin>", "<DateOffset: days=2, months=2>", "<BusinessDay>", "<SemiMonthEnd: day_of_month=15>", "<SemiMonthBegin: day_of_month=15>"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "412f51bfc037b5b10f23387d475123e2c8ebd62a69e6a5692a07f7924f5149ac", "warmup_time": -1}, "tslibs.offsets.OffestDatetimeArithmetic.time_add_np_dt64": {"code": "class OffestDatetimeArithmetic:\n    def time_add_np_dt64(self, offset):\n        offset + self.dt64\n\n    def setup(self, offset):\n        self.date = datetime(2011, 1, 1)\n        self.dt64 = np.datetime64(\"2011-01-01 09:00Z\")", "min_run_count": 2, "name": "tslibs.offsets.OffestDatetimeArithmetic.time_add_np_dt64", "number": 0, "param_names": ["offset"], "params": [["<Day>", "<BYearEnd: month=12>", "<BYearBegin: month=1>", "<BusinessQuarterEnd: startingMonth=3>", "<BusinessQuarterBegin: startingMonth=3>", "<BusinessMonthEnd>", "<BusinessMonthBegin>", "<CustomBusinessDay> (0)", "<CustomBusinessDay> (1)", "<CustomBusinessMonthBegin>", "<CustomBusinessMonthEnd> (0)", "<CustomBusinessMonthEnd> (1)", "<YearEnd: month=12>", "<YearBegin: month=1>", "<QuarterEnd: startingMonth=3>", "<QuarterBegin: startingMonth=3>", "<MonthEnd>", "<MonthBegin>", "<DateOffset: days=2, months=2>", "<BusinessDay>", "<SemiMonthEnd: day_of_month=15>", "<SemiMonthBegin: day_of_month=15>"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "1165522291f90bef9f0aa75d6407828206ad6efc49a2b7023f47fdfd998851fa", "warmup_time": -1}, "tslibs.offsets.OffestDatetimeArithmetic.time_subtract": {"code": "class OffestDatetimeArithmetic:\n    def time_subtract(self, offset):\n        self.date - offset\n\n    def setup(self, offset):\n        self.date = datetime(2011, 1, 1)\n        self.dt64 = np.datetime64(\"2011-01-01 09:00Z\")", "min_run_count": 2, "name": "tslibs.offsets.OffestDatetimeArithmetic.time_subtract", "number": 0, "param_names": ["offset"], "params": [["<Day>", "<BYearEnd: month=12>", "<BYearBegin: month=1>", "<BusinessQuarterEnd: startingMonth=3>", "<BusinessQuarterBegin: startingMonth=3>", "<BusinessMonthEnd>", "<BusinessMonthBegin>", "<CustomBusinessDay> (0)", "<CustomBusinessDay> (1)", "<CustomBusinessMonthBegin>", "<CustomBusinessMonthEnd> (0)", "<CustomBusinessMonthEnd> (1)", "<YearEnd: month=12>", "<YearBegin: month=1>", "<QuarterEnd: startingMonth=3>", "<QuarterBegin: startingMonth=3>", "<MonthEnd>", "<MonthBegin>", "<DateOffset: days=2, months=2>", "<BusinessDay>", "<SemiMonthEnd: day_of_month=15>", "<SemiMonthBegin: day_of_month=15>"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "775bbe2574e947fdebb23ba6451a8510d68d5dfaf0e0813a6967a39209d770fc", "warmup_time": -1}, "tslibs.offsets.OffestDatetimeArithmetic.time_subtract_10": {"code": "class OffestDatetimeArithmetic:\n    def time_subtract_10(self, offset):\n        self.date - (10 * offset)\n\n    def setup(self, offset):\n        self.date = datetime(2011, 1, 1)\n        self.dt64 = np.datetime64(\"2011-01-01 09:00Z\")", "min_run_count": 2, "name": "tslibs.offsets.OffestDatetimeArithmetic.time_subtract_10", "number": 0, "param_names": ["offset"], "params": [["<Day>", "<BYearEnd: month=12>", "<BYearBegin: month=1>", "<BusinessQuarterEnd: startingMonth=3>", "<BusinessQuarterBegin: startingMonth=3>", "<BusinessMonthEnd>", "<BusinessMonthBegin>", "<CustomBusinessDay> (0)", "<CustomBusinessDay> (1)", "<CustomBusinessMonthBegin>", "<CustomBusinessMonthEnd> (0)", "<CustomBusinessMonthEnd> (1)", "<YearEnd: month=12>", "<YearBegin: month=1>", "<QuarterEnd: startingMonth=3>", "<QuarterBegin: startingMonth=3>", "<MonthEnd>", "<MonthBegin>", "<DateOffset: days=2, months=2>", "<BusinessDay>", "<SemiMonthEnd: day_of_month=15>", "<SemiMonthBegin: day_of_month=15>"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "f0a5bf6590a5f4e89c95b4b22ecc27ec52e4cb03e8255cef5009879bb71dbc69", "warmup_time": -1}, "tslibs.offsets.OnOffset.time_on_offset": {"code": "class OnOffset:\n    def time_on_offset(self, offset):\n        for date in self.dates:\n            offset.is_on_offset(date)\n\n    def setup(self, offset):\n        self.dates = [\n            datetime(2016, m, d)\n            for m in [10, 11, 12]\n            for d in [1, 2, 3, 28, 29, 30, 31]\n            if not (m == 11 and d == 31)\n        ]", "min_run_count": 2, "name": "tslibs.offsets.OnOffset.time_on_offset", "number": 0, "param_names": ["offset"], "params": [["<Day>", "<BYearEnd: month=12>", "<BYearBegin: month=1>", "<BusinessQuarterEnd: startingMonth=3>", "<BusinessQuarterBegin: startingMonth=3>", "<BusinessMonthEnd>", "<BusinessMonthBegin>", "<CustomBusinessDay> (0)", "<CustomBusinessDay> (1)", "<CustomBusinessMonthBegin>", "<CustomBusinessMonthEnd> (0)", "<CustomBusinessMonthEnd> (1)", "<YearEnd: month=12>", "<YearBegin: month=1>", "<QuarterEnd: startingMonth=3>", "<QuarterBegin: startingMonth=3>", "<MonthEnd>", "<MonthBegin>", "<DateOffset: days=2, months=2>", "<BusinessDay>", "<SemiMonthEnd: day_of_month=15>", "<SemiMonthBegin: day_of_month=15>"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "ae5cbac53a07afd70222f6a228bac6518d5df75e369f5e8450db66831ba8afa2", "warmup_time": -1}, "tslibs.period.PeriodConstructor.time_period_constructor": {"code": "class PeriodConstructor:\n    def time_period_constructor(self, freq, is_offset):\n        Period(\"2012-06-01\", freq=freq)\n\n    def setup(self, freq, is_offset):\n        if is_offset:\n            self.freq = to_offset(freq)\n        else:\n            self.freq = freq", "min_run_count": 2, "name": "tslibs.period.PeriodConstructor.time_period_constructor", "number": 0, "param_names": ["freq", "is_offset"], "params": [["'D'"], ["True", "False"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "d98fc24ec3bee7645af5de9f3e7af5e28f028c74e4785bda4ceb36f1d46a671d", "warmup_time": -1}, "tslibs.period.PeriodProperties.time_property": {"code": "class PeriodProperties:\n    def time_property(self, freq, attr):\n        getattr(self.per, attr)\n\n    def setup(self, freq, attr):\n        self.per = Period(\"2012-06-01\", freq=freq)", "min_run_count": 2, "name": "tslibs.period.PeriodProperties.time_property", "number": 0, "param_names": ["freq", "attr"], "params": [["'M'", "'min'"], ["'year'", "'month'", "'day'", "'hour'", "'minute'", "'second'", "'is_leap_year'", "'quarter'", "'qyear'", "'week'", "'daysinmonth'", "'dayofweek'", "'dayofyear'", "'start_time'", "'end_time'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "6c0fa44f9b9f197537446c79ae6f7ce95ab1d18e2e68b5acb2a96103c097f4c6", "warmup_time": -1}, "tslibs.period.PeriodUnaryMethods.time_asfreq": {"code": "class PeriodUnaryMethods:\n    def time_asfreq(self, freq):\n        self.per.asfreq(\"Y\")\n\n    def setup(self, freq):\n        self.per = Period(\"2012-06-01\", freq=freq)\n        if freq == \"M\":\n            self.default_fmt = \"%Y-%m\"\n        elif freq == \"min\":\n            self.default_fmt = \"%Y-%m-%d %H:%M\"", "min_run_count": 2, "name": "tslibs.period.PeriodUnaryMethods.time_asfreq", "number": 0, "param_names": ["freq"], "params": [["'M'", "'min'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "f7636fac37be75ac435c3f2c26c70c768d8d6ac6a2f2ec4147c53e28bd84e016", "warmup_time": -1}, "tslibs.period.PeriodUnaryMethods.time_now": {"code": "class PeriodUnaryMethods:\n    def time_now(self, freq):\n        self.per.now(freq)\n\n    def setup(self, freq):\n        self.per = Period(\"2012-06-01\", freq=freq)\n        if freq == \"M\":\n            self.default_fmt = \"%Y-%m\"\n        elif freq == \"min\":\n            self.default_fmt = \"%Y-%m-%d %H:%M\"", "min_run_count": 2, "name": "tslibs.period.PeriodUnaryMethods.time_now", "number": 0, "param_names": ["freq"], "params": [["'M'", "'min'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "ca497c2d273dcef636fd17b5cea2c596ea5d0e00aeb08e468f29db99e141026b", "warmup_time": -1}, "tslibs.period.PeriodUnaryMethods.time_repr": {"code": "class PeriodUnaryMethods:\n    def time_repr(self, freq):\n        repr(self.per)\n\n    def setup(self, freq):\n        self.per = Period(\"2012-06-01\", freq=freq)\n        if freq == \"M\":\n            self.default_fmt = \"%Y-%m\"\n        elif freq == \"min\":\n            self.default_fmt = \"%Y-%m-%d %H:%M\"", "min_run_count": 2, "name": "tslibs.period.PeriodUnaryMethods.time_repr", "number": 0, "param_names": ["freq"], "params": [["'M'", "'min'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "61db62d1d01fccdc5715ddf23d9ee8a51342bcf44f53ef99823dc6c5c23ccd95", "warmup_time": -1}, "tslibs.period.PeriodUnaryMethods.time_str": {"code": "class PeriodUnaryMethods:\n    def time_str(self, freq):\n        str(self.per)\n\n    def setup(self, freq):\n        self.per = Period(\"2012-06-01\", freq=freq)\n        if freq == \"M\":\n            self.default_fmt = \"%Y-%m\"\n        elif freq == \"min\":\n            self.default_fmt = \"%Y-%m-%d %H:%M\"", "min_run_count": 2, "name": "tslibs.period.PeriodUnaryMethods.time_str", "number": 0, "param_names": ["freq"], "params": [["'M'", "'min'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "8d0bcff5d02fdbae27d445ee63fb0f76ca46a7b3470124eb29f12fb7d2e8fe92", "warmup_time": -1}, "tslibs.period.PeriodUnaryMethods.time_strftime_custom": {"code": "class PeriodUnaryMethods:\n    def time_strftime_custom(self, freq):\n        self.per.strftime(\"%b. %d, %Y was a %A\")\n\n    def setup(self, freq):\n        self.per = Period(\"2012-06-01\", freq=freq)\n        if freq == \"M\":\n            self.default_fmt = \"%Y-%m\"\n        elif freq == \"min\":\n            self.default_fmt = \"%Y-%m-%d %H:%M\"", "min_run_count": 2, "name": "tslibs.period.PeriodUnaryMethods.time_strftime_custom", "number": 0, "param_names": ["freq"], "params": [["'M'", "'min'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "6c1e84f9e7ff08f4aa2690c6ffd1b1031f1c278b0054d9070885809726493eb5", "warmup_time": -1}, "tslibs.period.PeriodUnaryMethods.time_strftime_default": {"code": "class PeriodUnaryMethods:\n    def time_strftime_default(self, freq):\n        self.per.strftime(None)\n\n    def setup(self, freq):\n        self.per = Period(\"2012-06-01\", freq=freq)\n        if freq == \"M\":\n            self.default_fmt = \"%Y-%m\"\n        elif freq == \"min\":\n            self.default_fmt = \"%Y-%m-%d %H:%M\"", "min_run_count": 2, "name": "tslibs.period.PeriodUnaryMethods.time_strftime_default", "number": 0, "param_names": ["freq"], "params": [["'M'", "'min'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "a72f29d38796a94ca930f1af6cc6420afa2c6a70670e067a947c4b6a5240d08b", "warmup_time": -1}, "tslibs.period.PeriodUnaryMethods.time_strftime_default_explicit": {"code": "class PeriodUnaryMethods:\n    def time_strftime_default_explicit(self, freq):\n        self.per.strftime(self.default_fmt)\n\n    def setup(self, freq):\n        self.per = Period(\"2012-06-01\", freq=freq)\n        if freq == \"M\":\n            self.default_fmt = \"%Y-%m\"\n        elif freq == \"min\":\n            self.default_fmt = \"%Y-%m-%d %H:%M\"", "min_run_count": 2, "name": "tslibs.period.PeriodUnaryMethods.time_strftime_default_explicit", "number": 0, "param_names": ["freq"], "params": [["'M'", "'min'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "68d6b14934e4f96084f7276c1f9cb2ca0f3cec4f1132c94b1347849287da909f", "warmup_time": -1}, "tslibs.period.PeriodUnaryMethods.time_to_timestamp": {"code": "class PeriodUnaryMethods:\n    def time_to_timestamp(self, freq):\n        self.per.to_timestamp()\n\n    def setup(self, freq):\n        self.per = Period(\"2012-06-01\", freq=freq)\n        if freq == \"M\":\n            self.default_fmt = \"%Y-%m\"\n        elif freq == \"min\":\n            self.default_fmt = \"%Y-%m-%d %H:%M\"", "min_run_count": 2, "name": "tslibs.period.PeriodUnaryMethods.time_to_timestamp", "number": 0, "param_names": ["freq"], "params": [["'M'", "'min'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "622b732f215b2fcad912dbef729ddb69296d8e499bf7c12df2048003b7253980", "warmup_time": -1}, "tslibs.period.TimeDT64ArrToPeriodArr.time_dt64arr_to_periodarr": {"code": "class TimeDT64ArrToPeriodArr:\n    def time_dt64arr_to_periodarr(self, size, freq, tz):\n        dt64arr_to_periodarr(self.i8values, freq, tz)\n\n    def setup(self, size, freq, tz):\n        if size == 10**6 and tz is tzlocal_obj:\n            # tzlocal is cumbersomely slow, so skip to keep runtime in check\n            raise NotImplementedError\n    \n        # we pick 2**55 because smaller values end up returning\n        # -1 from npy_datetimestruct_to_datetime with NPY_FR_Y frequency\n        # this artificially slows down functions since -1 is also the\n        # error sentinel\n        arr = np.arange(2**55, 2**55 + 10, dtype=\"i8\").repeat(size // 10)\n        self.i8values = arr", "min_run_count": 2, "name": "tslibs.period.TimeDT64ArrToPeriodArr.time_dt64arr_to_periodarr", "number": 0, "param_names": ["size", "freq", "tz"], "params": [["0", "1", "100", "10000", "1000000"], ["1000", "1011", "2000", "2011", "3000", "4000", "4006", "5000", "6000", "7000", "8000", "9000", "10000", "11000", "12000"], ["None", "datetime.timezone.utc", "datetime.timezone(datetime.timedelta(seconds=3600))", "<DstTzInfo 'US/Pacific' LMT-1 day, 16:07:00 STD>", "tzfile('/usr/share/zoneinfo/Asia/Tokyo')", "tzlocal()"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "ae34f49e649e17a7c1cd4e91306253105adec71ba2612a4c890005782d8339c6", "warmup_time": -1}, "tslibs.period.TimePeriodArrToDT64Arr.time_periodarray_to_dt64arr": {"code": "class TimePeriodArrToDT64Arr:\n    def time_periodarray_to_dt64arr(self, size, freq):\n        periodarr_to_dt64arr(self.i8values, freq)\n\n    def setup(self, size, freq):\n        arr = np.arange(10, dtype=\"i8\").repeat(size // 10)\n        self.i8values = arr", "min_run_count": 2, "name": "tslibs.period.TimePeriodArrToDT64Arr.time_periodarray_to_dt64arr", "number": 0, "param_names": ["size", "freq"], "params": [["0", "1", "100", "10000", "1000000"], ["1000", "1011", "2000", "2011", "3000", "4000", "4006", "5000", "6000", "7000", "8000", "9000", "10000", "11000", "12000"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "780a003a3675ffce34b1163502be5f0eb10d3e9c8e10d3a8f2ce56387e643da2", "warmup_time": -1}, "tslibs.resolution.TimeResolution.time_get_resolution": {"code": "class TimeResolution:\n    def time_get_resolution(self, unit, size, tz):\n        get_resolution(self.i8data, tz)\n\n    def setup(self, unit, size, tz):\n        if size == 10**6 and tz is tzlocal_obj:\n            # tzlocal is cumbersomely slow, so skip to keep runtime in check\n            raise NotImplementedError\n    \n        arr = np.random.randint(0, 10, size=size, dtype=\"i8\")\n        arr = arr.view(f\"M8[{unit}]\").astype(\"M8[ns]\").view(\"i8\")\n        self.i8data = arr", "min_run_count": 2, "name": "tslibs.resolution.TimeResolution.time_get_resolution", "number": 0, "param_names": ["unit", "size", "tz"], "params": [["'D'", "'h'", "'m'", "'s'", "'us'", "'ns'"], ["0", "1", "100", "10000", "1000000"], ["None", "datetime.timezone.utc", "datetime.timezone(datetime.timedelta(seconds=3600))", "<DstTzInfo 'US/Pacific' LMT-1 day, 16:07:00 STD>", "tzfile('/usr/share/zoneinfo/Asia/Tokyo')", "tzlocal()"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "31259509175475d91c89e0d7ed2c1aeb7f584c1ef106af6b79c15883759acb97", "warmup_time": -1}, "tslibs.timedelta.TimedeltaConstructor.time_from_components": {"code": "class TimedeltaConstructor:\n    def time_from_components(self):\n        Timedelta(\n            days=1,\n            hours=2,\n            minutes=3,\n            seconds=4,\n            milliseconds=5,\n            microseconds=6,\n            nanoseconds=7,\n        )\n\n    def setup(self):\n        self.nptimedelta64 = np.timedelta64(3600)\n        self.dttimedelta = datetime.timedelta(seconds=3600)\n        self.td = Timedelta(3600, unit=\"s\")", "min_run_count": 2, "name": "tslibs.timedelta.TimedeltaConstructor.time_from_components", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "976de79734124e410aadd9f6fdb589658515fb75c3456c6c5003df04e31495c8", "warmup_time": -1}, "tslibs.timedelta.TimedeltaConstructor.time_from_datetime_timedelta": {"code": "class TimedeltaConstructor:\n    def time_from_datetime_timedelta(self):\n        Timedelta(self.dttimedelta)\n\n    def setup(self):\n        self.nptimedelta64 = np.timedelta64(3600)\n        self.dttimedelta = datetime.timedelta(seconds=3600)\n        self.td = Timedelta(3600, unit=\"s\")", "min_run_count": 2, "name": "tslibs.timedelta.TimedeltaConstructor.time_from_datetime_timedelta", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "3326b70bfe99c2a6a044540b5db8b882ec1b999993fff273029767c5717f11db", "warmup_time": -1}, "tslibs.timedelta.TimedeltaConstructor.time_from_int": {"code": "class TimedeltaConstructor:\n    def time_from_int(self):\n        Timedelta(123456789)\n\n    def setup(self):\n        self.nptimedelta64 = np.timedelta64(3600)\n        self.dttimedelta = datetime.timedelta(seconds=3600)\n        self.td = Timedelta(3600, unit=\"s\")", "min_run_count": 2, "name": "tslibs.timedelta.TimedeltaConstructor.time_from_int", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "ebc3b0e00ba7cba6a0d3e95134a6f1c56543605b5c4f0337fd76a0b846078e4d", "warmup_time": -1}, "tslibs.timedelta.TimedeltaConstructor.time_from_iso_format": {"code": "class TimedeltaConstructor:\n    def time_from_iso_format(self):\n        Timedelta(\"P4DT12H30M5S\")\n\n    def setup(self):\n        self.nptimedelta64 = np.timedelta64(3600)\n        self.dttimedelta = datetime.timedelta(seconds=3600)\n        self.td = Timedelta(3600, unit=\"s\")", "min_run_count": 2, "name": "tslibs.timedelta.TimedeltaConstructor.time_from_iso_format", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "a16446c3495768b14e84c7b2e947bdfbb1fb7558e73cd969d79d2fddd94f4961", "warmup_time": -1}, "tslibs.timedelta.TimedeltaConstructor.time_from_missing": {"code": "class TimedeltaConstructor:\n    def time_from_missing(self):\n        Timedelta(\"nat\")\n\n    def setup(self):\n        self.nptimedelta64 = np.timedelta64(3600)\n        self.dttimedelta = datetime.timedelta(seconds=3600)\n        self.td = Timedelta(3600, unit=\"s\")", "min_run_count": 2, "name": "tslibs.timedelta.TimedeltaConstructor.time_from_missing", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "ee87e86713ff7adca408473446c87ca651516e45b5a7c43b9142fead580aad84", "warmup_time": -1}, "tslibs.timedelta.TimedeltaConstructor.time_from_np_timedelta": {"code": "class TimedeltaConstructor:\n    def time_from_np_timedelta(self):\n        Timedelta(self.nptimedelta64)\n\n    def setup(self):\n        self.nptimedelta64 = np.timedelta64(3600)\n        self.dttimedelta = datetime.timedelta(seconds=3600)\n        self.td = Timedelta(3600, unit=\"s\")", "min_run_count": 2, "name": "tslibs.timedelta.TimedeltaConstructor.time_from_np_timedelta", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "a8fe79df54c66d13d34089a76ce37bd86f35e6da129e6de26dd0235934789c8c", "warmup_time": -1}, "tslibs.timedelta.TimedeltaConstructor.time_from_pd_timedelta": {"code": "class TimedeltaConstructor:\n    def time_from_pd_timedelta(self):\n        Timedelta(self.td)\n\n    def setup(self):\n        self.nptimedelta64 = np.timedelta64(3600)\n        self.dttimedelta = datetime.timedelta(seconds=3600)\n        self.td = Timedelta(3600, unit=\"s\")", "min_run_count": 2, "name": "tslibs.timedelta.TimedeltaConstructor.time_from_pd_timedelta", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "831bac3969b78367fedc8c945ad8667ac98baab3994380c2c72b8a30c1516c50", "warmup_time": -1}, "tslibs.timedelta.TimedeltaConstructor.time_from_string": {"code": "class TimedeltaConstructor:\n    def time_from_string(self):\n        Timedelta(\"1 days\")\n\n    def setup(self):\n        self.nptimedelta64 = np.timedelta64(3600)\n        self.dttimedelta = datetime.timedelta(seconds=3600)\n        self.td = Timedelta(3600, unit=\"s\")", "min_run_count": 2, "name": "tslibs.timedelta.TimedeltaConstructor.time_from_string", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "8da4af162b193652f720feee641b52568c67cc80c2eef6d146965283fb04bc8d", "warmup_time": -1}, "tslibs.timedelta.TimedeltaConstructor.time_from_unit": {"code": "class TimedeltaConstructor:\n    def time_from_unit(self):\n        Timedelta(1, unit=\"d\")\n\n    def setup(self):\n        self.nptimedelta64 = np.timedelta64(3600)\n        self.dttimedelta = datetime.timedelta(seconds=3600)\n        self.td = Timedelta(3600, unit=\"s\")", "min_run_count": 2, "name": "tslibs.timedelta.TimedeltaConstructor.time_from_unit", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "3ca91b1679620f3ab96408d006de6a0f62611d7e87e32ad104ff37e9f2538c2d", "warmup_time": -1}, "tslibs.timedelta.TimedeltaProperties.time_timedelta_days": {"code": "class TimedeltaProperties:\n    def time_timedelta_days(self, td):\n        td.days\n\n    def setup_cache(self):\n        td = Timedelta(days=365, minutes=35, seconds=25, milliseconds=35)\n        return td", "min_run_count": 2, "name": "tslibs.timedelta.TimedeltaProperties.time_timedelta_days", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "setup_cache_key": "tslibs.timedelta:55", "timeout": 60.0, "type": "time", "unit": "seconds", "version": "027721dc928a0aac947e4eb804535d4414cc57804449f21a50097455e1eb34cc", "warmup_time": -1}, "tslibs.timedelta.TimedeltaProperties.time_timedelta_microseconds": {"code": "class TimedeltaProperties:\n    def time_timedelta_microseconds(self, td):\n        td.microseconds\n\n    def setup_cache(self):\n        td = Timedelta(days=365, minutes=35, seconds=25, milliseconds=35)\n        return td", "min_run_count": 2, "name": "tslibs.timedelta.TimedeltaProperties.time_timedelta_microseconds", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "setup_cache_key": "tslibs.timedelta:55", "timeout": 60.0, "type": "time", "unit": "seconds", "version": "1c88f64d84fd4aa67383bda6396ed221e9b5a7fb816a7ff3ab0788a108b0c6c8", "warmup_time": -1}, "tslibs.timedelta.TimedeltaProperties.time_timedelta_nanoseconds": {"code": "class TimedeltaProperties:\n    def time_timedelta_nanoseconds(self, td):\n        td.nanoseconds\n\n    def setup_cache(self):\n        td = Timedelta(days=365, minutes=35, seconds=25, milliseconds=35)\n        return td", "min_run_count": 2, "name": "tslibs.timedelta.TimedeltaProperties.time_timedelta_nanoseconds", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "setup_cache_key": "tslibs.timedelta:55", "timeout": 60.0, "type": "time", "unit": "seconds", "version": "458eb6a15687e81995044a9cf3b9938fdf6724c379b347d74c6fcb101204008b", "warmup_time": -1}, "tslibs.timedelta.TimedeltaProperties.time_timedelta_seconds": {"code": "class TimedeltaProperties:\n    def time_timedelta_seconds(self, td):\n        td.seconds\n\n    def setup_cache(self):\n        td = Timedelta(days=365, minutes=35, seconds=25, milliseconds=35)\n        return td", "min_run_count": 2, "name": "tslibs.timedelta.TimedeltaProperties.time_timedelta_seconds", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "setup_cache_key": "tslibs.timedelta:55", "timeout": 60.0, "type": "time", "unit": "seconds", "version": "16d230d4bbe759fe887153a89399d0eb5eebbf999155cbe9ec2fdfef09305b0c", "warmup_time": -1}, "tslibs.timestamp.TimestampAcrossDst.time_replace_across_dst": {"code": "class TimestampAcrossDst:\n    def time_replace_across_dst(self):\n        self.ts2.replace(tzinfo=self.tzinfo)\n\n    def setup(self):\n        dt = datetime(2016, 3, 27, 1)\n        self.tzinfo = pytz.timezone(\"CET\").localize(dt, is_dst=False).tzinfo\n        self.ts2 = Timestamp(dt)", "min_run_count": 2, "name": "tslibs.timestamp.TimestampAcrossDst.time_replace_across_dst", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "4eeaaed494bd6b769b9c4efa262f1f90020591c46849984ea9edfa1d194b3a93", "warmup_time": -1}, "tslibs.timestamp.TimestampConstruction.time_from_datetime_aware": {"code": "class TimestampConstruction:\n    def time_from_datetime_aware(self):\n        Timestamp(self.dttime_aware)\n\n    def setup(self):\n        self.npdatetime64 = np.datetime64(\"2020-01-01 00:00:00\")\n        self.dttime_unaware = datetime(2020, 1, 1, 0, 0, 0)\n        self.dttime_aware = datetime(2020, 1, 1, 0, 0, 0, 0, pytz.UTC)\n        self.ts = Timestamp(\"2020-01-01 00:00:00\")", "min_run_count": 2, "name": "tslibs.timestamp.TimestampConstruction.time_from_datetime_aware", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "f14b2ba4c97e828628dc7b144124678a24812e53ec495a6f6f7f035d7e76716c", "warmup_time": -1}, "tslibs.timestamp.TimestampConstruction.time_from_datetime_unaware": {"code": "class TimestampConstruction:\n    def time_from_datetime_unaware(self):\n        Timestamp(self.dttime_unaware)\n\n    def setup(self):\n        self.npdatetime64 = np.datetime64(\"2020-01-01 00:00:00\")\n        self.dttime_unaware = datetime(2020, 1, 1, 0, 0, 0)\n        self.dttime_aware = datetime(2020, 1, 1, 0, 0, 0, 0, pytz.UTC)\n        self.ts = Timestamp(\"2020-01-01 00:00:00\")", "min_run_count": 2, "name": "tslibs.timestamp.TimestampConstruction.time_from_datetime_unaware", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "deda24fb69c398141fba8624b556966cc947474462ca0932939fad017e750985", "warmup_time": -1}, "tslibs.timestamp.TimestampConstruction.time_from_npdatetime64": {"code": "class TimestampConstruction:\n    def time_from_npdatetime64(self):\n        Timestamp(self.npdatetime64)\n\n    def setup(self):\n        self.npdatetime64 = np.datetime64(\"2020-01-01 00:00:00\")\n        self.dttime_unaware = datetime(2020, 1, 1, 0, 0, 0)\n        self.dttime_aware = datetime(2020, 1, 1, 0, 0, 0, 0, pytz.UTC)\n        self.ts = Timestamp(\"2020-01-01 00:00:00\")", "min_run_count": 2, "name": "tslibs.timestamp.TimestampConstruction.time_from_npdatetime64", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "e8deeb3f6693261772dcbea71d4d1e8cf5dc268d0ed889ebc2bd1159359fb79b", "warmup_time": -1}, "tslibs.timestamp.TimestampConstruction.time_from_pd_timestamp": {"code": "class TimestampConstruction:\n    def time_from_pd_timestamp(self):\n        Timestamp(self.ts)\n\n    def setup(self):\n        self.npdatetime64 = np.datetime64(\"2020-01-01 00:00:00\")\n        self.dttime_unaware = datetime(2020, 1, 1, 0, 0, 0)\n        self.dttime_aware = datetime(2020, 1, 1, 0, 0, 0, 0, pytz.UTC)\n        self.ts = Timestamp(\"2020-01-01 00:00:00\")", "min_run_count": 2, "name": "tslibs.timestamp.TimestampConstruction.time_from_pd_timestamp", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "aa508132de1d66508c66cf0477a1ef90bb0d697088197dbff1e6c1cf83db1d9b", "warmup_time": -1}, "tslibs.timestamp.TimestampConstruction.time_fromordinal": {"code": "class TimestampConstruction:\n    def time_fromordinal(self):\n        Timestamp.fromordinal(730120)\n\n    def setup(self):\n        self.npdatetime64 = np.datetime64(\"2020-01-01 00:00:00\")\n        self.dttime_unaware = datetime(2020, 1, 1, 0, 0, 0)\n        self.dttime_aware = datetime(2020, 1, 1, 0, 0, 0, 0, pytz.UTC)\n        self.ts = Timestamp(\"2020-01-01 00:00:00\")", "min_run_count": 2, "name": "tslibs.timestamp.TimestampConstruction.time_fromordinal", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "0d2c91d7caeb1e9f18e97e3b3e49b40506419ccf6a747aba57cec220392b56a6", "warmup_time": -1}, "tslibs.timestamp.TimestampConstruction.time_fromtimestamp": {"code": "class TimestampConstruction:\n    def time_fromtimestamp(self):\n        Timestamp.fromtimestamp(1515448538)\n\n    def setup(self):\n        self.npdatetime64 = np.datetime64(\"2020-01-01 00:00:00\")\n        self.dttime_unaware = datetime(2020, 1, 1, 0, 0, 0)\n        self.dttime_aware = datetime(2020, 1, 1, 0, 0, 0, 0, pytz.UTC)\n        self.ts = Timestamp(\"2020-01-01 00:00:00\")", "min_run_count": 2, "name": "tslibs.timestamp.TimestampConstruction.time_fromtimestamp", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "93f47b86a2ac5472723d056641e6cfea7e3fe451f6a8f80aaaa33d9639ffbcd6", "warmup_time": -1}, "tslibs.timestamp.TimestampConstruction.time_parse_dateutil": {"code": "class TimestampConstruction:\n    def time_parse_dateutil(self):\n        Timestamp(\"2017/08/25 08:16:14 AM\")\n\n    def setup(self):\n        self.npdatetime64 = np.datetime64(\"2020-01-01 00:00:00\")\n        self.dttime_unaware = datetime(2020, 1, 1, 0, 0, 0)\n        self.dttime_aware = datetime(2020, 1, 1, 0, 0, 0, 0, pytz.UTC)\n        self.ts = Timestamp(\"2020-01-01 00:00:00\")", "min_run_count": 2, "name": "tslibs.timestamp.TimestampConstruction.time_parse_dateutil", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "c0309203dabb15ebb9716def5049f52ea3e32116f035e7f28935eecb6eac953e", "warmup_time": -1}, "tslibs.timestamp.TimestampConstruction.time_parse_iso8601_no_tz": {"code": "class TimestampConstruction:\n    def time_parse_iso8601_no_tz(self):\n        Timestamp(\"2017-08-25 08:16:14\")\n\n    def setup(self):\n        self.npdatetime64 = np.datetime64(\"2020-01-01 00:00:00\")\n        self.dttime_unaware = datetime(2020, 1, 1, 0, 0, 0)\n        self.dttime_aware = datetime(2020, 1, 1, 0, 0, 0, 0, pytz.UTC)\n        self.ts = Timestamp(\"2020-01-01 00:00:00\")", "min_run_count": 2, "name": "tslibs.timestamp.TimestampConstruction.time_parse_iso8601_no_tz", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "edb87028a17ef2fe442cb82487dbdad5fc4264ab0c37256a5f0f9940a89ec02f", "warmup_time": -1}, "tslibs.timestamp.TimestampConstruction.time_parse_iso8601_tz": {"code": "class TimestampConstruction:\n    def time_parse_iso8601_tz(self):\n        Timestamp(\"2017-08-25 08:16:14-0500\")\n\n    def setup(self):\n        self.npdatetime64 = np.datetime64(\"2020-01-01 00:00:00\")\n        self.dttime_unaware = datetime(2020, 1, 1, 0, 0, 0)\n        self.dttime_aware = datetime(2020, 1, 1, 0, 0, 0, 0, pytz.UTC)\n        self.ts = Timestamp(\"2020-01-01 00:00:00\")", "min_run_count": 2, "name": "tslibs.timestamp.TimestampConstruction.time_parse_iso8601_tz", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "48fd2b6c0dfc61e556481168eb66875e3bdcabca2d9e2c6d79908f3b16e7a15d", "warmup_time": -1}, "tslibs.timestamp.TimestampConstruction.time_parse_now": {"code": "class TimestampConstruction:\n    def time_parse_now(self):\n        Timestamp(\"now\")\n\n    def setup(self):\n        self.npdatetime64 = np.datetime64(\"2020-01-01 00:00:00\")\n        self.dttime_unaware = datetime(2020, 1, 1, 0, 0, 0)\n        self.dttime_aware = datetime(2020, 1, 1, 0, 0, 0, 0, pytz.UTC)\n        self.ts = Timestamp(\"2020-01-01 00:00:00\")", "min_run_count": 2, "name": "tslibs.timestamp.TimestampConstruction.time_parse_now", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "4ae560aa20eee0beb52506ca024df933003e399825874b0aa280771feaef7ab9", "warmup_time": -1}, "tslibs.timestamp.TimestampConstruction.time_parse_today": {"code": "class TimestampConstruction:\n    def time_parse_today(self):\n        Timestamp(\"today\")\n\n    def setup(self):\n        self.npdatetime64 = np.datetime64(\"2020-01-01 00:00:00\")\n        self.dttime_unaware = datetime(2020, 1, 1, 0, 0, 0)\n        self.dttime_aware = datetime(2020, 1, 1, 0, 0, 0, 0, pytz.UTC)\n        self.ts = Timestamp(\"2020-01-01 00:00:00\")", "min_run_count": 2, "name": "tslibs.timestamp.TimestampConstruction.time_parse_today", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "92ca8839a0be3afb03e222c0647cc70fb3ed56ce204455637cfde1baeea43845", "warmup_time": -1}, "tslibs.timestamp.TimestampOps.time_ceil": {"code": "class TimestampOps:\n    def time_ceil(self, tz):\n        self.ts.ceil(\"5min\")\n\n    def setup(self, tz):\n        self.ts = Timestamp(\"2017-08-25 08:16:14\", tz=tz)", "min_run_count": 2, "name": "tslibs.timestamp.TimestampOps.time_ceil", "number": 0, "param_names": ["tz"], "params": [["None", "datetime.timezone.utc", "datetime.timezone(datetime.timedelta(seconds=3600))", "<DstTzInfo 'US/Pacific' LMT-1 day, 16:07:00 STD>", "tzfile('/usr/share/zoneinfo/Asia/Tokyo')", "tzlocal()"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "baf73e231e602f7995c8b34f3b99e8b6c695160889ca1f755f19fd2c8b6e776e", "warmup_time": -1}, "tslibs.timestamp.TimestampOps.time_floor": {"code": "class TimestampOps:\n    def time_floor(self, tz):\n        self.ts.floor(\"5min\")\n\n    def setup(self, tz):\n        self.ts = Timestamp(\"2017-08-25 08:16:14\", tz=tz)", "min_run_count": 2, "name": "tslibs.timestamp.TimestampOps.time_floor", "number": 0, "param_names": ["tz"], "params": [["None", "datetime.timezone.utc", "datetime.timezone(datetime.timedelta(seconds=3600))", "<DstTzInfo 'US/Pacific' LMT-1 day, 16:07:00 STD>", "tzfile('/usr/share/zoneinfo/Asia/Tokyo')", "tzlocal()"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "ad9343f6d07a8c951d0913deffcfa58ae1e8dd7f188610392b097ce3ca19e11b", "warmup_time": -1}, "tslibs.timestamp.TimestampOps.time_normalize": {"code": "class TimestampOps:\n    def time_normalize(self, tz):\n        self.ts.normalize()\n\n    def setup(self, tz):\n        self.ts = Timestamp(\"2017-08-25 08:16:14\", tz=tz)", "min_run_count": 2, "name": "tslibs.timestamp.TimestampOps.time_normalize", "number": 0, "param_names": ["tz"], "params": [["None", "datetime.timezone.utc", "datetime.timezone(datetime.timedelta(seconds=3600))", "<DstTzInfo 'US/Pacific' LMT-1 day, 16:07:00 STD>", "tzfile('/usr/share/zoneinfo/Asia/Tokyo')", "tzlocal()"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "f7688ade61af780f34bdb840481260073c8bfb88a7504a06758c91f033fb951d", "warmup_time": -1}, "tslibs.timestamp.TimestampOps.time_replace_None": {"code": "class TimestampOps:\n    def time_replace_None(self, tz):\n        self.ts.replace(tzinfo=None)\n\n    def setup(self, tz):\n        self.ts = Timestamp(\"2017-08-25 08:16:14\", tz=tz)", "min_run_count": 2, "name": "tslibs.timestamp.TimestampOps.time_replace_None", "number": 0, "param_names": ["tz"], "params": [["None", "datetime.timezone.utc", "datetime.timezone(datetime.timedelta(seconds=3600))", "<DstTzInfo 'US/Pacific' LMT-1 day, 16:07:00 STD>", "tzfile('/usr/share/zoneinfo/Asia/Tokyo')", "tzlocal()"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "395164d585e187bf1f2ecd1f965a26fe6f63a204fb26eb6daf8c2544e7895f5f", "warmup_time": -1}, "tslibs.timestamp.TimestampOps.time_replace_tz": {"code": "class TimestampOps:\n    def time_replace_tz(self, tz):\n        self.ts.replace(tzinfo=pytz.timezone(\"US/Eastern\"))\n\n    def setup(self, tz):\n        self.ts = Timestamp(\"2017-08-25 08:16:14\", tz=tz)", "min_run_count": 2, "name": "tslibs.timestamp.TimestampOps.time_replace_tz", "number": 0, "param_names": ["tz"], "params": [["None", "datetime.timezone.utc", "datetime.timezone(datetime.timedelta(seconds=3600))", "<DstTzInfo 'US/Pacific' LMT-1 day, 16:07:00 STD>", "tzfile('/usr/share/zoneinfo/Asia/Tokyo')", "tzlocal()"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "4364c2bc5207c0340c1149b8fb230b76c97f7646891613c57bd11cf528e78d77", "warmup_time": -1}, "tslibs.timestamp.TimestampOps.time_to_julian_date": {"code": "class TimestampOps:\n    def time_to_julian_date(self, tz):\n        self.ts.to_julian_date()\n\n    def setup(self, tz):\n        self.ts = Timestamp(\"2017-08-25 08:16:14\", tz=tz)", "min_run_count": 2, "name": "tslibs.timestamp.TimestampOps.time_to_julian_date", "number": 0, "param_names": ["tz"], "params": [["None", "datetime.timezone.utc", "datetime.timezone(datetime.timedelta(seconds=3600))", "<DstTzInfo 'US/Pacific' LMT-1 day, 16:07:00 STD>", "tzfile('/usr/share/zoneinfo/Asia/Tokyo')", "tzlocal()"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "b986ab53361d72e7f0d0ea59b3584f48d6d6fc4994e87be9157f503231f22e70", "warmup_time": -1}, "tslibs.timestamp.TimestampOps.time_to_pydatetime": {"code": "class TimestampOps:\n    def time_to_pydatetime(self, tz):\n        self.ts.to_pydatetime()\n\n    def setup(self, tz):\n        self.ts = Timestamp(\"2017-08-25 08:16:14\", tz=tz)", "min_run_count": 2, "name": "tslibs.timestamp.TimestampOps.time_to_pydatetime", "number": 0, "param_names": ["tz"], "params": [["None", "datetime.timezone.utc", "datetime.timezone(datetime.timedelta(seconds=3600))", "<DstTzInfo 'US/Pacific' LMT-1 day, 16:07:00 STD>", "tzfile('/usr/share/zoneinfo/Asia/Tokyo')", "tzlocal()"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "1db879395196c84d3fd8f358a23b86aaef86f45475d0f83716f8a546e489a627", "warmup_time": -1}, "tslibs.timestamp.TimestampOps.time_tz_convert": {"code": "class TimestampOps:\n    def time_tz_convert(self, tz):\n        if self.ts.tz is not None:\n            self.ts.tz_convert(tz)\n\n    def setup(self, tz):\n        self.ts = Timestamp(\"2017-08-25 08:16:14\", tz=tz)", "min_run_count": 2, "name": "tslibs.timestamp.TimestampOps.time_tz_convert", "number": 0, "param_names": ["tz"], "params": [["None", "datetime.timezone.utc", "datetime.timezone(datetime.timedelta(seconds=3600))", "<DstTzInfo 'US/Pacific' LMT-1 day, 16:07:00 STD>", "tzfile('/usr/share/zoneinfo/Asia/Tokyo')", "tzlocal()"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "43ec3d5f390c7c62a00c06c942395078df2cc729fd8f92a4b0276815f342896d", "warmup_time": -1}, "tslibs.timestamp.TimestampOps.time_tz_localize": {"code": "class TimestampOps:\n    def time_tz_localize(self, tz):\n        if self.ts.tz is None:\n            self.ts.tz_localize(tz)\n\n    def setup(self, tz):\n        self.ts = Timestamp(\"2017-08-25 08:16:14\", tz=tz)", "min_run_count": 2, "name": "tslibs.timestamp.TimestampOps.time_tz_localize", "number": 0, "param_names": ["tz"], "params": [["None", "datetime.timezone.utc", "datetime.timezone(datetime.timedelta(seconds=3600))", "<DstTzInfo 'US/Pacific' LMT-1 day, 16:07:00 STD>", "tzfile('/usr/share/zoneinfo/Asia/Tokyo')", "tzlocal()"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "0ed9c18cc2666c8a010ac46b26f73181d886d5bad76c5a2e012111741777d94c", "warmup_time": -1}, "tslibs.timestamp.TimestampProperties.time_dayofweek": {"code": "class TimestampProperties:\n    def time_dayofweek(self, tz):\n        self.ts.dayofweek\n\n    def setup(self, tz):\n        self.ts = Timestamp(\"2017-08-25 08:16:14\", tzinfo=tz)", "min_run_count": 2, "name": "tslibs.timestamp.TimestampProperties.time_dayofweek", "number": 0, "param_names": ["tz"], "params": [["None", "datetime.timezone.utc", "datetime.timezone(datetime.timedelta(seconds=3600))", "<DstTzInfo 'US/Pacific' LMT-1 day, 16:07:00 STD>", "tzfile('/usr/share/zoneinfo/Asia/Tokyo')", "tzlocal()"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "e29f2f9d5602cdd3653692a09582476ebfd93e83ef6498019842c6cf6b8ec80a", "warmup_time": -1}, "tslibs.timestamp.TimestampProperties.time_dayofyear": {"code": "class TimestampProperties:\n    def time_dayofyear(self, tz):\n        self.ts.dayofyear\n\n    def setup(self, tz):\n        self.ts = Timestamp(\"2017-08-25 08:16:14\", tzinfo=tz)", "min_run_count": 2, "name": "tslibs.timestamp.TimestampProperties.time_dayofyear", "number": 0, "param_names": ["tz"], "params": [["None", "datetime.timezone.utc", "datetime.timezone(datetime.timedelta(seconds=3600))", "<DstTzInfo 'US/Pacific' LMT-1 day, 16:07:00 STD>", "tzfile('/usr/share/zoneinfo/Asia/Tokyo')", "tzlocal()"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "ee2f40845ecc6394591ee911396fc80479a217eeabf14738f0a9b516b7709a70", "warmup_time": -1}, "tslibs.timestamp.TimestampProperties.time_days_in_month": {"code": "class TimestampProperties:\n    def time_days_in_month(self, tz):\n        self.ts.days_in_month\n\n    def setup(self, tz):\n        self.ts = Timestamp(\"2017-08-25 08:16:14\", tzinfo=tz)", "min_run_count": 2, "name": "tslibs.timestamp.TimestampProperties.time_days_in_month", "number": 0, "param_names": ["tz"], "params": [["None", "datetime.timezone.utc", "datetime.timezone(datetime.timedelta(seconds=3600))", "<DstTzInfo 'US/Pacific' LMT-1 day, 16:07:00 STD>", "tzfile('/usr/share/zoneinfo/Asia/Tokyo')", "tzlocal()"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "17752b2964de1c685127ffa838ee3c5e3b0e2a8a63461dff3cba393207ee472e", "warmup_time": -1}, "tslibs.timestamp.TimestampProperties.time_is_leap_year": {"code": "class TimestampProperties:\n    def time_is_leap_year(self, tz):\n        self.ts.is_leap_year\n\n    def setup(self, tz):\n        self.ts = Timestamp(\"2017-08-25 08:16:14\", tzinfo=tz)", "min_run_count": 2, "name": "tslibs.timestamp.TimestampProperties.time_is_leap_year", "number": 0, "param_names": ["tz"], "params": [["None", "datetime.timezone.utc", "datetime.timezone(datetime.timedelta(seconds=3600))", "<DstTzInfo 'US/Pacific' LMT-1 day, 16:07:00 STD>", "tzfile('/usr/share/zoneinfo/Asia/Tokyo')", "tzlocal()"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "e38d3b3704a4721bdc9af6bde865107faa0b6a19cceb1afc4db2be6abebcd5ef", "warmup_time": -1}, "tslibs.timestamp.TimestampProperties.time_is_month_end": {"code": "class TimestampProperties:\n    def time_is_month_end(self, tz):\n        self.ts.is_month_end\n\n    def setup(self, tz):\n        self.ts = Timestamp(\"2017-08-25 08:16:14\", tzinfo=tz)", "min_run_count": 2, "name": "tslibs.timestamp.TimestampProperties.time_is_month_end", "number": 0, "param_names": ["tz"], "params": [["None", "datetime.timezone.utc", "datetime.timezone(datetime.timedelta(seconds=3600))", "<DstTzInfo 'US/Pacific' LMT-1 day, 16:07:00 STD>", "tzfile('/usr/share/zoneinfo/Asia/Tokyo')", "tzlocal()"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "30c8d2e4ef76effa485342decbfb5349b1b96926523713ba746a85a9b4fc0819", "warmup_time": -1}, "tslibs.timestamp.TimestampProperties.time_is_month_start": {"code": "class TimestampProperties:\n    def time_is_month_start(self, tz):\n        self.ts.is_month_start\n\n    def setup(self, tz):\n        self.ts = Timestamp(\"2017-08-25 08:16:14\", tzinfo=tz)", "min_run_count": 2, "name": "tslibs.timestamp.TimestampProperties.time_is_month_start", "number": 0, "param_names": ["tz"], "params": [["None", "datetime.timezone.utc", "datetime.timezone(datetime.timedelta(seconds=3600))", "<DstTzInfo 'US/Pacific' LMT-1 day, 16:07:00 STD>", "tzfile('/usr/share/zoneinfo/Asia/Tokyo')", "tzlocal()"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "0c562c955215c96790f0242b5ba277157e69be2c739e9e95472aa6dd0416d299", "warmup_time": -1}, "tslibs.timestamp.TimestampProperties.time_is_quarter_end": {"code": "class TimestampProperties:\n    def time_is_quarter_end(self, tz):\n        self.ts.is_quarter_end\n\n    def setup(self, tz):\n        self.ts = Timestamp(\"2017-08-25 08:16:14\", tzinfo=tz)", "min_run_count": 2, "name": "tslibs.timestamp.TimestampProperties.time_is_quarter_end", "number": 0, "param_names": ["tz"], "params": [["None", "datetime.timezone.utc", "datetime.timezone(datetime.timedelta(seconds=3600))", "<DstTzInfo 'US/Pacific' LMT-1 day, 16:07:00 STD>", "tzfile('/usr/share/zoneinfo/Asia/Tokyo')", "tzlocal()"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "03313e5f8997f2a2420815b1bcafdef5fcda6334d1bd7ef80f122b59e7403ebe", "warmup_time": -1}, "tslibs.timestamp.TimestampProperties.time_is_quarter_start": {"code": "class TimestampProperties:\n    def time_is_quarter_start(self, tz):\n        self.ts.is_quarter_start\n\n    def setup(self, tz):\n        self.ts = Timestamp(\"2017-08-25 08:16:14\", tzinfo=tz)", "min_run_count": 2, "name": "tslibs.timestamp.TimestampProperties.time_is_quarter_start", "number": 0, "param_names": ["tz"], "params": [["None", "datetime.timezone.utc", "datetime.timezone(datetime.timedelta(seconds=3600))", "<DstTzInfo 'US/Pacific' LMT-1 day, 16:07:00 STD>", "tzfile('/usr/share/zoneinfo/Asia/Tokyo')", "tzlocal()"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "280e8892418c358b39acbba39be3acbd1c294f244e50db4c4ebb0c364fadad1d", "warmup_time": -1}, "tslibs.timestamp.TimestampProperties.time_is_year_end": {"code": "class TimestampProperties:\n    def time_is_year_end(self, tz):\n        self.ts.is_year_end\n\n    def setup(self, tz):\n        self.ts = Timestamp(\"2017-08-25 08:16:14\", tzinfo=tz)", "min_run_count": 2, "name": "tslibs.timestamp.TimestampProperties.time_is_year_end", "number": 0, "param_names": ["tz"], "params": [["None", "datetime.timezone.utc", "datetime.timezone(datetime.timedelta(seconds=3600))", "<DstTzInfo 'US/Pacific' LMT-1 day, 16:07:00 STD>", "tzfile('/usr/share/zoneinfo/Asia/Tokyo')", "tzlocal()"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "eb42a1cc4fe4177b738115226d04b4e2536031f7159767c9709bbb7556c64831", "warmup_time": -1}, "tslibs.timestamp.TimestampProperties.time_is_year_start": {"code": "class TimestampProperties:\n    def time_is_year_start(self, tz):\n        self.ts.is_year_start\n\n    def setup(self, tz):\n        self.ts = Timestamp(\"2017-08-25 08:16:14\", tzinfo=tz)", "min_run_count": 2, "name": "tslibs.timestamp.TimestampProperties.time_is_year_start", "number": 0, "param_names": ["tz"], "params": [["None", "datetime.timezone.utc", "datetime.timezone(datetime.timedelta(seconds=3600))", "<DstTzInfo 'US/Pacific' LMT-1 day, 16:07:00 STD>", "tzfile('/usr/share/zoneinfo/Asia/Tokyo')", "tzlocal()"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "5db3d7d1a89f3a35fe2a867c9046efedb39a0d8d9295b0880d0182689cb78a94", "warmup_time": -1}, "tslibs.timestamp.TimestampProperties.time_microsecond": {"code": "class TimestampProperties:\n    def time_microsecond(self, tz):\n        self.ts.microsecond\n\n    def setup(self, tz):\n        self.ts = Timestamp(\"2017-08-25 08:16:14\", tzinfo=tz)", "min_run_count": 2, "name": "tslibs.timestamp.TimestampProperties.time_microsecond", "number": 0, "param_names": ["tz"], "params": [["None", "datetime.timezone.utc", "datetime.timezone(datetime.timedelta(seconds=3600))", "<DstTzInfo 'US/Pacific' LMT-1 day, 16:07:00 STD>", "tzfile('/usr/share/zoneinfo/Asia/Tokyo')", "tzlocal()"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "657d803a947bd2ee87ff6e4f5fb74034cac717ea6c7234a95be94a19f3a9d926", "warmup_time": -1}, "tslibs.timestamp.TimestampProperties.time_month_name": {"code": "class TimestampProperties:\n    def time_month_name(self, tz):\n        self.ts.month_name()\n\n    def setup(self, tz):\n        self.ts = Timestamp(\"2017-08-25 08:16:14\", tzinfo=tz)", "min_run_count": 2, "name": "tslibs.timestamp.TimestampProperties.time_month_name", "number": 0, "param_names": ["tz"], "params": [["None", "datetime.timezone.utc", "datetime.timezone(datetime.timedelta(seconds=3600))", "<DstTzInfo 'US/Pacific' LMT-1 day, 16:07:00 STD>", "tzfile('/usr/share/zoneinfo/Asia/Tokyo')", "tzlocal()"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "601bf8fc4cd6762f48b99ed3cf7cc263fd851d65febdfa88735ffb31ed02e55d", "warmup_time": -1}, "tslibs.timestamp.TimestampProperties.time_quarter": {"code": "class TimestampProperties:\n    def time_quarter(self, tz):\n        self.ts.quarter\n\n    def setup(self, tz):\n        self.ts = Timestamp(\"2017-08-25 08:16:14\", tzinfo=tz)", "min_run_count": 2, "name": "tslibs.timestamp.TimestampProperties.time_quarter", "number": 0, "param_names": ["tz"], "params": [["None", "datetime.timezone.utc", "datetime.timezone(datetime.timedelta(seconds=3600))", "<DstTzInfo 'US/Pacific' LMT-1 day, 16:07:00 STD>", "tzfile('/usr/share/zoneinfo/Asia/Tokyo')", "tzlocal()"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "f822d240b6aab8f16f5cb4b0b15eb282a11540a85c12eb391cbf3adcd0dea0dd", "warmup_time": -1}, "tslibs.timestamp.TimestampProperties.time_tz": {"code": "class TimestampProperties:\n    def time_tz(self, tz):\n        self.ts.tz\n\n    def setup(self, tz):\n        self.ts = Timestamp(\"2017-08-25 08:16:14\", tzinfo=tz)", "min_run_count": 2, "name": "tslibs.timestamp.TimestampProperties.time_tz", "number": 0, "param_names": ["tz"], "params": [["None", "datetime.timezone.utc", "datetime.timezone(datetime.timedelta(seconds=3600))", "<DstTzInfo 'US/Pacific' LMT-1 day, 16:07:00 STD>", "tzfile('/usr/share/zoneinfo/Asia/Tokyo')", "tzlocal()"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "c7f2fb57fa5899b99e67eed5aed5efb470cddf82e1f2a8f1c6472ba40e5ea021", "warmup_time": -1}, "tslibs.timestamp.TimestampProperties.time_week": {"code": "class TimestampProperties:\n    def time_week(self, tz):\n        self.ts.week\n\n    def setup(self, tz):\n        self.ts = Timestamp(\"2017-08-25 08:16:14\", tzinfo=tz)", "min_run_count": 2, "name": "tslibs.timestamp.TimestampProperties.time_week", "number": 0, "param_names": ["tz"], "params": [["None", "datetime.timezone.utc", "datetime.timezone(datetime.timedelta(seconds=3600))", "<DstTzInfo 'US/Pacific' LMT-1 day, 16:07:00 STD>", "tzfile('/usr/share/zoneinfo/Asia/Tokyo')", "tzlocal()"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "cf7c5eef5480fb665a78f4c97bb9d21ac5d4a0141c4b107f915bcef238c4ceca", "warmup_time": -1}, "tslibs.timestamp.TimestampProperties.time_weekday_name": {"code": "class TimestampProperties:\n    def time_weekday_name(self, tz):\n        self.ts.day_name()\n\n    def setup(self, tz):\n        self.ts = Timestamp(\"2017-08-25 08:16:14\", tzinfo=tz)", "min_run_count": 2, "name": "tslibs.timestamp.TimestampProperties.time_weekday_name", "number": 0, "param_names": ["tz"], "params": [["None", "datetime.timezone.utc", "datetime.timezone(datetime.timedelta(seconds=3600))", "<DstTzInfo 'US/Pacific' LMT-1 day, 16:07:00 STD>", "tzfile('/usr/share/zoneinfo/Asia/Tokyo')", "tzlocal()"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "72364a32ce479df795dde42a507109f4f6ff8450ba4212e2469d7c7c09785e31", "warmup_time": -1}, "tslibs.tslib.TimeIntsToPydatetime.time_ints_to_pydatetime": {"code": "class TimeIntsToPydatetime:\n    def time_ints_to_pydatetime(self, box, size, tz):\n        ints_to_pydatetime(self.i8data, tz, box=box)\n\n    def setup(self, box, size, tz):\n        if box == \"date\" and tz is not None:\n            # tz is ignored, so avoid running redundant benchmarks\n            raise NotImplementedError  # skip benchmark\n        if size == 10**6 and tz is _tzs[-1]:\n            # This is cumbersomely-slow, so skip to trim runtime\n            raise NotImplementedError  # skip benchmark\n    \n        arr = np.random.randint(0, 10, size=size, dtype=\"i8\")\n        self.i8data = arr", "min_run_count": 2, "name": "tslibs.tslib.TimeIntsToPydatetime.time_ints_to_pydatetime", "number": 0, "param_names": ["box", "size", "tz"], "params": [["'time'", "'date'", "'datetime'", "'timestamp'"], ["0", "1", "100", "10000", "1000000"], ["None", "datetime.timezone.utc", "datetime.timezone(datetime.timedelta(seconds=3600))", "<DstTzInfo 'US/Pacific' LMT-1 day, 16:07:00 STD>", "tzfile('/usr/share/zoneinfo/Asia/Tokyo')", "tzlocal()"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "cc992ad9ce5601940faa38dd855be6b5df8a12c763443caf43906b262537aa5b", "warmup_time": -1}, "tslibs.tz_convert.TimeTZConvert.time_tz_convert_from_utc": {"code": "class TimeTZConvert:\n    def time_tz_convert_from_utc(self, size, tz):\n        # effectively:\n        #  dti = DatetimeIndex(self.i8data, tz=tz)\n        #  dti.tz_localize(None)\n        if old_sig:\n            tz_convert_from_utc(self.i8data, UTC, tz)\n        else:\n            tz_convert_from_utc(self.i8data, tz)\n\n    def setup(self, size, tz):\n        if size == 10**6 and tz is tzlocal_obj:\n            # tzlocal is cumbersomely slow, so skip to keep runtime in check\n            raise NotImplementedError\n    \n        arr = np.random.randint(0, 10, size=size, dtype=\"i8\")\n        self.i8data = arr", "min_run_count": 2, "name": "tslibs.tz_convert.TimeTZConvert.time_tz_convert_from_utc", "number": 0, "param_names": ["size", "tz"], "params": [["0", "1", "100", "10000", "1000000"], ["datetime.timezone.utc", "datetime.timezone(datetime.timedelta(seconds=3600))", "<DstTzInfo 'US/Pacific' LMT-1 day, 16:07:00 STD>", "tzfile('/usr/share/zoneinfo/Asia/Tokyo')", "tzlocal()"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "f36d5a11290654921892d1874be3d844db07e8633878642a38777b1b3439bfdd", "warmup_time": -1}, "tslibs.tz_convert.TimeTZConvert.time_tz_localize_to_utc": {"code": "class TimeTZConvert:\n    def time_tz_localize_to_utc(self, size, tz):\n        # effectively:\n        #  dti = DatetimeIndex(self.i8data)\n        #  dti.tz_localize(tz, ambiguous=\"NaT\", nonexistent=\"NaT\")\n        tz_localize_to_utc(self.i8data, tz, ambiguous=\"NaT\", nonexistent=\"NaT\")\n\n    def setup(self, size, tz):\n        if size == 10**6 and tz is tzlocal_obj:\n            # tzlocal is cumbersomely slow, so skip to keep runtime in check\n            raise NotImplementedError\n    \n        arr = np.random.randint(0, 10, size=size, dtype=\"i8\")\n        self.i8data = arr", "min_run_count": 2, "name": "tslibs.tz_convert.TimeTZConvert.time_tz_localize_to_utc", "number": 0, "param_names": ["size", "tz"], "params": [["0", "1", "100", "10000", "1000000"], ["datetime.timezone.utc", "datetime.timezone(datetime.timedelta(seconds=3600))", "<DstTzInfo 'US/Pacific' LMT-1 day, 16:07:00 STD>", "tzfile('/usr/share/zoneinfo/Asia/Tokyo')", "tzlocal()"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 60.0, "type": "time", "unit": "seconds", "version": "3bcf7f94df95f8ab82da03b954dc9d477df030167d67f9ead7d5549deb4025d2", "warmup_time": -1}}, "machines": {"asv-runner": {"arch": "x86_64", "cpu": "Intel(R) Core(TM) i7-4980HQ CPU @ 2.80GHz", "machine": "asv-runner", "os": "Linux 3.13.0-116-generic", "ram": "501692", "version": 1}}, "tags": {"0.3.0": 288, "debian/0.4.0-1": 874, "debian/0.4.1-1": 933, "debian/0.4.3-1": 1084, "debian/0.5.0+git7-gcf32be2-1": 1194, "debian/0.6.1-1": 1632, "debian/0.7.0-1": 2077, "debian/0.7.1+git1-ga2e86c2-1": 2247, "debian/0.7.3-1": 2555, "debian/0.8.0-1": 3418, "debian/0.8.0-2": 3494, "debian/0.8.0_b2+git68-g7240b87-1": 3344, "debian/0.8.0_b2-1": 3266, "debian/0.8.0_rc2+git26-g76c6351-1": 3393, "debian/0.8.1-1": 3557, "v0.10.0": 4816, "v0.10.0b1": 4723, "v0.10.1": 5022, "v0.11.0": 5863, "v0.11.0rc1": 5767, "v0.12.0": 6794, "v0.12.0rc1": 6664, "v0.13.0": 8139, "v0.13.0_ahl1": 8234, "v0.13.0_ahl2": 8327, "v0.13.0rc1": 7983, "v0.13.1": 8680, "v0.14.0": 9713, "v0.14.0rc1": 9617, "v0.14.1": 10140, "v0.15.0": 10853, "v0.15.0rc1": 10793, "v0.15.1": 10956, "v0.15.2": 11188, "v0.15.2pre": 11042, "v0.15pre": 10501, "v0.16.0": 11564, "v0.16.0rc1": 11528, "v0.16.1": 11906, "v0.16.2": 12077, "v0.16.3": 12091, "v0.17.0": 12889, "v0.17.0rc1": 12722, "v0.17.0rc2": 12860, "v0.17.1": 13158, "v0.18.0": 13626, "v0.18.0rc1": 13524, "v0.18.0rc2": 13615, "v0.18.1": 13836, "v0.19.0": 14330, "v0.19.0rc1": 14282, "v0.19.1": 14435, "v0.19.2": 14706, "v0.20.0": 15365, "v0.20.0rc1": 15300, "v0.20.0rc2": 15357, "v0.20.1": 15371, "v0.20.2": 15574, "v0.20.3": 15686, "v0.21.0": 16141, "v0.21.0.dev": 15372, "v0.21.0rc1": 16095, "v0.21.1": 16592, "v0.22.0": 16721, "v0.22.0.dev0": 16142, "v0.23.0": 17589, "v0.23.0.dev0": 16694, "v0.23.0rc1": 17530, "v0.23.0rc2": 17532, "v0.23.1": 17746, "v0.23.2": 17916, "v0.23.3": 17943, "v0.23.4": 18118, "v0.24.0": 19354, "v0.24.0.dev0": 17590, "v0.24.0rc1": 19274, "v0.24.1": 19436, "v0.24.2": 19671, "v0.25.0": 20423, "v0.25.0.dev0": 19355, "v0.25.0rc0": 20330, "v0.25.1": 20697, "v0.25.2": 21096, "v0.25.3": 21232, "v0.26.0.dev0": 20424, "v0.4.0": 862, "v0.4.1": 926, "v0.4.2": 981, "v0.4.3": 1029, "v0.5.0": 1185, "v0.6.0": 1342, "v0.6.1": 1440, "v0.7.0": 2072, "v0.7.0rc1": 1812, "v0.7.1": 2196, "v0.7.2": 2358, "v0.7.3": 2539, "v0.8.0": 3412, "v0.8.0b1": 3074, "v0.8.0b2": 3262, "v0.8.0rc1": 3360, "v0.8.0rc2": 3361, "v0.8.1": 3551, "v0.9.0": 4026, "v0.9.0rc1": 3912, "v0.9.0rc2": 3955, "v0.9.1": 4289, "v0.9.1rc1": 4249, "v1.0.0": 22538, "v1.0.0rc0": 22237, "v1.0.1": 22700, "v1.0.2": 23185, "v1.0.3": 23272, "v1.0.4": 24131, "v1.0.5": 24338, "v1.1.0": 24603, "v1.1.0.dev0": 22238, "v1.1.0rc0": 24593, "v1.1.1": 24770, "v1.1.2": 24989, "v1.1.3": 25339, "v1.1.4": 25725, "v1.1.5": 26258, "v1.2.0": 26509, "v1.2.0.dev0": 24604, "v1.2.0rc0": 26276, "v1.2.1": 26847, "v1.2.2": 27078, "v1.2.3": 27326, "v1.2.4": 27737, "v1.2.5": 28492, "v1.3.0": 28584, "v1.3.0.dev0": 26277, "v1.3.0rc0": 28350, "v1.3.0rc1": 28359, "v1.3.1": 28769, "v1.3.2": 28954, "v1.3.3": 29206, "v1.3.4": 29489, "v1.3.5": 29970, "v1.4.0": 30391, "v1.4.0.dev0": 28351, "v1.4.0rc0": 30182, "v1.4.1": 30639, "v1.4.2": 30963, "v1.4.3": 31386, "v1.4.4": 31829, "v1.5.0": 31988, "v1.5.0.dev0": 30183, "v1.5.0rc0": 31776, "v1.5.1": 32263, "v1.5.2": 32634, "v1.5.3": 33231, "v1.6.0.dev0": 31777, "v2.0.0": 34135, "v2.0.0.dev0": 31777, "v2.0.0rc0": 33598, "v2.0.0rc1": 33930, "v2.0.1": 34414, "v2.0.2": 34689, "v2.0.3": 34960, "v2.1.0": 35525, "v2.1.0.dev0": 33599, "v2.1.0rc0": 35327, "v2.1.1": 35703, "v2.1.2": 35952, "v2.1.3": 36062, "v2.1.4": 36374, "v2.2.0.dev0": 35328, "v2.2.0dev0": 35328}, "pages": [["", "Grid view", "Display as a agrid"], ["summarylist", "List view", "Display as a list"], ["regressions", "Show regressions", "Display information about recent regressions"]]}